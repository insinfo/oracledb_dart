traduza para dart mantendo somente as anssinatutas dos metodos sem implementação
# All imports
from . import __name__ as MODULE_NAME
from . import base_impl
from . import base_impl, constants, driver_mode, errors, thick_impl, thin_impl
from . import base_impl, thick_impl, thin_impl
from . import base_impl, utils
from . import builtin_hooks
from . import connection
from . import connection as connection_module
from . import constants
from . import driver_mode
from . import errors
from . import exceptions
from . import pool as pool_module
from . import utils
from .. import errors
from .aq import AsyncQueue, Queue, MessageProperties
from .base_impl cimport (
from .base_impl import (
from .base_impl import DB_TYPE_BFILE, DB_TYPE_BLOB
from .base_impl import DB_TYPE_BLOB, DB_TYPE_CLOB, DB_TYPE_NCLOB, DbType
from .base_impl import DbType
from .base_impl import DbType, DB_TYPE_OBJECT
from .base_impl import PipelineImpl, PipelineOpImpl, PipelineOpResultImpl
from .base_impl import get_array_type_code_uint32, SparseVectorImpl
from .buffer import OracleColumnBuffer
from .column import OracleColumn
from .connect_params import ConnectParams
from .connect_params import ConnectParams as ConnectParams
from .connection import (
from .constants import (
from .constructors import (
from .cursor import (
from .cursor import AsyncCursor, Cursor
from .dbobject import DbObject as DbObject, DbObjectType as DbObjectType
from .dbobject import DbObject, DbObjectType
from .dbobject import DbObjectType
from .dbobject import DbObjectType, DbObject
from .defaults import defaults
from .defaults import defaults as defaults
from .driver_mode import is_thin_mode
from .driver_mode import is_thin_mode as is_thin_mode
from .dsn import makedsn as makedsn
from .enums import (
from .enums import PipelineOpType
from .errors import _Error
from .errors import _Error as _Error
from .exceptions import (
from .fetch_info import FetchInfo
from .fetch_info import FetchInfo as FetchInfo
from .future import (
from .interchange.dataframe import (
from .interchange.nanoarrow_bridge cimport (
from .lob import (
from .lob import AsyncLOB, LOB
from .nanoarrow_bridge import (
from .pipeline import (
from .pipeline import Pipeline
from .pool import (
from .pool_params import PoolParams
from .pool_params import PoolParams as PoolParams
from .protocol import (
from .protocol import DataFrame
from .soda import SodaDatabase
from .sparse_vector import (
from .subscr import (
from .subscr import Subscription
from .thick_impl import (
from .utils import (
from .utils import register_password_type, register_protocol
from .var import Var
from .var import Var as Var
from .version import __version__ as __version__
from abc import (
from azure.appconfiguration import AzureAppConfigurationClient
from azure.core.exceptions import ResourceNotFoundError
from azure.identity import (
from azure.keyvault.secrets import SecretClient
from cpython cimport array
from cpython.pycapsule cimport PyCapsule_New
from cryptography.hazmat.primitives import serialization
from cryptography.hazmat.primitives.asymmetric import rsa
from libc.stdint cimport UINT8_MAX, UINT16_MAX, UINT32_MAX, UINT64_MAX
from libc.stdint cimport int8_t, int16_t, int32_t, int64_t
from libc.stdint cimport uint8_t, uint16_t, uint32_t, uint64_t
from libc.stdint cimport uintptr_t
from libc.stdlib cimport atoi, atof
from libc.string cimport memchr, memcpy, memset
from libc.string cimport memcpy
from libc.string cimport memcpy, memset
from libc.string cimport memcpy, strlen, strchr
from typing import (
from typing import Any, Callable, Type, Optional, Union
from typing import Any, Callable, Union
from typing import Any, Dict, Iterable, List, Optional, Sequence
from typing import Any, Dict, Iterable, Optional, Tuple
from typing import Any, Sequence, Union
from typing import Any, Union
from typing import Any, Union, Callable, Optional
from typing import Any, Union, List
from typing import Callable, Type, Union, Any, Optional
from typing import Callable, Union
from typing import Callable, Union, List
from typing import Tuple
from typing import Union
from typing import Union, Callable, Any, Optional
from urllib.parse import urlparse, parse_qs
import array
import asyncio
import base64
import collections
import copy
import datetime
import decimal
import enum
import functools
import getpass
import hashlib
import inspect
import json
import locale
import msal
import oci
import oracledb
import os
import random
import re
import secrets
import select
import socket
import ssl
import string
import subprocess
import sys
import threading
import time
import urllib.parse
import uuid
import warnings


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\aq.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2021, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# aq.py
#
# Contains the classes used for handling Advanced Queuing (AQ): Queue,
# DeqOptions, EnqOptions and MessageProperties.
# -----------------------------------------------------------------------------

import datetime

from . import connection as connection_module
from typing import Any, Union, List
from . import errors
from .dbobject import DbObject, DbObjectType


class BaseQueue:
    @classmethod
    def _from_impl(cls, connection, impl):
        queue = cls.__new__(cls)
        queue._connection = connection
        queue._deq_options = DeqOptions._from_impl(impl.deq_options_impl)
        queue._enq_options = EnqOptions._from_impl(impl.enq_options_impl)
        queue._payload_type = None
        queue._impl = impl
        return queue

    def _verify_message(self, message: "MessageProperties") -> None:
        """
        Internal method used for verifying a message.
        """
        if not isinstance(message, MessageProperties):
            raise TypeError("expecting MessageProperties object")
        if message.payload is None:
            errors._raise_err(errors.ERR_MESSAGE_HAS_NO_PAYLOAD)
        if isinstance(self.payload_type, DbObjectType):
            if (
                not isinstance(message.payload, DbObject)
                or message.payload.type != self.payload_type
            ):
                errors._raise_err(errors.ERR_PAYLOAD_CANNOT_BE_ENQUEUED)
        elif self.payload_type == "JSON":
            if not isinstance(message.payload, (dict, list)):
                errors._raise_err(errors.ERR_PAYLOAD_CANNOT_BE_ENQUEUED)
        else:
            if not isinstance(message.payload, (str, bytes)):
                errors._raise_err(errors.ERR_PAYLOAD_CANNOT_BE_ENQUEUED)
        if self.connection.thin:
            if message.recipients:
                errors._raise_not_supported("specifying AQ message recipients")

    @property
    def connection(self) -> "connection_module.Connection":
        """
        Returns the connection on which the queue was created.
        """
        return self._connection

    @property
    def deqoptions(self) -> "DeqOptions":
        """
        Returns the options that will be used when dequeuing messages from the
        queue.
        """
        return self._deq_options

    @property
    def deqOptions(self) -> "DeqOptions":
        """
        Deprecated: use deqoptions instead.
        """
        return self.deqoptions

    @property
    def enqoptions(self) -> "EnqOptions":
        """
        Returns the options that will be used when enqueuing messages into the
        queue.
        """
        return self._enq_options

    @property
    def enqOptions(self) -> "EnqOptions":
        """
        Deprecated: use enqoptions() instead.
        """
        return self.enqoptions

    @property
    def name(self) -> str:
        """
        Returns the name of the queue.
        """
        return self._impl.name

    @property
    def payload_type(self) -> Union[DbObjectType, None]:
        """
        Returns the object type for payloads that can be enqueued and dequeued.
        If using a raw queue, this returns the value None.
        """
        if self._payload_type is None:
            if self._impl.is_json:
                self._payload_type = "JSON"
            elif self._impl.payload_type is not None:
                self._payload_type = DbObjectType._from_impl(
                    self._impl.payload_type
                )
        return self._payload_type

    @property
    def payloadType(self) -> Union[DbObjectType, None]:
        """
        Deprecated: use payload_type instead.
        """
        return self.payload_type


class Queue(BaseQueue):

    def deqmany(self, max_num_messages: int) -> list:
        """
        Dequeues up to the specified number of messages from the queue and
        returns a list of these messages.
        """
        message_impls = self._impl.deq_many(max_num_messages)
        return [MessageProperties._from_impl(impl) for impl in message_impls]

    def deqMany(self, max_num_messages: int) -> List["MessageProperties"]:
        """
        Deprecated: use deqmany() instead.
        """
        return self.deqmany(max_num_messages)

    def deqone(self) -> Union["MessageProperties", None]:
        """
        Dequeues at most one message from the queue and returns it. If no
        message is dequeued, None is returned.
        """
        message_impl = self._impl.deq_one()
        if message_impl is not None:
            return MessageProperties._from_impl(message_impl)

    def deqOne(self) -> Union["MessageProperties", None]:
        """
        Deprecated: use deqone() instead.
        """
        return self.deqone()

    def enqmany(self, messages: list) -> None:
        """
        Enqueues multiple messages into the queue. The messages parameter must
        be a sequence containing message property objects which have all had
        their payload attribute set to a value that the queue supports.

        Warning: calling this function in parallel on different connections
        acquired from the same pool may fail due to Oracle bug 29928074. Ensure
        that this function is not run in parallel, use standalone connections
        or connections from different pools, or make multiple calls to
        enqone() instead. The function Queue.deqmany() call is not affected.
        """
        for message in messages:
            self._verify_message(message)
        message_impls = [m._impl for m in messages]
        self._impl.enq_many(message_impls)

    def enqMany(self, messages: list) -> None:
        """
        Deprecated: use enqmany() instead.
        """
        return self.enqmany(messages)

    def enqone(self, message: "MessageProperties") -> None:
        """
        Enqueues a single message into the queue. The message must be a message
        property object which has had its payload attribute set to a value that
        the queue supports.
        """
        self._verify_message(message)
        self._impl.enq_one(message._impl)

    def enqOne(self, message: "MessageProperties") -> None:
        """
        Deprecated: use enqone() instead.
        """
        return self.enqone(message)


class AsyncQueue(BaseQueue):

    async def deqmany(self, max_num_messages: int) -> list:
        """
        Dequeues up to the specified number of messages from the queue and
        returns a list of these messages.
        """
        message_impls = await self._impl.deq_many(max_num_messages)
        return [MessageProperties._from_impl(impl) for impl in message_impls]

    async def deqone(self) -> Union["MessageProperties", None]:
        """
        Dequeues at most one message from the queue and returns it. If no
        message is dequeued, None is returned.
        """
        message_impl = await self._impl.deq_one()
        if message_impl is not None:
            return MessageProperties._from_impl(message_impl)

    async def enqmany(self, messages: list) -> None:
        """
        Enqueues multiple messages into the queue. The messages parameter must
        be a sequence containing message property objects which have all had
        their payload attribute set to a value that the queue supports.

        Warning: calling this function in parallel on different connections
        acquired from the same pool may fail due to Oracle bug 29928074. Ensure
        that this function is not run in parallel, use standalone connections
        or connections from different pools, or make multiple calls to
        enqone() instead. The function Queue.deqmany() call is not affected.
        """
        for message in messages:
            self._verify_message(message)
        message_impls = [m._impl for m in messages]
        await self._impl.enq_many(message_impls)

    async def enqone(self, message: "MessageProperties") -> None:
        """
        Enqueues a single message into the queue. The message must be a message
        property object which has had its payload attribute set to a value that
        the queue supports.
        """
        self._verify_message(message)
        await self._impl.enq_one(message._impl)


class DeqOptions:
    @classmethod
    def _from_impl(cls, impl):
        options = cls.__new__(cls)
        options._impl = impl
        return options

    @property
    def condition(self) -> str:
        """
        Specifies a boolean expression similar to the where clause of a SQL
        query. The boolean expression can include conditions on message
        properties, user data properties and PL/SQL or SQL functions. The
        default is to have no condition specified.
        """
        return self._impl.get_condition()

    @condition.setter
    def condition(self, value: str) -> None:
        self._impl.set_condition(value)

    @property
    def consumername(self) -> str:
        """
        Specifies the name of the consumer. Only messages matching the consumer
        name will be accessed. If the queue is not set up for multiple
        consumers this attribute should not be set. The default is to have no
        consumer name specified.
        """
        return self._impl.get_consumer_name()

    @consumername.setter
    def consumername(self, value: str) -> None:
        self._impl.set_consumer_name(value)

    @property
    def correlation(self) -> str:
        """
        Specifies the correlation identifier of the message to be dequeued.
        Special pattern-matching characters, such as the percent sign (%) and
        the underscore (_), can be used. If multiple messages satisfy the
        pattern, the order of dequeuing is indeterminate. The default is to
        have no correlation specified.
        """
        return self._impl.get_correlation()

    @correlation.setter
    def correlation(self, value: str) -> None:
        self._impl.set_correlation(value)

    @property
    def deliverymode(self) -> None:
        """
        Specifies what types of messages should be dequeued. It should be one
        of the values MSG_PERSISTENT (default), MSG_BUFFERED or
        MSG_PERSISTENT_OR_BUFFERED.
        """
        raise AttributeError("deliverymode can only be written")

    @deliverymode.setter
    def deliverymode(self, value: int) -> None:
        self._impl.set_delivery_mode(value)

    @property
    def mode(self) -> int:
        """
        Specifies the locking behaviour associated with the dequeue operation.
        It should be one of the values DEQ_BROWSE, DEQ_LOCKED, DEQ_REMOVE
        (default), or DEQ_REMOVE_NODATA.
        """
        return self._impl.get_mode()

    @mode.setter
    def mode(self, value: int) -> None:
        self._impl.set_mode(value)

    @property
    def msgid(self) -> bytes:
        """
        Specifies the identifier of the message to be dequeued. The default is
        to have no message identifier specified.
        """
        return self._impl.get_message_id()

    @msgid.setter
    def msgid(self, value: bytes) -> None:
        self._impl.set_message_id(value)

    @property
    def navigation(self) -> int:
        """
        Specifies the position of the message that is retrieved. It should be
        one of the values DEQ_FIRST_MSG, DEQ_NEXT_MSG (default), or
        DEQ_NEXT_TRANSACTION.
        """
        return self._impl.get_navigation()

    @navigation.setter
    def navigation(self, value: int) -> None:
        self._impl.set_navigation(value)

    @property
    def transformation(self) -> str:
        """
        Specifies the name of the transformation that must be applied after the
        message is dequeued from the database but before it is returned to the
        calling application. The transformation must be created using
        dbms_transform. The default is to have no transformation specified.
        """
        return self._impl.get_transformation()

    @transformation.setter
    def transformation(self, value: str) -> None:
        self._impl.set_transformation(value)

    @property
    def visibility(self) -> int:
        """
        Specifies the transactional behavior of the dequeue request. It should
        be one of the values DEQ_ON_COMMIT (default) or DEQ_IMMEDIATE. This
        attribute is ignored when using the DEQ_BROWSE mode. Note the value of
        autocommit is always ignored.
        """
        return self._impl.get_visibility()

    @visibility.setter
    def visibility(self, value: int) -> None:
        self._impl.set_visibility(value)

    @property
    def wait(self) -> int:
        """
        Specifies the time to wait, in seconds, for a message matching the
        search criteria to become available for dequeuing. One of the values
        DEQ_NO_WAIT or DEQ_WAIT_FOREVER can also be used. The default is
        DEQ_WAIT_FOREVER.
        """
        return self._impl.get_wait()

    @wait.setter
    def wait(self, value: int) -> None:
        self._impl.set_wait(value)


class EnqOptions:
    @classmethod
    def _from_impl(cls, impl):
        options = cls.__new__(cls)
        options._impl = impl
        return options

    @property
    def deliverymode(self) -> int:
        """
        Specifies what type of messages should be enqueued. It should be one of
        the values MSG_PERSISTENT (default) or MSG_BUFFERED.
        """
        raise AttributeError("deliverymode can only be written")

    @deliverymode.setter
    def deliverymode(self, value: int) -> None:
        self._impl.set_delivery_mode(value)

    @property
    def transformation(self) -> str:
        """
        Specifies the name of the transformation that must be applied before
        the message is enqueued into the database. The transformation must be
        created using dbms_transform. The default is to have no transformation
        specified.
        """
        return self._impl.get_transformation()

    @transformation.setter
    def transformation(self, value: str) -> None:
        self._impl.set_transformation(value)

    @property
    def visibility(self) -> int:
        """
        Specifies the transactional behavior of the enqueue request. It should
        be one of the values ENQ_ON_COMMIT (default) or ENQ_IMMEDIATE. Note the
        value of autocommit is ignored.
        """
        return self._impl.get_visibility()

    @visibility.setter
    def visibility(self, value: int) -> None:
        self._impl.set_visibility(value)


class MessageProperties:
    _recipients = []

    @classmethod
    def _from_impl(cls, impl):
        props = cls.__new__(cls)
        props._impl = impl
        return props

    @property
    def attempts(self) -> int:
        """
        Specifies the number of attempts that have been made to dequeue the
        message.
        """
        return self._impl.get_num_attempts()

    @property
    def correlation(self) -> str:
        """
        Specifies the correlation used when the message was enqueued.
        """
        return self._impl.get_correlation()

    @correlation.setter
    def correlation(self, value: str) -> None:
        self._impl.set_correlation(value)

    @property
    def delay(self) -> int:
        """
        Specifies the number of seconds to delay an enqueued message. Any
        integer is acceptable but the constant MSG_NO_DELAY can also be used
        indicating that the message is available for immediate dequeuing.
        """
        return self._impl.get_delay()

    @delay.setter
    def delay(self, value: int) -> None:
        self._impl.set_delay(value)

    @property
    def deliverymode(self) -> int:
        """
        Specifies the type of message that was dequeued. It will be one of the
        values MSG_PERSISTENT or MSG_BUFFERED.
        """
        return self._impl.get_delivery_mode()

    @property
    def enqtime(self) -> datetime.datetime:
        """
        Specifies the time that the message was enqueued.
        """
        return self._impl.get_enq_time()

    @property
    def exceptionq(self) -> str:
        """
        Specifies the name of the queue to which the message is moved if it
        cannot be processed successfully. Messages are moved if the number of
        unsuccessful dequeue attempts has exceeded the maximum number of
        retries or if the message has expired. All messages in the exception
        queue are in the MSG_EXPIRED state. The default value is the name of
        the exception queue associated with the queue table.
        """
        return self._impl.get_exception_queue()

    @exceptionq.setter
    def exceptionq(self, value: str) -> None:
        self._impl.set_exception_queue(value)

    @property
    def expiration(self) -> int:
        """
        Specifies, in seconds, how long the message is available for dequeuing.
        This attribute is an offset from the delay attribute. Expiration
        processing requires the queue monitor to be running. Any integer is
        accepted but the constant MSG_NO_EXPIRATION can also be used indicating
        that the message never expires.
        """
        return self._impl.get_expiration()

    @expiration.setter
    def expiration(self, value: int) -> None:
        self._impl.set_expiration(value)

    @property
    def msgid(self) -> bytes:
        """
        Specifies the id of the message in the last queue that enqueued or
        dequeued this message. If the message has never been dequeued or
        enqueued, the value will be `None`.
        """
        return self._impl.get_message_id()

    @property
    def payload(self) -> Union[bytes, DbObject]:
        """
        Specifies the payload that will be enqueued or the payload that was
        dequeued when using a queue. When enqueuing, the value is checked to
        ensure that it conforms to the type expected by that queue. For RAW
        queues, the value can be a bytes object or a string. If the value is a
        string it will be converted to bytes in the encoding UTF-8.
        """
        return self._impl.payload

    @payload.setter
    def payload(self, value: Any) -> None:
        if isinstance(value, DbObject):
            self._impl.set_payload_object(value._impl)
        elif not isinstance(value, (str, bytes)):
            self._impl.set_payload_json(value)
        else:
            if isinstance(value, str):
                value_bytes = value.encode()
            elif isinstance(value, bytes):
                value_bytes = value
            self._impl.set_payload_bytes(value_bytes)
        self._impl.payload = value

    @property
    def priority(self) -> int:
        """
        Specifies the priority of the message. A smaller number indicates a
        higher priority. The priority can be any integer, including negative
        numbers. The default value is zero.
        """
        return self._impl.get_priority()

    @priority.setter
    def priority(self, value: int) -> None:
        self._impl.set_priority(value)

    @property
    def recipients(self) -> list:
        """
        A list of recipient names can be associated with a message at the time
        a message is enqueued. This allows a limited set of recipients to
        dequeue each message. The recipient list associated with the message
        overrides the queue subscriber list, if there is one. The recipient
        names need not be in the subscriber list but can be, if desired.

        To dequeue a message, the consumername attribute can be set to one of
        the recipient names. The original message recipient list is not
        available on dequeued messages. All recipients have to dequeue a
        message before it gets removed from the queue.

        Subscribing to a queue is like subscribing to a magazine: each
        subscriber can dequeue all the messages placed into a specific queue,
        just as each magazine subscriber has access to all its articles. Being
        a recipient, however, is like getting a letter: each recipient is a
        designated target of a particular message.
        """
        return self._recipients

    @recipients.setter
    def recipients(self, value: list) -> None:
        self._impl.set_recipients(value)
        self._recipients = value

    @property
    def state(self) -> int:
        """
        Specifies the state of the message at the time of the dequeue. It will
        be one of the values MSG_WAITING, MSG_READY, MSG_PROCESSED or
        MSG_EXPIRED.
        """
        return self._impl.get_state()


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\base_impl.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# base_impl.pyx
#
# Cython file for the base implementation that the thin and thick
# implementations use.
#------------------------------------------------------------------------------

# cython: language_level=3

cimport cython
cimport cpython
cimport cpython.datetime as cydatetime

from libc.stdint cimport int8_t, int16_t, int32_t, int64_t
from libc.stdint cimport uint8_t, uint16_t, uint32_t, uint64_t
from libc.stdint cimport UINT8_MAX, UINT16_MAX, UINT32_MAX, UINT64_MAX
from libc.stdlib cimport atoi, atof
from libc.string cimport memcpy
from cpython cimport array

from .interchange.nanoarrow_bridge cimport (
    NANOARROW_TIME_UNIT_SECOND,
    NANOARROW_TIME_UNIT_MILLI,
    NANOARROW_TIME_UNIT_MICRO,
    NANOARROW_TIME_UNIT_NANO,
    NANOARROW_TYPE_BOOL,
    NANOARROW_TYPE_BINARY,
    NANOARROW_TYPE_DECIMAL128,
    NANOARROW_TYPE_DOUBLE,
    NANOARROW_TYPE_FLOAT,
    NANOARROW_TYPE_INT64,
    NANOARROW_TYPE_LARGE_BINARY,
    NANOARROW_TYPE_LARGE_STRING,
    NANOARROW_TYPE_STRING,
    NANOARROW_TYPE_TIMESTAMP,
)

import array

import base64
import copy
import datetime
import decimal
import getpass
import inspect
import json
import os
import random
import secrets
import socket
import ssl
import string
import sys
import time
import warnings

cydatetime.import_datetime()

# Python types used by the driver
cdef type PY_TYPE_ASYNC_CURSOR
cdef type PY_TYPE_ASYNC_LOB
cdef type PY_TYPE_BOOL = bool
cdef type PY_TYPE_CURSOR
cdef object PY_TYPE_DATAFRAME
cdef type PY_TYPE_DATE = datetime.date
cdef type PY_TYPE_DATETIME = datetime.datetime
cdef type PY_TYPE_DECIMAL = decimal.Decimal
cdef type PY_TYPE_DB_OBJECT
cdef type PY_TYPE_DB_OBJECT_TYPE
cdef type PY_TYPE_JSON_ID
cdef type PY_TYPE_INTERVAL_YM
cdef type PY_TYPE_LOB
cdef type PY_TYPE_MESSAGE
cdef type PY_TYPE_MESSAGE_QUERY
cdef type PY_TYPE_MESSAGE_ROW
cdef type PY_TYPE_MESSAGE_TABLE
cdef type PY_TYPE_SPARSE_VECTOR
cdef type PY_TYPE_TIMEDELTA = datetime.timedelta
cdef type PY_TYPE_VAR
cdef type PY_TYPE_FETCHINFO

# enumerations used by the driver in connect parameters
cdef object ENUM_AUTH_MODE
cdef object ENUM_POOL_GET_MODE
cdef object ENUM_PURITY

cdef const char* DRIVER_NAME = "python-oracledb"
cdef const char* DRIVER_VERSION
cdef const char* DRIVER_INSTALLATION_URL = \
        "https://python-oracledb.readthedocs.io/en/" \
        "latest/user_guide/initialization.html"
cdef const char* ENCODING_UTF8 = "UTF-8"
cdef const char* ENCODING_UTF16 = "UTF-16BE"

# protocols registered with the library
REGISTERED_PROTOCOLS = {}

# password types registered with the library
REGISTERED_PASSWORD_TYPES = {}

# params hooks registered with the library
REGISTERED_PARAMS_HOOKS = []

include "impl/base/types.pyx"
include "impl/base/constants.pxi"
include "impl/base/decoders.pyx"
include "impl/base/encoders.pyx"
include "impl/base/metadata.pyx"
include "impl/base/utils.pyx"
include "impl/base/defaults.pyx"
include "impl/base/pipeline.pyx"
include "impl/base/converters.pyx"
include "impl/base/buffer.pyx"
include "impl/base/parsers.pyx"
include "impl/base/oson.pyx"
include "impl/base/vector.pyx"
include "impl/base/connect_params.pyx"
include "impl/base/pool_params.pyx"
include "impl/base/connection.pyx"
include "impl/base/pool.pyx"
include "impl/base/cursor.pyx"
include "impl/base/var.pyx"
include "impl/base/bind_var.pyx"
include "impl/base/dbobject.pyx"
include "impl/base/lob.pyx"
include "impl/base/soda.pyx"
include "impl/base/queue.pyx"
include "impl/base/subscr.pyx"


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\builtin_hooks.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2024, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# config_provider.py
#
# Contains the built-in config providers.
# -----------------------------------------------------------------------------

import base64
import json
import os
import urllib.parse
import warnings

from . import errors
from .utils import register_password_type, register_protocol


def config_provider_file_hook(protocol, protocol_arg, connect_params):
    """
    Hook for "config-file://". The protocol_arg is expected to be the name of a
    file containing one or more configurations. An optional "key" parameter is
    allowed which will choose a configuration from a set of configurations
    stored in the file.
    """
    pos = protocol_arg.find("?")
    if pos < 0:
        file_name = protocol_arg
        key = None
    else:
        file_name = protocol_arg[:pos]
        args = urllib.parse.parse_qs(protocol_arg[pos + 1 :])
        key = args.get("key")
        if key is not None:
            key = key[0]
    if not os.path.isabs(file_name):
        if connect_params.config_dir is None:
            errors._raise_err(errors.ERR_NO_CONFIG_DIR)
        file_name = os.path.join(connect_params.config_dir, file_name)
    config = json.load(open(file_name))
    if key is not None:
        config = config[key]
    connect_params.set_from_config(config)


register_protocol("config-file", config_provider_file_hook)


def ldap_hook(protocol, arg, params):
    """
    Default hook for LDAP which simply points the user to the documentation
    which explains how they can write their own hook for LDAP.
    This hook is needed for python-oracledb Thin mode,or when
    defaults.thick_mode_dsn_passthrough is False in Thick mode.
    """
    doc_url = (
        "https://python-oracledb.readthedocs.io/en/latest"
        "/user_guide/connection_handling.html#ldap-directory-naming"
    )
    message = (
        f"To use an LDAP URL in python-oracledb, "
        f"register an LDAP resolution function as shown in {doc_url}"
    )
    raise Exception(message)


register_protocol("ldap", ldap_hook)
register_protocol("ldaps", ldap_hook)


def password_type_base64_hook(args):
    """
    Hook for password type "base64". The key "value" in the supplied args is
    expected to be a base64-encoded string.
    """
    warnings.warn("base64 encoded passwords are insecure")
    return base64.b64decode(args["value"].encode()).decode()


register_password_type("base64", password_type_base64_hook)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\connection.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# connection.py
#
# Contains the Connection class and the factory method connect() used for
# establishing connections to the database.
#
# *** NOTICE *** This file is generated from a template and should not be
# modified directly. See build_from_template.py in the utils subdirectory for
# more information.
# -----------------------------------------------------------------------------

import collections
import functools
import ssl
from typing import Any, Callable, Type, Optional, Union

import oracledb

from . import __name__ as MODULE_NAME

from . import base_impl, constants, driver_mode, errors, thick_impl, thin_impl
from . import pool as pool_module
from .aq import AsyncQueue, Queue, MessageProperties
from .base_impl import DB_TYPE_BLOB, DB_TYPE_CLOB, DB_TYPE_NCLOB, DbType
from .connect_params import ConnectParams
from .cursor import AsyncCursor, Cursor
from .dbobject import DbObjectType, DbObject
from .lob import AsyncLOB, LOB
from .pipeline import Pipeline
from .soda import SodaDatabase
from .subscr import Subscription

# named tuple used for representing global transactions
Xid = collections.namedtuple(
    "Xid", ["format_id", "global_transaction_id", "branch_qualifier"]
)


class BaseConnection:
    __module__ = MODULE_NAME
    _impl = None

    def __init__(self):
        self._version = None

    def __repr__(self):
        typ = self.__class__
        cls_name = f"{typ.__module__}.{typ.__qualname__}"
        if self._impl is None:
            return f"<{cls_name} disconnected>"
        elif self.username is None:
            return f"<{cls_name} to externally identified user>"
        return f"<{cls_name} to {self.username}@{self.dsn}>"

    def _verify_connected(self) -> None:
        """
        Verifies that the connection is connected to the database. If it is
        not, an exception is raised.
        """
        if self._impl is None:
            errors._raise_err(errors.ERR_NOT_CONNECTED)

    def _verify_xid(self, xid: Xid) -> None:
        """
        Verifies that the supplied xid is of the correct type.
        """
        if not isinstance(xid, Xid):
            message = "expecting transaction id created with xid()"
            raise TypeError(message)

    @property
    def action(self) -> None:
        raise AttributeError("action is not readable")

    @action.setter
    def action(self, value: str) -> None:
        """
        Specifies the action column in the v$session table. It is a string
        attribute but the value None is also accepted and treated as an empty
        string.
        """
        self._verify_connected()
        self._impl.set_action(value)

    @property
    def autocommit(self) -> bool:
        """
        Specifies whether autocommit mode is on or off. When autocommit mode is
        on, all statements are committed as soon as they have completed
        executing successfully.
        """
        self._verify_connected()
        return self._impl.autocommit

    @autocommit.setter
    def autocommit(self, value: bool) -> None:
        self._verify_connected()
        self._impl.autocommit = value

    @property
    def call_timeout(self) -> int:
        """
        Specifies the amount of time (in milliseconds) that a single round-trip
        to the database may take before a timeout will occur. A value of 0
        means that no timeout will take place.
        """
        self._verify_connected()
        return self._impl.get_call_timeout()

    @call_timeout.setter
    def call_timeout(self, value: int) -> None:
        self._verify_connected()
        self._impl.set_call_timeout(value)

    def cancel(self) -> None:
        """
        Break a long-running transaction.
        """
        self._verify_connected()
        self._impl.cancel()

    @property
    def client_identifier(self) -> None:
        raise AttributeError("client_identifier is not readable")

    @client_identifier.setter
    def client_identifier(self, value: str) -> None:
        """
        Specifies the client_identifier column in the v$session table.
        """
        self._verify_connected()
        self._impl.set_client_identifier(value)

    @property
    def clientinfo(self) -> None:
        raise AttributeError("clientinfo is not readable")

    @clientinfo.setter
    def clientinfo(self, value: str) -> None:
        """
        Specifies the client_info column in the v$session table.
        """
        self._verify_connected()
        self._impl.set_client_info(value)

    @property
    def current_schema(self) -> str:
        """
        Specifies the current schema for the session. Setting this value is the
        same as executing the SQL statement "ALTER SESSION SET CURRENT_SCHEMA".
        The attribute is set (and verified) on the next call that does a round
        trip to the server. The value is placed before unqualified database
        objects in SQL statements you then execute.
        """
        self._verify_connected()
        return self._impl.get_current_schema()

    @current_schema.setter
    def current_schema(self, value: str) -> None:
        self._verify_connected()
        self._impl.set_current_schema(value)

    @property
    def dbop(self) -> None:
        raise AttributeError("dbop is not readable")

    @dbop.setter
    def dbop(self, value: str) -> None:
        """
        Specifies the database operation that is to be monitored. This can be
        viewed in the DBOP_NAME column of the V$SQL_MONITOR table.
        """
        self._verify_connected()
        self._impl.set_dbop(value)

    @property
    def dsn(self) -> str:
        """
        Specifies the connection string (TNS entry) of the database to which a
        connection has been established.
        """
        self._verify_connected()
        return self._impl.dsn

    @property
    def econtext_id(self) -> None:
        raise AttributeError("econtext_id is not readable")

    @econtext_id.setter
    def econtext_id(self, value: str) -> None:
        """
        Specifies the execution context id. This value can be found as ecid in
        the v$session table and econtext_id in the auditing tables. The maximum
        length is 64 bytes.
        """
        self._verify_connected()
        self._impl.set_econtext_id(value)

    @property
    def db_domain(self) -> str:
        """
        Specifies the name of the database domain.
        """
        self._verify_connected()
        return self._impl.get_db_domain()

    @property
    def db_name(self) -> str:
        """
        Specifies the name of the database.
        """
        self._verify_connected()
        return self._impl.get_db_name()

    @property
    def session_id(self) -> int:
        """
        Specifies the session identifier.
        """
        self._verify_connected()
        return self._impl.get_session_id()

    @property
    def serial_num(self) -> int:
        """
        Specifies the session serial number.
        """
        self._verify_connected()
        return self._impl.get_serial_num()

    @property
    def edition(self) -> str:
        """
        Specifies the session edition.
        """
        self._verify_connected()
        return self._impl.get_edition()

    @property
    def external_name(self) -> str:
        """
        Specifies the external name that is used by the connection when logging
        distributed transactions.
        """
        self._verify_connected()
        return self._impl.get_external_name()

    @external_name.setter
    def external_name(self, value: str) -> None:
        self._verify_connected()
        self._impl.set_external_name(value)

    @property
    def inputtypehandler(self) -> Callable:
        """
        Specifies a method called for each value that is bound to a statement
        executed on any cursor associated with this connection. The method
        signature is handler(cursor, value, arraysize) and the return value is
        expected to be a variable object or None in which case a default
        variable object will be created. If this attribute is None, the default
        behavior will take place for all values bound to statements.
        """
        self._verify_connected()
        return self._impl.inputtypehandler

    @inputtypehandler.setter
    def inputtypehandler(self, value: Callable) -> None:
        self._verify_connected()
        self._impl.inputtypehandler = value

    @property
    def instance_name(self) -> str:
        """
        Returns the instance name associated with the connection. This is the
        equivalent of the SQL expression:

        sys_context('userenv', 'instance_name')
        """
        self._verify_connected()
        return self._impl.get_instance_name()

    @property
    def internal_name(self) -> str:
        """
        Specifies the internal name that is used by the connection when logging
        distributed transactions.
        """
        self._verify_connected()
        return self._impl.get_internal_name()

    @internal_name.setter
    def internal_name(self, value: str) -> None:
        self._verify_connected()
        self._impl.set_internal_name(value)

    def is_healthy(self) -> bool:
        """
        Returns a boolean indicating the health status of a connection.

        Connections may become unusable in several cases, such as if the
        network socket is broken, if an Oracle error indicates the connection
        is unusable, or after receiving a planned down notification from the
        database.

        This function is best used before starting a new database request on an
        existing standalone connection. Pooled connections internally perform
        this check before returning a connection to the application.

        If this function returns False, the connection should be not be used by
        the application and a new connection should be established instead.

        This function performs a local check. To fully check a connection's
        health, use ping() which performs a round-trip to the database.
        """
        return self._impl is not None and self._impl.get_is_healthy()

    @property
    def ltxid(self) -> bytes:
        """
        Returns the logical transaction id for the connection. It is used
        within Oracle Transaction Guard as a means of ensuring that
        transactions are not duplicated. See the Oracle documentation and the
        provided sample for more information.
        """
        self._verify_connected()
        return self._impl.get_ltxid()

    @property
    def max_identifier_length(self) -> int:
        """
        Returns the maximum length of identifiers supported by the database to
        which this connection has been established.
        """
        self._verify_connected()
        return self._impl.get_max_identifier_length()

    @property
    def max_open_cursors(self) -> int:
        """
        Specifies the maximum number of cursors that the database can have open
        concurrently.
        """
        self._verify_connected()
        return self._impl.get_max_open_cursors()

    @property
    def module(self) -> None:
        raise AttributeError("module is not readable")

    @module.setter
    def module(self, value: str) -> None:
        """
        Specifies the module column in the v$session table. The maximum length
        for this string is 48 and if you exceed this length you will get
        ORA-24960.
        """
        self._verify_connected()
        self._impl.set_module(value)

    def msgproperties(
        self,
        payload: Optional[Union[bytes, str, DbObject]] = None,
        correlation: Optional[str] = None,
        delay: Optional[int] = None,
        exceptionq: Optional[str] = None,
        expiration: Optional[int] = None,
        priority: Optional[int] = None,
        recipients: Optional[list] = None,
    ) -> MessageProperties:
        """
        Create and return a message properties object. If the parameters are
        not None, they act as a shortcut for setting each of the equivalently
        named properties.
        """
        impl = self._impl.create_msg_props_impl()
        props = MessageProperties._from_impl(impl)
        if payload is not None:
            props.payload = payload
        if correlation is not None:
            props.correlation = correlation
        if delay is not None:
            props.delay = delay
        if exceptionq is not None:
            props.exceptionq = exceptionq
        if expiration is not None:
            props.expiration = expiration
        if priority is not None:
            props.priority = priority
        if recipients is not None:
            props.recipients = recipients
        return props

    def queue(
        self,
        name: str,
        payload_type: Optional[Union[DbObjectType, str]] = None,
        *,
        payloadType: Optional[DbObjectType] = None,
    ) -> Queue:
        """
        Creates and returns a queue which is used to enqueue and dequeue
        messages in Advanced Queueing (AQ).

        The name parameter is expected to be a string identifying the queue in
        which messages are to be enqueued or dequeued.

        The payload_type parameter, if specified, is expected to be an
        object type that identifies the type of payload the queue expects.
        If the string "JSON" is specified, JSON data is enqueued and dequeued.
        If not specified, RAW data is enqueued and dequeued.
        """
        self._verify_connected()
        payload_type_impl = None
        is_json = False
        if payloadType is not None:
            if payload_type is not None:
                errors._raise_err(
                    errors.ERR_DUPLICATED_PARAMETER,
                    deprecated_name="payloadType",
                    new_name="payload_type",
                )
            payload_type = payloadType
        if payload_type is not None:
            if payload_type == "JSON":
                is_json = True
            elif not isinstance(payload_type, DbObjectType):
                raise TypeError("expecting DbObjectType")
            else:
                payload_type_impl = payload_type._impl
        impl = self._impl.create_queue_impl()
        impl.initialize(self._impl, name, payload_type_impl, is_json)
        return self._create_queue(impl)

    @property
    def outputtypehandler(self) -> Callable:
        """
        Specifies a method called for each column that is going to be fetched
        from any cursor associated with this connection. The method signature
        is handler(cursor, name, defaultType, length, precision, scale) and the
        return value is expected to be a variable object or None in which case
        a default variable object will be created. If this attribute is None,
        the default behavior will take place for all columns fetched from
        cursors associated with this connection.
        """
        self._verify_connected()
        return self._impl.outputtypehandler

    @outputtypehandler.setter
    def outputtypehandler(self, value: Callable) -> None:
        self._verify_connected()
        self._impl.outputtypehandler = value

    @property
    def sdu(self) -> int:
        """
        Specifies the size of the Session Data Unit (SDU) that is being used by
        the connection.
        """
        self._verify_connected()
        return self._impl.get_sdu()

    @property
    def service_name(self) -> str:
        """
        Specifies the name of the service that was used to connect to the
        database.
        """
        self._verify_connected()
        return self._impl.get_service_name()

    @property
    def stmtcachesize(self) -> int:
        """
        Specifies the size of the statement cache. This value can make a
        significant difference in performance (up to 100x) if you have a small
        number of statements that you execute repeatedly.
        """
        self._verify_connected()
        return self._impl.get_stmt_cache_size()

    @stmtcachesize.setter
    def stmtcachesize(self, value: int) -> None:
        self._verify_connected()
        self._impl.set_stmt_cache_size(value)

    @property
    def thin(self) -> bool:
        """
        Returns a boolean indicating if the connection was established in
        python-oracledb's thin mode (True) or thick mode (False).
        """
        self._verify_connected()
        return self._impl.thin

    @property
    def transaction_in_progress(self) -> bool:
        """
        Specifies whether a transaction is currently in progress on the
        database using this connection.
        """
        self._verify_connected()
        return self._impl.get_transaction_in_progress()

    @property
    def username(self) -> str:
        """
        Returns the name of the user which established the connection to the
        database.
        """
        self._verify_connected()
        return self._impl.username

    @property
    def version(self) -> str:
        """
        Returns the version of the database to which the connection has been
        established.
        """
        if self._version is None:
            self._verify_connected()
            self._version = ".".join(str(c) for c in self._impl.server_version)
        return self._version

    @property
    def warning(self) -> errors._Error:
        """
        Returns any warning that was generated when the connection was created,
        or the value None if no warning was generated. The value will be
        cleared for pooled connections after they are returned to the pool.
        """
        self._verify_connected()
        return self._impl.warning

    def xid(
        self,
        format_id: int,
        global_transaction_id: Union[bytes, str],
        branch_qualifier: Union[bytes, str],
    ) -> Xid:
        """
        Returns a global transaction identifier that can be used with the TPC
        (two-phase commit) functions.

        The format_id parameter should be a non-negative 32-bit integer. The
        global_transaction_id and branch_qualifier parameters should be bytes
        (or a string which will be UTF-8 encoded to bytes) of no more than 64
        bytes.
        """
        return Xid(format_id, global_transaction_id, branch_qualifier)


class Connection(BaseConnection):
    __module__ = MODULE_NAME

    def __init__(
        self,
        dsn: Optional[str] = None,
        *,
        pool: Optional["pool_module.ConnectionPool"] = None,
        params: Optional[ConnectParams] = None,
        **kwargs,
    ) -> None:
        """
        Constructor for creating a connection to the database.

        The dsn parameter (data source name) can be a string in the format
        user/password@connect_string or can simply be the connect string (in
        which case authentication credentials such as the username and password
        need to be specified separately). See the documentation on connection
        strings for more information.

        The pool parameter is expected to be a pool object and the use of this
        parameter is the equivalent of calling acquire() on the pool.

        The params parameter is expected to be of type ConnectParams and
        contains connection parameters that will be used when establishing the
        connection. See the documentation on ConnectParams for more
        information. If this parameter is not specified, the additional keyword
        parameters will be used to create an instance of ConnectParams. If both
        the params parameter and additional keyword parameters are specified,
        the values in the keyword parameters have precedence. Note that if a
        dsn is also supplied, then in the python-oracledb Thin mode, the values
        of the parameters specified (if any) within the dsn will override the
        values passed as additional keyword parameters, which themselves
        override the values set in the params parameter object.
        """

        super().__init__()

        # determine if thin mode is being used
        with driver_mode.get_manager() as mode_mgr:
            thin = mode_mgr.thin

            # determine which connection parameters to use
            if params is None:
                params_impl = base_impl.ConnectParamsImpl()
            elif not isinstance(params, ConnectParams):
                errors._raise_err(errors.ERR_INVALID_CONNECT_PARAMS)
            else:
                params_impl = params._impl.copy()
            dsn = params_impl.process_args(dsn, kwargs, thin)

            # see if connection is being acquired from a pool
            if pool is None:
                pool_impl = None
            else:
                pool._verify_open()
                pool_impl = pool._impl

            # create thin or thick implementation object
            if thin:
                if (
                    params_impl.shardingkey is not None
                    or params_impl.supershardingkey is not None
                ):
                    errors._raise_err(
                        errors.ERR_FEATURE_NOT_SUPPORTED,
                        feature="sharding",
                        driver_type="thick",
                    )
                if pool is not None:
                    impl = pool_impl.acquire(params_impl)
                else:
                    impl = thin_impl.ThinConnImpl(dsn, params_impl)
                    impl.connect(params_impl)
            else:
                impl = thick_impl.ThickConnImpl(dsn, params_impl)
                impl.connect(params_impl, pool_impl)
            self._impl = impl

            # invoke callback, if applicable
            if (
                impl.invoke_session_callback
                and pool is not None
                and pool.session_callback is not None
                and callable(pool.session_callback)
            ):
                pool.session_callback(self, params_impl.tag)
                impl.invoke_session_callback = False

    def __del__(self):
        if self._impl is not None:
            self._impl.close(in_del=True)
            self._impl = None

    def __enter__(self):
        self._verify_connected()
        return self

    def __exit__(self, exc_type, exc_value, exc_tb):
        if self._impl is not None:
            self._impl.close(in_del=True)
            self._impl = None

    def _create_queue(self, impl):
        """
        Returns a queue object that the user can use to dequeue and enqueue
        messages.
        """
        return Queue._from_impl(self, impl)

    def _get_oci_attr(
        self, handle_type: int, attr_num: int, attr_type: int
    ) -> Any:
        """
        Returns the value of the specified OCI attribute from the internal
        handle. This is only supported in python-oracledb thick mode and should
        only be used as directed by Oracle.
        """
        self._verify_connected()
        return self._impl._get_oci_attr(handle_type, attr_num, attr_type)

    def _set_oci_attr(
        self, handle_type: int, attr_num: int, attr_type: int, value: Any
    ) -> None:
        """
        Sets the value of the specified OCI attribute on the internal handle.
        This is only supported in python-oracledb thick mode and should only
        be used as directed by Oracle.
        """
        self._verify_connected()
        self._impl._set_oci_attr(handle_type, attr_num, attr_type, value)

    def begin(
        self,
        format_id: int = -1,
        transaction_id: str = "",
        branch_id: str = "",
    ) -> None:
        """
        Deprecated. Use tpc_begin() instead.
        """
        if format_id != -1:
            self.tpc_begin(self.xid(format_id, transaction_id, branch_id))

    @property
    def callTimeout(self) -> int:
        """
        Deprecated. Use property call_timeout instead.
        """
        return self.call_timeout

    @callTimeout.setter
    def callTimeout(self, value: int) -> None:
        self._verify_connected()
        self._impl.set_call_timeout(value)

    def changepassword(self, old_password: str, new_password: str) -> None:
        """
        Changes the password for the user to which the connection is connected.
        """
        self._verify_connected()
        self._impl.change_password(old_password, new_password)

    def close(self) -> None:
        """
        Closes the connection and makes it unusable for further operations. An
        Error exception will be raised if any operation is attempted with this
        connection after this method completes successfully.
        """
        self._verify_connected()
        self._impl.close()
        self._impl = None

    def commit(self) -> None:
        """
        Commits any pending transactions to the database.
        """
        self._verify_connected()
        self._impl.commit()

    def createlob(
        self, lob_type: DbType, data: Optional[Union[str, bytes]] = None
    ) -> LOB:
        """
        Create and return a new temporary LOB of the specified type.
        """
        self._verify_connected()
        if lob_type not in (DB_TYPE_CLOB, DB_TYPE_NCLOB, DB_TYPE_BLOB):
            message = (
                "parameter should be one of oracledb.DB_TYPE_CLOB, "
                "oracledb.DB_TYPE_BLOB or oracledb.DB_TYPE_NCLOB"
            )
            raise TypeError(message)
        impl = self._impl.create_temp_lob_impl(lob_type)
        lob = LOB._from_impl(impl)
        if data:
            lob.write(data)
        return lob

    def cursor(self, scrollable: bool = False) -> Cursor:
        """
        Returns a cursor associated with the connection.
        """
        self._verify_connected()
        return Cursor(self, scrollable)

    def decode_oson(self, data):
        """
        Decode OSON-encoded bytes and return the object encoded in those bytes.
        """
        self._verify_connected()
        return self._impl.decode_oson(data)

    def encode_oson(self, value):
        """
        Return OSON-encoded bytes encoded from the supplied object.
        """
        self._verify_connected()
        return self._impl.encode_oson(value)

    def fetch_df_all(
        self,
        statement: str,
        parameters: Optional[Union[list, tuple, dict]] = None,
        arraysize: Optional[int] = None,
    ):
        """
        Fetch all data as OracleDataFrame.
        """
        cursor = self.cursor()
        cursor._impl.fetching_arrow = True
        if arraysize is not None:
            cursor.arraysize = arraysize
        cursor.prefetchrows = cursor.arraysize
        cursor.execute(statement, parameters)
        return cursor._impl.fetch_df_all(cursor)

    def fetch_df_batches(
        self,
        statement: str,
        parameters: Optional[Union[list, tuple, dict]] = None,
        size: Optional[int] = None,
    ):
        """
        Fetch data in batches. Each batch is an OracleDataFrame
        """
        cursor = self.cursor()
        cursor._impl.fetching_arrow = True
        if size is not None:
            cursor.arraysize = size
        cursor.prefetchrows = cursor.arraysize
        cursor.execute(statement, parameters)
        if size is None:
            yield cursor._impl.fetch_df_all(cursor)
        else:
            yield from cursor._impl.fetch_df_batches(cursor, batch_size=size)

    def getSodaDatabase(self) -> SodaDatabase:
        """
        Return a SODA database object for performing all operations on Simple
        Oracle Document Access (SODA).
        """
        self._verify_connected()
        db_impl = self._impl.create_soda_database_impl(self)
        return SodaDatabase._from_impl(self, db_impl)

    def gettype(self, name: str) -> DbObjectType:
        """
        Return a type object given its name. This can then be used to create
        objects which can be bound to cursors created by this connection.
        """
        self._verify_connected()
        obj_type_impl = self._impl.get_type(self, name)
        return DbObjectType._from_impl(obj_type_impl)

    @property
    def handle(self) -> int:
        """
        Returns the OCI service context handle for the connection. It is
        primarily provided to facilitate testing the creation of a connection
        using the OCI service context handle.

        This property is only relevant to python-oracledb's thick mode.
        """
        self._verify_connected()
        return self._impl.get_handle()

    @property
    def maxBytesPerCharacter(self) -> int:
        """
        Deprecated. Use the constant value 4 instead.
        """
        return 4

    def ping(self) -> None:
        """
        Pings the database to verify the connection is valid.
        """
        self._verify_connected()
        self._impl.ping()

    def prepare(self) -> bool:
        """
        Deprecated. Use tpc_prepare() instead.
        """
        return self.tpc_prepare()

    @property
    def proxy_user(self) -> Union[str, None]:
        """
        Returns the name of the proxy user, if applicable.
        """
        self._verify_connected()
        return self._impl.proxy_user

    def rollback(self) -> None:
        """
        Rolls back any pending transactions.
        """
        self._verify_connected()
        self._impl.rollback()

    def shutdown(self, mode: int = 0) -> None:
        """
        Shutdown the database. In order to do this the connection must be
        connected as SYSDBA or SYSOPER. Two calls must be made unless the mode
        specified is DBSHUTDOWN_ABORT.
        """
        self._verify_connected()
        self._impl.shutdown(mode)

    def startup(
        self,
        force: bool = False,
        restrict: bool = False,
        pfile: Optional[str] = None,
    ) -> None:
        """
        Startup the database. This is equivalent to the SQL*Plus command
        “startup nomount”. The connection must be connected as SYSDBA or
        SYSOPER with the PRELIM_AUTH option specified for this to work.

        The pfile parameter, if specified, is expected to be a string
        identifying the location of the parameter file (PFILE) which will be
        used instead of the stored parameter file (SPFILE).
        """
        self._verify_connected()
        self._impl.startup(force, restrict, pfile)

    def subscribe(
        self,
        namespace: int = constants.SUBSCR_NAMESPACE_DBCHANGE,
        protocol: int = constants.SUBSCR_PROTO_CALLBACK,
        callback: Optional[Callable] = None,
        timeout: int = 0,
        operations: int = constants.OPCODE_ALLOPS,
        port: int = 0,
        qos: int = constants.SUBSCR_QOS_DEFAULT,
        ip_address: Optional[str] = None,
        grouping_class: int = constants.SUBSCR_GROUPING_CLASS_NONE,
        grouping_value: int = 0,
        grouping_type: int = constants.SUBSCR_GROUPING_TYPE_SUMMARY,
        name: Optional[str] = None,
        client_initiated: bool = False,
        *,
        ipAddress: Optional[str] = None,
        groupingClass: int = constants.SUBSCR_GROUPING_CLASS_NONE,
        groupingValue: int = 0,
        groupingType: int = constants.SUBSCR_GROUPING_TYPE_SUMMARY,
        clientInitiated: bool = False,
    ) -> Subscription:
        """
        Return a new subscription object that receives notification for events
        that take place in the database that match the given parameters.

        The namespace parameter specifies the namespace the subscription uses.
        It can be one of SUBSCR_NAMESPACE_DBCHANGE or SUBSCR_NAMESPACE_AQ.

        The protocol parameter specifies the protocol to use when notifications
        are sent. Currently the only valid value is SUBSCR_PROTO_CALLBACK.

        The callback is expected to be a callable that accepts a single
        parameter. A message object is passed to this callback whenever a
        notification is received.

        The timeout value specifies that the subscription expires after the
        given time in seconds. The default value of 0 indicates that the
        subscription never expires.

        The operations parameter enables filtering of the messages that are
        sent (insert, update, delete). The default value will send
        notifications for all operations. This parameter is only used when the
        namespace is set to SUBSCR_NAMESPACE_DBCHANGE.

        The port parameter specifies the listening port for callback
        notifications from the database server. If not specified, an unused
        port will be selected by the Oracle Client libraries.

        The qos parameter specifies quality of service options. It should be
        one or more of the following flags, OR'ed together:
        SUBSCR_QOS_RELIABLE,
        SUBSCR_QOS_DEREG_NFY,
        SUBSCR_QOS_ROWIDS,
        SUBSCR_QOS_QUERY,
        SUBSCR_QOS_BEST_EFFORT.

        The ip_address parameter specifies the IP address (IPv4 or IPv6) in
        standard string notation to bind for callback notifications from the
        database server. If not specified, the client IP address will be
        determined by the Oracle Client libraries.

        The grouping_class parameter specifies what type of grouping of
        notifications should take place. Currently, if set, this value can
        only be set to the value SUBSCR_GROUPING_CLASS_TIME, which will group
        notifications by the number of seconds specified in the grouping_value
        parameter. The grouping_type parameter should be one of the values
        SUBSCR_GROUPING_TYPE_SUMMARY (the default) or
        SUBSCR_GROUPING_TYPE_LAST.

        The name parameter is used to identify the subscription and is specific
        to the selected namespace. If the namespace parameter is
        SUBSCR_NAMESPACE_DBCHANGE then the name is optional and can be any
        value. If the namespace parameter is SUBSCR_NAMESPACE_AQ, however, the
        name must be in the format '<QUEUE_NAME>' for single consumer queues
        and '<QUEUE_NAME>:<CONSUMER_NAME>' for multiple consumer queues, and
        identifies the queue that will be monitored for messages. The queue
        name may include the schema, if needed.

        The client_initiated parameter is used to determine if client initiated
        connections or server initiated connections (the default) will be
        established. Client initiated connections are only available in Oracle
        Client 19.4 and Oracle Database 19.4 and higher.
        """
        self._verify_connected()
        if ipAddress is not None:
            if ip_address is not None:
                errors._raise_err(
                    errors.ERR_DUPLICATED_PARAMETER,
                    deprecated_name="ipAddress",
                    new_name="ip_address",
                )
            ip_address = ipAddress
        if groupingClass != constants.SUBSCR_GROUPING_CLASS_NONE:
            if grouping_class != constants.SUBSCR_GROUPING_CLASS_NONE:
                errors._raise_err(
                    errors.ERR_DUPLICATED_PARAMETER,
                    deprecated_name="groupingClass",
                    new_name="grouping_class",
                )
            grouping_class = groupingClass
        if groupingValue != 0:
            if grouping_value != 0:
                errors._raise_err(
                    errors.ERR_DUPLICATED_PARAMETER,
                    deprecated_name="groupingValue",
                    new_name="grouping_value",
                )
            grouping_value = groupingValue
        if groupingType != constants.SUBSCR_GROUPING_TYPE_SUMMARY:
            if grouping_type != constants.SUBSCR_GROUPING_TYPE_SUMMARY:
                errors._raise_err(
                    errors.ERR_DUPLICATED_PARAMETER,
                    deprecated_name="groupingType",
                    new_name="grouping_type",
                )
            grouping_type = groupingType
        if clientInitiated:
            if client_initiated:
                errors._raise_err(
                    errors.ERR_DUPLICATED_PARAMETER,
                    deprecated_name="clientInitiated",
                    new_name="client_initiated",
                )
            client_initiated = clientInitiated
        impl = self._impl.create_subscr_impl(
            self,
            callback,
            namespace,
            name,
            protocol,
            ip_address,
            port,
            timeout,
            operations,
            qos,
            grouping_class,
            grouping_value,
            grouping_type,
            client_initiated,
        )
        subscr = Subscription._from_impl(impl)
        impl.subscribe(subscr, self._impl)
        return subscr

    @property
    def tag(self) -> str:
        """
        This property initially contains the actual tag of the session that was
        acquired from a pool. If the connection was not acquired from a pool or
        no tagging parameters were specified (tag and matchanytag) when the
        connection was acquired from the pool, this value will be None. If the
        value is changed, it must be a string containing name=value pairs like
        “k1=v1;k2=v2”.

        If this value is not None when the connection is released back to the
        pool it will be used to retag the session. This value can be overridden
        in the call to SessionPool.release().
        """
        self._verify_connected()
        return self._impl.tag

    @tag.setter
    def tag(self, value: str) -> None:
        self._verify_connected()
        self._impl.tag = value

    def tpc_begin(
        self, xid: Xid, flags: int = constants.TPC_BEGIN_NEW, timeout: int = 0
    ) -> None:
        """
        Begins a TPC (two-phase commit) transaction with the given transaction
        id. This method should be called outside of a transaction (i.e. nothing
        may have executed since the last commit() or rollback() was performed).
        """
        self._verify_connected()
        self._verify_xid(xid)
        if flags not in (
            constants.TPC_BEGIN_NEW,
            constants.TPC_BEGIN_JOIN,
            constants.TPC_BEGIN_RESUME,
            constants.TPC_BEGIN_PROMOTE,
        ):
            errors._raise_err(errors.ERR_INVALID_TPC_BEGIN_FLAGS)
        self._impl.tpc_begin(xid, flags, timeout)

    def tpc_commit(
        self, xid: Optional[Xid] = None, one_phase: bool = False
    ) -> None:
        """
        Prepare the global transaction for commit. Return a boolean indicating
        if a transaction was actually prepared in order to avoid the error
        ORA-24756 (transaction does not exist).

        When called with no arguments, commits a transaction previously
        prepared with tpc_prepare(). If tpc_prepare() is not called, a single
        phase commit is performed. A transaction manager may choose to do this
        if only a single resource is participating in the global transaction.

        When called with a transaction id, the database commits the given
        transaction. This form should be called outside of a transaction and is
        intended for use in recovery.
        """
        self._verify_connected()
        if xid is not None:
            self._verify_xid(xid)
        self._impl.tpc_commit(xid, one_phase)

    def tpc_end(
        self, xid: Optional[Xid] = None, flags: int = constants.TPC_END_NORMAL
    ) -> None:
        """
        Ends (detaches from) a TPC (two-phase commit) transaction.
        """
        self._verify_connected()
        if xid is not None:
            self._verify_xid(xid)
        if flags not in (constants.TPC_END_NORMAL, constants.TPC_END_SUSPEND):
            errors._raise_err(errors.ERR_INVALID_TPC_END_FLAGS)
        self._impl.tpc_end(xid, flags)

    def tpc_forget(self, xid: Xid) -> None:
        """
        Forgets a TPC (two-phase commit) transaction.
        """
        self._verify_connected()
        self._verify_xid(xid)
        self._impl.tpc_forget(xid)

    def tpc_prepare(self, xid: Optional[Xid] = None) -> bool:
        """
        Prepares a global transaction for commit. After calling this function,
        no further activity should take place on this connection until either
        tpc_commit() or tpc_rollback() have been called.

        A boolean is returned indicating whether a commit is needed or not. If
        a commit is performed when one is not needed the error ORA-24756:
        transaction does not exist is raised.
        """
        self._verify_connected()
        if xid is not None:
            self._verify_xid(xid)
        return self._impl.tpc_prepare(xid)

    def tpc_recover(self) -> list:
        """
        Returns a list of pending transaction ids suitable for use with
        tpc_commit() or tpc_rollback().

        This function requires select privilege on the view
        DBA_PENDING_TRANSACTIONS.
        """
        with self.cursor() as cursor:
            cursor.execute(
                """
                    select
                        formatid,
                        globalid,
                        branchid
                    from dba_pending_transactions"""
            )
            cursor.rowfactory = Xid
            return cursor.fetchall()

    def tpc_rollback(self, xid: Optional[Xid] = None) -> None:
        """
        When called with no arguments, rolls back the transaction previously
        started with tpc_begin().

        When called with a transaction id, the database rolls back the given
        transaction. This form should be called outside of a transaction and is
        intended for use in recovery.
        """
        self._verify_connected()
        if xid is not None:
            self._verify_xid(xid)
        self._impl.tpc_rollback(xid)

    def unsubscribe(self, subscr: Subscription) -> None:
        """
        Unsubscribe from events in the database that were originally subscribed
        to using subscribe(). The connection used to unsubscribe should be the
        same one used to create the subscription, or should access the same
        database and be connected as the same user name.
        """
        self._verify_connected()
        if not isinstance(subscr, Subscription):
            raise TypeError("expecting subscription")
        subscr._impl.unsubscribe(self._impl)


def _connection_factory(
    f: Callable[..., Connection]
) -> Callable[..., Connection]:
    """
    Decorator which checks the validity of the supplied keyword parameters by
    calling the original function (which does nothing), then creates and
    returns an instance of the requested Connection class. The base Connection
    class constructor does not check the validity of the supplied keyword
    parameters.
    """

    @functools.wraps(f)
    def connect(
        dsn: Optional[str] = None,
        *,
        pool: Optional["pool_module.ConnectionPool"] = None,
        pool_alias: Optional[str] = None,
        conn_class: Type[Connection] = Connection,
        params: Optional[ConnectParams] = None,
        **kwargs,
    ) -> Connection:
        f(
            dsn=dsn,
            pool=pool,
            pool_alias=pool_alias,
            conn_class=conn_class,
            params=params,
            **kwargs,
        )
        if not issubclass(conn_class, Connection):
            errors._raise_err(errors.ERR_INVALID_CONN_CLASS)
        if pool is not None and pool_alias is not None:
            errors._raise_err(
                errors.ERR_DUPLICATED_PARAMETER,
                deprecated_name="pool",
                new_name="pool_alias",
            )
        if pool_alias is not None:
            pool = pool_module.named_pools.pools.get(pool_alias)
            if pool is None:
                errors._raise_err(
                    errors.ERR_NAMED_POOL_MISSING, alias=pool_alias
                )
        if pool is not None and not isinstance(
            pool, pool_module.ConnectionPool
        ):
            message = "pool must be an instance of oracledb.ConnectionPool"
            raise TypeError(message)
        return conn_class(dsn=dsn, pool=pool, params=params, **kwargs)

    return connect


@_connection_factory
def connect(
    dsn: Optional[str] = None,
    *,
    pool: Optional["pool_module.ConnectionPool"] = None,
    pool_alias: Optional[str] = None,
    conn_class: Type[Connection] = Connection,
    params: Optional[ConnectParams] = None,
    user: Optional[str] = None,
    proxy_user: Optional[str] = None,
    password: Optional[str] = None,
    newpassword: Optional[str] = None,
    wallet_password: Optional[str] = None,
    access_token: Optional[Union[str, tuple, Callable]] = None,
    host: Optional[str] = None,
    port: Optional[int] = None,
    protocol: Optional[str] = None,
    https_proxy: Optional[str] = None,
    https_proxy_port: Optional[int] = None,
    service_name: Optional[str] = None,
    instance_name: Optional[str] = None,
    sid: Optional[str] = None,
    server_type: Optional[str] = None,
    cclass: Optional[str] = None,
    purity: Optional[oracledb.Purity] = None,
    expire_time: Optional[int] = None,
    retry_count: Optional[int] = None,
    retry_delay: Optional[int] = None,
    tcp_connect_timeout: Optional[float] = None,
    ssl_server_dn_match: Optional[bool] = None,
    ssl_server_cert_dn: Optional[str] = None,
    wallet_location: Optional[str] = None,
    events: Optional[bool] = None,
    externalauth: Optional[bool] = None,
    mode: Optional[oracledb.AuthMode] = None,
    disable_oob: Optional[bool] = None,
    stmtcachesize: Optional[int] = None,
    edition: Optional[str] = None,
    tag: Optional[str] = None,
    matchanytag: Optional[bool] = None,
    config_dir: Optional[str] = None,
    appcontext: Optional[list] = None,
    shardingkey: Optional[list] = None,
    supershardingkey: Optional[list] = None,
    debug_jdwp: Optional[str] = None,
    connection_id_prefix: Optional[str] = None,
    ssl_context: Optional[Any] = None,
    sdu: Optional[int] = None,
    pool_boundary: Optional[str] = None,
    use_tcp_fast_open: Optional[bool] = None,
    ssl_version: Optional[ssl.TLSVersion] = None,
    program: Optional[str] = None,
    machine: Optional[str] = None,
    terminal: Optional[str] = None,
    osuser: Optional[str] = None,
    driver_name: Optional[str] = None,
    use_sni: Optional[bool] = None,
    thick_mode_dsn_passthrough: Optional[bool] = None,
    extra_auth_params: Optional[dict] = None,
    handle: Optional[int] = None,
) -> Connection:
    """
    Factory function which creates a connection to the database and returns it.

    The dsn parameter (data source name) can be a string in the format
    user/password@connect_string or can simply be the connect string (in
    which case authentication credentials such as the username and password
    need to be specified separately). See the documentation on connection
    strings for more information.

    The pool parameter is expected to be a pool object and the use of this
    parameter is the equivalent of calling pool.acquire().

    The conn_class parameter is expected to be Connection or a subclass of
    Connection.

    The params parameter is expected to be of type ConnectParams and contains
    connection parameters that will be used when establishing the connection.
    See the documentation on ConnectParams for more information. If this
    parameter is not specified, the additional keyword parameters will be used
    to create an instance of ConnectParams. If both the params parameter and
    additional keyword parameters are specified, the values in the keyword
    parameters have precedence. Note that if a dsn is also supplied,
    then in the python-oracledb Thin mode, the values of the parameters
    specified (if any) within the dsn will override the values passed as
    additional keyword parameters, which themselves override the values set in
    the params parameter object.

    The following parameters are all optional. A brief description of each
    parameter follows:

    - user: the name of the user to connect to (default: None)

    - proxy_user: the name of the proxy user to connect to. If this value is
      not specified, it will be parsed out of user if user is in the form
      "user[proxy_user]" (default: None)

    - password: the password for the user (default: None)

    - newpassword: the new password for the user. The new password will take
      effect immediately upon a successful connection to the database (default:
      None)

    - wallet_password: the password to use to decrypt the wallet, if it is
      encrypted. This value is only used in thin mode (default: None)

    - access_token: expected to be a string or a 2-tuple or a callable. If it
      is a string, it specifies an Azure AD OAuth2 token used for Open
      Authorization (OAuth 2.0) token based authentication. If it is a 2-tuple,
      it specifies the token and private key strings used for Oracle Cloud
      Infrastructure (OCI) Identity and Access Management (IAM) token based
      authentication. If it is a callable, it returns either a string or a
      2-tuple used for OAuth 2.0 or OCI IAM token based authentication and is
      useful when the pool needs to expand and create new connections but the
      current authentication token has expired (default: None)

    - host: the name or IP address of the machine hosting the database or the
      database listener (default: None)

    - port: the port number on which the database listener is listening
      (default: 1521)

    - protocol: one of the strings "tcp" or "tcps" indicating whether to use
      unencrypted network traffic or encrypted network traffic (TLS) (default:
      "tcp")

    - https_proxy: the name or IP address of a proxy host to use for tunneling
      secure connections (default: None)

    - https_proxy_port: the port on which to communicate with the proxy host
      (default: 0)

    - service_name: the service name of the database (default: None)

    - instance_name: the instance name of the database (default: None)

    - sid: the system identifier (SID) of the database. Note using a
      service_name instead is recommended (default: None)

    - server_type: the type of server connection that should be established. If
      specified, it should be one of "dedicated", "shared" or "pooled"
      (default: None)

    - cclass: connection class to use for Database Resident Connection Pooling
      (DRCP) (default: None)

    - purity: purity to use for Database Resident Connection Pooling (DRCP)
      (default: oracledb.PURITY_DEFAULT)

    - expire_time: an integer indicating the number of minutes between the
      sending of keepalive probes. If this parameter is set to a value greater
      than zero it enables keepalive (default: 0)

    - retry_count: the number of times that a connection attempt should be
      retried before the attempt is terminated (default: 0)

    - retry_delay: the number of seconds to wait before making a new connection
      attempt (default: 1)

    - tcp_connect_timeout: a float indicating the maximum number of seconds to
      wait for establishing a connection to the database host (default: 20.0)

    - ssl_server_dn_match: boolean indicating whether the server certificate
      distinguished name (DN) should be matched in addition to the regular
      certificate verification that is performed. Note that if the
      ssl_server_cert_dn parameter is not privided, host name matching is
      performed instead (default: True)

    - ssl_server_cert_dn: the distinguished name (DN) which should be matched
      with the server. This value is ignored if the ssl_server_dn_match
      parameter is not set to the value True. If specified this value is used
      for any verfication. Otherwise the hostname will be used (default: None)

    - wallet_location: the directory where the wallet can be found. In thin
      mode this must be the directory containing the PEM-encoded wallet file
      ewallet.pem. In thick mode this must be the directory containing the file
      cwallet.sso (default: None)

    - events: boolean specifying whether events mode should be enabled. This
      value is only used in thick mode and is needed for continuous query
      notification and high availability event notifications (default: False)

    - externalauth: a boolean indicating whether to use external authentication
      (default: False)

    - mode: authorization mode to use. For example oracledb.AUTH_MODE_SYSDBA
      (default: oracledb.AUTH_MODE_DEFAULT)

    - disable_oob: boolean indicating whether out-of-band breaks should be
      disabled. This value is only used in thin mode. It has no effect on
      Windows which does not support this functionality (default: False)

    - stmtcachesize: identifies the initial size of the statement cache
      (default: oracledb.defaults.stmtcachesize)

    - edition: edition to use for the connection. This parameter cannot be used
      simultaneously with the cclass parameter (default: None)

    - tag: identifies the type of connection that should be returned from a
      pool. This value is only used in thick mode (default: None)

    - matchanytag: boolean specifying whether any tag can be used when
      acquiring a connection from the pool. This value is only used in thick
      mode (default: False)

    - config_dir: directory in which the optional tnsnames.ora configuration
      file is located. This value is only used in thin mode. For thick mode use
      the config_dir parameter of init_oracle_client() (default:
      oracledb.defaults.config_dir)

    - appcontext: application context used by the connection. It should be a
      list of 3-tuples (namespace, name, value) and each entry in the tuple
      should be a string. This value is only used in thick mode (default: None)

    - shardingkey: a list of strings, numbers, bytes or dates that identify the
      database shard to connect to. This value is only used in thick mode
      (default: None)

    - supershardingkey: a list of strings, numbers, bytes or dates that
      identify the database shard to connect to. This value is only used in
      thick mode (default: None)

    - debug_jdwp: a string with the format "host=<host>;port=<port>" that
      specifies the host and port of the PL/SQL debugger. This value is only
      used in thin mode. For thick mode set the ORA_DEBUG_JDWP environment
      variable (default: None)

    - connection_id_prefix: an application specific prefix that is added to the
      connection identifier used for tracing (default: None)

    - ssl_context: an SSLContext object used for connecting to the database
      using TLS.  This SSL context will be modified to include the private key
      or any certificates found in a separately supplied wallet. This parameter
      should only be specified if the default SSLContext object cannot be used
      (default: None)

    - sdu: the requested size of the Session Data Unit (SDU), in bytes. The
      value tunes internal buffers used for communication to the database.
      Bigger values can increase throughput for large queries or bulk data
      loads, but at the cost of higher memory use. The SDU size that will
      actually be used is negotiated down to the lower of this value and the
      database network SDU configuration value (default: 8192)

    - pool_boundary: one of the values "statement" or "transaction" indicating
      when pooled DRCP connections can be returned to the pool. This requires
      the use of DRCP with Oracle Database 23.4 or higher (default: None)

    - use_tcp_fast_open: boolean indicating whether to use TCP fast open. This
      is an Oracle Autonomous Database Serverless (ADB-S) specific property for
      clients connecting from within OCI Cloud network. Please refer to the
      ADB-S documentation for more information (default: False)

    - ssl_version: one of the values ssl.TLSVersion.TLSv1_2 or
      ssl.TLSVersion.TLSv1_3 indicating which TLS version to use (default:
      None)

    - program: the name of the executable program or application connected to
      the Oracle Database (default: oracledb.defaults.program)

    - machine: the machine name of the client connecting to the Oracle Database
      (default: oracledb.defaults.machine)

    - terminal: the terminal identifier from which the connection originates
      (default: oracledb.defaults.terminal)

    - osuser: the operating system user that initiates the database connection
      (default: oracledb.defaults.osuser)

    - driver_name: the driver name used by the client to connect to the Oracle
      Database (default: oracledb.defaults.driver_name)

    - use_sni: boolean indicating whether to use the TLS SNI extension to
      bypass the second TLS neogiation that would otherwise be required
      (default: False)

    - thick_mode_dsn_passthrough: boolean indicating whether to pass the
      connect string to the Oracle Client libraries unchanged without parsing
      by the driver. Setting this to False makes thick and thin mode
      applications behave similarly regarding connection string parameter
      handling and locating any optional tnsnames.ora configuration file
      (default: oracledb.defaults.thick_mode_dsn_passthrough)

    - extra_auth_params: a dictionary containing configuration parameters
      necessary for Oracle Database authentication using plugins, such as the
      Azure and OCI cloud-native authentication plugins (default: None)

    - handle: an integer representing a pointer to a valid service context
      handle. This value is only used in thick mode. It should be used with
      extreme caution (default: 0)
    """
    pass


class AsyncConnection(BaseConnection):
    __module__ = MODULE_NAME

    def __init__(
        self,
        dsn: str,
        pool: pool_module.AsyncConnectionPool,
        params: ConnectParams,
        kwargs: dict,
    ) -> None:
        """
        Constructor for asynchronous connection pool. Not intended to be used
        directly but only indirectly through async_connect().
        """
        super().__init__()
        self._connect_coroutine = self._connect(dsn, pool, params, kwargs)

    def __await__(self):
        coroutine = self._connect_coroutine
        self._connect_coroutine = None
        return coroutine.__await__()

    async def __aenter__(self):
        if self._connect_coroutine is not None:
            await self._connect_coroutine
        else:
            self._verify_connected()
        return self

    async def __aexit__(self, *exc_info):
        if self._impl is not None:
            await self._impl.close()
            self._impl = None

    async def _connect(self, dsn, pool, params, kwargs):
        """
        Internal method for establishing a connection to the database using
        asyncio.
        """

        # mandate that thin mode is required; with asyncio, only thin mode is
        # supported and only one thread is executing, so the manager can be
        # manipulated directly
        driver_mode.manager.thin_mode = True

        # determine which connection parameters to use
        if params is None:
            params_impl = base_impl.ConnectParamsImpl()
        elif not isinstance(params, ConnectParams):
            errors._raise_err(errors.ERR_INVALID_CONNECT_PARAMS)
        else:
            params_impl = params._impl.copy()
        dsn = params_impl.process_args(dsn, kwargs, thin=True)

        # see if connection is being acquired from a pool
        if pool is None:
            pool_impl = None
        elif not isinstance(pool, pool_module.AsyncConnectionPool):
            message = (
                "pool must be an instance of oracledb.AsyncConnectionPool"
            )
            raise TypeError(message)
        else:
            pool._verify_open()
            pool_impl = pool._impl

        # create implementation object
        if pool is not None:
            impl = await pool_impl.acquire(params_impl)
        else:
            impl = thin_impl.AsyncThinConnImpl(dsn, params_impl)
            await impl.connect(params_impl)
        self._impl = impl

        # invoke callback, if applicable
        if (
            impl.invoke_session_callback
            and pool is not None
            and pool.session_callback is not None
            and callable(pool.session_callback)
        ):
            await pool.session_callback(self, params_impl.tag)
            impl.invoke_session_callback = False

        return self

    def _create_queue(self, impl):
        """
        Returns a queue object that the user can use to dequeue and enqueue
        messages.
        """
        return AsyncQueue._from_impl(self, impl)

    def _verify_can_execute(
        self, parameters: Any, keyword_parameters: Any
    ) -> Any:
        """
        Verifies that the connection can be used to execute
        Verifies that the connection is connected to the database. If it is
        not, an exception is raised.
        """
        self._verify_connected()
        if keyword_parameters:
            if parameters:
                errors._raise_err(errors.ERR_ARGS_AND_KEYWORD_ARGS)
            return keyword_parameters
        elif parameters is not None and not isinstance(
            parameters, (list, tuple, dict)
        ):
            errors._raise_err(errors.ERR_WRONG_EXECUTE_PARAMETERS_TYPE)
        return parameters

    async def callfunc(
        self,
        name: str,
        return_type: Any,
        parameters: Optional[Union[list, tuple]] = None,
        keyword_parameters: Optional[dict] = None,
    ) -> Any:
        """
        Call a PL/SQL function with the given name.

        This is a shortcut for creating a cursor, calling the stored function
        with the cursor and then closing the cursor.
        """
        with self.cursor() as cursor:
            return await cursor.callfunc(
                name, return_type, parameters, keyword_parameters
            )

    async def callproc(
        self,
        name: str,
        parameters: Optional[Union[list, tuple]] = None,
        keyword_parameters: Optional[dict] = None,
    ) -> list:
        """
        Call a PL/SQL procedure with the given name.

        This is a shortcut for creating a cursor, calling the stored procedure
        with the cursor and then closing the cursor.
        """
        with self.cursor() as cursor:
            return await cursor.callproc(name, parameters, keyword_parameters)

    async def changepassword(
        self, old_password: str, new_password: str
    ) -> None:
        """
        Changes the password for the user to which the connection is connected.
        """
        self._verify_connected()
        await self._impl.change_password(old_password, new_password)

    async def close(self) -> None:
        """
        Closes the connection.
        """
        self._verify_connected()
        await self._impl.close()
        self._impl = None

    async def commit(self) -> None:
        """
        Commits any pending transaction to the database.
        """
        self._verify_connected()
        await self._impl.commit()

    async def createlob(
        self, lob_type: DbType, data: Optional[Union[str, bytes]] = None
    ) -> AsyncLOB:
        """
        Create and return a new temporary LOB of the specified type.
        """
        self._verify_connected()
        if lob_type not in (DB_TYPE_CLOB, DB_TYPE_NCLOB, DB_TYPE_BLOB):
            message = (
                "parameter should be one of oracledb.DB_TYPE_CLOB, "
                "oracledb.DB_TYPE_BLOB or oracledb.DB_TYPE_NCLOB"
            )
            raise TypeError(message)
        impl = await self._impl.create_temp_lob_impl(lob_type)
        lob = AsyncLOB._from_impl(impl)
        if data:
            await lob.write(data)
        return lob

    def cursor(self, scrollable: bool = False) -> AsyncCursor:
        """
        Returns a cursor associated with the connection.
        """
        self._verify_connected()
        return AsyncCursor(self, scrollable)

    async def execute(
        self,
        statement: str,
        parameters: Optional[Union[list, tuple, dict]] = None,
    ) -> None:
        """
        Execute a statement against the database.

        This is a shortcut for creating a cursor, executing a statement with
        the cursor and then closing the cursor.
        """
        with self.cursor() as cursor:
            await cursor.execute(statement, parameters)

    async def executemany(
        self, statement: Union[str, None], parameters: Union[list, int]
    ) -> None:
        """
        Prepare a statement for execution against a database and then execute
        it against all parameter mappings or sequences found in the sequence
        parameters.

        This is a shortcut for creating a cursor, calling executemany() on the
        cursor and then closing the cursor.
        """
        with self.cursor() as cursor:
            await cursor.executemany(statement, parameters)

    async def fetchall(
        self,
        statement: str,
        parameters: Optional[Union[list, tuple, dict]] = None,
        arraysize: Optional[int] = None,
        rowfactory: Optional[Callable] = None,
    ) -> list:
        """
        Executes a query and returns all of the rows. After the rows are
        fetched, the cursor is closed.
        """
        with self.cursor() as cursor:
            if arraysize is not None:
                cursor.arraysize = arraysize
            cursor.prefetchrows = cursor.arraysize
            await cursor.execute(statement, parameters)
            cursor.rowfactory = rowfactory
            return await cursor.fetchall()

    async def fetch_df_all(
        self,
        statement: str,
        parameters: Optional[Union[list, tuple, dict]] = None,
        arraysize: Optional[int] = None,
    ):
        """
        Fetch all data as OracleDataFrame.
        """
        cursor = self.cursor()
        cursor._impl.fetching_arrow = True
        if arraysize is not None:
            cursor.arraysize = arraysize
        cursor.prefetchrows = cursor.arraysize
        await cursor.execute(statement, parameters)
        return await cursor._impl.fetch_df_all(cursor)

    async def fetch_df_batches(
        self,
        statement: str,
        parameters: Optional[Union[list, tuple, dict]] = None,
        size: Optional[int] = None,
    ):
        """
        Fetch data in batches. Each batch is an OracleDataFrame
        """
        cursor = self.cursor()
        cursor._impl.fetching_arrow = True
        if size is not None:
            cursor.arraysize = size
        cursor.prefetchrows = cursor.arraysize
        await cursor.execute(statement, parameters)
        if size is None:
            yield await cursor._impl.fetch_df_all(cursor)
        else:
            async for df in cursor._impl.fetch_df_batches(cursor, size):
                yield df

    async def fetchmany(
        self,
        statement: str,
        parameters: Optional[Union[list, tuple, dict]] = None,
        num_rows: Optional[int] = None,
        rowfactory: Optional[Callable] = None,
    ) -> list:
        """
        Executes a query and returns up to the specified number of rows. After
        the rows are fetched, the cursor is closed.
        """
        with self.cursor() as cursor:
            if num_rows is None:
                num_rows = cursor.arraysize
            elif num_rows <= 0:
                return []
            cursor.arraysize = cursor.prefetchrows = num_rows
            await cursor.execute(statement, parameters)
            cursor.rowfactory = rowfactory
            return await cursor.fetchmany(num_rows)

    async def fetchone(
        self,
        statement: str,
        parameters: Optional[Union[list, tuple, dict]] = None,
        rowfactory: Optional[Callable] = None,
    ) -> Any:
        """
        Executes a query and returns the first row of the result set if one
        exists (or None if no rows exist). After the row is fetched the cursor
        is closed.
        """
        with self.cursor() as cursor:
            cursor.prefetchrows = cursor.arraysize = 1
            await cursor.execute(statement, parameters)
            cursor.rowfactory = rowfactory
            return await cursor.fetchone()

    async def gettype(self, name: str) -> DbObjectType:
        """
        Return a type object given its name. This can then be used to create
        objects which can be bound to cursors created by this connection.
        """
        self._verify_connected()
        obj_type_impl = await self._impl.get_type(self, name)
        return DbObjectType._from_impl(obj_type_impl)

    async def ping(self) -> None:
        """
        Pings the database to verify the connection is valid.
        """
        self._verify_connected()
        await self._impl.ping()

    async def rollback(self) -> None:
        """
        Rolls back any pending transaction.
        """
        self._verify_connected()
        await self._impl.rollback()

    async def run_pipeline(
        self,
        pipeline: Pipeline,
        continue_on_error: bool = False,
    ) -> list:
        """
        Runs all of the operations in the pipeline on the connection. If the
        database is Oracle Database 23ai or higher, the operations will be
        performed in a single round trip, subject to the following caveats:
            - queries that contain LOBs require an additional round trip
            - queries that contain DbObject values may require multiple round
              trips
            - queries that fetch all of the rows may require multiple round
              trips
        For all other databases, the operations will be performed in the same
        way as they would be performed independently of the pipeline.
        """
        self._verify_connected()
        results = [op._create_result() for op in pipeline.operations]
        if self._impl.supports_pipelining() and len(results) > 1:
            await self._impl.run_pipeline_with_pipelining(
                self, results, continue_on_error
            )
        else:
            await self._impl.run_pipeline_without_pipelining(
                self, results, continue_on_error
            )
        return results

    async def tpc_begin(
        self, xid: Xid, flags: int = constants.TPC_BEGIN_NEW, timeout: int = 0
    ) -> None:
        """
        Begins a TPC (two-phase commit) transaction with the given transaction
        id. This method should be called outside of a transaction (i.e. nothing
        may have executed since the last commit() or rollback() was performed).
        """
        self._verify_connected()
        self._verify_xid(xid)
        if flags not in (
            constants.TPC_BEGIN_NEW,
            constants.TPC_BEGIN_JOIN,
            constants.TPC_BEGIN_RESUME,
            constants.TPC_BEGIN_PROMOTE,
        ):
            errors._raise_err(errors.ERR_INVALID_TPC_BEGIN_FLAGS)
        await self._impl.tpc_begin(xid, flags, timeout)

    async def tpc_commit(
        self, xid: Optional[Xid] = None, one_phase: bool = False
    ) -> None:
        """
        Prepare the global transaction for commit. Return a boolean indicating
        if a transaction was actually prepared in order to avoid the error
        ORA-24756 (transaction does not exist).

        When called with no arguments, commits a transaction previously
        prepared with tpc_prepare(). If tpc_prepare() is not called, a single
        phase commit is performed. A transaction manager may choose to do this
        if only a single resource is participating in the global transaction.

        When called with a transaction id, the database commits the given
        transaction. This form should be called outside of a transaction and is
        intended for use in recovery.
        """
        self._verify_connected()
        if xid is not None:
            self._verify_xid(xid)
        await self._impl.tpc_commit(xid, one_phase)

    async def tpc_end(
        self, xid: Optional[Xid] = None, flags: int = constants.TPC_END_NORMAL
    ) -> None:
        """
        Ends (detaches from) a TPC (two-phase commit) transaction.
        """
        self._verify_connected()
        if xid is not None:
            self._verify_xid(xid)
        if flags not in (constants.TPC_END_NORMAL, constants.TPC_END_SUSPEND):
            errors._raise_err(errors.ERR_INVALID_TPC_END_FLAGS)
        await self._impl.tpc_end(xid, flags)

    async def tpc_forget(self, xid: Xid) -> None:
        """
        Forgets a TPC (two-phase commit) transaction.
        """
        self._verify_connected()
        self._verify_xid(xid)
        await self._impl.tpc_forget(xid)

    async def tpc_prepare(self, xid: Optional[Xid] = None) -> bool:
        """
        Prepares a global transaction for commit. After calling this function,
        no further activity should take place on this connection until either
        tpc_commit() or tpc_rollback() have been called.

        A boolean is returned indicating whether a commit is needed or not. If
        a commit is performed when one is not needed the error ORA-24756:
        transaction does not exist is raised.
        """
        self._verify_connected()
        if xid is not None:
            self._verify_xid(xid)
        return await self._impl.tpc_prepare(xid)

    async def tpc_recover(self) -> list:
        """
        Returns a list of pending transaction ids suitable for use with
        tpc_commit() or tpc_rollback().

        This function requires select privilege on the view
        DBA_PENDING_TRANSACTIONS.
        """
        with self.cursor() as cursor:
            await cursor.execute(
                """
                    select
                        formatid,
                        globalid,
                        branchid
                    from dba_pending_transactions"""
            )
            cursor.rowfactory = Xid
            return await cursor.fetchall()

    async def tpc_rollback(self, xid: Optional[Xid] = None) -> None:
        """
        When called with no arguments, rolls back the transaction previously
        started with tpc_begin().

        When called with a transaction id, the database rolls back the given
        transaction. This form should be called outside of a transaction and is
        intended for use in recovery.
        """
        self._verify_connected()
        if xid is not None:
            self._verify_xid(xid)
        await self._impl.tpc_rollback(xid)


def _async_connection_factory(
    f: Callable[..., AsyncConnection]
) -> Callable[..., AsyncConnection]:
    """
    Decorator which checks the validity of the supplied keyword parameters by
    calling the original function (which does nothing), then creates and
    returns an instance of the requested AsyncConnection class.
    """

    @functools.wraps(f)
    def connect_async(
        dsn: Optional[str] = None,
        *,
        pool: Optional["pool_module.AsyncConnectionPool"] = None,
        pool_alias: Optional[str] = None,
        conn_class: Type[AsyncConnection] = AsyncConnection,
        params: Optional[ConnectParams] = None,
        **kwargs,
    ) -> AsyncConnection:
        # check arguments
        f(
            dsn=dsn,
            pool=pool,
            pool_alias=pool_alias,
            conn_class=conn_class,
            params=params,
            **kwargs,
        )
        if not issubclass(conn_class, AsyncConnection):
            errors._raise_err(errors.ERR_INVALID_CONN_CLASS)

        if pool is not None and pool_alias is not None:
            errors._raise_err(
                errors.ERR_DUPLICATED_PARAMETER,
                deprecated_name="pool",
                new_name="pool_alias",
            )
        if pool_alias is not None:
            pool = pool_module.named_pools.pools.get(pool_alias)
            if pool is None:
                errors._raise_err(
                    errors.ERR_NAMED_POOL_MISSING, alias=pool_alias
                )
        if pool is not None and not isinstance(
            pool, pool_module.AsyncConnectionPool
        ):
            message = (
                "pool must be an instance of oracledb.AsyncConnectionPool"
            )
            raise TypeError(message)
        if params is not None and not isinstance(params, ConnectParams):
            errors._raise_err(errors.ERR_INVALID_CONNECT_PARAMS)

        # build connection class and call the implementation connect to
        # actually establish the connection
        oracledb.enable_thin_mode()
        return conn_class(dsn, pool, params, kwargs)

    return connect_async


@_async_connection_factory
def connect_async(
    dsn: Optional[str] = None,
    *,
    pool: Optional["pool_module.AsyncConnectionPool"] = None,
    pool_alias: Optional[str] = None,
    conn_class: Type[AsyncConnection] = AsyncConnection,
    params: Optional[ConnectParams] = None,
    user: Optional[str] = None,
    proxy_user: Optional[str] = None,
    password: Optional[str] = None,
    newpassword: Optional[str] = None,
    wallet_password: Optional[str] = None,
    access_token: Optional[Union[str, tuple, Callable]] = None,
    host: Optional[str] = None,
    port: Optional[int] = None,
    protocol: Optional[str] = None,
    https_proxy: Optional[str] = None,
    https_proxy_port: Optional[int] = None,
    service_name: Optional[str] = None,
    instance_name: Optional[str] = None,
    sid: Optional[str] = None,
    server_type: Optional[str] = None,
    cclass: Optional[str] = None,
    purity: Optional[oracledb.Purity] = None,
    expire_time: Optional[int] = None,
    retry_count: Optional[int] = None,
    retry_delay: Optional[int] = None,
    tcp_connect_timeout: Optional[float] = None,
    ssl_server_dn_match: Optional[bool] = None,
    ssl_server_cert_dn: Optional[str] = None,
    wallet_location: Optional[str] = None,
    events: Optional[bool] = None,
    externalauth: Optional[bool] = None,
    mode: Optional[oracledb.AuthMode] = None,
    disable_oob: Optional[bool] = None,
    stmtcachesize: Optional[int] = None,
    edition: Optional[str] = None,
    tag: Optional[str] = None,
    matchanytag: Optional[bool] = None,
    config_dir: Optional[str] = None,
    appcontext: Optional[list] = None,
    shardingkey: Optional[list] = None,
    supershardingkey: Optional[list] = None,
    debug_jdwp: Optional[str] = None,
    connection_id_prefix: Optional[str] = None,
    ssl_context: Optional[Any] = None,
    sdu: Optional[int] = None,
    pool_boundary: Optional[str] = None,
    use_tcp_fast_open: Optional[bool] = None,
    ssl_version: Optional[ssl.TLSVersion] = None,
    program: Optional[str] = None,
    machine: Optional[str] = None,
    terminal: Optional[str] = None,
    osuser: Optional[str] = None,
    driver_name: Optional[str] = None,
    use_sni: Optional[bool] = None,
    thick_mode_dsn_passthrough: Optional[bool] = None,
    extra_auth_params: Optional[dict] = None,
    handle: Optional[int] = None,
) -> AsyncConnection:
    """
    Factory function which creates a connection to the database and returns it.

    The dsn parameter (data source name) can be a string in the format
    user/password@connect_string or can simply be the connect string (in
    which case authentication credentials such as the username and password
    need to be specified separately). See the documentation on connection
    strings for more information.

    The pool parameter is expected to be a pool object and the use of this
    parameter is the equivalent of calling pool.acquire().

    The conn_class parameter is expected to be AsyncConnection or a subclass of
    AsyncConnection.

    The params parameter is expected to be of type ConnectParams and contains
    connection parameters that will be used when establishing the connection.
    See the documentation on ConnectParams for more information. If this
    parameter is not specified, the additional keyword parameters will be used
    to create an instance of ConnectParams. If both the params parameter and
    additional keyword parameters are specified, the values in the keyword
    parameters have precedence. Note that if a dsn is also supplied,
    then in the python-oracledb Thin mode, the values of the parameters
    specified (if any) within the dsn will override the values passed as
    additional keyword parameters, which themselves override the values set in
    the params parameter object.

    The following parameters are all optional. A brief description of each
    parameter follows:

    - user: the name of the user to connect to (default: None)

    - proxy_user: the name of the proxy user to connect to. If this value is
      not specified, it will be parsed out of user if user is in the form
      "user[proxy_user]" (default: None)

    - password: the password for the user (default: None)

    - newpassword: the new password for the user. The new password will take
      effect immediately upon a successful connection to the database (default:
      None)

    - wallet_password: the password to use to decrypt the wallet, if it is
      encrypted. This value is only used in thin mode (default: None)

    - access_token: expected to be a string or a 2-tuple or a callable. If it
      is a string, it specifies an Azure AD OAuth2 token used for Open
      Authorization (OAuth 2.0) token based authentication. If it is a 2-tuple,
      it specifies the token and private key strings used for Oracle Cloud
      Infrastructure (OCI) Identity and Access Management (IAM) token based
      authentication. If it is a callable, it returns either a string or a
      2-tuple used for OAuth 2.0 or OCI IAM token based authentication and is
      useful when the pool needs to expand and create new connections but the
      current authentication token has expired (default: None)

    - host: the name or IP address of the machine hosting the database or the
      database listener (default: None)

    - port: the port number on which the database listener is listening
      (default: 1521)

    - protocol: one of the strings "tcp" or "tcps" indicating whether to use
      unencrypted network traffic or encrypted network traffic (TLS) (default:
      "tcp")

    - https_proxy: the name or IP address of a proxy host to use for tunneling
      secure connections (default: None)

    - https_proxy_port: the port on which to communicate with the proxy host
      (default: 0)

    - service_name: the service name of the database (default: None)

    - instance_name: the instance name of the database (default: None)

    - sid: the system identifier (SID) of the database. Note using a
      service_name instead is recommended (default: None)

    - server_type: the type of server connection that should be established. If
      specified, it should be one of "dedicated", "shared" or "pooled"
      (default: None)

    - cclass: connection class to use for Database Resident Connection Pooling
      (DRCP) (default: None)

    - purity: purity to use for Database Resident Connection Pooling (DRCP)
      (default: oracledb.PURITY_DEFAULT)

    - expire_time: an integer indicating the number of minutes between the
      sending of keepalive probes. If this parameter is set to a value greater
      than zero it enables keepalive (default: 0)

    - retry_count: the number of times that a connection attempt should be
      retried before the attempt is terminated (default: 0)

    - retry_delay: the number of seconds to wait before making a new connection
      attempt (default: 1)

    - tcp_connect_timeout: a float indicating the maximum number of seconds to
      wait for establishing a connection to the database host (default: 20.0)

    - ssl_server_dn_match: boolean indicating whether the server certificate
      distinguished name (DN) should be matched in addition to the regular
      certificate verification that is performed. Note that if the
      ssl_server_cert_dn parameter is not privided, host name matching is
      performed instead (default: True)

    - ssl_server_cert_dn: the distinguished name (DN) which should be matched
      with the server. This value is ignored if the ssl_server_dn_match
      parameter is not set to the value True. If specified this value is used
      for any verfication. Otherwise the hostname will be used (default: None)

    - wallet_location: the directory where the wallet can be found. In thin
      mode this must be the directory containing the PEM-encoded wallet file
      ewallet.pem. In thick mode this must be the directory containing the file
      cwallet.sso (default: None)

    - events: boolean specifying whether events mode should be enabled. This
      value is only used in thick mode and is needed for continuous query
      notification and high availability event notifications (default: False)

    - externalauth: a boolean indicating whether to use external authentication
      (default: False)

    - mode: authorization mode to use. For example oracledb.AUTH_MODE_SYSDBA
      (default: oracledb.AUTH_MODE_DEFAULT)

    - disable_oob: boolean indicating whether out-of-band breaks should be
      disabled. This value is only used in thin mode. It has no effect on
      Windows which does not support this functionality (default: False)

    - stmtcachesize: identifies the initial size of the statement cache
      (default: oracledb.defaults.stmtcachesize)

    - edition: edition to use for the connection. This parameter cannot be used
      simultaneously with the cclass parameter (default: None)

    - tag: identifies the type of connection that should be returned from a
      pool. This value is only used in thick mode (default: None)

    - matchanytag: boolean specifying whether any tag can be used when
      acquiring a connection from the pool. This value is only used in thick
      mode (default: False)

    - config_dir: directory in which the optional tnsnames.ora configuration
      file is located. This value is only used in thin mode. For thick mode use
      the config_dir parameter of init_oracle_client() (default:
      oracledb.defaults.config_dir)

    - appcontext: application context used by the connection. It should be a
      list of 3-tuples (namespace, name, value) and each entry in the tuple
      should be a string. This value is only used in thick mode (default: None)

    - shardingkey: a list of strings, numbers, bytes or dates that identify the
      database shard to connect to. This value is only used in thick mode
      (default: None)

    - supershardingkey: a list of strings, numbers, bytes or dates that
      identify the database shard to connect to. This value is only used in
      thick mode (default: None)

    - debug_jdwp: a string with the format "host=<host>;port=<port>" that
      specifies the host and port of the PL/SQL debugger. This value is only
      used in thin mode. For thick mode set the ORA_DEBUG_JDWP environment
      variable (default: None)

    - connection_id_prefix: an application specific prefix that is added to the
      connection identifier used for tracing (default: None)

    - ssl_context: an SSLContext object used for connecting to the database
      using TLS.  This SSL context will be modified to include the private key
      or any certificates found in a separately supplied wallet. This parameter
      should only be specified if the default SSLContext object cannot be used
      (default: None)

    - sdu: the requested size of the Session Data Unit (SDU), in bytes. The
      value tunes internal buffers used for communication to the database.
      Bigger values can increase throughput for large queries or bulk data
      loads, but at the cost of higher memory use. The SDU size that will
      actually be used is negotiated down to the lower of this value and the
      database network SDU configuration value (default: 8192)

    - pool_boundary: one of the values "statement" or "transaction" indicating
      when pooled DRCP connections can be returned to the pool. This requires
      the use of DRCP with Oracle Database 23.4 or higher (default: None)

    - use_tcp_fast_open: boolean indicating whether to use TCP fast open. This
      is an Oracle Autonomous Database Serverless (ADB-S) specific property for
      clients connecting from within OCI Cloud network. Please refer to the
      ADB-S documentation for more information (default: False)

    - ssl_version: one of the values ssl.TLSVersion.TLSv1_2 or
      ssl.TLSVersion.TLSv1_3 indicating which TLS version to use (default:
      None)

    - program: the name of the executable program or application connected to
      the Oracle Database (default: oracledb.defaults.program)

    - machine: the machine name of the client connecting to the Oracle Database
      (default: oracledb.defaults.machine)

    - terminal: the terminal identifier from which the connection originates
      (default: oracledb.defaults.terminal)

    - osuser: the operating system user that initiates the database connection
      (default: oracledb.defaults.osuser)

    - driver_name: the driver name used by the client to connect to the Oracle
      Database (default: oracledb.defaults.driver_name)

    - use_sni: boolean indicating whether to use the TLS SNI extension to
      bypass the second TLS neogiation that would otherwise be required
      (default: False)

    - thick_mode_dsn_passthrough: boolean indicating whether to pass the
      connect string to the Oracle Client libraries unchanged without parsing
      by the driver. Setting this to False makes thick and thin mode
      applications behave similarly regarding connection string parameter
      handling and locating any optional tnsnames.ora configuration file
      (default: oracledb.defaults.thick_mode_dsn_passthrough)

    - extra_auth_params: a dictionary containing configuration parameters
      necessary for Oracle Database authentication using plugins, such as the
      Azure and OCI cloud-native authentication plugins (default: None)

    - handle: an integer representing a pointer to a valid service context
      handle. This value is only used in thick mode. It should be used with
      extreme caution (default: 0)
    """
    pass


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\connect_params.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2021, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# connect_params.py
#
# Contains the ConnectParams class used for managing the parameters required to
# establish a connection to the database.
#
# *** NOTICE *** This file is generated from a template and should not be
# modified directly. See build_from_template.py in the utils subdirectory for
# more information.
# -----------------------------------------------------------------------------

import functools
import ssl
from typing import Union, Callable, Any, Optional

import oracledb

from . import base_impl, utils


class ConnectParams:
    """
    Contains all parameters used for establishing a connection to the
    database.
    """

    __module__ = oracledb.__name__
    __slots__ = ["_impl"]
    _impl_class = base_impl.ConnectParamsImpl

    @utils.params_initer
    def __init__(
        self,
        *,
        user: Optional[str] = None,
        proxy_user: Optional[str] = None,
        password: Optional[str] = None,
        newpassword: Optional[str] = None,
        wallet_password: Optional[str] = None,
        access_token: Optional[Union[str, tuple, Callable]] = None,
        host: Optional[str] = None,
        port: Optional[int] = None,
        protocol: Optional[str] = None,
        https_proxy: Optional[str] = None,
        https_proxy_port: Optional[int] = None,
        service_name: Optional[str] = None,
        instance_name: Optional[str] = None,
        sid: Optional[str] = None,
        server_type: Optional[str] = None,
        cclass: Optional[str] = None,
        purity: Optional[oracledb.Purity] = None,
        expire_time: Optional[int] = None,
        retry_count: Optional[int] = None,
        retry_delay: Optional[int] = None,
        tcp_connect_timeout: Optional[float] = None,
        ssl_server_dn_match: Optional[bool] = None,
        ssl_server_cert_dn: Optional[str] = None,
        wallet_location: Optional[str] = None,
        events: Optional[bool] = None,
        externalauth: Optional[bool] = None,
        mode: Optional[oracledb.AuthMode] = None,
        disable_oob: Optional[bool] = None,
        stmtcachesize: Optional[int] = None,
        edition: Optional[str] = None,
        tag: Optional[str] = None,
        matchanytag: Optional[bool] = None,
        config_dir: Optional[str] = None,
        appcontext: Optional[list] = None,
        shardingkey: Optional[list] = None,
        supershardingkey: Optional[list] = None,
        debug_jdwp: Optional[str] = None,
        connection_id_prefix: Optional[str] = None,
        ssl_context: Optional[Any] = None,
        sdu: Optional[int] = None,
        pool_boundary: Optional[str] = None,
        use_tcp_fast_open: Optional[bool] = None,
        ssl_version: Optional[ssl.TLSVersion] = None,
        program: Optional[str] = None,
        machine: Optional[str] = None,
        terminal: Optional[str] = None,
        osuser: Optional[str] = None,
        driver_name: Optional[str] = None,
        use_sni: Optional[bool] = None,
        thick_mode_dsn_passthrough: Optional[bool] = None,
        extra_auth_params: Optional[dict] = None,
        handle: Optional[int] = None,
    ):
        """
        All parameters are optional. A brief description of each parameter
        follows:

        - user: the name of the user to connect to (default: None)

        - proxy_user: the name of the proxy user to connect to. If this value
          is not specified, it will be parsed out of user if user is in the
          form "user[proxy_user]" (default: None)

        - password: the password for the user (default: None)

        - newpassword: the new password for the user. The new password will
          take effect immediately upon a successful connection to the database
          (default: None)

        - wallet_password: the password to use to decrypt the wallet, if it is
          encrypted. This value is only used in thin mode (default: None)

        - access_token: expected to be a string or a 2-tuple or a callable. If
          it is a string, it specifies an Azure AD OAuth2 token used for Open
          Authorization (OAuth 2.0) token based authentication. If it is a
          2-tuple, it specifies the token and private key strings used for
          Oracle Cloud Infrastructure (OCI) Identity and Access Management
          (IAM) token based authentication. If it is a callable, it returns
          either a string or a 2-tuple used for OAuth 2.0 or OCI IAM token
          based authentication and is useful when the pool needs to expand and
          create new connections but the current authentication token has
          expired (default: None)

        - host: the name or IP address of the machine hosting the database or
          the database listener (default: None)

        - port: the port number on which the database listener is listening
          (default: 1521)

        - protocol: one of the strings "tcp" or "tcps" indicating whether to
          use unencrypted network traffic or encrypted network traffic (TLS)
          (default: "tcp")

        - https_proxy: the name or IP address of a proxy host to use for
          tunneling secure connections (default: None)

        - https_proxy_port: the port on which to communicate with the proxy
          host (default: 0)

        - service_name: the service name of the database (default: None)

        - instance_name: the instance name of the database (default: None)

        - sid: the system identifier (SID) of the database. Note using a
          service_name instead is recommended (default: None)

        - server_type: the type of server connection that should be
          established. If specified, it should be one of "dedicated", "shared"
          or "pooled" (default: None)

        - cclass: connection class to use for Database Resident Connection
          Pooling (DRCP) (default: None)

        - purity: purity to use for Database Resident Connection Pooling (DRCP)
          (default: oracledb.PURITY_DEFAULT)

        - expire_time: an integer indicating the number of minutes between the
          sending of keepalive probes. If this parameter is set to a value
          greater than zero it enables keepalive (default: 0)

        - retry_count: the number of times that a connection attempt should be
          retried before the attempt is terminated (default: 0)

        - retry_delay: the number of seconds to wait before making a new
          connection attempt (default: 1)

        - tcp_connect_timeout: a float indicating the maximum number of seconds
          to wait for establishing a connection to the database host (default:
          20.0)

        - ssl_server_dn_match: boolean indicating whether the server
          certificate distinguished name (DN) should be matched in addition to
          the regular certificate verification that is performed. Note that if
          the ssl_server_cert_dn parameter is not privided, host name matching
          is performed instead (default: True)

        - ssl_server_cert_dn: the distinguished name (DN) which should be
          matched with the server. This value is ignored if the
          ssl_server_dn_match parameter is not set to the value True. If
          specified this value is used for any verfication. Otherwise the
          hostname will be used (default: None)

        - wallet_location: the directory where the wallet can be found. In thin
          mode this must be the directory containing the PEM-encoded wallet
          file ewallet.pem. In thick mode this must be the directory containing
          the file cwallet.sso (default: None)

        - events: boolean specifying whether events mode should be enabled.
          This value is only used in thick mode and is needed for continuous
          query notification and high availability event notifications
          (default: False)

        - externalauth: a boolean indicating whether to use external
          authentication (default: False)

        - mode: authorization mode to use. For example
          oracledb.AUTH_MODE_SYSDBA (default: oracledb.AUTH_MODE_DEFAULT)

        - disable_oob: boolean indicating whether out-of-band breaks should be
          disabled. This value is only used in thin mode. It has no effect on
          Windows which does not support this functionality (default: False)

        - stmtcachesize: identifies the initial size of the statement cache
          (default: oracledb.defaults.stmtcachesize)

        - edition: edition to use for the connection. This parameter cannot be
          used simultaneously with the cclass parameter (default: None)

        - tag: identifies the type of connection that should be returned from a
          pool. This value is only used in thick mode (default: None)

        - matchanytag: boolean specifying whether any tag can be used when
          acquiring a connection from the pool. This value is only used in
          thick mode (default: False)

        - config_dir: directory in which the optional tnsnames.ora
          configuration file is located. This value is only used in thin mode.
          For thick mode use the config_dir parameter of init_oracle_client()
          (default: oracledb.defaults.config_dir)

        - appcontext: application context used by the connection. It should be
          a list of 3-tuples (namespace, name, value) and each entry in the
          tuple should be a string. This value is only used in thick mode
          (default: None)

        - shardingkey: a list of strings, numbers, bytes or dates that identify
          the database shard to connect to. This value is only used in thick
          mode (default: None)

        - supershardingkey: a list of strings, numbers, bytes or dates that
          identify the database shard to connect to. This value is only used in
          thick mode (default: None)

        - debug_jdwp: a string with the format "host=<host>;port=<port>" that
          specifies the host and port of the PL/SQL debugger. This value is
          only used in thin mode. For thick mode set the ORA_DEBUG_JDWP
          environment variable (default: None)

        - connection_id_prefix: an application specific prefix that is added to
          the connection identifier used for tracing (default: None)

        - ssl_context: an SSLContext object used for connecting to the database
          using TLS.  This SSL context will be modified to include the private
          key or any certificates found in a separately supplied wallet. This
          parameter should only be specified if the default SSLContext object
          cannot be used (default: None)

        - sdu: the requested size of the Session Data Unit (SDU), in bytes. The
          value tunes internal buffers used for communication to the database.
          Bigger values can increase throughput for large queries or bulk data
          loads, but at the cost of higher memory use. The SDU size that will
          actually be used is negotiated down to the lower of this value and
          the database network SDU configuration value (default: 8192)

        - pool_boundary: one of the values "statement" or "transaction"
          indicating when pooled DRCP connections can be returned to the pool.
          This requires the use of DRCP with Oracle Database 23.4 or higher
          (default: None)

        - use_tcp_fast_open: boolean indicating whether to use TCP fast open.
          This is an Oracle Autonomous Database Serverless (ADB-S) specific
          property for clients connecting from within OCI Cloud network. Please
          refer to the ADB-S documentation for more information (default:
          False)

        - ssl_version: one of the values ssl.TLSVersion.TLSv1_2 or
          ssl.TLSVersion.TLSv1_3 indicating which TLS version to use (default:
          None)

        - program: the name of the executable program or application connected
          to the Oracle Database (default: oracledb.defaults.program)

        - machine: the machine name of the client connecting to the Oracle
          Database (default: oracledb.defaults.machine)

        - terminal: the terminal identifier from which the connection
          originates (default: oracledb.defaults.terminal)

        - osuser: the operating system user that initiates the database
          connection (default: oracledb.defaults.osuser)

        - driver_name: the driver name used by the client to connect to the
          Oracle Database (default: oracledb.defaults.driver_name)

        - use_sni: boolean indicating whether to use the TLS SNI extension to
          bypass the second TLS neogiation that would otherwise be required
          (default: False)

        - thick_mode_dsn_passthrough: boolean indicating whether to pass the
          connect string to the Oracle Client libraries unchanged without
          parsing by the driver. Setting this to False makes thick and thin
          mode applications behave similarly regarding connection string
          parameter handling and locating any optional tnsnames.ora
          configuration file (default:
          oracledb.defaults.thick_mode_dsn_passthrough)

        - extra_auth_params: a dictionary containing configuration parameters
          necessary for Oracle Database authentication using plugins, such as
          the Azure and OCI cloud-native authentication plugins (default: None)

        - handle: an integer representing a pointer to a valid service context
          handle. This value is only used in thick mode. It should be used with
          extreme caution (default: 0)
        """
        pass

    def __repr__(self):
        return (
            self.__class__.__qualname__ + "("
            f"user={self.user!r}, "
            f"proxy_user={self.proxy_user!r}, "
            f"host={self.host!r}, "
            f"port={self.port!r}, "
            f"protocol={self.protocol!r}, "
            f"https_proxy={self.https_proxy!r}, "
            f"https_proxy_port={self.https_proxy_port!r}, "
            f"service_name={self.service_name!r}, "
            f"instance_name={self.instance_name!r}, "
            f"sid={self.sid!r}, "
            f"server_type={self.server_type!r}, "
            f"cclass={self.cclass!r}, "
            f"purity={self.purity!r}, "
            f"expire_time={self.expire_time!r}, "
            f"retry_count={self.retry_count!r}, "
            f"retry_delay={self.retry_delay!r}, "
            f"tcp_connect_timeout={self.tcp_connect_timeout!r}, "
            f"ssl_server_dn_match={self.ssl_server_dn_match!r}, "
            f"ssl_server_cert_dn={self.ssl_server_cert_dn!r}, "
            f"wallet_location={self.wallet_location!r}, "
            f"events={self.events!r}, "
            f"externalauth={self.externalauth!r}, "
            f"mode={self.mode!r}, "
            f"disable_oob={self.disable_oob!r}, "
            f"stmtcachesize={self.stmtcachesize!r}, "
            f"edition={self.edition!r}, "
            f"tag={self.tag!r}, "
            f"matchanytag={self.matchanytag!r}, "
            f"config_dir={self.config_dir!r}, "
            f"appcontext={self.appcontext!r}, "
            f"shardingkey={self.shardingkey!r}, "
            f"supershardingkey={self.supershardingkey!r}, "
            f"debug_jdwp={self.debug_jdwp!r}, "
            f"connection_id_prefix={self.connection_id_prefix!r}, "
            f"ssl_context={self.ssl_context!r}, "
            f"sdu={self.sdu!r}, "
            f"pool_boundary={self.pool_boundary!r}, "
            f"use_tcp_fast_open={self.use_tcp_fast_open!r}, "
            f"ssl_version={self.ssl_version!r}, "
            f"program={self.program!r}, "
            f"machine={self.machine!r}, "
            f"terminal={self.terminal!r}, "
            f"osuser={self.osuser!r}, "
            f"driver_name={self.driver_name!r}, "
            f"use_sni={self.use_sni!r}, "
            f"thick_mode_dsn_passthrough={self.thick_mode_dsn_passthrough!r}, "
            f"extra_auth_params={self.extra_auth_params!r}"
            ")"
        )

    def _flatten_value(f):
        """
        Helper function used to flatten arrays of values if they only contain a
        single item.
        """

        @functools.wraps(f)
        def wrapped(self):
            values = f(self)
            return values if len(values) > 1 else values[0]

        return wrapped

    @property
    def appcontext(self) -> list:
        """
        Application context used by the connection. It should be a list of
        3-tuples (namespace, name, value) and each entry in the tuple should be
        a string. This value is only used in thick mode.
        """
        return self._impl.appcontext

    @property
    @_flatten_value
    def cclass(self) -> Union[list, str]:
        """
        Connection class to use for Database Resident Connection Pooling
        (DRCP).
        """
        return [d.cclass for d in self._impl.description_list.children]

    @property
    def config_dir(self) -> str:
        """
        Directory in which the optional tnsnames.ora configuration file is
        located. This value is only used in thin mode. For thick mode use the
        config_dir parameter of init_oracle_client().
        """
        return self._impl.config_dir

    @property
    @_flatten_value
    def connection_id_prefix(self) -> Union[list, str]:
        """
        An application specific prefix that is added to the connection
        identifier used for tracing.
        """
        return [
            d.connection_id_prefix
            for d in self._impl.description_list.children
        ]

    @property
    def debug_jdwp(self) -> str:
        """
        A string with the format "host=<host>;port=<port>" that specifies the
        host and port of the PL/SQL debugger. This value is only used in thin
        mode. For thick mode set the ORA_DEBUG_JDWP environment variable.
        """
        return self._impl.debug_jdwp

    @property
    def disable_oob(self) -> bool:
        """
        Boolean indicating whether out-of-band breaks should be disabled. This
        value is only used in thin mode. It has no effect on Windows which does
        not support this functionality.
        """
        return self._impl.disable_oob

    @property
    def driver_name(self) -> str:
        """
        The driver name used by the client to connect to the Oracle Database.
        """
        return self._impl.driver_name

    @property
    def edition(self) -> str:
        """
        Edition to use for the connection. This parameter cannot be used
        simultaneously with the cclass parameter.
        """
        return self._impl.edition

    @property
    def events(self) -> bool:
        """
        Boolean specifying whether events mode should be enabled. This value is
        only used in thick mode and is needed for continuous query notification
        and high availability event notifications.
        """
        return self._impl.events

    @property
    @_flatten_value
    def expire_time(self) -> Union[list, int]:
        """
        An integer indicating the number of minutes between the sending of
        keepalive probes. If this parameter is set to a value greater than zero
        it enables keepalive.
        """
        return [d.expire_time for d in self._impl.description_list.children]

    @property
    def externalauth(self) -> bool:
        """
        A boolean indicating whether to use external authentication.
        """
        return self._impl.externalauth

    @property
    def extra_auth_params(self) -> dict:
        """
        A dictionary containing configuration parameters necessary for Oracle
        Database authentication using plugins, such as the Azure and OCI cloud-
        native authentication plugins.
        """
        return self._impl.extra_auth_params

    @property
    @_flatten_value
    def host(self) -> Union[list, str]:
        """
        The name or IP address of the machine hosting the database or the
        database listener.
        """
        return [a.host for a in self._impl._get_addresses()]

    @property
    @_flatten_value
    def https_proxy(self) -> Union[list, str]:
        """
        The name or IP address of a proxy host to use for tunneling secure
        connections.
        """
        return [a.https_proxy for a in self._impl._get_addresses()]

    @property
    @_flatten_value
    def https_proxy_port(self) -> Union[list, int]:
        """
        The port on which to communicate with the proxy host.
        """
        return [a.https_proxy_port for a in self._impl._get_addresses()]

    @property
    @_flatten_value
    def instance_name(self) -> Union[list, str]:
        """
        The instance name of the database.
        """
        return [d.instance_name for d in self._impl.description_list.children]

    @property
    def machine(self) -> str:
        """
        The machine name of the client connecting to the Oracle Database.
        """
        return self._impl.machine

    @property
    def matchanytag(self) -> bool:
        """
        Boolean specifying whether any tag can be used when acquiring a
        connection from the pool. This value is only used in thick mode.
        """
        return self._impl.matchanytag

    @property
    def mode(self) -> oracledb.AuthMode:
        """
        Authorization mode to use. For example oracledb.AUTH_MODE_SYSDBA.
        """
        return oracledb.AuthMode(self._impl.mode)

    @property
    def osuser(self) -> str:
        """
        The operating system user that initiates the database connection.
        """
        return self._impl.osuser

    @property
    @_flatten_value
    def pool_boundary(self) -> Union[list, str]:
        """
        One of the values "statement" or "transaction" indicating when pooled
        DRCP connections can be returned to the pool. This requires the use of
        DRCP with Oracle Database 23.4 or higher.
        """
        return [d.pool_boundary for d in self._impl.description_list.children]

    @property
    @_flatten_value
    def port(self) -> Union[list, int]:
        """
        The port number on which the database listener is listening.
        """
        return [a.port for a in self._impl._get_addresses()]

    @property
    def program(self) -> str:
        """
        The name of the executable program or application connected to the
        Oracle Database.
        """
        return self._impl.program

    @property
    @_flatten_value
    def protocol(self) -> Union[list, str]:
        """
        One of the strings "tcp" or "tcps" indicating whether to use
        unencrypted network traffic or encrypted network traffic (TLS).
        """
        return [a.protocol for a in self._impl._get_addresses()]

    @property
    def proxy_user(self) -> str:
        """
        The name of the proxy user to connect to. If this value is not
        specified, it will be parsed out of user if user is in the form
        "user[proxy_user]".
        """
        return self._impl.proxy_user

    @property
    @_flatten_value
    def purity(self) -> Union[list, oracledb.Purity]:
        """
        Purity to use for Database Resident Connection Pooling (DRCP).
        """
        return [
            oracledb.Purity(d.purity)
            for d in self._impl.description_list.children
        ]

    @property
    @_flatten_value
    def retry_count(self) -> Union[list, int]:
        """
        The number of times that a connection attempt should be retried before
        the attempt is terminated.
        """
        return [d.retry_count for d in self._impl.description_list.children]

    @property
    @_flatten_value
    def retry_delay(self) -> Union[list, int]:
        """
        The number of seconds to wait before making a new connection attempt.
        """
        return [d.retry_delay for d in self._impl.description_list.children]

    @property
    @_flatten_value
    def sdu(self) -> Union[list, int]:
        """
        The requested size of the Session Data Unit (SDU), in bytes. The value
        tunes internal buffers used for communication to the database. Bigger
        values can increase throughput for large queries or bulk data loads,
        but at the cost of higher memory use. The SDU size that will actually
        be used is negotiated down to the lower of this value and the database
        network SDU configuration value.
        """
        return [d.sdu for d in self._impl.description_list.children]

    @property
    @_flatten_value
    def server_type(self) -> Union[list, str]:
        """
        The type of server connection that should be established. If specified,
        it should be one of "dedicated", "shared" or "pooled".
        """
        return [d.server_type for d in self._impl.description_list.children]

    @property
    @_flatten_value
    def service_name(self) -> Union[list, str]:
        """
        The service name of the database.
        """
        return [d.service_name for d in self._impl.description_list.children]

    @property
    def shardingkey(self) -> list:
        """
        A list of strings, numbers, bytes or dates that identify the database
        shard to connect to. This value is only used in thick mode.
        """
        return self._impl.shardingkey

    @property
    @_flatten_value
    def sid(self) -> Union[list, str]:
        """
        The system identifier (SID) of the database. Note using a service_name
        instead is recommended.
        """
        return [d.sid for d in self._impl.description_list.children]

    @property
    def ssl_context(self) -> Any:
        """
        An SSLContext object used for connecting to the database using TLS.
        This SSL context will be modified to include the private key or any
        certificates found in a separately supplied wallet. This parameter
        should only be specified if the default SSLContext object cannot be
        used.
        """
        return self._impl.ssl_context

    @property
    @_flatten_value
    def ssl_server_cert_dn(self) -> Union[list, str]:
        """
        The distinguished name (DN) which should be matched with the server.
        This value is ignored if the ssl_server_dn_match parameter is not set
        to the value True. If specified this value is used for any verfication.
        Otherwise the hostname will be used.
        """
        return [
            d.ssl_server_cert_dn for d in self._impl.description_list.children
        ]

    @property
    @_flatten_value
    def ssl_server_dn_match(self) -> Union[list, bool]:
        """
        Boolean indicating whether the server certificate distinguished name
        (DN) should be matched in addition to the regular certificate
        verification that is performed. Note that if the ssl_server_cert_dn
        parameter is not privided, host name matching is performed instead.
        """
        return [
            d.ssl_server_dn_match for d in self._impl.description_list.children
        ]

    @property
    @_flatten_value
    def ssl_version(self) -> Union[list, ssl.TLSVersion]:
        """
        One of the values ssl.TLSVersion.TLSv1_2 or ssl.TLSVersion.TLSv1_3
        indicating which TLS version to use.
        """
        return [d.ssl_version for d in self._impl.description_list.children]

    @property
    def stmtcachesize(self) -> int:
        """
        Identifies the initial size of the statement cache.
        """
        return self._impl.stmtcachesize

    @property
    def supershardingkey(self) -> list:
        """
        A list of strings, numbers, bytes or dates that identify the database
        shard to connect to. This value is only used in thick mode.
        """
        return self._impl.supershardingkey

    @property
    def tag(self) -> str:
        """
        Identifies the type of connection that should be returned from a pool.
        This value is only used in thick mode.
        """
        return self._impl.tag

    @property
    @_flatten_value
    def tcp_connect_timeout(self) -> Union[list, float]:
        """
        A float indicating the maximum number of seconds to wait for
        establishing a connection to the database host.
        """
        return [
            d.tcp_connect_timeout for d in self._impl.description_list.children
        ]

    @property
    def terminal(self) -> str:
        """
        The terminal identifier from which the connection originates.
        """
        return self._impl.terminal

    @property
    def thick_mode_dsn_passthrough(self) -> bool:
        """
        Boolean indicating whether to pass the connect string to the Oracle
        Client libraries unchanged without parsing by the driver. Setting this
        to False makes thick and thin mode applications behave similarly
        regarding connection string parameter handling and locating any
        optional tnsnames.ora configuration file.
        """
        return self._impl.thick_mode_dsn_passthrough

    @property
    def user(self) -> str:
        """
        The name of the user to connect to.
        """
        return self._impl.user

    @property
    @_flatten_value
    def use_sni(self) -> Union[list, bool]:
        """
        Boolean indicating whether to use the TLS SNI extension to bypass the
        second TLS neogiation that would otherwise be required.
        """
        return [d.use_sni for d in self._impl.description_list.children]

    @property
    @_flatten_value
    def use_tcp_fast_open(self) -> Union[list, bool]:
        """
        Boolean indicating whether to use TCP fast open. This is an Oracle
        Autonomous Database Serverless (ADB-S) specific property for clients
        connecting from within OCI Cloud network. Please refer to the ADB-S
        documentation for more information.
        """
        return [
            d.use_tcp_fast_open for d in self._impl.description_list.children
        ]

    @property
    @_flatten_value
    def wallet_location(self) -> Union[list, str]:
        """
        The directory where the wallet can be found. In thin mode this must be
        the directory containing the PEM-encoded wallet file ewallet.pem. In
        thick mode this must be the directory containing the file cwallet.sso.
        """
        return [
            d.wallet_location for d in self._impl.description_list.children
        ]

    def copy(self) -> "ConnectParams":
        """
        Creates a copy of the parameters and returns it.
        """
        params = ConnectParams.__new__(ConnectParams)
        params._impl = self._impl.copy()
        return params

    def get_connect_string(self) -> str:
        """
        Returns a connect string generated from the parameters.
        """
        return self._impl.get_connect_string()

    def get_network_service_names(self) -> list:
        """
        Returns a list of the network service names found in the tnsnames.ora
        file found in the configuration directory associated with the
        parameters. If no such file exists, an error is raised.
        """
        return self._impl.get_network_service_names()

    def parse_connect_string(self, connect_string: str) -> None:
        """
        Parses the connect string into its components and stores the
        parameters.  The connect string could be an Easy Connect string,
        name-value pairs or a simple alias which is looked up in tnsnames.ora.
        Any parameters found in the connect string override any currently
        stored values.
        """
        self._impl.parse_connect_string(connect_string)

    def parse_dsn_with_credentials(self, dsn: str) -> tuple:
        """
        Parses a dsn in the form <user>/<password>@<connect_string> or in the
        form <user>/<password> and returns a 3-tuple containing the parsed
        user, password and connect string. Empty strings are returned as the
        value None. This is done automatically when a value is passed to
        the dsn parameter but no value is passed to the user password when
        creating a standalone connection or connection pool.
        """
        return self._impl.parse_dsn_with_credentials(dsn)

    @utils.params_setter
    def set(
        self,
        *,
        user: Optional[str] = None,
        proxy_user: Optional[str] = None,
        password: Optional[str] = None,
        newpassword: Optional[str] = None,
        wallet_password: Optional[str] = None,
        access_token: Optional[Union[str, tuple, Callable]] = None,
        host: Optional[str] = None,
        port: Optional[int] = None,
        protocol: Optional[str] = None,
        https_proxy: Optional[str] = None,
        https_proxy_port: Optional[int] = None,
        service_name: Optional[str] = None,
        instance_name: Optional[str] = None,
        sid: Optional[str] = None,
        server_type: Optional[str] = None,
        cclass: Optional[str] = None,
        purity: Optional[oracledb.Purity] = None,
        expire_time: Optional[int] = None,
        retry_count: Optional[int] = None,
        retry_delay: Optional[int] = None,
        tcp_connect_timeout: Optional[float] = None,
        ssl_server_dn_match: Optional[bool] = None,
        ssl_server_cert_dn: Optional[str] = None,
        wallet_location: Optional[str] = None,
        events: Optional[bool] = None,
        externalauth: Optional[bool] = None,
        mode: Optional[oracledb.AuthMode] = None,
        disable_oob: Optional[bool] = None,
        stmtcachesize: Optional[int] = None,
        edition: Optional[str] = None,
        tag: Optional[str] = None,
        matchanytag: Optional[bool] = None,
        config_dir: Optional[str] = None,
        appcontext: Optional[list] = None,
        shardingkey: Optional[list] = None,
        supershardingkey: Optional[list] = None,
        debug_jdwp: Optional[str] = None,
        connection_id_prefix: Optional[str] = None,
        ssl_context: Optional[Any] = None,
        sdu: Optional[int] = None,
        pool_boundary: Optional[str] = None,
        use_tcp_fast_open: Optional[bool] = None,
        ssl_version: Optional[ssl.TLSVersion] = None,
        program: Optional[str] = None,
        machine: Optional[str] = None,
        terminal: Optional[str] = None,
        osuser: Optional[str] = None,
        driver_name: Optional[str] = None,
        use_sni: Optional[bool] = None,
        thick_mode_dsn_passthrough: Optional[bool] = None,
        extra_auth_params: Optional[dict] = None,
        handle: Optional[int] = None,
    ):
        """
        All parameters are optional. A brief description of each parameter
        follows:

        - user: the name of the user to connect to

        - proxy_user: the name of the proxy user to connect to. If this value
          is not specified, it will be parsed out of user if user is in the
          form "user[proxy_user]"

        - password: the password for the user

        - newpassword: the new password for the user. The new password will
          take effect immediately upon a successful connection to the database

        - wallet_password: the password to use to decrypt the wallet, if it is
          encrypted. This value is only used in thin mode

        - access_token: expected to be a string or a 2-tuple or a callable. If
          it is a string, it specifies an Azure AD OAuth2 token used for Open
          Authorization (OAuth 2.0) token based authentication. If it is a
          2-tuple, it specifies the token and private key strings used for
          Oracle Cloud Infrastructure (OCI) Identity and Access Management
          (IAM) token based authentication. If it is a callable, it returns
          either a string or a 2-tuple used for OAuth 2.0 or OCI IAM token
          based authentication and is useful when the pool needs to expand and
          create new connections but the current authentication token has
          expired

        - host: the name or IP address of the machine hosting the database or
          the database listener

        - port: the port number on which the database listener is listening

        - protocol: one of the strings "tcp" or "tcps" indicating whether to
          use unencrypted network traffic or encrypted network traffic (TLS)

        - https_proxy: the name or IP address of a proxy host to use for
          tunneling secure connections

        - https_proxy_port: the port on which to communicate with the proxy
          host

        - service_name: the service name of the database

        - instance_name: the instance name of the database

        - sid: the system identifier (SID) of the database. Note using a
          service_name instead is recommended

        - server_type: the type of server connection that should be
          established. If specified, it should be one of "dedicated", "shared"
          or "pooled"

        - cclass: connection class to use for Database Resident Connection
          Pooling (DRCP)

        - purity: purity to use for Database Resident Connection Pooling (DRCP)

        - expire_time: an integer indicating the number of minutes between the
          sending of keepalive probes. If this parameter is set to a value
          greater than zero it enables keepalive

        - retry_count: the number of times that a connection attempt should be
          retried before the attempt is terminated

        - retry_delay: the number of seconds to wait before making a new
          connection attempt

        - tcp_connect_timeout: a float indicating the maximum number of seconds
          to wait for establishing a connection to the database host

        - ssl_server_dn_match: boolean indicating whether the server
          certificate distinguished name (DN) should be matched in addition to
          the regular certificate verification that is performed. Note that if
          the ssl_server_cert_dn parameter is not privided, host name matching
          is performed instead

        - ssl_server_cert_dn: the distinguished name (DN) which should be
          matched with the server. This value is ignored if the
          ssl_server_dn_match parameter is not set to the value True. If
          specified this value is used for any verfication. Otherwise the
          hostname will be used

        - wallet_location: the directory where the wallet can be found. In thin
          mode this must be the directory containing the PEM-encoded wallet
          file ewallet.pem. In thick mode this must be the directory containing
          the file cwallet.sso

        - events: boolean specifying whether events mode should be enabled.
          This value is only used in thick mode and is needed for continuous
          query notification and high availability event notifications

        - externalauth: a boolean indicating whether to use external
          authentication

        - mode: authorization mode to use. For example
          oracledb.AUTH_MODE_SYSDBA

        - disable_oob: boolean indicating whether out-of-band breaks should be
          disabled. This value is only used in thin mode. It has no effect on
          Windows which does not support this functionality

        - stmtcachesize: identifies the initial size of the statement cache

        - edition: edition to use for the connection. This parameter cannot be
          used simultaneously with the cclass parameter

        - tag: identifies the type of connection that should be returned from a
          pool. This value is only used in thick mode

        - matchanytag: boolean specifying whether any tag can be used when
          acquiring a connection from the pool. This value is only used in
          thick mode

        - config_dir: directory in which the optional tnsnames.ora
          configuration file is located. This value is only used in thin mode.
          For thick mode use the config_dir parameter of init_oracle_client()

        - appcontext: application context used by the connection. It should be
          a list of 3-tuples (namespace, name, value) and each entry in the
          tuple should be a string. This value is only used in thick mode

        - shardingkey: a list of strings, numbers, bytes or dates that identify
          the database shard to connect to. This value is only used in thick
          mode

        - supershardingkey: a list of strings, numbers, bytes or dates that
          identify the database shard to connect to. This value is only used in
          thick mode

        - debug_jdwp: a string with the format "host=<host>;port=<port>" that
          specifies the host and port of the PL/SQL debugger. This value is
          only used in thin mode. For thick mode set the ORA_DEBUG_JDWP
          environment variable

        - connection_id_prefix: an application specific prefix that is added to
          the connection identifier used for tracing

        - ssl_context: an SSLContext object used for connecting to the database
          using TLS.  This SSL context will be modified to include the private
          key or any certificates found in a separately supplied wallet. This
          parameter should only be specified if the default SSLContext object
          cannot be used

        - sdu: the requested size of the Session Data Unit (SDU), in bytes. The
          value tunes internal buffers used for communication to the database.
          Bigger values can increase throughput for large queries or bulk data
          loads, but at the cost of higher memory use. The SDU size that will
          actually be used is negotiated down to the lower of this value and
          the database network SDU configuration value

        - pool_boundary: one of the values "statement" or "transaction"
          indicating when pooled DRCP connections can be returned to the pool.
          This requires the use of DRCP with Oracle Database 23.4 or higher

        - use_tcp_fast_open: boolean indicating whether to use TCP fast open.
          This is an Oracle Autonomous Database Serverless (ADB-S) specific
          property for clients connecting from within OCI Cloud network. Please
          refer to the ADB-S documentation for more information

        - ssl_version: one of the values ssl.TLSVersion.TLSv1_2 or
          ssl.TLSVersion.TLSv1_3 indicating which TLS version to use

        - program: the name of the executable program or application connected
          to the Oracle Database

        - machine: the machine name of the client connecting to the Oracle
          Database

        - terminal: the terminal identifier from which the connection
          originates

        - osuser: the operating system user that initiates the database
          connection

        - driver_name: the driver name used by the client to connect to the
          Oracle Database

        - use_sni: boolean indicating whether to use the TLS SNI extension to
          bypass the second TLS neogiation that would otherwise be required

        - thick_mode_dsn_passthrough: boolean indicating whether to pass the
          connect string to the Oracle Client libraries unchanged without
          parsing by the driver. Setting this to False makes thick and thin
          mode applications behave similarly regarding connection string
          parameter handling and locating any optional tnsnames.ora
          configuration file

        - extra_auth_params: a dictionary containing configuration parameters
          necessary for Oracle Database authentication using plugins, such as
          the Azure and OCI cloud-native authentication plugins

        - handle: an integer representing a pointer to a valid service context
          handle. This value is only used in thick mode. It should be used with
          extreme caution
        """
        pass

    def set_from_config(self, config: dict) -> None:
        """
        Sets the property values based on the supplied configuration. The
        configuration consists of a dictionary with the following keys, all of
        which are optional: "connect_descriptor", "user", "password" and "pyo".

        If the "connect_descriptor" key is supplied, it is expected to be a
        string, which will be parsed and the properties found within it stored
        in the parameters.

        If the "user" or "password" keys are supplied, and the parameters do
        not already have a user or password, these values will be stored;
        otherwise, they will be ignored. The "user" key is expected to be a
        string. The "password" key may be a string or it may be a dictionary
        containing the keys "type" and "value" which will be used to determine
        the actual password.

        If the "pyo" key is supplied, it is expected to be a dictionary
        containing keys corresponding to property names. Any property names
        accepted by the parameters will be stored; all other values will be
        ignored.
        """
        self._impl.set_from_config(config)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\constants.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2020, 2023, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# constants.py
#
# Contains the constants defined by the package.
# -----------------------------------------------------------------------------

# mandated DB API constants
apilevel = "2.0"
threadsafety = 2
paramstyle = "named"

# AQ delivery modes
MSG_BUFFERED = 2
MSG_PERSISTENT = 1
MSG_PERSISTENT_OR_BUFFERED = 3

# AQ dequeue modes
DEQ_BROWSE = 1
DEQ_LOCKED = 2
DEQ_REMOVE = 3
DEQ_REMOVE_NODATA = 4

# AQ dequeue navigation modes
DEQ_FIRST_MSG = 1
DEQ_NEXT_MSG = 3
DEQ_NEXT_TRANSACTION = 2

# AQ dequeue visibility modes
DEQ_IMMEDIATE = 1
DEQ_ON_COMMIT = 2

# AQ dequeue wait modes
DEQ_NO_WAIT = 0
DEQ_WAIT_FOREVER = 2**32 - 1

# AQ enqueue visibility modes
ENQ_IMMEDIATE = 1
ENQ_ON_COMMIT = 2

# AQ message states
MSG_EXPIRED = 3
MSG_PROCESSED = 2
MSG_READY = 0
MSG_WAITING = 1

# AQ other constants
MSG_NO_DELAY = 0
MSG_NO_EXPIRATION = -1

# shutdown modes
DBSHUTDOWN_ABORT = 4
DBSHUTDOWN_FINAL = 5
DBSHUTDOWN_IMMEDIATE = 3
DBSHUTDOWN_TRANSACTIONAL = 1
DBSHUTDOWN_TRANSACTIONAL_LOCAL = 2

# subscription grouping classes
SUBSCR_GROUPING_CLASS_NONE = 0
SUBSCR_GROUPING_CLASS_TIME = 1

# subscription grouping types
SUBSCR_GROUPING_TYPE_SUMMARY = 1
SUBSCR_GROUPING_TYPE_LAST = 2

# subscription namespaces
SUBSCR_NAMESPACE_AQ = 1
SUBSCR_NAMESPACE_DBCHANGE = 2

# subscription protocols
SUBSCR_PROTO_HTTP = 3
SUBSCR_PROTO_MAIL = 1
SUBSCR_PROTO_CALLBACK = 0
SUBSCR_PROTO_SERVER = 2

# subscription quality of service
SUBSCR_QOS_BEST_EFFORT = 0x10
SUBSCR_QOS_DEFAULT = 0
SUBSCR_QOS_DEREG_NFY = 0x02
SUBSCR_QOS_QUERY = 0x08
SUBSCR_QOS_RELIABLE = 0x01
SUBSCR_QOS_ROWIDS = 0x04

# event types
EVENT_AQ = 100
EVENT_DEREG = 5
EVENT_NONE = 0
EVENT_OBJCHANGE = 6
EVENT_QUERYCHANGE = 7
EVENT_SHUTDOWN = 2
EVENT_SHUTDOWN_ANY = 3
EVENT_STARTUP = 1

# operation codes
OPCODE_ALLOPS = 0
OPCODE_ALLROWS = 0x01
OPCODE_ALTER = 0x10
OPCODE_DELETE = 0x08
OPCODE_DROP = 0x20
OPCODE_INSERT = 0x02
OPCODE_UPDATE = 0x04

# flags for tpc_begin()
TPC_BEGIN_JOIN = 0x00000002
TPC_BEGIN_NEW = 0x00000001
TPC_BEGIN_PROMOTE = 0x00000008
TPC_BEGIN_RESUME = 0x00000004

# flags for tpc_end()
TPC_END_NORMAL = 0
TPC_END_SUSPEND = 0x00100000

# vector metadata flags
VECTOR_META_FLAG_FLEXIBLE_DIM = 0x01
VECTOR_META_FLAG_SPARSE_VECTOR = 0x02


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\constructors.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2020, 2023, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# constructors.py
#
# Contains the constructors mandated by the Python Database API.
# -----------------------------------------------------------------------------

import datetime

from . import errors

# synonyms for the types mandated by the database API
Binary = bytes
Date = datetime.date
Timestamp = datetime.datetime


def Time(hour: int, minute: int, second: int) -> None:
    """
    Constructor mandated by the database API for creating a time value. Since
    Oracle doesn't support time only values, an exception is raised when this
    method is called.
    """
    errors._raise_err(errors.ERR_TIME_NOT_SUPPORTED)


def DateFromTicks(ticks: float) -> datetime.date:
    """
    Constructor mandated by the database API for creating a date value given
    the number of seconds since the epoch (January 1, 1970). This is equivalent
    to using datetime.date.fromtimestamp() and that should be used instead.
    """
    return datetime.date.fromtimestamp(ticks)


def TimeFromTicks(ticks: float) -> None:
    """
    Constructor mandated by the database API for creating a time value given
    the number of seconds since the epoch (January 1, 1970). Since Oracle
    doesn't support time only values, an exception is raised when this method
    is called.
    """
    errors._raise_err(errors.ERR_TIME_NOT_SUPPORTED)


def TimestampFromTicks(ticks: float) -> datetime.datetime:
    """
    Constructor mandated by the database API for creating a timestamp value
    given the number of seconds since the epoch (January 1, 1970). This is
    equivalent to using datetime.datetime.fromtimestamp() and that should be
    used instead.
    """
    return datetime.datetime.fromtimestamp(ticks)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\cursor.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2021, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# cursor.py
#
# Contains the Cursor class used for executing statements on connections and
# fetching results from queries.
# -----------------------------------------------------------------------------

from typing import Any, Union, Callable, Optional

from . import __name__ as MODULE_NAME
from . import connection as connection_module
from . import errors
from . import utils
from .fetch_info import FetchInfo
from .var import Var
from .base_impl import DbType, DB_TYPE_OBJECT
from .dbobject import DbObjectType


class BaseCursor:
    _impl = None

    def __init__(
        self,
        connection: "connection_module.Connection",
        scrollable: bool = False,
    ) -> None:
        self.connection = connection
        self._impl = connection._impl.create_cursor_impl(scrollable)

    def __del__(self):
        if self._impl is not None:
            self._impl.close(in_del=True)

    def __enter__(self):
        self._verify_open()
        return self

    def __exit__(self, exc_type, exc_value, exc_tb):
        self._verify_open()
        self._impl.close(in_del=True)
        self._impl = None

    def __repr__(self):
        typ = self.__class__
        cls_name = f"{typ.__module__}.{typ.__qualname__}"
        return f"<{cls_name} on {self.connection!r}>"

    def _call(
        self,
        name: str,
        parameters: Union[list, tuple],
        keyword_parameters: dict,
        return_value: Any = None,
    ) -> None:
        """
        Internal method used for generating the PL/SQL block used to call
        stored procedures.
        """
        utils.verify_stored_proc_args(parameters, keyword_parameters)
        self._verify_open()
        statement, bind_values = self._call_get_execute_args(
            name, parameters, keyword_parameters, return_value
        )
        return self.execute(statement, bind_values)

    def _call_get_execute_args(
        self,
        name: str,
        parameters: Union[list, tuple],
        keyword_parameters: dict,
        return_value: str = None,
    ) -> None:
        """
        Internal method used for generating the PL/SQL block used to call
        stored procedures and functions. A tuple containing this statement and
        the bind values is returned.
        """
        bind_names = []
        bind_values = []
        statement_parts = ["begin "]
        if return_value is not None:
            statement_parts.append(":retval := ")
            bind_values.append(return_value)
        statement_parts.append(name + "(")
        if parameters:
            bind_values.extend(parameters)
            bind_names = [":%d" % (i + 1) for i in range(len(parameters))]
        if keyword_parameters:
            for arg_name, arg_value in keyword_parameters.items():
                bind_values.append(arg_value)
                bind_names.append(f"{arg_name} => :{len(bind_names) + 1}")
        statement_parts.append(",".join(bind_names))
        statement_parts.append("); end;")
        statement = "".join(statement_parts)
        return (statement, bind_values)

    def _prepare(
        self, statement: str, tag: str = None, cache_statement: bool = True
    ) -> None:
        """
        Internal method used for preparing a statement for execution.
        """
        self._impl.prepare(statement, tag, cache_statement)

    def _prepare_for_execute(
        self, statement, parameters, keyword_parameters=None
    ):
        """
        Internal method for preparing a statement for execution.
        """
        self._verify_open()
        self._impl._prepare_for_execute(
            self, statement, parameters, keyword_parameters
        )

    def _verify_fetch(self) -> None:
        """
        Verifies that fetching is possible from this cursor.
        """
        self._verify_open()
        if not self._impl.is_query(self):
            errors._raise_err(errors.ERR_NOT_A_QUERY)

    def _verify_open(self) -> None:
        """
        Verifies that the cursor is open and the associated connection is
        connected. If either condition is false an exception is raised.
        """
        if self._impl is None:
            errors._raise_err(errors.ERR_CURSOR_NOT_OPEN)
        self.connection._verify_connected()

    @property
    def arraysize(self) -> int:
        """
        Tunes the number of rows fetched and buffered by internal calls to the
        database when fetching rows from SELECT statements and REF CURSORS. The
        value can drastically affect the performance of a query since it
        directly affects the number of network round trips between Python and
        the database. For methods like fetchone() and fetchall() it does not
        change how many rows are returned to the application. For fetchmany()
        it is the default number of rows to fetch.

        Due to the performance benefits, the default value is 100 instead of
        the 1 that the DB API recommends. This value means that 100 rows are
        fetched by each internal call to the database.
        """
        self._verify_open()
        return self._impl.arraysize

    @arraysize.setter
    def arraysize(self, value: int) -> None:
        self._verify_open()
        if not isinstance(value, int) or value <= 0:
            errors._raise_err(errors.ERR_INVALID_ARRAYSIZE)
        self._impl.arraysize = value

    def arrayvar(
        self,
        typ: Union[DbType, DbObjectType, type],
        value: Union[list, int],
        size: int = 0,
    ) -> Var:
        """
        Create an array variable associated with the cursor of the given type
        and size and return a variable object. The value is either an integer
        specifying the number of elements to allocate or it is a list and the
        number of elements allocated is drawn from the size of the list. If the
        value is a list, the variable is also set with the contents of the
        list. If the size is not specified and the type is a string or binary,
        4000 bytes is allocated. This is needed for passing arrays to PL/SQL
        (in cases where the list might be empty and the type cannot be
        determined automatically) or returning arrays from PL/SQL.

        Array variables can only be used for PL/SQL associative arrays with
        contiguous keys. For PL/SQL associative arrays with sparsely populated
        keys or for varrays and nested tables, the DbObject approach needs to
        be used instead.
        """
        self._verify_open()
        if isinstance(value, list):
            num_elements = len(value)
        elif isinstance(value, int):
            num_elements = value
        else:
            raise TypeError("expecting integer or list of values")
        var = self._impl.create_var(
            self.connection,
            typ,
            size=size,
            num_elements=num_elements,
            is_array=True,
        )
        if isinstance(value, list):
            var.setvalue(0, value)
        return var

    def bindnames(self) -> list:
        """
        Return the list of bind variable names bound to the statement. Note
        that a statement must have been prepared first.
        """
        self._verify_open()
        if self._impl.statement is None:
            errors._raise_err(errors.ERR_NO_STATEMENT_PREPARED)
        return self._impl.get_bind_names()

    @property
    def bindvars(self) -> list:
        """
        Returns the bind variables used for the last execute. The value will be
        either a list or a dictionary depending on whether binding was done by
        position or name. Care should be taken when referencing this attribute.
        In particular, elements should not be removed or replaced.
        """
        self._verify_open()
        return self._impl.get_bind_vars()

    def close(self) -> None:
        """
        Close the cursor now, rather than whenever __del__ is called. The
        cursor will be unusable from this point forward; an Error exception
        will be raised if any operation is attempted with the cursor.
        """
        self._verify_open()
        self._impl.close()
        self._impl = None

    @property
    def description(self) -> tuple:
        """
        Returns a sequence of 7-item sequences. Each of these sequences
        contains information describing one result column: (name, type,
        display_size, internal_size, precision, scale, null_ok).  This
        attribute will be None for operations that do not return rows or if the
        cursor has not had an operation invoked via the execute() method yet.
        """
        self._verify_open()
        if self._impl.is_query(self):
            return [FetchInfo._from_impl(i) for i in self._impl.fetch_metadata]

    @property
    def fetchvars(self) -> list:
        """
        Specifies the list of variables created for the last query that was
        executed on the cursor. Care should be taken when referencing this
        attribute. In particular, elements should not be removed or replaced.
        """
        self._verify_open()
        return self._impl.get_fetch_vars()

    def getarraydmlrowcounts(self) -> list:
        """
        Return the DML row counts after a call to executemany() with
        arraydmlrowcounts enabled. This will return a list of integers
        corresponding to the number of rows affected by the DML statement for
        each element of the array passed to executemany().
        """
        self._verify_open()
        return self._impl.get_array_dml_row_counts()

    def getbatcherrors(self) -> list:
        """
        Return the exceptions that took place after a call to executemany()
        with batcherrors enabled. This will return a list of Error objects, one
        error for each iteration that failed. The offset can be determined by
        looking at the offset attribute of the error object.
        """
        self._verify_open()
        return self._impl.get_batch_errors()

    def getimplicitresults(self) -> list:
        """
        Return a list of cursors which correspond to implicit results made
        available from a PL/SQL block or procedure without the use of OUT ref
        cursor parameters. The PL/SQL block or procedure opens the cursors and
        marks them for return to the client using the procedure
        dbms_sql.return_result. Cursors returned in this fashion should not be
        closed. They will be closed automatically by the parent cursor when it
        is closed. Closing the parent cursor will invalidate the cursors
        returned by this method.
        """
        self._verify_open()
        return self._impl.get_implicit_results(self.connection)

    @property
    def inputtypehandler(self) -> Callable:
        """
        Specifies a method called for each value that is bound to a statement
        executed on this cursor. The method signature is handler(cursor, value,
        arraysize) and the return value is expected to be a variable object or
        None in which case a default variable object will be created. If this
        attribute is None, the default behavior will take place for all values
        bound to statements.
        """
        self._verify_open()
        return self._impl.inputtypehandler

    @inputtypehandler.setter
    def inputtypehandler(self, value: Callable) -> None:
        self._verify_open()
        self._impl.inputtypehandler = value

    @property
    def lastrowid(self) -> str:
        """
        Returns the rowid of the last row modified by the cursor. If no row was
        modified by the last operation performed on the cursor, the value None
        is returned.
        """
        self._verify_open()
        return self._impl.get_lastrowid()

    @property
    def outputtypehandler(self) -> Callable:
        """
        Specifies a method called for each column that is going to be fetched
        from this cursor. The method signature is handler(cursor, name,
        defaultType, length, precision, scale) and the return value is expected
        to be a variable object or None in which case a default variable object
        will be created. If this attribute is None, the default behavior will
        take place for all columns fetched from this cursor.
        """
        self._verify_open()
        return self._impl.outputtypehandler

    @outputtypehandler.setter
    def outputtypehandler(self, value: Callable) -> None:
        self._verify_open()
        self._impl.outputtypehandler = value

    @property
    def prefetchrows(self) -> int:
        """
        Used to tune the number of rows fetched when a SELECT statement is
        executed. This value can reduce the number of round-trips to the
        database that are required to fetch rows but at the cost of additional
        memory. Setting this value to 0 can be useful when the timing of
        fetches must be explicitly controlled.
        """
        self._verify_open()
        return self._impl.prefetchrows

    @prefetchrows.setter
    def prefetchrows(self, value: int) -> None:
        self._verify_open()
        self._impl.prefetchrows = value

    def prepare(
        self, statement: str, tag: str = None, cache_statement: bool = True
    ) -> None:
        """
        This can be used before a call to execute() to define the statement
        that will be executed. When this is done, the prepare phase will not be
        performed when the call to execute() is made with None or the same
        string object as the statement. If the tag parameter is specified and
        the cache_statement parameter is True, the statement will be returned
        to the statement cache with the given tag. If the cache_statement
        parameter is False, the statement will be removed from the statement
        cache (if it was found there) or will simply not be cached. See the
        Oracle documentation for more information about the statement cache.
        """
        self._verify_open()
        self._prepare(statement, tag, cache_statement)

    @property
    def rowcount(self) -> int:
        """
        This read-only attribute specifies the number of rows that have
        currently been fetched from the cursor (for select statements), that
        have been affected by the operation (for insert, update, delete and
        merge statements), or the number of successful executions of the
        statement (for PL/SQL statements).
        """
        if self._impl is not None and self.connection._impl is not None:
            return self._impl.rowcount
        return -1

    @property
    def rowfactory(self) -> Callable:
        """
        Specifies a method to call for each row that is retrieved from the
        database.  Ordinarily a tuple is returned for each row but if this
        attribute is set, the method is called with the tuple that would
        normally be returned, and the result of the method is returned instead.
        """
        self._verify_open()
        return self._impl.rowfactory

    @rowfactory.setter
    def rowfactory(self, value: Callable) -> None:
        self._verify_open()
        self._impl.rowfactory = value

    @property
    def scrollable(self) -> bool:
        """
        Specifies whether the cursor can be scrolled or not. By default,
        cursors are not scrollable, as the server resources and response times
        are greater than for nonscrollable cursors. This attribute is checked
        and the corresponding mode set in Oracle when calling the method
        execute().
        """
        self._verify_open()
        return self._impl.scrollable

    @scrollable.setter
    def scrollable(self, value: bool) -> None:
        self._verify_open()
        self._impl.scrollable = value

    def setinputsizes(self, *args: Any, **kwargs: Any) -> Union[list, dict]:
        """
        This can be used before a call to execute(), callfunc() or callproc()
        to predefine memory areas for the operation’s parameters. Each
        parameter should be a type object corresponding to the input that will
        be used or it should be an integer specifying the maximum length of a
        string parameter. Use keyword parameters when binding by name and
        positional parameters when binding by position. The singleton None can
        be used as a parameter when using positional parameters to indicate
        that no space should be reserved for that position.
        """
        if args and kwargs:
            errors._raise_err(errors.ERR_ARGS_AND_KEYWORD_ARGS)
        elif args or kwargs:
            self._verify_open()
            return self._impl.setinputsizes(self.connection, args, kwargs)
        return []

    def setoutputsize(self, size: int, column: int = 0) -> None:
        """
        Sets a column buffer size for fetches of long columns.  However
        python-oracledb does not require it so this method does nothing.
        """
        pass

    @property
    def statement(self) -> Union[str, None]:
        """
        Returns the statement associated with the cursor, if one is present.
        """
        if self._impl is not None:
            return self._impl.statement

    def var(
        self,
        typ: Union[DbType, DbObjectType, type],
        size: int = 0,
        arraysize: int = 1,
        inconverter: Callable = None,
        outconverter: Callable = None,
        typename: str = None,
        encoding_errors: str = None,
        bypass_decode: bool = False,
        convert_nulls: bool = False,
        *,
        encodingErrors: str = None,
    ) -> "Var":
        """
        Create a variable with the specified characteristics. This method was
        designed for use with PL/SQL in/out variables where the length or type
        cannot be determined automatically from the Python object passed in or
        for use in input and output type handlers defined on cursors or
        connections.

        The typ parameter specifies the type of data that should be stored
        in the variable. This should be one of the database type constants, DB
        API constants, an object type returned from the method
        Connection.gettype() or one of the following Python types:

            Python Type         Database Type
            bool                DB_TYPE_BOOLEAN
            bytes               DB_TYPE_RAW
            datetime.date       DB_TYPE_DATE
            datetime.datetime   DB_TYPE_DATE
            datetime.timedelta  DB_TYPE_INTERVAL_DS
            decimal.Decimal     DB_TYPE_NUMBER
            float               DB_TYPE_NUMBER
            int                 DB_TYPE_NUMBER
            str                 DB_TYPE_VARCHAR

        The size parameter specifies the length of string and raw variables and
        is ignored in all other cases. If not specified for string and raw
        variables, the value 4000 is used.

        The arraysize parameter specifies the number of elements the variable
        will have. If not specified the bind array size (usually 1) is used.
        When a variable is created in an output type handler this parameter
        should be set to the cursor’s array size.

        The inconverter and outconverter parameters specify methods used for
        converting values to/from the database. More information can be found
        in the section on variable objects.

        The typename parameter specifies the name of a SQL object type and must
        be specified when using type DB_TYPE_OBJECT unless the type object
        was passed directly as the first parameter.

        The encoding_errors parameter specifies what should happen when
        decoding byte strings fetched from the database into strings. It should
        be one of the values noted in the builtin decode function.

        The bypass_decode parameter, if specified, should be passed as a
        boolean value. Passing a True value causes values of database types
        DB_TYPE_VARCHAR, DB_TYPE_CHAR, DB_TYPE_NVARCHAR, DB_TYPE_NCHAR and
        DB_TYPE_LONG to be returned as bytes instead of str, meaning that
        oracledb doesn't do any decoding.

        The convert_nulls parameter specifies whether the outconverter should
        be called when null values are fetched from the database.
        """
        self._verify_open()
        if typename is not None:
            typ = self.connection.gettype(typename)
        elif typ is DB_TYPE_OBJECT:
            errors._raise_err(errors.ERR_MISSING_TYPE_NAME_FOR_OBJECT_VAR)
        if encodingErrors is not None:
            if encoding_errors is not None:
                errors._raise_err(
                    errors.ERR_DUPLICATED_PARAMETER,
                    deprecated_name="encodingErrors",
                    new_name="encoding_errors",
                )
            encoding_errors = encodingErrors
        return self._impl.create_var(
            self.connection,
            typ,
            size,
            arraysize,
            inconverter,
            outconverter,
            encoding_errors,
            bypass_decode,
            convert_nulls=convert_nulls,
        )

    @property
    def warning(self) -> Union[errors._Error, None]:
        """
        Returns any warning that was generated during the last call to
        execute() or executemany(), or the value None if no warning was
        generated. This value will be cleared on the next call to execute() or
        executemany().
        """
        self._verify_open()
        return self._impl.warning


class Cursor(BaseCursor):
    __module__ = MODULE_NAME

    def __iter__(self):
        return self

    def __next__(self):
        self._verify_fetch()
        row = self._impl.fetch_next_row(self)
        if row is not None:
            return row
        raise StopIteration

    def _get_oci_attr(self, attr_num: int, attr_type: int) -> Any:
        """
        Returns the value of the specified OCI attribute from the internal
        handle. This is only supported in python-oracledb's thick mode and
        should only be used as directed by Oracle.
        """
        self._verify_open()
        return self._impl._get_oci_attr(attr_num, attr_type)

    def _set_oci_attr(self, attr_num: int, attr_type: int, value: Any) -> None:
        """
        Sets the value of the specified OCI attribute on the internal handle.
        This is only supported in python-oracledb's thick mode and should only
        be used as directed by Oracle.
        """
        self._verify_open()
        self._impl._set_oci_attr(attr_num, attr_type, value)

    def callfunc(
        self,
        name: str,
        return_type: Any,
        parameters: Optional[Union[list, tuple]] = None,
        keyword_parameters: Optional[dict] = None,
        *,
        keywordParameters: Optional[dict] = None,
    ) -> Any:
        """
        Call a function with the given name. The return type is specified in
        the same notation as is required by setinputsizes(). The sequence of
        parameters must contain one entry for each parameter that the function
        expects. Any keyword parameters will be included after the positional
        parameters. The result of the call is the return value of the function.
        """
        var = self.var(return_type)
        if keywordParameters is not None:
            if keyword_parameters is not None:
                errors._raise_err(
                    errors.ERR_DUPLICATED_PARAMETER,
                    deprecated_name="keywordParameters",
                    new_name="keyword_parameters",
                )
            keyword_parameters = keywordParameters
        self._call(name, parameters, keyword_parameters, var)
        return var.getvalue()

    def callproc(
        self,
        name: str,
        parameters: Optional[Union[list, tuple]] = None,
        keyword_parameters: Optional[dict] = None,
        *,
        keywordParameters: Optional[dict] = None,
    ) -> list:
        """
        Call a procedure with the given name. The sequence of parameters must
        contain one entry for each parameter that the procedure expects. The
        result of the call is a modified copy of the input sequence. Input
        parameters are left untouched; output and input/output parameters are
        replaced with possibly new values. Keyword parameters will be included
        after the positional parameters and are not returned as part of the
        output sequence.
        """
        if keywordParameters is not None:
            if keyword_parameters is not None:
                errors._raise_err(
                    errors.ERR_DUPLICATED_PARAMETER,
                    deprecated_name="keywordParameters",
                    new_name="keyword_parameters",
                )
            keyword_parameters = keywordParameters
        self._call(name, parameters, keyword_parameters)
        if parameters is None:
            return []
        return [
            v.get_value(0) for v in self._impl.bind_vars[: len(parameters)]
        ]

    def execute(
        self,
        statement: Optional[str],
        parameters: Optional[Union[list, tuple, dict]] = None,
        **keyword_parameters: Any,
    ) -> Any:
        """
        Execute a statement against the database.

        Parameters may be passed as a dictionary or sequence or as keyword
        parameters. If the parameters are a dictionary, the values will be
        bound by name and if the parameters are a sequence the values will be
        bound by position. Note that if the values are bound by position, the
        order of the variables is from left to right as they are encountered in
        the statement and SQL statements are processed differently than PL/SQL
        statements. For this reason, it is generally recommended to bind
        parameters by name instead of by position.

        Parameters passed as a dictionary are name and value pairs. The name
        maps to the bind variable name used by the statement and the value maps
        to the Python value you wish bound to that bind variable.

        A reference to the statement will be retained by the cursor. If None or
        the same string object is passed in again, the cursor will execute that
        statement again without performing a prepare or rebinding and
        redefining. This is most effective for algorithms where the same
        statement is used, but different parameters are bound to it (many
        times). Note that parameters that are not passed in during subsequent
        executions will retain the value passed in during the last execution
        that contained them.

        For maximum efficiency when reusing an statement, it is best to use the
        setinputsizes() method to specify the parameter types and sizes ahead
        of time; in particular, None is assumed to be a string of length 1 so
        any values that are later bound as numbers or dates will raise a
        TypeError exception.

        If the statement is a query, the cursor is returned as a convenience to
        the caller (so it can be used directly as an iterator over the rows in
        the cursor); otherwise, None is returned.
        """
        self._prepare_for_execute(statement, parameters, keyword_parameters)
        impl = self._impl
        impl.execute(self)
        if impl.fetch_vars is not None:
            return self

    def executemany(
        self,
        statement: Optional[str],
        parameters: Union[list, int],
        batcherrors: bool = False,
        arraydmlrowcounts: bool = False,
    ) -> None:
        """
        Prepare a statement for execution against a database and then execute
        it against all parameter mappings or sequences found in the sequence
        parameters.

        The statement is managed in the same way as the execute() method
        manages it. If the size of the buffers allocated for any of the
        parameters exceeds 2 GB and you are using the thick implementation, you
        will receive the error “DPI-1015: array size of <n> is too large”,
        where <n> varies with the size of each element being allocated in the
        buffer. If you receive this error, decrease the number of elements in
        the sequence parameters.

        If there are no parameters, or parameters have previously been bound,
        the number of iterations can be specified as an integer instead of
        needing to provide a list of empty mappings or sequences.

        When true, the batcherrors parameter enables batch error support within
        Oracle and ensures that the call succeeds even if an exception takes
        place in one or more of the sequence of parameters. The errors can then
        be retrieved using getbatcherrors().

        When true, the arraydmlrowcounts parameter enables DML row counts to be
        retrieved from Oracle after the method has completed. The row counts
        can then be retrieved using getarraydmlrowcounts().

        Both the batcherrors parameter and the arraydmlrowcounts parameter can
        only be true when executing an insert, update, delete or merge
        statement; in all other cases an error will be raised.

        For maximum efficiency, it is best to use the setinputsizes() method to
        specify the parameter types and sizes ahead of time; in particular,
        None is assumed to be a string of length 1 so any values that are later
        bound as numbers or dates will raise a TypeError exception.
        """
        self._verify_open()
        num_execs = self._impl._prepare_for_executemany(
            self, statement, parameters
        )
        self._impl.executemany(
            self, num_execs, bool(batcherrors), bool(arraydmlrowcounts)
        )

    def fetchall(self) -> list:
        """
        Fetch all (remaining) rows of a query result, returning them as a list
        of tuples. An empty list is returned if no more rows are available.
        Note that the cursor’s arraysize attribute can affect the performance
        of this operation, as internally reads from the database are done in
        batches corresponding to the arraysize.

        An exception is raised if the previous call to execute() did not
        produce any result set or no call was issued yet.
        """
        self._verify_fetch()
        result = []
        fetch_next_row = self._impl.fetch_next_row
        while True:
            row = fetch_next_row(self)
            if row is None:
                break
            result.append(row)
        return result

    def fetchmany(
        self, size: Optional[int] = None, numRows: Optional[int] = None
    ) -> list:
        """
        Fetch the next set of rows of a query result, returning a list of
        tuples. An empty list is returned if no more rows are available. Note
        that the cursor’s arraysize attribute can affect the performance of
        this operation.

        The number of rows to fetch is specified by the parameter (the second
        parameter is retained for backwards compatibility and should not be
        used). If it is not given, the cursor’s arraysize attribute determines
        the number of rows to be fetched. If the number of rows available to be
        fetched is fewer than the amount requested, fewer rows will be
        returned.

        An exception is raised if the previous call to execute() did not
        produce any result set or no call was issued yet.
        """
        self._verify_fetch()
        if size is None:
            if numRows is not None:
                size = numRows
            else:
                size = self._impl.arraysize
        elif numRows is not None:
            errors._raise_err(
                errors.ERR_DUPLICATED_PARAMETER,
                deprecated_name="numRows",
                new_name="size",
            )
        result = []
        fetch_next_row = self._impl.fetch_next_row
        while len(result) < size:
            row = fetch_next_row(self)
            if row is None:
                break
            result.append(row)
        return result

    def fetchone(self) -> Any:
        """
        Fetch the next row of a query result set, returning a single tuple or
        None when no more data is available.

        An exception is raised if the previous call to execute() did not
        produce any result set or no call was issued yet.
        """
        self._verify_fetch()
        return self._impl.fetch_next_row(self)

    def parse(self, statement: str) -> None:
        """
        This can be used to parse a statement without actually executing it
        (this step is done automatically by Oracle when a statement is
        executed).
        """
        self._verify_open()
        self._prepare(statement)
        self._impl.parse(self)

    def scroll(self, value: int = 0, mode: str = "relative") -> None:
        """
        Scroll the cursor in the result set to a new position according to the
        mode.

        If mode is "relative" (the default value), the value is taken as an
        offset to the current position in the result set. If set to "absolute",
        value states an absolute target position. If set to "first", the cursor
        is positioned at the first row and if set to "last", the cursor is set
        to the last row in the result set.

        An error is raised if the mode is "relative" or "absolute" and the
        scroll operation would position the cursor outside of the result set.
        """
        self._verify_open()
        self._impl.scroll(self, value, mode)


class AsyncCursor(BaseCursor):
    __module__ = MODULE_NAME

    async def __aenter__(self):
        self._verify_open()
        return self

    async def __aexit__(self, *exc_info):
        self._verify_open()
        self._impl.close(in_del=True)
        self._impl = None

    def __aiter__(self):
        return self

    async def __anext__(self):
        self._verify_fetch()
        row = await self._impl.fetch_next_row(self)
        if row is not None:
            return row
        raise StopAsyncIteration

    async def callfunc(
        self,
        name: str,
        return_type: Any,
        parameters: Optional[Union[list, tuple]] = None,
        keyword_parameters: Optional[dict] = None,
    ) -> Any:
        """
        Call a function with the given name. The return type is specified in
        the same notation as is required by setinputsizes(). The sequence of
        parameters must contain one entry for each parameter that the function
        expects. Any keyword parameters will be included after the positional
        parameters. The result of the call is the return value of the function.
        """
        var = self.var(return_type)
        await self._call(name, parameters, keyword_parameters, var)
        return var.getvalue()

    async def callproc(
        self,
        name: str,
        parameters: Optional[Union[list, tuple]] = None,
        keyword_parameters: Optional[dict] = None,
    ) -> list:
        """
        Call a procedure with the given name. The sequence of parameters must
        contain one entry for each parameter that the procedure expects. The
        result of the call is a modified copy of the input sequence. Input
        parameters are left untouched; output and input/output parameters are
        replaced with possibly new values. Keyword parameters will be included
        after the positional parameters and are not returned as part of the
        output sequence.
        """
        await self._call(name, parameters, keyword_parameters)
        if parameters is None:
            return []
        return [
            v.get_value(0) for v in self._impl.bind_vars[: len(parameters)]
        ]

    async def execute(
        self,
        statement: Optional[str],
        parameters: Optional[Union[list, tuple, dict]] = None,
        **keyword_parameters: Any,
    ) -> None:
        """
        Execute a statement against the database.

        Parameters may be passed as a dictionary or sequence or as keyword
        parameters. If the parameters are a dictionary, the values will be
        bound by name and if the parameters are a sequence the values will be
        bound by position. Note that if the values are bound by position, the
        order of the variables is from left to right as they are encountered in
        the statement and SQL statements are processed differently than PL/SQL
        statements. For this reason, it is generally recommended to bind
        parameters by name instead of by position.

        Parameters passed as a dictionary are name and value pairs. The name
        maps to the bind variable name used by the statement and the value maps
        to the Python value you wish bound to that bind variable.

        A reference to the statement will be retained by the cursor. If None or
        the same string object is passed in again, the cursor will execute that
        statement again without performing a prepare or rebinding and
        redefining. This is most effective for algorithms where the same
        statement is used, but different parameters are bound to it (many
        times). Note that parameters that are not passed in during subsequent
        executions will retain the value passed in during the last execution
        that contained them.

        For maximum efficiency when reusing an statement, it is best to use the
        setinputsizes() method to specify the parameter types and sizes ahead
        of time; in particular, None is assumed to be a string of length 1 so
        any values that are later bound as numbers or dates will raise a
        TypeError exception.
        """
        self._prepare_for_execute(statement, parameters, keyword_parameters)
        await self._impl.execute(self)

    async def executemany(
        self,
        statement: Optional[str],
        parameters: Union[list, int],
        batcherrors: bool = False,
        arraydmlrowcounts: bool = False,
    ) -> None:
        """
        Prepare a statement for execution against a database and then execute
        it against all parameter mappings or sequences found in the sequence
        parameters.

        The statement is managed in the same way as the execute() method
        manages it. If the size of the buffers allocated for any of the
        parameters exceeds 2 GB and you are using the thick implementation, you
        will receive the error “DPI-1015: array size of <n> is too large”,
        where <n> varies with the size of each element being allocated in the
        buffer. If you receive this error, decrease the number of elements in
        the sequence parameters.

        If there are no parameters, or parameters have previously been bound,
        the number of iterations can be specified as an integer instead of
        needing to provide a list of empty mappings or sequences.

        When true, the batcherrors parameter enables batch error support within
        Oracle and ensures that the call succeeds even if an exception takes
        place in one or more of the sequence of parameters. The errors can then
        be retrieved using getbatcherrors().

        When true, the arraydmlrowcounts parameter enables DML row counts to be
        retrieved from Oracle after the method has completed. The row counts
        can then be retrieved using getarraydmlrowcounts().

        Both the batcherrors parameter and the arraydmlrowcounts parameter can
        only be true when executing an insert, update, delete or merge
        statement; in all other cases an error will be raised.

        For maximum efficiency, it is best to use the setinputsizes() method to
        specify the parameter types and sizes ahead of time; in particular,
        None is assumed to be a string of length 1 so any values that are later
        bound as numbers or dates will raise a TypeError exception.
        """
        self._verify_open()
        num_execs = self._impl._prepare_for_executemany(
            self, statement, parameters
        )
        await self._impl.executemany(
            self, num_execs, bool(batcherrors), bool(arraydmlrowcounts)
        )

    async def fetchall(self) -> list:
        """
        Fetch all (remaining) rows of a query result, returning them as a list
        of tuples. An empty list is returned if no more rows are available.
        Note that the cursor’s arraysize attribute can affect the performance
        of this operation, as internally reads from the database are done in
        batches corresponding to the arraysize.

        An exception is raised if the previous call to execute() did not
        produce any result set or no call was issued yet.
        """
        self._verify_fetch()
        result = []
        fetch_next_row = self._impl.fetch_next_row
        while True:
            row = await fetch_next_row(self)
            if row is None:
                break
            result.append(row)
        return result

    async def fetchmany(self, size: Optional[int] = None) -> list:
        """
        Fetch the next set of rows of a query result, returning a list of
        tuples. An empty list is returned if no more rows are available. Note
        that the cursor’s arraysize attribute can affect the performance of
        this operation.

        The number of rows to fetch is specified by the parameter (the second
        parameter is retained for backwards compatibility and should not be
        used). If it is not given, the cursor’s arraysize attribute determines
        the number of rows to be fetched. If the number of rows available to be
        fetched is fewer than the amount requested, fewer rows will be
        returned.

        An exception is raised if the previous call to execute() did not
        produce any result set or no call was issued yet.
        """
        self._verify_fetch()
        if size is None:
            size = self._impl.arraysize
        result = []
        fetch_next_row = self._impl.fetch_next_row
        while len(result) < size:
            row = await fetch_next_row(self)
            if row is None:
                break
            result.append(row)
        return result

    async def fetchone(self) -> Any:
        """
        Fetch the next row of a query result set, returning a single tuple or
        None when no more data is available.

        An exception is raised if the previous call to execute() did not
        produce any result set or no call was issued yet.
        """
        self._verify_fetch()
        return await self._impl.fetch_next_row(self)

    async def parse(self, statement: str) -> None:
        """
        This can be used to parse a statement without actually executing it
        (this step is done automatically by Oracle when a statement is
        executed).
        """
        self._verify_open()
        self._prepare(statement)
        await self._impl.parse(self)

    async def scroll(self, value: int = 0, mode: str = "relative") -> None:
        """
        Scroll the cursor in the result set to a new position according to the
        mode.

        If mode is "relative" (the default value), the value is taken as an
        offset to the current position in the result set. If set to "absolute",
        value states an absolute target position. If set to "first", the cursor
        is positioned at the first row and if set to "last", the cursor is set
        to the last row in the result set.

        An error is raised if the mode is "relative" or "absolute" and the
        scroll operation would position the cursor outside of the result set.
        """
        self._verify_open()
        await self._impl.scroll(self, value, mode)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\dbobject.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2021, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# dbobject.py
#
# Contains the classes used for managing database objects and the database
# object type metadata: DbObject, DbObjectType and DbObjectAttr.
# -----------------------------------------------------------------------------

from typing import Any, Sequence, Union

from . import errors
from . import __name__ as MODULE_NAME
from .base_impl import DbType


class DbObject:
    __module__ = MODULE_NAME

    def __getattr__(self, name):
        try:
            attr_impl = self._impl.type.attrs_by_name[name]
        except KeyError:
            return super().__getattribute__(name)
        return self._impl.get_attr_value(attr_impl)

    def __iter__(self):
        self._ensure_is_collection()
        ix = self._impl.get_first_index()
        while ix is not None:
            yield self._impl.get_element_by_index(ix)
            ix = self._impl.get_next_index(ix)

    def __repr__(self):
        return (
            f"<oracledb.DbObject {self.type._get_full_name()} at "
            f"{hex(id(self))}>"
        )

    def __setattr__(self, name, value):
        if name == "_impl" or name == "_type":
            super().__setattr__(name, value)
        else:
            attr_impl = self._impl.type.attrs_by_name[name]
            self._impl.set_attr_value(attr_impl, value)

    def _ensure_is_collection(self):
        """
        Ensures that the object refers to a collection. If not, an exception is
        raised.
        """
        if not self.type.iscollection:
            errors._raise_err(
                errors.ERR_OBJECT_IS_NOT_A_COLLECTION,
                name=self.type._get_full_name(),
            )

    @classmethod
    def _from_impl(cls, impl):
        obj = cls.__new__(cls)
        obj._impl = impl
        obj._type = None
        return obj

    def append(self, element: Any) -> None:
        """
        Append an element to the collection object. If no elements exist in the
        collection, this creates an element at index 0; otherwise, it creates
        an element immediately following the highest index available in the
        collection.
        """
        self._impl.append(element)

    def asdict(self) -> dict:
        """
        Return a dictionary where the collection’s indexes are the keys and the
        elements are its values.
        """
        self._ensure_is_collection()
        result = {}
        ix = self._impl.get_first_index()
        while ix is not None:
            result[ix] = self._impl.get_element_by_index(ix)
            ix = self._impl.get_next_index(ix)
        return result

    def aslist(self) -> list:
        """
        Return a list of each of the collection’s elements in index order.
        """
        return list(self)

    def copy(self) -> "DbObject":
        """
        Create a copy of the object and return it.
        """
        copied_impl = self._impl.copy()
        return DbObject._from_impl(copied_impl)

    def delete(self, index: int) -> None:
        """
        Delete the element at the specified index of the collection. If the
        element does not exist or is otherwise invalid, an error is raised.
        Note that the indices of the remaining elements in the collection are
        not changed. In other words, the delete operation creates holes in the
        collection.
        """
        self._ensure_is_collection()
        self._impl.delete_by_index(index)

    def exists(self, index: int) -> bool:
        """
        Return True or False indicating if an element exists in the collection
        at the specified index.
        """
        self._ensure_is_collection()
        return self._impl.exists_by_index(index)

    def extend(self, seq: list) -> None:
        """
        Append all of the elements in the sequence to the collection. This is
        the equivalent of performing append() for each element found in the
        sequence.
        """
        self._ensure_is_collection()
        for value in seq:
            self.append(value)

    def first(self) -> int:
        """
        Return the index of the first element in the collection. If the
        collection is empty, None is returned.
        """
        self._ensure_is_collection()
        return self._impl.get_first_index()

    def getelement(self, index: int) -> Any:
        """
        Return the element at the specified index of the collection. If no
        element exists at that index, an exception is raised.
        """
        self._ensure_is_collection()
        return self._impl.get_element_by_index(index)

    def last(self) -> int:
        """
        Return the index of the last element in the collection. If the
        collection is empty, None is returned.
        """
        self._ensure_is_collection()
        return self._impl.get_last_index()

    def next(self, index: int) -> int:
        """
        Return the index of the next element in the collection following the
        specified index. If there are no elements in the collection following
        the specified index, None is returned.
        """
        self._ensure_is_collection()
        return self._impl.get_next_index(index)

    def prev(self, index: int) -> int:
        """
        Return the index of the element in the collection preceding the
        specified index. If there are no elements in the collection preceding
        the specified index, None is returned.
        """
        self._ensure_is_collection()
        return self._impl.get_prev_index(index)

    def setelement(self, index: int, value: Any) -> None:
        """
        Set the value in the collection at the specified index to the given
        value.
        """
        self._ensure_is_collection()
        self._impl.set_element_by_index(index, value)

    def size(self) -> int:
        """
        Return the number of elements in the collection.
        """
        self._ensure_is_collection()
        return self._impl.get_size()

    def trim(self, num: int) -> None:
        """
        Remove the specified number of elements from the end of the collection.
        """
        self._ensure_is_collection()
        self._impl.trim(num)

    @property
    def type(self) -> "DbObjectType":
        """
        Returns an ObjectType corresponding to the type of the object.
        """
        if self._type is None:
            self._type = DbObjectType._from_impl(self._impl.type)
        return self._type


class DbObjectAttr:
    __module__ = MODULE_NAME

    def __repr__(self):
        return f"<oracledb.DbObjectAttr {self.name}>"

    @classmethod
    def _from_impl(cls, impl):
        attr = cls.__new__(cls)
        attr._impl = impl
        attr._type = None
        return attr

    @property
    def max_size(self) -> Union[int, None]:
        """
        Returns the max size of the attribute (in bytes) for attributes of type
        DB_TYPE_RAW, DB_TYPE_CHAR, DB_TYPE_NCHAR, DB_TYPE_VARCHAR and
        DB_TYPE_NVARCHAR.
        """
        if self._impl.max_size:
            return self._impl.max_size

    @property
    def name(self) -> str:
        """
        This read-only attribute returns the name of the attribute.
        """
        return self._impl.name

    @property
    def precision(self) -> Union[int, None]:
        """
        Returns the precision of the attribute.
        """
        if self._impl.precision or self._impl.scale:
            return self._impl.precision

    @property
    def scale(self) -> Union[int, None]:
        """
        Returns the scale of the column.
        """
        if self._impl.precision or self._impl.scale:
            return self._impl.scale

    @property
    def type(self) -> Union["DbObjectType", DbType]:
        """
        This read-only attribute returns the type of the attribute. This will
        be an Oracle Object Type if the variable binds Oracle objects;
        otherwise, it will be one of the database type constants.
        """
        if self._type is None:
            if self._impl.objtype is not None:
                self._type = DbObjectType._from_impl(self._impl.objtype)
            else:
                self._type = self._impl.dbtype
        return self._type


class DbObjectType:
    __module__ = MODULE_NAME

    def __call__(self, value=None):
        return self.newobject(value)

    def __eq__(self, other):
        if isinstance(other, DbObjectType):
            return other._impl == self._impl
        return NotImplemented

    def __repr__(self):
        return f"<oracledb.DbObjectType {self._get_full_name()}>"

    @classmethod
    def _from_impl(cls, impl):
        typ = cls.__new__(cls)
        typ._impl = impl
        typ._attributes = None
        typ._element_type = None
        return typ

    def _get_full_name(self):
        """
        Returns the full name of the type.
        """
        return self._impl._get_fqn()

    @property
    def attributes(self) -> list:
        """
        This read-only attribute returns a list of the attributes that make up
        the object type.
        """
        if self._attributes is None:
            self._attributes = [
                DbObjectAttr._from_impl(i) for i in self._impl.attrs
            ]
        return self._attributes

    @property
    def iscollection(self) -> bool:
        """
        This read-only attribute returns a boolean indicating if the object
        type refers to a collection or not.
        """
        return self._impl.is_collection

    @property
    def name(self) -> str:
        """
        This read-only attribute returns the name of the type.
        """
        return self._impl.name

    @property
    def element_type(self) -> Union["DbObjectType", DbType]:
        """
        This read-only attribute returns the type of elements found in
        collections of this type, if iscollection is True; otherwise, it
        returns None. If the collection contains objects, this will be another
        object type; otherwise, it will be one of the database type constants.
        """
        if self._element_type is None:
            if self._impl.element_metadata.objtype is not None:
                typ_impl = self._impl.element_metadata.objtype
                self._element_type = DbObjectType._from_impl(typ_impl)
            else:
                self._element_type = self._impl.element_metadata.dbtype
        return self._element_type

    def newobject(self, value: Sequence = None) -> DbObject:
        """
        Return a new Oracle object of the given type. This object can then be
        modified by setting its attributes and then bound to a cursor for
        interaction with Oracle. If the object type refers to a collection, a
        sequence may be passed and the collection will be initialized with the
        items in that sequence.
        """
        obj_impl = self._impl.create_new_object()
        obj = DbObject._from_impl(obj_impl)
        if value is not None:
            obj.extend(value)
        return obj

    @property
    def package_name(self) -> str:
        """
        This read-only attribute returns the name of the package containing the
        PL/SQL type or None if the type is not a PL/SQL type.
        """
        return self._impl.package_name

    @property
    def schema(self) -> str:
        """
        This read-only attribute returns the name of the schema that owns the
        type.
        """
        return self._impl.schema


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\defaults.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2021, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# defaults.py
#
# Contains the Defaults class used for managing default values used throughout
# the module.
# -----------------------------------------------------------------------------

from . import base_impl
from . import __name__ as MODULE_NAME
from . import errors


class Defaults:
    """
    Identifies the default values used by the driver.
    """

    __module__ = MODULE_NAME

    def __init__(self) -> None:
        self._impl = base_impl.DEFAULTS

    @property
    def arraysize(self) -> int:
        """
        Specifies the default arraysize to use when cursors are created.
        """
        return self._impl.arraysize

    @arraysize.setter
    def arraysize(self, value: int):
        self._impl.arraysize = value

    @property
    def config_dir(self) -> str:
        """
        Specifies the directory to search for tnsnames.ora.
        """
        return self._impl.config_dir

    @config_dir.setter
    def config_dir(self, value: str):
        self._impl.config_dir = value

    @property
    def fetch_lobs(self) -> bool:
        """
        Specifies whether queries that contain LOBs should return LOB objects
        or their contents instead.
        """
        return self._impl.fetch_lobs

    @fetch_lobs.setter
    def fetch_lobs(self, value: bool):
        self._impl.fetch_lobs = value

    @property
    def fetch_decimals(self) -> bool:
        """
        Specifies whether queries that contain numbers should return
        decimal.Decimal objects or floating point numbers.
        """
        return self._impl.fetch_decimals

    @fetch_decimals.setter
    def fetch_decimals(self, value: bool):
        self._impl.fetch_decimals = value

    @property
    def prefetchrows(self) -> int:
        """
        Specifies the default number of rows to prefetch when cursors are
        executed.
        """
        return self._impl.prefetchrows

    @prefetchrows.setter
    def prefetchrows(self, value: int):
        self._impl.prefetchrows = value

    @property
    def stmtcachesize(self) -> int:
        """
        Specifies the default size of the statement cache.
        """
        return self._impl.stmtcachesize

    @stmtcachesize.setter
    def stmtcachesize(self, value: int):
        self._impl.stmtcachesize = value

    @property
    def program(self) -> str:
        """
        Specifies the program name connected to the Oracle Database.
        """
        return self._impl.program

    @program.setter
    def program(self, value: str):
        if base_impl.sanitize(value) != value:
            errors._raise_err(errors.ERR_INVALID_NETWORK_NAME, name="program")
        self._impl.program = value

    @property
    def machine(self) -> str:
        """
        Specifies the machine name connected to the Oracle Database.
        """
        return self._impl.machine

    @machine.setter
    def machine(self, value: str):
        if base_impl.sanitize(value) != value:
            errors._raise_err(errors.ERR_INVALID_NETWORK_NAME, name="machine")
        self._impl.machine = value

    @property
    def terminal(self) -> str:
        """
        Specifies the terminal identifier from which the connection originates.
        """
        return self._impl.terminal

    @terminal.setter
    def terminal(self, value: str):
        self._impl.terminal = value

    @property
    def osuser(self) -> str:
        """
        Specifies the os user that initiates the connection to the
        Oracle Database.
        """
        return self._impl.osuser

    @osuser.setter
    def osuser(self, value: str):
        if base_impl.sanitize(value) != value:
            errors._raise_err(errors.ERR_INVALID_NETWORK_NAME, name="osuser")
        self._impl.osuser = value

    @property
    def driver_name(self) -> str:
        """
        Specifies the driver used for the connection.
        """
        return self._impl.driver_name

    @driver_name.setter
    def driver_name(self, value: str):
        self._impl.driver_name = value

    @property
    def thick_mode_dsn_passthrough(self) -> str:
        """
        Specifies whether to pass connect strings to the Oracle Client
        libraries unchanged when using thick mode.
        """
        return self._impl.thick_mode_dsn_passthrough

    @thick_mode_dsn_passthrough.setter
    def thick_mode_dsn_passthrough(self, value: str):
        self._impl.thick_mode_dsn_passthrough = value


defaults = Defaults()


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\driver_mode.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2021, 2023 Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# driver_mode.py
#
# Contains a simple method for checking and returning which mode the driver is
# currently using. The driver only supports creating connections and pools with
# either the thin implementation or the thick implementation, not both
# simultaneously.
# -----------------------------------------------------------------------------

import threading

from . import errors


# The DriverModeHandler class is used to manage which mode the driver is using.
#
# The "thin_mode" flag contains the current state:
#     None: neither thick nor thin implementation has been used yet
#     False: thick implementation is being used
#     True: thin implementation is being used
#
# The "requested_thin_mode" flag is set to the mode that is being requested:
#     False: thick implementation is being initialized
#     True: thin implementation is being initialized
class DriverModeManager:
    """
    Manages the mode the driver is using. The "thin_mode" flag contains the
    current state:
        None: neither thick nor thin implementation has been used yet
        False: thick implementation is being used
        True: thin implementation is being used
    The "requested_thin_mode" is set to the mode that is being requested, but
    only while initialization is taking place (otherwise, it contains the value
    None):
        False: thick implementation is being initialized
        True: thin implementation is being initialized
    The condition is used to ensure that only one thread is performing
    initialization.
    """

    def __init__(self):
        self.thin_mode = None
        self.requested_thin_mode = None
        self.condition = threading.Condition()

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_value, exc_tb):
        with self.condition:
            if (
                exc_type is None
                and exc_value is None
                and exc_tb is None
                and self.requested_thin_mode is not None
            ):
                self.thin_mode = self.requested_thin_mode
            self.requested_thin_mode = None
            self.condition.notify()

    @property
    def thin(self):
        if self.requested_thin_mode is not None:
            return self.requested_thin_mode
        return self.thin_mode


manager = DriverModeManager()


def get_manager(requested_thin_mode=None):
    """
    Returns the manager, but only after ensuring that no other threads are
    attempting to initialize the mode.
    """
    with manager.condition:
        if manager.thin_mode is None:
            if manager.requested_thin_mode is not None:
                manager.condition.wait()
            if manager.thin_mode is None:
                if requested_thin_mode is None:
                    manager.requested_thin_mode = True
                else:
                    manager.requested_thin_mode = requested_thin_mode
        elif (
            requested_thin_mode is not None
            and requested_thin_mode != manager.thin_mode
        ):
            if requested_thin_mode:
                errors._raise_err(errors.ERR_THICK_MODE_ENABLED)
            else:
                errors._raise_err(errors.ERR_THIN_CONNECTION_ALREADY_CREATED)
    return manager


def is_thin_mode() -> bool:
    """
    Return a boolean specifying whether the driver is using thin mode (True) or
    thick mode (False).

    Immediately after python-oracledb is imported, this function will return
    True indicating that python-oracledb defaults to Thin mode. If
    oracledb.init_oracle_client() is called successfully, then a subsequent
    call to is_thin_mode() will return False indicating that Thick mode is
    enabled.  Once the first standalone connection or connection pool is
    created succesfully, or a call to oracledb.init_oracle_client() is made
    successfully, then python-oracledb's mode is fixed and the value returned
    by is_thin_mode() will never change for the lifetime of the process.

    """
    if manager.thin_mode is not None:
        return manager.thin_mode
    return True


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\dsn.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2021, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# dsn.py
#
# Contains makedsn(), a method available for backwards compatibility with
# cx_Oracle. Use of the ConnectParams class or the keyword arguments to
# connect() and create_pool() is recommended instead.
# -----------------------------------------------------------------------------

from . import errors


def _check_arg(name: str, value: str) -> None:
    """
    Checks the argument to ensure that it does not contain (, ) or = as these
    characters are not permitted within connect strings.
    """
    if "(" in value or ")" in value or "=" in value:
        errors._raise_err(errors.ERR_INVALID_MAKEDSN_ARG, name=name)


def makedsn(
    host: str,
    port: int,
    sid: str = None,
    service_name: str = None,
    region: str = None,
    sharding_key: str = None,
    super_sharding_key: str = None,
) -> str:
    """
    Return a string suitable for use as the dsn parameter for connect(). This
    string is identical to the strings that are defined in the tnsnames.ora
    file.
    """
    connect_data_parts = []
    _check_arg("host", host)
    if service_name is not None:
        _check_arg("service_name", service_name)
        connect_data_parts.append(f"(SERVICE_NAME={service_name})")
    elif sid is not None:
        _check_arg("sid", sid)
        connect_data_parts.append(f"(SID={sid})")
    if region is not None:
        _check_arg("region", region)
        connect_data_parts.append(f"(REGION={region})")
    if sharding_key is not None:
        _check_arg("sharding_key", sharding_key)
        connect_data_parts.append(f"(SHARDING_KEY={sharding_key})")
    if super_sharding_key is not None:
        _check_arg("super_sharding_key", super_sharding_key)
        connect_data_parts.append(f"(SUPER_SHARDING_KEY={super_sharding_key})")
    connect_data = "".join(connect_data_parts)
    return (
        f"(DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST={host})"
        f"(PORT={port}))(CONNECT_DATA={connect_data}))"
    )


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\enums.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# enums.py
#
# Contains the enumerations of various constants used throughout the package.
# -----------------------------------------------------------------------------

import enum

from . import base_impl


class AuthMode(enum.IntFlag):
    DEFAULT = base_impl.AUTH_MODE_DEFAULT
    PRELIM = base_impl.AUTH_MODE_PRELIM
    SYSASM = base_impl.AUTH_MODE_SYSASM
    SYSBKP = base_impl.AUTH_MODE_SYSBKP
    SYSDBA = base_impl.AUTH_MODE_SYSDBA
    SYSDGD = base_impl.AUTH_MODE_SYSDGD
    SYSKMT = base_impl.AUTH_MODE_SYSKMT
    SYSOPER = base_impl.AUTH_MODE_SYSOPER
    SYSRAC = base_impl.AUTH_MODE_SYSRAC


class PipelineOpType(enum.IntFlag):
    CALL_FUNC = base_impl.PIPELINE_OP_TYPE_CALL_FUNC
    CALL_PROC = base_impl.PIPELINE_OP_TYPE_CALL_PROC
    COMMIT = base_impl.PIPELINE_OP_TYPE_COMMIT
    EXECUTE = base_impl.PIPELINE_OP_TYPE_EXECUTE
    EXECUTE_MANY = base_impl.PIPELINE_OP_TYPE_EXECUTE_MANY
    FETCH_ALL = base_impl.PIPELINE_OP_TYPE_FETCH_ALL
    FETCH_MANY = base_impl.PIPELINE_OP_TYPE_FETCH_MANY
    FETCH_ONE = base_impl.PIPELINE_OP_TYPE_FETCH_ONE


class PoolGetMode(enum.IntEnum):
    FORCEGET = base_impl.POOL_GETMODE_FORCEGET
    NOWAIT = base_impl.POOL_GETMODE_NOWAIT
    TIMEDWAIT = base_impl.POOL_GETMODE_TIMEDWAIT
    WAIT = base_impl.POOL_GETMODE_WAIT


class Purity(enum.IntEnum):
    DEFAULT = base_impl.PURITY_DEFAULT
    NEW = base_impl.PURITY_NEW
    SELF = base_impl.PURITY_SELF


class VectorFormat(enum.IntEnum):
    BINARY = base_impl.VECTOR_FORMAT_BINARY
    FLOAT32 = base_impl.VECTOR_FORMAT_FLOAT32
    FLOAT64 = base_impl.VECTOR_FORMAT_FLOAT64
    INT8 = base_impl.VECTOR_FORMAT_INT8


# provide aliases for all enumerated values
AUTH_MODE_DEFAULT = AuthMode.DEFAULT
AUTH_MODE_PRELIM = AuthMode.PRELIM
AUTH_MODE_SYSASM = AuthMode.SYSASM
AUTH_MODE_SYSBKP = AuthMode.SYSBKP
AUTH_MODE_SYSDBA = AuthMode.SYSDBA
AUTH_MODE_SYSDGD = AuthMode.SYSDGD
AUTH_MODE_SYSKMT = AuthMode.SYSKMT
AUTH_MODE_SYSOPER = AuthMode.SYSOPER
AUTH_MODE_SYSRAC = AuthMode.SYSRAC
PIPELINE_OP_TYPE_CALL_FUNC = PipelineOpType.CALL_FUNC
PIPELINE_OP_TYPE_CALL_PROC = PipelineOpType.CALL_PROC
PIPELINE_OP_TYPE_COMMIT = PipelineOpType.COMMIT
PIPELINE_OP_TYPE_EXECUTE = PipelineOpType.EXECUTE
PIPELINE_OP_TYPE_EXECUTE_MANY = PipelineOpType.EXECUTE_MANY
PIPELINE_OP_TYPE_FETCH_ALL = PipelineOpType.FETCH_ALL
PIPELINE_OP_TYPE_FETCH_MANY = PipelineOpType.FETCH_MANY
PIPELINE_OP_TYPE_FETCH_ONE = PipelineOpType.FETCH_ONE
POOL_GETMODE_FORCEGET = PoolGetMode.FORCEGET
POOL_GETMODE_NOWAIT = PoolGetMode.NOWAIT
POOL_GETMODE_TIMEDWAIT = PoolGetMode.TIMEDWAIT
POOL_GETMODE_WAIT = PoolGetMode.WAIT
PURITY_DEFAULT = Purity.DEFAULT
PURITY_NEW = Purity.NEW
PURITY_SELF = Purity.SELF
VECTOR_FORMAT_BINARY = VectorFormat.BINARY
VECTOR_FORMAT_FLOAT32 = VectorFormat.FLOAT32
VECTOR_FORMAT_FLOAT64 = VectorFormat.FLOAT64
VECTOR_FORMAT_INT8 = VectorFormat.INT8


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\errors.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# errors.py
#
# Contains the _Error class and all of the errors that are raised explicitly by
# the package. Oracle Database errors and ODPI-C errors (when using thick mode)
# are only referenced here if they are transformed into package specific
# errors.
# -----------------------------------------------------------------------------

import re

from .driver_mode import is_thin_mode
from . import exceptions


class _Error:
    """
    Error class which is used for all errors that are raised by the driver.
    """

    def __init__(
        self,
        message: str = None,
        context: str = None,
        isrecoverable: bool = False,
        iswarning: bool = False,
        code: int = 0,
        offset: int = 0,
    ) -> None:
        self.message = message
        self.context = context
        self.isrecoverable = isrecoverable
        self.iswarning = iswarning
        self.code = code
        self.offset = offset
        self.is_session_dead = False
        self.full_code = ""
        self.exc_type = exceptions.DatabaseError
        self._make_adjustments()

    def _make_adjustments(self):
        """
        Make adjustments to the error, if needed, and calculate the full_code
        attribute.
        """
        if self.message is not None:
            pos = self.message.find(":")
            if pos > 0:
                self.full_code = self.message[:pos]

                # add Oracle Database Error Help Portal URL for database error
                # messages, but only in thin mode since this is done
                # automatically in thick mode with Oracle Client 23ai and
                # higher
                if (
                    self.code != 0
                    and (self.code < 20000 or self.code >= 21000)
                    and is_thin_mode()
                ):
                    self.message = (
                        self.message
                        + "\n"
                        + "Help: https://docs.oracle.com/error-help/db/ora-"
                        + f"{self.code:05}/"
                    )
                elif self.full_code in ERR_TROUBLESHOOTING_AVAILABLE:
                    self.message = (
                        self.message
                        + "\n"
                        + "Help: https://python-oracledb.readthedocs.io/en/"
                        + "latest/user_guide/troubleshooting.html#"
                        + self.full_code.lower()
                    )

        # transform Oracle and ODPI-C specific error codes to driver errors,
        # if applicable
        if self.code != 0 or self.full_code.startswith("DPI-"):
            args = {}
            if self.code != 0:
                driver_error_info = ERR_ORACLE_ERROR_XREF.get(self.code)
            else:
                error_num = int(self.full_code[4:])
                driver_error_info = ERR_DPI_ERROR_XREF.get(error_num)
            if driver_error_info is not None:
                if isinstance(driver_error_info, tuple):
                    driver_error_num, pattern = driver_error_info
                    match = re.search(pattern, self.message)
                    args = {} if match is None else match.groupdict()
                else:
                    driver_error_num = driver_error_info
                if driver_error_num == ERR_CONNECTION_CLOSED:
                    self.is_session_dead = True
                driver_error = _get_error_text(driver_error_num, **args)
                self.message = f"{driver_error}\n{self.message}"
                self.full_code = f"{ERR_PREFIX}-{driver_error_num:04}"

        # determine exception class to use when raising this error
        if self.full_code.startswith("DPY-"):
            driver_error_num = int(self.full_code[4:])
            self.exc_type = ERR_EXCEPTION_TYPES[driver_error_num // 1000]
        elif self.code != 0:
            if self.code in ERR_INTEGRITY_ERROR_CODES:
                self.exc_type = exceptions.IntegrityError
            elif self.code in ERR_INTERFACE_ERROR_CODES:
                self.exc_type = exceptions.InterfaceError
            elif self.code in ERR_OPERATIONAL_ERROR_CODES:
                self.exc_type = exceptions.OperationalError

    def __str__(self):
        return self.message


def _get_error_text(error_num: int, **args) -> str:
    """
    Return the error text for the driver specific error number.
    """
    message_format = ERR_MESSAGE_FORMATS.get(error_num)
    if message_format is None:
        message_format = "missing error {error_num}"
        args = dict(error_num=error_num)
        error_num = ERR_MISSING_ERROR
    try:
        message = message_format.format(**args)
    except KeyError:
        message = (
            message_format
            + "\nWrong arguments to message format:\n"
            + repr(args)
        )
    return f"{ERR_PREFIX}-{error_num:04}: {message}"


def _create_err(
    error_num: int,
    context_error_message: str = None,
    cause: Exception = None,
    **args,
) -> _Error:
    """
    Returns a driver specific error object for the specified error number and
    supplied arguments.
    """
    message = _get_error_text(error_num, **args)
    if context_error_message is None and cause is not None:
        context_error_message = str(cause)
    if context_error_message is not None:
        message = f"{message}\n{context_error_message}"
    return _Error(message)


def _create_warning(error_num: int, **args) -> _Error:
    """
    Returns a warning error object for the specified error number and supplied
    arguments.
    """
    message = _get_error_text(error_num, **args)
    return _Error(message, iswarning=True)


def _raise_err(
    error_num: int,
    context_error_message: str = None,
    cause: Exception = None,
    **args,
) -> None:
    """
    Raises a driver specific exception from the specified error number and
    supplied arguments.
    """
    error = _create_err(error_num, context_error_message, cause, **args)
    raise error.exc_type(error) from cause


def _raise_not_supported(feature: str) -> None:
    """
    Raises an exception that the specified feature is not supported. This is
    used as the default implementation of all functions for the implementation
    objects.
    """
    driver_type = "thick" if is_thin_mode() else "thin"
    _raise_err(
        ERR_FEATURE_NOT_SUPPORTED, feature=feature, driver_type=driver_type
    )


# prefix used for all error messages
ERR_PREFIX = "DPY"

# error numbers that result in InterfaceError
ERR_MISSING_ERROR = 1000
ERR_NOT_CONNECTED = 1001
ERR_POOL_NOT_OPEN = 1002
ERR_NOT_A_QUERY = 1003
ERR_NO_STATEMENT_EXECUTED = 1004
ERR_POOL_HAS_BUSY_CONNECTIONS = 1005
ERR_CURSOR_NOT_OPEN = 1006

# error numbers that result in ProgrammingError
ERR_MESSAGE_HAS_NO_PAYLOAD = 2000
ERR_NO_STATEMENT = 2001
ERR_NO_STATEMENT_PREPARED = 2002
ERR_WRONG_EXECUTE_PARAMETERS_TYPE = 2003
ERR_WRONG_EXECUTEMANY_PARAMETERS_TYPE = 2004
ERR_ARGS_AND_KEYWORD_ARGS = 2005
ERR_MIXED_POSITIONAL_AND_NAMED_BINDS = 2006
ERR_EXPECTING_TYPE = 2007
ERR_WRONG_OBJECT_TYPE = 2008
ERR_WRONG_SCROLL_MODE = 2009
ERR_MIXED_ELEMENT_TYPES = 2010
ERR_WRONG_ARRAY_DEFINITION = 2011
ERR_ARGS_MUST_BE_LIST_OR_TUPLE = 2012
ERR_KEYWORD_ARGS_MUST_BE_DICT = 2013
ERR_DUPLICATED_PARAMETER = 2014
ERR_EXPECTING_VAR = 2015
ERR_INCORRECT_VAR_ARRAYSIZE = 2016
ERR_LIBRARY_ALREADY_INITIALIZED = 2017
ERR_WALLET_FILE_MISSING = 2018
ERR_THIN_CONNECTION_ALREADY_CREATED = 2019
ERR_INVALID_MAKEDSN_ARG = 2020
ERR_INIT_ORACLE_CLIENT_NOT_CALLED = 2021
ERR_INVALID_OCI_ATTR_TYPE = 2022
ERR_INVALID_CONN_CLASS = 2023
ERR_INVALID_CONNECT_PARAMS = 2025
ERR_INVALID_POOL_CLASS = 2026
ERR_INVALID_POOL_PARAMS = 2027
ERR_EXPECTING_LIST_FOR_ARRAY_VAR = 2028
ERR_HTTPS_PROXY_REQUIRES_TCPS = 2029
ERR_INVALID_LOB_OFFSET = 2030
ERR_INVALID_ACCESS_TOKEN_PARAM = 2031
ERR_INVALID_ACCESS_TOKEN_RETURNED = 2032
ERR_EXPIRED_ACCESS_TOKEN = 2033
ERR_ACCESS_TOKEN_REQUIRES_TCPS = 2034
ERR_INVALID_OBJECT_TYPE_NAME = 2035
ERR_OBJECT_IS_NOT_A_COLLECTION = 2036
ERR_MISSING_TYPE_NAME_FOR_OBJECT_VAR = 2037
ERR_INVALID_COLL_INDEX_GET = 2038
ERR_INVALID_COLL_INDEX_SET = 2039
ERR_EXECUTE_MODE_ONLY_FOR_DML = 2040
ERR_MISSING_ENDING_SINGLE_QUOTE = 2041
ERR_MISSING_ENDING_DOUBLE_QUOTE = 2042
ERR_DBOBJECT_ATTR_MAX_SIZE_VIOLATED = 2043
ERR_DBOBJECT_ELEMENT_MAX_SIZE_VIOLATED = 2044
ERR_INVALID_ARRAYSIZE = 2045
ERR_CURSOR_HAS_BEEN_CLOSED = 2046
ERR_INVALID_LOB_AMOUNT = 2047
ERR_DML_RETURNING_DUP_BINDS = 2048
ERR_MISSING_ADDRESS = 2049
ERR_INVALID_TPC_BEGIN_FLAGS = 2050
ERR_INVALID_TPC_END_FLAGS = 2051
ERR_MISMATCHED_TOKEN = 2052
ERR_THICK_MODE_ENABLED = 2053
ERR_NAMED_POOL_MISSING = 2054
ERR_NAMED_POOL_EXISTS = 2055
ERR_PROTOCOL_HANDLER_FAILED = 2056
ERR_PASSWORD_TYPE_HANDLER_FAILED = 2057
ERR_PLAINTEXT_PASSWORD_IN_CONFIG = 2058
ERR_MISSING_CONNECT_DESCRIPTOR = 2059
ERR_ARROW_C_API_ERROR = 2060
ERR_PARAMS_HOOK_HANDLER_FAILED = 2061
ERR_PAYLOAD_CANNOT_BE_ENQUEUED = 2062
ERR_SCROLL_OUT_OF_RESULT_SET = 2063

# error numbers that result in NotSupportedError
ERR_TIME_NOT_SUPPORTED = 3000
ERR_FEATURE_NOT_SUPPORTED = 3001
ERR_PYTHON_VALUE_NOT_SUPPORTED = 3002
ERR_PYTHON_TYPE_NOT_SUPPORTED = 3003
ERR_UNSUPPORTED_TYPE_SET = 3004
ERR_ARRAYS_OF_ARRAYS = 3005
ERR_ORACLE_TYPE_NOT_SUPPORTED = 3006
ERR_DB_TYPE_NOT_SUPPORTED = 3007
ERR_UNSUPPORTED_INBAND_NOTIFICATION = 3008
ERR_SELF_BIND_NOT_SUPPORTED = 3009
ERR_SERVER_VERSION_NOT_SUPPORTED = 3010
ERR_NCHAR_CS_NOT_SUPPORTED = 3012
ERR_UNSUPPORTED_PYTHON_TYPE_FOR_DB_TYPE = 3013
ERR_LOB_OF_WRONG_TYPE = 3014
ERR_UNSUPPORTED_VERIFIER_TYPE = 3015
ERR_NO_CRYPTOGRAPHY_PACKAGE = 3016
ERR_ORACLE_TYPE_NAME_NOT_SUPPORTED = 3017
ERR_TDS_TYPE_NOT_SUPPORTED = 3018
ERR_OSON_NODE_TYPE_NOT_SUPPORTED = 3019
ERR_OSON_FIELD_NAME_LIMITATION = 3020
ERR_OSON_VERSION_NOT_SUPPORTED = 3021
ERR_NAMED_TIMEZONE_NOT_SUPPORTED = 3022
ERR_VECTOR_VERSION_NOT_SUPPORTED = 3023
ERR_VECTOR_FORMAT_NOT_SUPPORTED = 3024
ERR_OPERATION_NOT_SUPPORTED_ON_BFILE = 3025
ERR_OPERATION_ONLY_SUPPORTED_ON_BFILE = 3026
ERR_CURSOR_DIFF_CONNECTION = 3027
ERR_UNSUPPORTED_PIPELINE_OPERATION = 3028
ERR_INVALID_NETWORK_NAME = 3029
ERR_ARROW_UNSUPPORTED_DATA_TYPE = 3030

# error numbers that result in DatabaseError
ERR_TNS_ENTRY_NOT_FOUND = 4000
ERR_NO_CREDENTIALS = 4001
ERR_COLUMN_TRUNCATED = 4002
ERR_ORACLE_NUMBER_NO_REPR = 4003
ERR_INVALID_NUMBER = 4004
ERR_POOL_NO_CONNECTION_AVAILABLE = 4005
ERR_ARRAY_DML_ROW_COUNTS_NOT_ENABLED = 4006
ERR_INCONSISTENT_DATATYPES = 4007
ERR_INVALID_BIND_NAME = 4008
ERR_WRONG_NUMBER_OF_POSITIONAL_BINDS = 4009
ERR_MISSING_BIND_VALUE = 4010
ERR_CONNECTION_CLOSED = 4011
ERR_NUMBER_WITH_INVALID_EXPONENT = 4012
ERR_NUMBER_STRING_OF_ZERO_LENGTH = 4013
ERR_NUMBER_STRING_TOO_LONG = 4014
ERR_NUMBER_WITH_EMPTY_EXPONENT = 4015
ERR_CONTENT_INVALID_AFTER_NUMBER = 4016
ERR_INVALID_CONNECT_DESCRIPTOR = 4017
ERR_CANNOT_PARSE_CONNECT_STRING = 4018
ERR_INVALID_REDIRECT_DATA = 4019
ERR_INVALID_PROTOCOL = 4021
ERR_INVALID_ENUM_VALUE = 4022
ERR_CALL_TIMEOUT_EXCEEDED = 4024
ERR_INVALID_REF_CURSOR = 4025
ERR_MISSING_FILE = 4026
ERR_NO_CONFIG_DIR = 4027
ERR_INVALID_SERVER_TYPE = 4028
ERR_TOO_MANY_BATCH_ERRORS = 4029
ERR_IFILE_CYCLE_DETECTED = 4030
ERR_INVALID_VECTOR = 4031
ERR_INVALID_SSL_VERSION = 4032
ERR_EXCEEDED_IDLE_TIME = 4033
ERR_INVALID_PASSWORD_TYPE = 4034

# error numbers that result in InternalError
ERR_MESSAGE_TYPE_UNKNOWN = 5000
ERR_BUFFER_LENGTH_INSUFFICIENT = 5001
ERR_INTEGER_TOO_LARGE = 5002
ERR_UNEXPECTED_NEGATIVE_INTEGER = 5003
ERR_UNEXPECTED_DATA = 5004
ERR_UNEXPECTED_REFUSE = 5005
ERR_UNEXPECTED_END_OF_DATA = 5006
ERR_UNEXPECTED_XML_TYPE = 5007
ERR_UNKNOWN_SERVER_PIGGYBACK = 5009
ERR_UNKNOWN_TRANSACTION_STATE = 5010
ERR_UNEXPECTED_PIPELINE_FAILURE = 5011
ERR_NOT_IMPLEMENTED = 5012

# error numbers that result in OperationalError
ERR_LISTENER_REFUSED_CONNECTION = 6000
ERR_INVALID_SERVICE_NAME = 6001
ERR_INVALID_SERVER_CERT_DN = 6002
ERR_INVALID_SID = 6003
ERR_PROXY_FAILURE = 6004
ERR_CONNECTION_FAILED = 6005
ERR_INVALID_SERVER_NAME = 6006

# error numbers that result in Warning
WRN_COMPILATION_ERROR = 7000

# Oracle error number cross reference
ERR_ORACLE_ERROR_XREF = {
    22: ERR_CONNECTION_CLOSED,
    28: ERR_CONNECTION_CLOSED,
    31: ERR_CONNECTION_CLOSED,
    45: ERR_CONNECTION_CLOSED,
    378: ERR_CONNECTION_CLOSED,
    600: ERR_CONNECTION_CLOSED,
    602: ERR_CONNECTION_CLOSED,
    603: ERR_CONNECTION_CLOSED,
    609: ERR_CONNECTION_CLOSED,
    1005: ERR_NO_CREDENTIALS,
    1012: ERR_CONNECTION_CLOSED,
    1041: ERR_CONNECTION_CLOSED,
    1043: ERR_CONNECTION_CLOSED,
    1089: ERR_CONNECTION_CLOSED,
    1092: ERR_CONNECTION_CLOSED,
    1740: ERR_MISSING_ENDING_DOUBLE_QUOTE,
    1756: ERR_MISSING_ENDING_SINGLE_QUOTE,
    2396: ERR_CONNECTION_CLOSED,
    3113: ERR_CONNECTION_CLOSED,
    3114: ERR_CONNECTION_CLOSED,
    3122: ERR_CONNECTION_CLOSED,
    3135: ERR_CONNECTION_CLOSED,
    12153: ERR_CONNECTION_CLOSED,
    12537: ERR_CONNECTION_CLOSED,
    12547: ERR_CONNECTION_CLOSED,
    12570: ERR_CONNECTION_CLOSED,
    12583: ERR_CONNECTION_CLOSED,
    22165: (
        ERR_INVALID_COLL_INDEX_SET,
        r"index \[(?P<index>\d+)\] must be in the range of "
        r"\[(?P<min_index>\d+)\] to \[(?P<max_index>\d+)\]",
    ),
    22303: (ERR_INVALID_OBJECT_TYPE_NAME, r'type "(?P<name>[^"]*"."[^"]*)"'),
    24422: ERR_POOL_HAS_BUSY_CONNECTIONS,
    24349: ERR_ARRAY_DML_ROW_COUNTS_NOT_ENABLED,
    24457: ERR_POOL_NO_CONNECTION_AVAILABLE,
    24459: ERR_POOL_NO_CONNECTION_AVAILABLE,
    24496: ERR_POOL_NO_CONNECTION_AVAILABLE,
    24338: ERR_INVALID_REF_CURSOR,
    24344: WRN_COMPILATION_ERROR,
    27146: ERR_CONNECTION_CLOSED,
    28511: ERR_CONNECTION_CLOSED,
    38902: ERR_TOO_MANY_BATCH_ERRORS,
    56600: ERR_CONNECTION_CLOSED,
}

# ODPI-C error number cross reference
ERR_DPI_ERROR_XREF = {
    1010: ERR_NOT_CONNECTED,
    1024: (ERR_INVALID_COLL_INDEX_GET, r"at index (?P<index>\d+) does"),
    1027: ERR_SCROLL_OUT_OF_RESULT_SET,
    1043: ERR_INVALID_NUMBER,
    1044: ERR_ORACLE_NUMBER_NO_REPR,
    1063: ERR_EXECUTE_MODE_ONLY_FOR_DML,
    1067: (ERR_CALL_TIMEOUT_EXCEEDED, r"call timeout of (?P<timeout>\d+) ms"),
    1080: ERR_CONNECTION_CLOSED,
}

# Oracle error codes that result in IntegrityError exceptions
ERR_INTEGRITY_ERROR_CODES = [
    1,  # unique constraint violated
    1400,  # cannot insert NULL
    1438,  # value larger than specified precision
    2290,  # check constraint violated
    2291,  # integrity constraint violated - parent key not found
    2292,  # integrity constraint violated - child record found
    21525,  # attribute or collection element violated its constraints
    40479,  # internal JSON serializer error
]

# Oracle error codes that result in InterfaceError exceptions
ERR_INTERFACE_ERROR_CODES = [
    24422,  # error occurred while trying to destroy the Session Pool
]

# Oracle error codes that result in OperationalError exceptions
ERR_OPERATIONAL_ERROR_CODES = [
    22,  # invalid session ID; access denied
    378,  # buffer pools cannot be created as specified
    600,  # internal error code
    602,  # internal programming exception
    603,  # ORACLE server session terminated by fatal error
    604,  # error occurred at recursive SQL level
    609,  # could not attach to incoming connection
    1012,  # not logged on
    1013,  # user requested cancel of current operation
    1033,  # ORACLE initialization or shutdown in progress
    1034,  # ORACLE not available
    1041,  # internal error. hostdef extension doesn't exist
    1043,  # user side memory corruption
    1089,  # immediate shutdown or close in progress
    1090,  # shutdown in progress - connection is not permitted
    1092,  # ORACLE instance terminated. Disconnection forced
    3111,  # break received on communication channel
    3113,  # end-of-file on communication channel
    3114,  # not connected to ORACLE
    3122,  # attempt to close ORACLE-side window on user side
    3135,  # connection lost contact
    12153,  # TNS:not connected
    12203,  # TNS:unable to connect to destination
    12500,  # TNS:listener failed to start a dedicated server process
    12571,  # TNS:packet writer failure
    27146,  # post/wait initialization failed
    28511,  # lost RPC connection to heterogeneous remote agent
]

# driver error message exception types (multiples of 1000)
ERR_EXCEPTION_TYPES = {
    1: exceptions.InterfaceError,
    2: exceptions.ProgrammingError,
    3: exceptions.NotSupportedError,
    4: exceptions.DatabaseError,
    5: exceptions.InternalError,
    6: exceptions.OperationalError,
    7: exceptions.Warning,
}

# error messages that have a troubleshooting section available
ERR_TROUBLESHOOTING_AVAILABLE = set(
    [
        "DPI-1047",  # Oracle Client library cannot be loaded
        "DPI-1072",  # Oracle Client library version is unsupported
        "DPY-3010",  # connections to Oracle Database version not supported
        "DPY-3015",  # password verifier type is not supported
        "DPY-4011",  # the database or network closed the connection
    ]
)

# error message formats
ERR_MESSAGE_FORMATS = {
    ERR_ACCESS_TOKEN_REQUIRES_TCPS: (
        "access_token requires use of the tcps protocol"
    ),
    ERR_ARGS_MUST_BE_LIST_OR_TUPLE: "arguments must be a list or tuple",
    ERR_ARGS_AND_KEYWORD_ARGS: (
        "expecting positional arguments or keyword arguments, not both"
    ),
    ERR_ARRAY_DML_ROW_COUNTS_NOT_ENABLED: (
        "array DML row counts mode is not enabled"
    ),
    ERR_ARRAYS_OF_ARRAYS: "arrays of arrays are not supported",
    ERR_BUFFER_LENGTH_INSUFFICIENT: (
        "internal error: buffer of length {actual_buffer_len} "
        "insufficient to hold {required_buffer_len} bytes"
    ),
    ERR_CALL_TIMEOUT_EXCEEDED: "call timeout of {timeout} ms exceeded",
    ERR_CANNOT_PARSE_CONNECT_STRING: 'cannot parse connect string "{data}"',
    ERR_COLUMN_TRUNCATED: (
        "column truncated to {col_value_len} {unit}. "
        "Untruncated was {actual_len}"
    ),
    ERR_CONNECTION_FAILED: (
        "cannot connect to database (CONNECTION_ID={connection_id})."
    ),
    ERR_CONTENT_INVALID_AFTER_NUMBER: "invalid number (content after number)",
    ERR_CURSOR_DIFF_CONNECTION: (
        "binding a cursor from a different connection is not supported"
    ),
    ERR_CURSOR_NOT_OPEN: "cursor is not open",
    ERR_CURSOR_HAS_BEEN_CLOSED: "cursor has been closed by the database",
    ERR_DBOBJECT_ATTR_MAX_SIZE_VIOLATED: (
        "attribute {attr_name} of type {type_name} exceeds its maximum size "
        "(actual: {actual_size}, maximum: {max_size})"
    ),
    ERR_DBOBJECT_ELEMENT_MAX_SIZE_VIOLATED: (
        "element {index} of type {type_name} exceeds its maximum size "
        "(actual: {actual_size}, maximum: {max_size})"
    ),
    ERR_DB_TYPE_NOT_SUPPORTED: 'database type "{name}" is not supported',
    ERR_DML_RETURNING_DUP_BINDS: (
        'the bind variable placeholder ":{name}" cannot be used both before '
        "and after the RETURNING clause in a DML RETURNING statement"
    ),
    ERR_DUPLICATED_PARAMETER: (
        '"{deprecated_name}" and "{new_name}" cannot be specified together'
    ),
    ERR_EXCEEDED_IDLE_TIME: (
        "the database closed the connection because the connection's idle "
        "time has been exceeded"
    ),
    ERR_EXECUTE_MODE_ONLY_FOR_DML: (
        'parameters "batcherrors" and "arraydmlrowcounts" may only be '
        "true when used with insert, update, delete and merge statements"
    ),
    ERR_EXPECTING_LIST_FOR_ARRAY_VAR: (
        "expecting list when setting array variables"
    ),
    ERR_EXPECTING_TYPE: "expected a type",
    ERR_EXPECTING_VAR: (
        "type handler should return None or the value returned by a call "
        "to cursor.var()"
    ),
    ERR_EXPIRED_ACCESS_TOKEN: "access token has expired",
    ERR_FEATURE_NOT_SUPPORTED: (
        "{feature} is only supported in python-oracledb {driver_type} mode"
    ),
    ERR_HTTPS_PROXY_REQUIRES_TCPS: (
        "https_proxy requires use of the tcps protocol"
    ),
    ERR_IFILE_CYCLE_DETECTED: (
        "file '{including_file_name}' includes file '{included_file_name}', "
        "which forms a cycle"
    ),
    ERR_INCONSISTENT_DATATYPES: (
        "cannot convert from data type {input_type} to {output_type}"
    ),
    ERR_INCORRECT_VAR_ARRAYSIZE: (
        "variable array size of {var_arraysize} is "
        "too small (should be at least {required_arraysize})"
    ),
    ERR_INIT_ORACLE_CLIENT_NOT_CALLED: (
        "init_oracle_client() must be called first"
    ),
    ERR_INTEGER_TOO_LARGE: (
        "internal error: read integer of length {length} when expecting "
        "integer of no more than length {max_length}"
    ),
    ERR_INVALID_ACCESS_TOKEN_PARAM: (
        "invalid access token: value must be a string (for OAuth), a "
        "2-tuple containing the token and private key strings (for IAM), "
        "or a callable that returns a string or 2-tuple"
    ),
    ERR_INVALID_ACCESS_TOKEN_RETURNED: (
        "invalid access token returned from callable: value must be a "
        "string (for OAuth) or a 2-tuple containing the token and private "
        "key strings (for IAM)"
    ),
    ERR_INVALID_ARRAYSIZE: "arraysize must be an integer greater than zero",
    ERR_INVALID_BIND_NAME: (
        'no bind placeholder named ":{name}" was found in the SQL text'
    ),
    ERR_INVALID_CONN_CLASS: "invalid connection class",
    ERR_INVALID_CONNECT_DESCRIPTOR: 'invalid connect descriptor "{data}"',
    ERR_INVALID_CONNECT_PARAMS: "invalid connection params",
    ERR_INVALID_COLL_INDEX_GET: "element at index {index} does not exist",
    ERR_INVALID_COLL_INDEX_SET: (
        "given index {index} must be in the range of {min_index} to "
        "{max_index}"
    ),
    ERR_INVALID_ENUM_VALUE: "invalid value for enumeration {name}: {value}",
    ERR_INVALID_LOB_AMOUNT: "LOB amount must be greater than zero",
    ERR_INVALID_LOB_OFFSET: "LOB offset must be greater than zero",
    ERR_INVALID_MAKEDSN_ARG: '"{name}" argument contains invalid values',
    ERR_INVALID_NUMBER: "invalid number",
    ERR_INVALID_OBJECT_TYPE_NAME: 'invalid object type name: "{name}"',
    ERR_INVALID_OCI_ATTR_TYPE: "invalid OCI attribute type {attr_type}",
    ERR_INVALID_PASSWORD_TYPE: 'invalid password type "{password_type}"',
    ERR_INVALID_POOL_CLASS: "invalid connection pool class",
    ERR_INVALID_POOL_PARAMS: "invalid pool params",
    ERR_INVALID_PROTOCOL: 'invalid protocol "{protocol}"',
    ERR_INVALID_REDIRECT_DATA: "invalid redirect data {data}",
    ERR_INVALID_REF_CURSOR: "invalid REF CURSOR: never opened in PL/SQL",
    ERR_INVALID_SERVER_CERT_DN: (
        "The distinguished name (DN) on the server certificate does not "
        "match the expected value: {expected_dn}"
    ),
    ERR_INVALID_SERVER_NAME: (
        "The name on the server certificate does not match the expected "
        'value: "{expected_name}"'
    ),
    ERR_INVALID_SERVER_TYPE: "invalid server_type: {server_type}",
    ERR_INVALID_SERVICE_NAME: (
        'Service "{service_name}" is not registered with the listener at '
        'host "{host}" port {port}. (Similar to ORA-12514)'
    ),
    ERR_INVALID_SID: (
        'SID "{sid}" is not registered with the listener at host "{host}" '
        "port {port}. (Similar to ORA-12505)"
    ),
    ERR_INVALID_SSL_VERSION: 'invalid value for ssl_version: "{ssl_version}"',
    ERR_INVALID_TPC_BEGIN_FLAGS: "invalid flags for tpc_begin()",
    ERR_INVALID_TPC_END_FLAGS: "invalid flags for tpc_end()",
    ERR_INVALID_VECTOR: "vector cannot contain zero dimensions",
    ERR_KEYWORD_ARGS_MUST_BE_DICT: (
        '"keyword_parameters" argument must be a dict'
    ),
    ERR_LIBRARY_ALREADY_INITIALIZED: (
        "init_oracle_client() was already called with different arguments"
    ),
    ERR_LISTENER_REFUSED_CONNECTION: (
        "Listener refused connection. (Similar to ORA-{error_code})"
    ),
    ERR_LOB_OF_WRONG_TYPE: (
        "LOB is of type {actual_type_name} but must be of type "
        "{expected_type_name}"
    ),
    ERR_MESSAGE_HAS_NO_PAYLOAD: "message has no payload",
    ERR_MESSAGE_TYPE_UNKNOWN: (
        "internal error: unknown protocol message type {message_type} "
        "at position {position}"
    ),
    ERR_MISMATCHED_TOKEN: (
        "internal error: pipeline token number {token_num} does not match "
        "expected token number {expected_token_num}"
    ),
    ERR_MISSING_ADDRESS: (
        "no addresses are defined in connect descriptor: {connect_string}"
    ),
    ERR_MISSING_BIND_VALUE: (
        'a bind variable replacement value for placeholder ":{name}" was '
        "not provided"
    ),
    ERR_MISSING_CONNECT_DESCRIPTOR: (
        '"connect_descriptor" key missing from configuration'
    ),
    ERR_MISSING_FILE: "file '{file_name}' is missing or unreadable",
    ERR_MISSING_ENDING_DOUBLE_QUOTE: 'missing ending quote (")',
    ERR_MISSING_ENDING_SINGLE_QUOTE: "missing ending quote (')",
    ERR_MISSING_TYPE_NAME_FOR_OBJECT_VAR: (
        "no object type specified for object variable"
    ),
    ERR_MIXED_ELEMENT_TYPES: (
        "element {element} is not the same data type as previous elements"
    ),
    ERR_MIXED_POSITIONAL_AND_NAMED_BINDS: (
        "positional and named binds cannot be intermixed"
    ),
    ERR_NAMED_POOL_EXISTS: (
        'connection pool with alias "{alias}" already exists'
    ),
    ERR_NAMED_POOL_MISSING: (
        'connection pool with alias "{alias}" does not exist'
    ),
    ERR_NAMED_TIMEZONE_NOT_SUPPORTED: (
        "named time zones are not supported in thin mode"
    ),
    ERR_NCHAR_CS_NOT_SUPPORTED: (
        "national character set id {charset_id} is not supported by "
        "python-oracledb in thin mode"
    ),
    ERR_NO_CONFIG_DIR: "no configuration directory specified",
    ERR_NO_CREDENTIALS: "no credentials specified",
    ERR_NO_CRYPTOGRAPHY_PACKAGE: (
        "python-oracledb thin mode cannot be used because the "
        "cryptography package cannot be imported"
    ),
    ERR_NO_STATEMENT: "no statement specified and no prior statement prepared",
    ERR_NO_STATEMENT_EXECUTED: "no statement executed",
    ERR_NO_STATEMENT_PREPARED: "statement must be prepared first",
    ERR_NOT_A_QUERY: "the executed statement does not return rows",
    ERR_NOT_CONNECTED: "not connected to database",
    ERR_NOT_IMPLEMENTED: "not implemented",
    ERR_NUMBER_STRING_OF_ZERO_LENGTH: "invalid number: zero length string",
    ERR_NUMBER_STRING_TOO_LONG: "invalid number: string too long",
    ERR_NUMBER_WITH_EMPTY_EXPONENT: "invalid number: empty exponent",
    ERR_NUMBER_WITH_INVALID_EXPONENT: "invalid number: invalid exponent",
    ERR_OBJECT_IS_NOT_A_COLLECTION: "object {name} is not a collection",
    ERR_OPERATION_NOT_SUPPORTED_ON_BFILE: (
        "operation is not supported on BFILE LOBs"
    ),
    ERR_OPERATION_ONLY_SUPPORTED_ON_BFILE: (
        "operation is only supported on BFILE LOBs"
    ),
    ERR_ORACLE_NUMBER_NO_REPR: (
        "value cannot be represented as an Oracle number"
    ),
    ERR_ORACLE_TYPE_NAME_NOT_SUPPORTED: (
        'Oracle data type name "{name}" is not supported'
    ),
    ERR_ORACLE_TYPE_NOT_SUPPORTED: "Oracle data type {num} is not supported",
    ERR_OSON_FIELD_NAME_LIMITATION: (
        "OSON field names may not exceed {max_fname_size} UTF-8 encoded bytes"
    ),
    ERR_OSON_NODE_TYPE_NOT_SUPPORTED: (
        "OSON node type 0x{node_type:x} is not supported"
    ),
    ERR_OSON_VERSION_NOT_SUPPORTED: "OSON version {version} is not supported",
    ERR_PARAMS_HOOK_HANDLER_FAILED: (
        "registered handler for params hook failed"
    ),
    ERR_PASSWORD_TYPE_HANDLER_FAILED: (
        'registered handler for password type "{password_type}" failed'
    ),
    ERR_PAYLOAD_CANNOT_BE_ENQUEUED: (
        "payload cannot be enqueued since it does not match the payload type "
        "supported by the queue"
    ),
    ERR_PLAINTEXT_PASSWORD_IN_CONFIG: (
        "password in configuration must specify a type"
    ),
    ERR_POOL_HAS_BUSY_CONNECTIONS: (
        "connection pool cannot be closed because connections are busy"
    ),
    ERR_POOL_NO_CONNECTION_AVAILABLE: (
        "timed out waiting for the connection pool to return a connection"
    ),
    ERR_POOL_NOT_OPEN: "connection pool is not open",
    ERR_PROTOCOL_HANDLER_FAILED: (
        'registered handler for protocol "{protocol}" failed for arg "{arg}"'
    ),
    ERR_PROXY_FAILURE: "network proxy failed: response was {response}",
    ERR_PYTHON_TYPE_NOT_SUPPORTED: "Python type {typ} is not supported",
    ERR_PYTHON_VALUE_NOT_SUPPORTED: (
        'Python value of type "{type_name}" is not supported'
    ),
    ERR_SCROLL_OUT_OF_RESULT_SET: (
        "scroll operation would go out of the result set"
    ),
    ERR_SELF_BIND_NOT_SUPPORTED: "binding to self is not supported",
    ERR_CONNECTION_CLOSED: "the database or network closed the connection",
    ERR_SERVER_VERSION_NOT_SUPPORTED: (
        "connections to this database server version are not supported "
        "by python-oracledb in thin mode"
    ),
    ERR_TDS_TYPE_NOT_SUPPORTED: "Oracle TDS data type {num} is not supported",
    ERR_THICK_MODE_ENABLED: (
        "python-oracledb thin mode cannot be used because thick mode has "
        "already been enabled"
    ),
    ERR_THIN_CONNECTION_ALREADY_CREATED: (
        "python-oracledb thick mode cannot be used because thin mode has "
        "already been enabled or a thin mode connection has already been "
        "created"
    ),
    ERR_TIME_NOT_SUPPORTED: (
        "Oracle Database does not support time only variables"
    ),
    ERR_TNS_ENTRY_NOT_FOUND: 'unable to find "{name}" in {file_name}',
    ERR_TOO_MANY_BATCH_ERRORS: (
        "the number of batch errors from executemany() exceeds 65535"
    ),
    ERR_UNEXPECTED_PIPELINE_FAILURE: "unexpected pipeline failure",
    ERR_UNEXPECTED_DATA: "unexpected data received: {data}",
    ERR_UNEXPECTED_END_OF_DATA: (
        "unexpected end of data: want {num_bytes_wanted} bytes but "
        "only {num_bytes_available} bytes are available"
    ),
    ERR_UNEXPECTED_NEGATIVE_INTEGER: (
        "internal error: read a negative integer when expecting a "
        "positive integer"
    ),
    ERR_UNEXPECTED_REFUSE: (
        "the listener refused the connection but an unexpected error "
        "format was returned"
    ),
    ERR_UNEXPECTED_XML_TYPE: "unexpected XMLType with flag {flag}",
    ERR_UNKNOWN_SERVER_PIGGYBACK: (
        "internal error: unknown server side piggyback opcode {opcode}"
    ),
    ERR_UNKNOWN_TRANSACTION_STATE: (
        "internal error: unknown transaction state {state}"
    ),
    ERR_UNSUPPORTED_PIPELINE_OPERATION: (
        "unsupported pipeline operation type: {op_type}"
    ),
    ERR_UNSUPPORTED_INBAND_NOTIFICATION: (
        "unsupported in-band notification with error number {err_num}"
    ),
    ERR_UNSUPPORTED_PYTHON_TYPE_FOR_DB_TYPE: (
        "unsupported Python type {py_type_name} for database type "
        "{db_type_name}"
    ),
    ERR_UNSUPPORTED_TYPE_SET: "type {db_type_name} does not support being set",
    ERR_UNSUPPORTED_VERIFIER_TYPE: (
        "password verifier type 0x{verifier_type:x} is not supported by "
        "python-oracledb in thin mode"
    ),
    ERR_VECTOR_FORMAT_NOT_SUPPORTED: (
        "VECTOR type {vector_format} is not supported"
    ),
    ERR_VECTOR_VERSION_NOT_SUPPORTED: (
        "VECTOR version {version} is not supported"
    ),
    ERR_WALLET_FILE_MISSING: "wallet file {name} was not found",
    ERR_WRONG_ARRAY_DEFINITION: (
        "expecting a list of two elements [type, numelems]"
    ),
    ERR_WRONG_EXECUTE_PARAMETERS_TYPE: (
        "expecting a dictionary, list or tuple, or keyword args"
    ),
    ERR_WRONG_EXECUTEMANY_PARAMETERS_TYPE: (
        '"parameters" argument should be a list of sequences or '
        "dictionaries, or an integer specifying the number of "
        "times to execute the statement"
    ),
    ERR_WRONG_NUMBER_OF_POSITIONAL_BINDS: (
        "{expected_num} positional bind values are required but "
        "{actual_num} were provided"
    ),
    ERR_WRONG_OBJECT_TYPE: (
        'found object of type "{actual_schema}.{actual_name}" when '
        'expecting object of type "{expected_schema}.{expected_name}"'
    ),
    ERR_WRONG_SCROLL_MODE: (
        "scroll mode must be relative, absolute, first or last"
    ),
    WRN_COMPILATION_ERROR: "creation succeeded with compilation errors",
    ERR_INVALID_NETWORK_NAME: (
        '"{name}" includes characters that are not allowed'
    ),
    ERR_ARROW_UNSUPPORTED_DATA_TYPE: (
        "conversion from Oracle Database type {db_type_name} to Apache "
        "Arrow format is not supported"
    ),
    ERR_ARROW_C_API_ERROR: (
        "Arrow C Data Interface operation failed with error code {code}"
    ),
}


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\exceptions.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2020, 2023, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# exceptions.py
#
# Contains the exception classes mandated by the Python Database API.
# -----------------------------------------------------------------------------


class Warning(Exception):
    pass


class Error(Exception):
    pass


class DatabaseError(Error):
    pass


class DataError(DatabaseError):
    pass


class IntegrityError(DatabaseError):
    pass


class InterfaceError(Error):
    pass


class InternalError(DatabaseError):
    pass


class NotSupportedError(DatabaseError):
    pass


class OperationalError(DatabaseError):
    pass


class ProgrammingError(DatabaseError):
    pass


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\fetch_info.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2023, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# fetch_info.py
#
# Contains the FetchInfo class which stores metadata about columns that are
# being fetched.
# -----------------------------------------------------------------------------

from typing import Union

import oracledb

from . import __name__ as MODULE_NAME
from . import constants
from .dbobject import DbObjectType
from .base_impl import (
    DbType,
    DB_TYPE_DATE,
    DB_TYPE_TIMESTAMP,
    DB_TYPE_TIMESTAMP_LTZ,
    DB_TYPE_TIMESTAMP_TZ,
    DB_TYPE_BINARY_FLOAT,
    DB_TYPE_BINARY_DOUBLE,
    DB_TYPE_BINARY_INTEGER,
    DB_TYPE_NUMBER,
    DB_TYPE_VECTOR,
)


class FetchInfo:
    """
    Identifies metadata of columns that are being fetched.
    """

    __module__ = MODULE_NAME

    def __eq__(self, other):
        return tuple(self) == other

    def __getitem__(self, index):
        """
        Return the parts mandated by the Python Database API.
        """
        if index == 0 or index == -7:
            return self.name
        elif index == 1 or index == -6:
            return self.type_code
        elif index == 2 or index == -5:
            return self.display_size
        elif index == 3 or index == -4:
            return self.internal_size
        elif index == 4 or index == -3:
            return self.precision
        elif index == 5 or index == -2:
            return self.scale
        elif index == 6 or index == -1:
            return self.null_ok
        elif isinstance(index, slice):
            return tuple(self).__getitem__(index)
        raise IndexError("list index out of range")

    def __len__(self):
        """
        Length mandated by the Python Database API.
        """
        return 7

    def __repr__(self):
        return repr(tuple(self))

    def __str__(self):
        return str(tuple(self))

    @classmethod
    def _from_impl(cls, impl):
        info = cls.__new__(cls)
        info._impl = impl
        info._type = None
        return info

    @property
    def annotations(self) -> Union[dict, None]:
        """
        Returns a dictionary of the annotations associated with the column, if
        applicable.
        """
        return self._impl.annotations

    @property
    def display_size(self) -> Union[int, None]:
        """
        Returns the display size of the column.
        """
        if self._impl.max_size > 0:
            return self._impl.max_size
        dbtype = self._impl.dbtype
        if (
            dbtype is DB_TYPE_DATE
            or dbtype is DB_TYPE_TIMESTAMP
            or dbtype is DB_TYPE_TIMESTAMP_LTZ
            or dbtype is DB_TYPE_TIMESTAMP_TZ
        ):
            return 23
        elif (
            dbtype is DB_TYPE_BINARY_FLOAT
            or dbtype is DB_TYPE_BINARY_DOUBLE
            or dbtype is DB_TYPE_BINARY_INTEGER
            or dbtype is DB_TYPE_NUMBER
        ):
            if self._impl.precision:
                display_size = self._impl.precision + 1
                if self._impl.scale > 0:
                    display_size += self._impl.scale + 1
            else:
                display_size = 127
            return display_size

    @property
    def domain_name(self) -> Union[str, None]:
        """
        Returns the name of the domain, if applicable.
        """
        return self._impl.domain_name

    @property
    def domain_schema(self) -> Union[str, None]:
        """
        Returns the name of the schema in which the domain is found, if
        applicable.
        """
        return self._impl.domain_schema

    @property
    def internal_size(self) -> Union[int, None]:
        """
        Returns the size in bytes of the column.
        """
        if self._impl.max_size > 0:
            return self._impl.buffer_size

    @property
    def is_json(self) -> bool:
        """
        Returns whether the column contains JSON.
        """
        return self._impl.is_json

    @property
    def is_oson(self) -> bool:
        """
        Returns whether the column contains OSON encoded bytes.
        """
        return self._impl.is_oson

    @property
    def name(self) -> str:
        """
        Returns the name of the column.
        """
        return self._impl.name

    @property
    def null_ok(self) -> bool:
        """
        Returns whether nulls or permitted or not in the column.
        """
        return self._impl.nulls_allowed

    @property
    def precision(self) -> Union[int, None]:
        """
        Returns the precision of the column.
        """
        if self._impl.precision or self._impl.scale:
            return self._impl.precision

    @property
    def scale(self) -> Union[int, None]:
        """
        Returns the scale of the column.
        """
        if self._impl.precision or self._impl.scale:
            return self._impl.scale

    @property
    def type(self) -> Union[DbType, DbObjectType]:
        """
        Returns the type of the column, as either a database object type or a
        database type.
        """
        if self._type is None:
            if self._impl.objtype is not None:
                self._type = DbObjectType._from_impl(self._impl.objtype)
            else:
                self._type = self._impl.dbtype
        return self._type

    @property
    def type_code(self) -> DbType:
        """
        Returns the type of the column.
        """
        return self._impl.dbtype

    @property
    def vector_dimensions(self) -> [int, None]:
        """
        Returns the number of dimensions required by vector columns. If the
        column is not a vector column or allows for any number of dimensions,
        the value returned is None.
        """
        if self._impl.dbtype is DB_TYPE_VECTOR:
            flags = self._impl.vector_flags
            if not (flags & constants.VECTOR_META_FLAG_FLEXIBLE_DIM):
                return self._impl.vector_dimensions

    @property
    def vector_format(self) -> [oracledb.VectorFormat, None]:
        """
        Returns the storage type required by vector columns. If the column is
        not a vector column or allows for any type of storage, the value
        returned is None.
        """
        if (
            self._impl.dbtype is DB_TYPE_VECTOR
            and self._impl.vector_format != 0
        ):
            return oracledb.VectorFormat(self._impl.vector_format)

    @property
    def vector_is_sparse(self) -> Union[bool, None]:
        """
        Returns a boolean indicating if the vector is sparse or not. If the
        column is not a vector column, the value returned is None.
        """
        if self._impl.dbtype is DB_TYPE_VECTOR:
            flags = self._impl.vector_flags
            return bool(flags & constants.VECTOR_META_FLAG_SPARSE_VECTOR)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\future.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2020, 2023, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# future.py
#
# Module for handling backwards incompatible changes.
# -----------------------------------------------------------------------------

FEATURES = []


# future object used for managing backwards incompatible changes
class Future:
    def __getattr__(self, name):
        if name in FEATURES:
            return super().__getattr__(name)
        return None

    def __setattr__(self, name, value):
        if name in FEATURES:
            return super().__setattr__(name, value)


future = Future()


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\bind_var.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2022, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# bind_var.pyx
#
# Cython file defining the BindVar implementation class (embedded in
# base_impl.pyx).
#------------------------------------------------------------------------------

@cython.freelist(20)
cdef class BindVar:

    cdef int _create_var_from_type(self, object conn,
                                   BaseCursorImpl cursor_impl,
                                   object value) except -1:
        """
        Creates a variable given type information. This may be supplied as a
        list of size 2 (type, num_elements) which internally creates an array
        variable, or as an integer which internally creates a string of the
        given length, or as a database type, API type or Python type.
        """
        cdef BaseVarImpl var_impl
        var_impl = cursor_impl._create_var_impl(conn)
        var_impl.num_elements = 1
        if isinstance(value, list):
            if len(value) != 2:
                errors._raise_err(errors.ERR_WRONG_ARRAY_DEFINITION)
            var_impl._set_metadata_from_type(value[0])
            var_impl.num_elements = value[1]
            var_impl.is_array = True
        elif isinstance(value, int):
            var_impl._set_metadata_from_type(str)
            var_impl.metadata.max_size = value
        else:
            var_impl._set_metadata_from_type(value)
        var_impl._finalize_init()
        self.var_impl = var_impl
        if isinstance(value, PY_TYPE_DB_OBJECT_TYPE):
            self.var = PY_TYPE_VAR._from_impl(self.var_impl, value)

    cdef int _create_var_from_value(self, object conn,
                                    BaseCursorImpl cursor_impl, object value,
                                    uint32_t num_elements) except -1:
        """
        Creates a variable using the value as a template.
        """
        cdef:
            bint is_plsql = cursor_impl._is_plsql()
            OracleMetadata metadata
            BaseVarImpl var_impl
        var_impl = cursor_impl._create_var_impl(conn)
        if not isinstance(value, list):
            var_impl.num_elements = num_elements
            var_impl._set_metadata_from_value(value, is_plsql)
        else:
            var_impl.is_array = True
            var_impl.num_elements = max(num_elements, len(value))
            for element in value:
                if element is not None:
                    var_impl._set_metadata_from_value(element, is_plsql)
            if var_impl.metadata is None:
                metadata = OracleMetadata.__new__(OracleMetadata)
                metadata.dbtype = DB_TYPE_VARCHAR
                metadata.max_size = 1
                var_impl.metadata = metadata
        var_impl._finalize_init()
        self.var_impl = var_impl

    cdef int _set_by_type(self, object conn, BaseCursorImpl cursor_impl,
                          object typ) except -1:
        """
        Sets the bind variable information given a type.
        """
        if typ is not None:
            if isinstance(typ, PY_TYPE_VAR):
                self.var = typ
                self.var_impl = typ._impl
                if self.var_impl._has_returned_data:
                    self.var_impl._finalize_init()
            else:
                self._create_var_from_type(conn, cursor_impl, typ)

    cdef int _set_by_value(self, object conn, BaseCursorImpl cursor_impl,
                           object cursor, object value, object type_handler,
                           uint32_t row_num, uint32_t num_elements,
                           bint defer_type_assignment) except -1:
        """
        Sets the bind variable information given a value. The row number
        supplied is used as the offset into the variable value array. Type
        assignment is deferred for None values if specified. Once a value that
        is not None is set, an exception is raised for any non-compliant values
        that are seen after that.
        """
        cdef:
            bint was_set = True
            object var

        # a variable can be set directly in which case nothing further needs to
        # be done!
        if isinstance(value, PY_TYPE_VAR):
            if value is not self.var:
                self.var = value
                self.var_impl = value._impl
                if self.var_impl._has_returned_data:
                    self.var_impl._finalize_init()
            return 0

        # if a variable already exists check to see if the value can be set on
        # that variable; an exception is raised if a value has been previously
        # set on that bind variable; otherwise, the variable is replaced with a
        # new one
        if self.var_impl is not None:
            if self.has_value:
                return self.var_impl._check_and_set_value(row_num, value, NULL)
            self.var_impl._check_and_set_value(row_num, value, &was_set)
            if was_set:
                self.has_value = True
                return 0
            self.var_impl = None
            self.var = None

        # a new variable needs to be created; if the value is null (None),
        # however, and type assignment is deferred, nothing to do!
        if value is None and defer_type_assignment:
            return 0

        # if an input type handler is specified, call it; the input type
        # handler should return a variable or None; the value None implies
        # that the default processing should take place just as if no input
        # type handler was defined
        if type_handler is not None:
            var = type_handler(cursor, value, num_elements)
            if var is not None:
                if not isinstance(var, PY_TYPE_VAR):
                    errors._raise_err(errors.ERR_EXPECTING_VAR)
                self.var = var
                self.var_impl = var._impl
                self.var_impl._check_and_set_value(row_num, value, NULL)
                self.has_value = True
                return 0

        # otherwise, if no type handler exists or the type handler returned
        # the value None, create a new variable deriving type information
        # from the value that is being set
        self._create_var_from_value(conn, cursor_impl, value, num_elements)
        self.var_impl._check_and_set_value(row_num, value, NULL)
        self.has_value = True

    def get_value(self, uint32_t pos):
        """
        Internal method for getting the value of a variable at a given
        position.
        """
        if self.var_impl is not None:
            return self.var_impl.get_value(pos)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\buffer.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# buffer.pyx
#
# Cython file defining the low-level read and write methods for packed data.
#------------------------------------------------------------------------------

cdef enum:
    NUMBER_AS_TEXT_CHARS = 172
    NUMBER_MAX_DIGITS = 40

cdef class Buffer:

    cdef int _get_int_length_and_sign(self, uint8_t *length,
                                      bint *is_negative,
                                      uint8_t max_length) except -1:
        """
        Returns the length of an integer stored in the buffer. A check is also
        made to ensure the integer does not exceed the maximum length. If the
        is_negative pointer is NULL, negative integers will result in an
        exception being raised.
        """
        cdef const char_type *ptr = self._get_raw(1)
        if ptr[0] & 0x80:
            if is_negative == NULL:
                errors._raise_err(errors.ERR_UNEXPECTED_NEGATIVE_INTEGER)
            is_negative[0] = True
            length[0] = ptr[0] & 0x7f
        else:
            if is_negative != NULL:
                is_negative[0] = False
            length[0] = ptr[0]
        if length[0] > max_length:
            errors._raise_err(errors.ERR_INTEGER_TOO_LARGE, length=length[0],
                              max_length=max_length)

    cdef const char_type* _get_raw(self, ssize_t num_bytes) except NULL:
        """
        Returns a pointer to a buffer containing the requested number of bytes.
        """
        cdef:
            ssize_t num_bytes_left
            const char_type *ptr
        num_bytes_left = self._size - self._pos
        if num_bytes > num_bytes_left:
            errors._raise_err(errors.ERR_UNEXPECTED_END_OF_DATA,
                              num_bytes_wanted=num_bytes,
                              num_bytes_available=num_bytes_left)
        ptr = &self._data[self._pos]
        self._pos += num_bytes
        return ptr

    cdef int _initialize(self, ssize_t max_size = TNS_CHUNK_SIZE) except -1:
        """
        Initialize the buffer with an empty bytearray of the specified size.
        """
        self._max_size = max_size
        self._data_obj = bytearray(max_size)
        self._data_view = self._data_obj
        self._data = <char_type*> self._data_obj

    cdef int _populate_from_bytes(self, bytes data) except -1:
        """
        Initialize the buffer with the data in the specified byte string.
        """
        self._max_size = self._size = len(data)
        self._data_obj = bytearray(data)
        self._data_view = self._data_obj
        self._data = <char_type*> self._data_obj

    cdef int _read_raw_bytes_and_length(self, const char_type **ptr,
                                        ssize_t *num_bytes) except -1:
        """
        Helper function that processes the length (if needed) and then acquires
        the specified number of bytes from the buffer. The base function simply
        uses the length as given.
        """
        ptr[0] = self._get_raw(num_bytes[0])

    cdef int _resize(self, ssize_t new_max_size) except -1:
        """
        Resizes the buffer to the new maximum size, copying the data already
        stored in the buffer first.
        """
        cdef:
            bytearray data_obj
            char_type* data
        data_obj = bytearray(new_max_size)
        data = <char_type*> data_obj
        memcpy(data, self._data, self._max_size)
        self._max_size = new_max_size
        self._data_obj = data_obj
        self._data_view = data_obj
        self._data = data

    cdef int _skip_int(self, uint8_t max_length, bint *is_negative) except -1:
        """
        Skips reading an integer of the specified maximum length from the
        buffer.
        """
        cdef uint8_t length
        self._get_int_length_and_sign(&length, is_negative, max_length)
        self.skip_raw_bytes(length)

    cdef int _write_more_data(self, ssize_t num_bytes_available,
                              ssize_t num_bytes_wanted) except -1:
        """
        Called when the amount of buffer available is less than the amount of
        data requested. By default an error is raised.
        """
        errors._raise_err(errors.ERR_BUFFER_LENGTH_INSUFFICIENT,
                          required_buffer_len=num_bytes_wanted,
                          actual_buffer_len=num_bytes_available)

    cdef int _write_raw_bytes_and_length(self, const char_type *ptr,
                                         ssize_t num_bytes) except -1:
        """
        Helper function that writes the length in the format required before
        writing the bytes.
        """
        cdef ssize_t chunk_len
        if num_bytes <= TNS_MAX_SHORT_LENGTH:
            self.write_uint8(<uint8_t> num_bytes)
            if num_bytes > 0:
                self.write_raw(ptr, num_bytes)
        else:
            self.write_uint8(TNS_LONG_LENGTH_INDICATOR)
            while num_bytes > 0:
                chunk_len = min(num_bytes, TNS_CHUNK_SIZE)
                self.write_ub4(chunk_len)
                num_bytes -= chunk_len
                self.write_raw(ptr, chunk_len)
                ptr += chunk_len
            self.write_ub4(0)

    cdef inline ssize_t bytes_left(self):
        """
        Return the number of bytes remaining in the buffer.
        """
        return self._size - self._pos

    cdef int read_oracle_data(self, OracleMetadata metadata,
                              OracleData* data, bint from_dbobject) except -1:
        """
        Reads Oracle data of the given type from the buffer.
        """
        cdef:
            uint8_t ora_type_num
            const uint8_t* ptr
            ssize_t num_bytes
        self.read_raw_bytes_and_length(&ptr, &num_bytes)
        data.is_null = (ptr == NULL)
        if not data.is_null:
            ora_type_num = metadata.dbtype._ora_type_num
            if ora_type_num == ORA_TYPE_NUM_BINARY_DOUBLE:
                decode_binary_double(ptr, num_bytes, &data.buffer)
            elif ora_type_num == ORA_TYPE_NUM_BINARY_FLOAT:
                decode_binary_float(ptr, num_bytes, &data.buffer)
            elif ora_type_num == ORA_TYPE_NUM_BOOLEAN:
                decode_bool(ptr, num_bytes, &data.buffer)
            elif ora_type_num in (
                ORA_TYPE_NUM_CHAR,
                ORA_TYPE_NUM_LONG,
                ORA_TYPE_NUM_LONG_RAW,
                ORA_TYPE_NUM_RAW,
                ORA_TYPE_NUM_VARCHAR,
            ):
                data.buffer.as_raw_bytes.ptr = ptr
                data.buffer.as_raw_bytes.num_bytes = num_bytes
            elif ora_type_num in (
                ORA_TYPE_NUM_DATE,
                ORA_TYPE_NUM_TIMESTAMP,
                ORA_TYPE_NUM_TIMESTAMP_LTZ,
                ORA_TYPE_NUM_TIMESTAMP_TZ,
            ):
                decode_date(ptr, num_bytes, &data.buffer)
            elif ora_type_num == ORA_TYPE_NUM_INTERVAL_DS:
                decode_interval_ds(ptr, num_bytes, &data.buffer)
            elif ora_type_num == ORA_TYPE_NUM_INTERVAL_YM:
                decode_interval_ym(ptr, num_bytes, &data.buffer)
            elif from_dbobject and ora_type_num == ORA_TYPE_NUM_BINARY_INTEGER:
                data.buffer.as_integer = \
                        <int32_t> decode_integer(ptr, num_bytes)
            elif ora_type_num in (ORA_TYPE_NUM_NUMBER,
                                  ORA_TYPE_NUM_BINARY_INTEGER):
                decode_number(ptr, num_bytes, &data.buffer)
            else:
                errors._raise_err(errors.ERR_DB_TYPE_NOT_SUPPORTED,
                                  name=metadata.dbtype.name)

    cdef object read_bytes(self):
        """
        Read bytes from the buffer and return the corresponding Python object
        representing that value.
        """
        cdef:
            const char_type *ptr
            ssize_t num_bytes
        self.read_raw_bytes_and_length(&ptr, &num_bytes)
        if ptr != NULL:
            return ptr[:num_bytes]

    cdef object read_bytes_with_length(self):
        """
        Reads a length from the buffer and then, if the length is non-zero,
        reads bytes from the buffer and returns it.
        """
        cdef uint32_t num_bytes
        self.read_ub4(&num_bytes)
        if num_bytes > 0:
            return self.read_bytes()

    cdef int read_int32be(self, int32_t *value) except -1:
        """
        Read a signed 32-bit integer in big endian order from the buffer.
        """
        value[0] = <int32_t> decode_uint32be(self._get_raw(4))

    cdef const char_type* read_raw_bytes(self, ssize_t num_bytes) except NULL:
        """
        Returns a pointer to a contiguous buffer containing the specified
        number of bytes found in the buffer.
        """
        return self._get_raw(num_bytes)

    cdef int read_raw_bytes_and_length(self, const char_type **ptr,
                                       ssize_t *num_bytes) except -1:
        """
        Reads bytes from the buffer into a contiguous buffer. The first byte
        read is the number of bytes to read.
        """
        cdef uint8_t length
        self.read_ub1(&length)
        if length == 0 or length == TNS_NULL_LENGTH_INDICATOR:
            ptr[0] = NULL
            num_bytes[0] = 0
        else:
            num_bytes[0] = length
            self._read_raw_bytes_and_length(ptr, num_bytes)

    cdef int read_sb1(self, int8_t *value) except -1:
        """
        Reads a signed 8-bit integer from the buffer.
        """
        cdef const char_type *ptr = self._get_raw(1)
        value[0] = <int8_t> ptr[0]

    cdef int read_sb2(self, int16_t *value) except -1:
        """
        Reads a signed 16-bit integer from the buffer.
        """
        cdef:
            const char_type *ptr
            bint is_negative
            uint8_t length
        self._get_int_length_and_sign(&length, &is_negative, 2)
        if length == 0:
            value[0] = 0
        else:
            ptr = self._get_raw(length)
            value[0] = <int16_t> decode_integer(ptr, length)
            if is_negative:
                value[0] = -value[0]

    cdef int read_sb4(self, int32_t *value) except -1:
        """
        Reads a signed 32-bit integer from the buffer.
        """
        cdef:
            const char_type *ptr
            bint is_negative
            uint8_t length
        self._get_int_length_and_sign(&length, &is_negative, 4)
        if length == 0:
            value[0] = 0
        else:
            ptr = self._get_raw(length)
            value[0] = <int32_t> decode_integer(ptr, length)
            if is_negative:
                value[0] = -value[0]

    cdef int read_sb8(self, int64_t *value) except -1:
        """
        Reads a signed 64-bit integer from the buffer.
        """
        cdef:
            const char_type *ptr
            bint is_negative
            uint8_t length
        self._get_int_length_and_sign(&length, &is_negative, 8)
        if length == 0:
            value[0] = 0
        else:
            ptr = self._get_raw(length)
            value[0] = decode_integer(ptr, length)
            if is_negative:
                value[0] = -value[0]

    cdef bytes read_null_terminated_bytes(self):
        """
        Reads null-terminated bytes from the buffer (including the null
        terminator). It is assumed that the buffer contains the full amount. If
        it does not, the remainder of the buffer is returned instead.
        """
        cdef ssize_t start_pos = self._pos, end_pos = self._pos
        while self._data[end_pos] != 0 and end_pos < self._size:
            end_pos += 1
        self._pos = end_pos + 1
        return self._data[start_pos:self._pos]

    cdef object read_str(self, int csfrm, const char* encoding_errors=NULL):
        """
        Reads bytes from the buffer and decodes them into a string following
        the supplied character set form.
        """
        cdef:
            const char_type *ptr
            ssize_t num_bytes
        self.read_raw_bytes_and_length(&ptr, &num_bytes)
        if ptr != NULL:
            if csfrm == CS_FORM_IMPLICIT:
                return ptr[:num_bytes].decode(ENCODING_UTF8, encoding_errors)
            return ptr[:num_bytes].decode(ENCODING_UTF16, encoding_errors)

    cdef object read_str_with_length(self):
        """
        Reads a length from the buffer and then, if the length is non-zero,
        reads string from the buffer and returns it.
        """
        cdef uint32_t num_bytes
        self.read_ub4(&num_bytes)
        if num_bytes > 0:
            return self.read_str(CS_FORM_IMPLICIT)

    cdef int read_ub1(self, uint8_t *value) except -1:
        """
        Reads an unsigned 8-bit integer from the buffer.
        """
        cdef const char_type *ptr = self._get_raw(1)
        value[0] = ptr[0]

    cdef int read_ub2(self, uint16_t *value) except -1:
        """
        Reads an unsigned 16-bit integer from the buffer.
        """
        cdef:
            const char_type *ptr
            uint8_t length
        self._get_int_length_and_sign(&length, NULL, 2)
        if length == 0:
            value[0] = 0
        else:
            ptr = self._get_raw(length)
            value[0] = <uint16_t> decode_integer(ptr, length)

    cdef int read_ub4(self, uint32_t *value) except -1:
        """
        Reads an unsigned 32-bit integer from the buffer.
        """
        cdef:
            const char_type *ptr
            uint8_t length
        self._get_int_length_and_sign(&length, NULL, 4)
        if length == 0:
            value[0] = 0
        else:
            ptr = self._get_raw(length)
            value[0] = <uint32_t> decode_integer(ptr, length)

    cdef int read_ub8(self, uint64_t *value) except -1:
        """
        Reads an unsigned 64-bit integer from the buffer.
        """
        cdef:
            const char_type *ptr
            uint8_t length
        self._get_int_length_and_sign(&length, NULL, 8)
        if length == 0:
            value[0] = 0
        else:
            ptr = self._get_raw(length)
            value[0] = decode_integer(ptr, length)

    cdef int read_uint16be(self, uint16_t *value) except -1:
        """
        Read a 16-bit integer in big endian order from the buffer.
        """
        value[0] = decode_uint16be(self._get_raw(2))

    cdef int read_uint16le(self, uint16_t *value) except -1:
        """
        Read a 16-bit integer in little endian order from the buffer.
        """
        value[0] = decode_uint16le(self._get_raw(2))

    cdef int read_uint32be(self, uint32_t *value) except -1:
        """
        Read a 32-bit integer in big endian order from the buffer.
        """
        value[0] = decode_uint32be(self._get_raw(4))

    cdef int skip_raw_bytes(self, ssize_t num_bytes) except -1:
        """
        Skip the specified number of bytes in the buffer. In order to avoid
        copying data, the number of bytes left in the packet is determined and
        only that amount is requested.
        """
        cdef ssize_t num_bytes_this_time
        while num_bytes > 0:
            num_bytes_this_time = min(num_bytes, self.bytes_left())
            if num_bytes_this_time == 0:
                num_bytes_this_time = num_bytes
            self._get_raw(num_bytes_this_time)
            num_bytes -= num_bytes_this_time

    cdef inline int skip_sb4(self) except -1:
        """
        Skips a signed 32-bit integer in the buffer.
        """
        cdef bint is_negative
        return self._skip_int(4, &is_negative)

    cdef inline void skip_to(self, ssize_t pos):
        """
        Skips to the specified location in the buffer.
        """
        self._pos = pos

    cdef inline int skip_ub1(self) except -1:
        """
        Skips an unsigned 8-bit integer in the buffer.
        """
        self._get_raw(1)

    cdef inline int skip_ub2(self) except -1:
        """
        Skips an unsigned 16-bit integer in the buffer.
        """
        return self._skip_int(2, NULL)

    cdef inline int skip_ub4(self) except -1:
        """
        Skips an unsigned 32-bit integer in the buffer.
        """
        return self._skip_int(4, NULL)

    cdef inline int skip_ub8(self) except -1:
        """
        Skips an unsigned 64-bit integer in the buffer.
        """
        return self._skip_int(8, NULL)

    cdef int write_binary_double(self, double value,
                                 bint write_length=True) except -1:
        """
        Writes a double value to the buffer in Oracle canonical double floating
        point format.
        """
        cdef:
            uint8_t b0, b1, b2, b3, b4, b5, b6, b7
            uint64_t all_bits
            char_type buf[8]
            uint64_t *ptr
        ptr = <uint64_t*> &value
        all_bits = ptr[0]
        b7 = all_bits & 0xff
        b6 = (all_bits >> 8) & 0xff
        b5 = (all_bits >> 16) & 0xff
        b4 = (all_bits >> 24) & 0xff
        b3 = (all_bits >> 32) & 0xff
        b2 = (all_bits >> 40) & 0xff
        b1 = (all_bits >> 48) & 0xff
        b0 = (all_bits >> 56) & 0xff
        if b0 & 0x80 == 0:
            b0 = b0 | 0x80
        else:
            b0 = ~b0
            b1 = ~b1
            b2 = ~b2
            b3 = ~b3
            b4 = ~b4
            b5 = ~b5
            b6 = ~b6
            b7 = ~b7
        buf[0] = b0
        buf[1] = b1
        buf[2] = b2
        buf[3] = b3
        buf[4] = b4
        buf[5] = b5
        buf[6] = b6
        buf[7] = b7
        if write_length:
            self.write_uint8(8)
        self.write_raw(buf, 8)

    cdef int write_binary_float(self, float value,
                                bint write_length=True) except -1:
        """
        Writes a float value to the buffer in Oracle canonical floating point
        format.
        """
        cdef:
            uint8_t b0, b1, b2, b3
            uint32_t all_bits
            char_type buf[4]
            uint32_t *ptr
        ptr = <uint32_t*> &value
        all_bits = ptr[0]
        b3 = all_bits & 0xff
        b2 = (all_bits >> 8) & 0xff
        b1 = (all_bits >> 16) & 0xff
        b0 = (all_bits >> 24) & 0xff
        if b0 & 0x80 == 0:
            b0 = b0 | 0x80
        else:
            b0 = ~b0
            b1 = ~b1
            b2 = ~b2
            b3 = ~b3
        buf[0] = b0
        buf[1] = b1
        buf[2] = b2
        buf[3] = b3
        if write_length:
            self.write_uint8(4)
        self.write_raw(buf, 4)

    cdef int write_bool(self, bint value) except -1:
        """
        Writes a boolean value to the buffer.
        """
        if value:
            self.write_uint8(2)
            self.write_uint16be(0x0101)
        else:
            self.write_uint16be(0x0100)

    cdef int write_bytes(self, bytes value) except -1:
        """
        Writes the bytes to the buffer directly.
        """
        cdef:
            ssize_t value_len
            char_type *ptr
        cpython.PyBytes_AsStringAndSize(value, <char**> &ptr, &value_len)
        self.write_raw(ptr, value_len)

    cdef int write_bytes_with_length(self, bytes value) except -1:
        """
        Writes the bytes to the buffer after first writing the length.
        """
        cdef:
            ssize_t value_len
            char_type *ptr
        cpython.PyBytes_AsStringAndSize(value, <char**> &ptr, &value_len)
        self._write_raw_bytes_and_length(ptr, value_len)

    cdef int write_interval_ds(self, object value,
                               bint write_length=True) except -1:
        """
        Writes an interval to the buffer in Oracle Interval Day To Second
        format.
        """
        cdef:
            int32_t days, seconds, fseconds
            char_type buf[11]
        days = cydatetime.timedelta_days(value)
        encode_uint32be(buf, days + TNS_DURATION_MID)
        seconds = cydatetime.timedelta_seconds(value)
        buf[4] = (seconds // 3600) + TNS_DURATION_OFFSET
        seconds = seconds % 3600
        buf[5] = (seconds // 60) + TNS_DURATION_OFFSET
        buf[6] = (seconds % 60) + TNS_DURATION_OFFSET
        fseconds = cydatetime.timedelta_microseconds(value) * 1000
        encode_uint32be(&buf[7], fseconds + TNS_DURATION_MID)
        if write_length:
            self.write_uint8(sizeof(buf))
        self.write_raw(buf, sizeof(buf))

    cdef int write_interval_ym(self, object value,
                               bint write_length=True) except -1:
        """
        Writes an interval to the buffer in Oracle Interval Day To Second
        format.
        """
        cdef:
            int32_t years, months
            char_type buf[5]
        years = (<tuple> value)[0]
        months = (<tuple> value)[1]
        encode_uint32be(buf, years + TNS_DURATION_MID)
        buf[4] = months + TNS_DURATION_OFFSET
        if write_length:
            self.write_uint8(sizeof(buf))
        self.write_raw(buf, sizeof(buf))

    cdef int write_oracle_date(self, object value, uint8_t length,
                               bint write_length=True) except -1:
        """
        Writes a date to the buffer in Oracle Date format.
        """
        cdef:
            unsigned int year
            char_type buf[13]
            uint32_t fsecond
        year = cydatetime.PyDateTime_GET_YEAR(value)
        buf[0] = <uint8_t> ((year // 100) + 100)
        buf[1] = <uint8_t> ((year % 100) + 100)
        buf[2] = <uint8_t> cydatetime.PyDateTime_GET_MONTH(value)
        buf[3] = <uint8_t> cydatetime.PyDateTime_GET_DAY(value)
        buf[4] = <uint8_t> cydatetime.PyDateTime_DATE_GET_HOUR(value) + 1
        buf[5] = <uint8_t> cydatetime.PyDateTime_DATE_GET_MINUTE(value) + 1
        buf[6] = <uint8_t> cydatetime.PyDateTime_DATE_GET_SECOND(value) + 1
        if length > 7:
            fsecond = <uint32_t> \
                    cydatetime.PyDateTime_DATE_GET_MICROSECOND(value) * 1000
            if fsecond == 0 and length <= 11:
                length = 7
            else:
                encode_uint32be(&buf[7], fsecond)
        if length > 11:
            buf[11] = TZ_HOUR_OFFSET
            buf[12] = TZ_MINUTE_OFFSET
        if write_length:
            self.write_uint8(length)
        self.write_raw(buf, length)

    cdef int write_oracle_number(self, bytes num_bytes) except -1:
        """
        Writes a number in UTF-8 encoded bytes in Oracle Number format to the
        buffer.
        """
        cdef:
            uint8_t num_digits = 0, digit, num_pairs, pair_num, digits_pos
            bint exponent_is_negative = False, append_sentinel = False
            ssize_t num_bytes_length, exponent_pos, pos = 0
            bint is_negative = False, prepend_zero = False
            uint8_t digits[NUMBER_AS_TEXT_CHARS]
            int16_t decimal_point_index
            int8_t exponent_on_wire
            const char_type *ptr
            int16_t exponent

        # zero length string cannot be converted
        num_bytes_length = len(num_bytes)
        if num_bytes_length == 0:
            errors._raise_err(errors.ERR_NUMBER_STRING_OF_ZERO_LENGTH)
        elif num_bytes_length > NUMBER_AS_TEXT_CHARS:
            errors._raise_err(errors.ERR_NUMBER_STRING_TOO_LONG)

        # check to see if number is negative (first character is '-')
        ptr = num_bytes
        if ptr[0] == b'-':
            is_negative = True
            pos += 1

        # scan for digits until the decimal point or exponent indicator found
        while pos < num_bytes_length:
            if ptr[pos] == b'.' or ptr[pos] == b'e' or ptr[pos] == b'E':
                break
            if ptr[pos] < b'0' or ptr[pos] > b'9':
                errors._raise_err(errors.ERR_INVALID_NUMBER)
            digit = ptr[pos] - <uint8_t> b'0'
            pos += 1
            if digit == 0 and num_digits == 0:
                continue
            digits[num_digits] = digit
            num_digits += 1
        decimal_point_index = num_digits

        # scan for digits following the decimal point, if applicable
        if pos < num_bytes_length and ptr[pos] == b'.':
            pos += 1
            while pos < num_bytes_length:
                if ptr[pos] == b'e' or ptr[pos] == b'E':
                    break
                digit = ptr[pos] - <uint8_t> b'0'
                pos += 1
                if digit == 0 and num_digits == 0:
                    decimal_point_index -= 1
                    continue
                digits[num_digits] = digit
                num_digits += 1

        # handle exponent, if applicable
        if pos < num_bytes_length and (ptr[pos] == b'e' or ptr[pos] == b'E'):
            pos += 1
            if pos < num_bytes_length:
                if ptr[pos] == b'-':
                    exponent_is_negative = True
                    pos += 1
                elif ptr[pos] == b'+':
                    pos += 1
            exponent_pos = pos
            while pos < num_bytes_length:
                if ptr[pos] < b'0' or ptr[pos] > b'9':
                    errors._raise_err(errors.ERR_NUMBER_WITH_INVALID_EXPONENT)
                pos += 1
            if exponent_pos == pos:
                errors._raise_err(errors.ERR_NUMBER_WITH_EMPTY_EXPONENT)
            exponent = <int16_t> int(ptr[exponent_pos:pos])
            if exponent_is_negative:
                exponent = -exponent
            decimal_point_index += exponent

        # if there is anything left in the string, that indicates an invalid
        # number as well
        if pos < num_bytes_length:
            errors._raise_err(errors.ERR_CONTENT_INVALID_AFTER_NUMBER)

        # skip trailing zeros
        while num_digits > 0 and digits[num_digits - 1] == 0:
            num_digits -= 1

        # value must be less than 1e126 and greater than 1e-129; the number of
        # digits also cannot exceed the maximum precision of Oracle numbers
        if num_digits > NUMBER_MAX_DIGITS or decimal_point_index > 126 \
                or decimal_point_index < -129:
            errors._raise_err(errors.ERR_ORACLE_NUMBER_NO_REPR)

        # if the exponent is odd, prepend a zero
        if decimal_point_index % 2 == 1:
            prepend_zero = True
            if num_digits > 0:
                digits[num_digits] = 0
                num_digits += 1
                decimal_point_index += 1

        # determine the number of digit pairs; if the number of digits is odd,
        # append a zero to make the number of digits even
        if num_digits % 2 == 1:
            digits[num_digits] = 0
            num_digits += 1
        num_pairs = num_digits // 2

        # append a sentinel 102 byte for negative numbers if there is room
        if is_negative and num_digits > 0 and num_digits < NUMBER_MAX_DIGITS:
            append_sentinel = True

        # write length of number
        self.write_uint8(num_pairs + 1 + append_sentinel)

        # if the number of digits is zero, the value is itself zero since all
        # leading and trailing zeros are removed from the digits string; this
        # is a special case
        if num_digits == 0:
            self.write_uint8(128)
            return 0

        # write the exponent
        exponent_on_wire = <int8_t> (decimal_point_index / 2) + 192
        if is_negative:
            exponent_on_wire = ~exponent_on_wire
        self.write_uint8(exponent_on_wire)

        # write the mantissa bytes
        digits_pos = 0
        for pair_num in range(num_pairs):
            if pair_num == 0 and prepend_zero:
                digit = digits[digits_pos]
                digits_pos += 1
            else:
                digit = digits[digits_pos] * 10 + digits[digits_pos + 1]
                digits_pos += 2
            if is_negative:
                digit = 101 - digit
            else:
                digit += 1
            self.write_uint8(digit)

        # append 102 byte for negative numbers if the number of digits is less
        # than the maximum allowable
        if append_sentinel:
            self.write_uint8(102)

    cdef int write_raw(self, const char_type *data, ssize_t length) except -1:
        """
        Writes raw bytes of the specified length to the buffer.
        """
        cdef ssize_t bytes_to_write
        while True:
            bytes_to_write = min(self._max_size - self._pos, length)
            if bytes_to_write > 0:
                memcpy(self._data + self._pos, <void*> data, bytes_to_write)
                self._pos += bytes_to_write
            if bytes_to_write == length:
                break
            self._write_more_data(self._max_size - self._pos, length)
            length -= bytes_to_write
            data += bytes_to_write

    cdef int write_sb4(self, int32_t value) except -1:
        """
        Writes a 32-bit signed integer to the buffer in universal format.
        """
        cdef uint8_t sign = 0
        if value < 0:
            value = -value
            sign = 0x80
        if value == 0:
            self.write_uint8(0)
        elif value <= UINT8_MAX:
            self.write_uint8(1 | sign)
            self.write_uint8(<uint8_t> value)
        elif value <= UINT16_MAX:
            self.write_uint8(2 | sign)
            self.write_uint16be(<uint16_t> value)
        else:
            self.write_uint8(4 | sign)
            self.write_uint32be(value)

    cdef int write_str(self, str value) except -1:
        """
        Writes a string to the buffer as UTF-8 encoded bytes.
        """
        self.write_bytes(value.encode())

    cdef int write_uint8(self, uint8_t value) except -1:
        """
        Writes an 8-bit integer to the buffer.
        """
        if self._pos + 1 > self._max_size:
            self._write_more_data(self._max_size - self._pos, 1)
        self._data[self._pos] = value
        self._pos += 1

    cdef int write_uint16be(self, uint16_t value) except -1:
        """
        Writes a 16-bit integer to the buffer in big endian format.
        """
        if self._pos + 2 > self._max_size:
            self._write_more_data(self._max_size - self._pos, 2)
        encode_uint16be(&self._data[self._pos], value)
        self._pos += 2

    cdef int write_uint16le(self, uint16_t value) except -1:
        """
        Writes a 16-bit integer to the buffer in little endian format.
        """
        if self._pos + 2 > self._max_size:
            self._write_more_data(self._max_size - self._pos, 2)
        encode_uint16le(&self._data[self._pos], value)
        self._pos += 2

    cdef int write_uint32be(self, uint32_t value) except -1:
        """
        Writes a 32-bit integer to the buffer in big endian format.
        """
        if self._pos + 4 > self._max_size:
            self._write_more_data(self._max_size - self._pos, 4)
        encode_uint32be(&self._data[self._pos], value)
        self._pos += 4

    cdef int write_uint64be(self, uint64_t value) except -1:
        """
        Writes a 64-bit integer to the buffer in big endian format.
        """
        if self._pos + 8 > self._max_size:
            self._write_more_data(self._max_size - self._pos, 8)
        encode_uint64be(&self._data[self._pos], value)
        self._pos += 8

    cdef int write_ub2(self, uint16_t value) except -1:
        """
        Writes a 16-bit integer to the buffer in universal format.
        """
        if value == 0:
            self.write_uint8(0)
        elif value <= UINT8_MAX:
            self.write_uint8(1)
            self.write_uint8(<uint8_t> value)
        else:
            self.write_uint8(2)
            self.write_uint16be(value)

    cdef int write_ub4(self, uint32_t value) except -1:
        """
        Writes a 32-bit integer to the buffer in universal format.
        """
        if value == 0:
            self.write_uint8(0)
        elif value <= UINT8_MAX:
            self.write_uint8(1)
            self.write_uint8(<uint8_t> value)
        elif value <= UINT16_MAX:
            self.write_uint8(2)
            self.write_uint16be(<uint16_t> value)
        else:
            self.write_uint8(4)
            self.write_uint32be(value)

    cdef int write_ub8(self, uint64_t value) except -1:
        """
        Writes a 64-bit integer to the buffer in universal format.
        """
        if value == 0:
            self.write_uint8(0)
        elif value <= UINT8_MAX:
            self.write_uint8(1)
            self.write_uint8(<uint8_t> value)
        elif value <= UINT16_MAX:
            self.write_uint8(2)
            self.write_uint16be(<uint16_t> value)
        elif value <= UINT32_MAX:
            self.write_uint8(4)
            self.write_uint32be(<uint32_t> value)
        else:
            self.write_uint8(8)
            self.write_uint64be(value)


cdef class GrowableBuffer(Buffer):

    cdef int _reserve_space(self, ssize_t num_bytes) except -1:
        """
        Reserves the requested amount of space in the buffer by moving the
        pointer forward, allocating more space if necessary.
        """
        self._pos += num_bytes
        if self._pos > self._size:
            self._write_more_data(self._size - self._pos + num_bytes,
                                  num_bytes)

    cdef int _write_more_data(self, ssize_t num_bytes_available,
                              ssize_t num_bytes_wanted) except -1:
        """
        Called when the amount of buffer available is less than the amount of
        data requested. The buffer is increased in multiples of TNS_CHUNK_SIZE
        in order to accomodate the number of bytes desired.
        """
        cdef:
            ssize_t num_bytes_needed = num_bytes_wanted - num_bytes_available
            ssize_t new_size
        new_size = (self._max_size + num_bytes_needed + TNS_CHUNK_SIZE - 1) & \
                ~(TNS_CHUNK_SIZE - 1)
        self._resize(new_size)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\connection.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# connection.pyx
#
# Cython file defining the base Connection implementation class (embedded in
# base_impl.pyx).
#------------------------------------------------------------------------------

cdef class BaseConnImpl:

    def __init__(self, str dsn, ConnectParamsImpl params):
        self.dsn = dsn
        self.username = params.user
        self.proxy_user = params.proxy_user
        self._oson_max_fname_size = 255

    cdef object _check_value(self, OracleMetadata metadata, object value,
                             bint* is_ok):
        """
        Checks that the specified Python value is acceptable for the given
        database type. If the "is_ok" parameter is passed as NULL, an exception
        is raised.  The value to use is returned (possibly modified from the
        value passed in).
        """
        cdef:
            uint32_t db_type_num
            BaseLobImpl lob_impl

        # null values are always accepted
        if value is None:
            return value

        # check to see if the Python value is accepted and perform any
        # necessary adjustments
        db_type_num = metadata.dbtype.num
        if db_type_num in (DB_TYPE_NUM_NUMBER,
                           DB_TYPE_NUM_BINARY_INTEGER,
                           DB_TYPE_NUM_BINARY_DOUBLE,
                           DB_TYPE_NUM_BINARY_FLOAT):
            if isinstance(value, (PY_TYPE_BOOL, int, float, PY_TYPE_DECIMAL)):
                if db_type_num in (DB_TYPE_NUM_BINARY_FLOAT,
                                   DB_TYPE_NUM_BINARY_DOUBLE):
                    return float(value)
                elif db_type_num == DB_TYPE_NUM_BINARY_INTEGER \
                        or cpython.PyBool_Check(value):
                    return int(value)
                return value
        elif db_type_num in (DB_TYPE_NUM_CHAR,
                             DB_TYPE_NUM_VARCHAR,
                             DB_TYPE_NUM_NCHAR,
                             DB_TYPE_NUM_NVARCHAR,
                             DB_TYPE_NUM_LONG_VARCHAR,
                             DB_TYPE_NUM_LONG_NVARCHAR):
            if isinstance(value, bytes):
                return (<bytes> value).decode()
            elif isinstance(value, str):
                return value
        elif db_type_num in (DB_TYPE_NUM_RAW, DB_TYPE_NUM_LONG_RAW):
            if isinstance(value, str):
                return (<str> value).encode()
            elif isinstance(value, bytes):
                return value
        elif db_type_num in (DB_TYPE_NUM_DATE,
                             DB_TYPE_NUM_TIMESTAMP,
                             DB_TYPE_NUM_TIMESTAMP_LTZ,
                             DB_TYPE_NUM_TIMESTAMP_TZ):
            if cydatetime.PyDateTime_Check(value) \
                    or cydatetime.PyDate_Check(value):
                return value
        elif db_type_num == DB_TYPE_NUM_INTERVAL_DS:
            if isinstance(value, PY_TYPE_TIMEDELTA):
                return value
        elif db_type_num in (DB_TYPE_NUM_CLOB,
                             DB_TYPE_NUM_NCLOB,
                             DB_TYPE_NUM_BLOB,
                             DB_TYPE_NUM_BFILE):
            if isinstance(value, (PY_TYPE_LOB, PY_TYPE_ASYNC_LOB)):
                lob_impl = value._impl
                if lob_impl.dbtype is not metadata.dbtype:
                    if is_ok != NULL:
                        is_ok[0] = False
                        return value
                    errors._raise_err(errors.ERR_LOB_OF_WRONG_TYPE,
                                      actual_type_name=lob_impl.dbtype.name,
                                      expected_type_name=metadata.dbtype.name)
                return value
            elif self._allow_bind_str_to_lob \
                    and db_type_num != DB_TYPE_NUM_BFILE \
                    and isinstance(value, (bytes, str)):
                if db_type_num == DB_TYPE_NUM_BLOB:
                    if isinstance(value, str):
                        value = value.encode()
                elif isinstance(value, bytes):
                    value = value.decode()
                lob_impl = self.create_temp_lob_impl(metadata.dbtype)
                if value:
                    lob_impl.write(value, 1)
                return PY_TYPE_LOB._from_impl(lob_impl)
        elif db_type_num == DB_TYPE_NUM_OBJECT:
            if isinstance(value, PY_TYPE_DB_OBJECT):
                if value._impl.type != metadata.objtype:
                    if is_ok != NULL:
                        is_ok[0] = False
                        return value
                    errors._raise_err(errors.ERR_WRONG_OBJECT_TYPE,
                                      actual_schema=value.type.schema,
                                      actual_name=value.type.name,
                                      expected_schema=metadata.objtype.schema,
                                      expected_name=metadata.objtype.name)
                return value
        elif db_type_num == DB_TYPE_NUM_CURSOR:
            if isinstance(value, (PY_TYPE_CURSOR, PY_TYPE_ASYNC_CURSOR)):
                value._verify_open()
                if value.connection._impl is not self:
                    errors._raise_err(errors.ERR_CURSOR_DIFF_CONNECTION)
                return value
        elif db_type_num == DB_TYPE_NUM_BOOLEAN:
            return bool(value)
        elif db_type_num == DB_TYPE_NUM_JSON:
            return value
        elif db_type_num == DB_TYPE_NUM_VECTOR:
            if isinstance(value, list):
                if len(value) == 0:
                    errors._raise_err(errors.ERR_INVALID_VECTOR)
                return array.array('d', value)
            elif isinstance(value, array.array) \
                    and value.typecode in ('f', 'd', 'b', 'B'):
                if len(value) == 0:
                    errors._raise_err(errors.ERR_INVALID_VECTOR)
                return value
            elif isinstance(value, PY_TYPE_SPARSE_VECTOR):
                return value
        elif db_type_num == DB_TYPE_NUM_INTERVAL_YM:
            if isinstance(value, PY_TYPE_INTERVAL_YM):
                return value
        else:
            if is_ok != NULL:
                is_ok[0] = False
                return value
            errors._raise_err(errors.ERR_UNSUPPORTED_TYPE_SET,
                              db_type_name=metadata.dbtype.name)

        # the Python value was not considered acceptable
        if is_ok != NULL:
            is_ok[0] = False
            return value
        errors._raise_err(errors.ERR_UNSUPPORTED_PYTHON_TYPE_FOR_DB_TYPE,
                          py_type_name=type(value).__name__,
                          db_type_name=metadata.dbtype.name)

    cdef BaseCursorImpl _create_cursor_impl(self):
        """
        Internal method for creating an empty cursor implementation object.
        """
        raise NotImplementedError()

    def _get_oci_attr(self, uint32_t handle_type, uint32_t attr_num,
                      uint32_t attr_type):
        errors._raise_not_supported("getting a connection OCI attribute")

    def _set_oci_attr(self, uint32_t handle_type, uint32_t attr_num,
                      uint32_t attr_type, object value):
        errors._raise_not_supported("setting a connection OCI attribute")

    def cancel(self):
        errors._raise_not_supported("aborting a currently executing statement")

    def change_password(self, old_password, new_password):
        errors._raise_not_supported("changing a password")

    def decode_oson(self, bytes data):
        """
        Decode OSON encoded bytes and return the object encoded in them.
        """
        cdef OsonDecoder decoder = OsonDecoder.__new__(OsonDecoder)
        return decoder.decode(data)

    def encode_oson(self, object value):
        """
        Return OSON encoded bytes encoded from the supplied object.
        """
        cdef OsonEncoder encoder = OsonEncoder.__new__(OsonEncoder)
        encoder.encode(value, self._oson_max_fname_size)
        return encoder._data[:encoder._pos]

    def get_is_healthy(self):
        errors._raise_not_supported("checking if the connection is healthy")

    def close(self, in_del=False):
        errors._raise_not_supported("closing a connection")

    def commit(self):
        errors._raise_not_supported("committing a transaction")

    def create_cursor_impl(self, bint scrollable):
        """
        Create the cursor implementation object.
        """
        cdef BaseCursorImpl cursor_impl = self._create_cursor_impl()
        cursor_impl.scrollable = scrollable
        cursor_impl.arraysize = C_DEFAULTS.arraysize
        cursor_impl.prefetchrows = C_DEFAULTS.prefetchrows
        return cursor_impl

    def create_msg_props_impl(self):
        errors._raise_not_supported("creating a message property object")

    def create_queue_impl(self):
        errors._raise_not_supported("creating a queue")

    def create_soda_database_impl(self, conn):
        errors._raise_not_supported("creating a SODA database object")

    def create_subscr_impl(self, object conn, object callback,
                           uint32_t namespace, str name, uint32_t protocol,
                           str ip_address, uint32_t port, uint32_t timeout,
                           uint32_t operations, uint32_t qos,
                           uint8_t grouping_class, uint32_t grouping_value,
                           uint8_t grouping_type, bint client_initiated):
        errors._raise_not_supported("creating a subscription")

    def create_temp_lob_impl(self, DbType dbtype):
        errors._raise_not_supported("creating a temporary LOB")

    def get_call_timeout(self):
        errors._raise_not_supported("getting the call timeout")

    def get_current_schema(self):
        errors._raise_not_supported("getting the current schema")

    def get_db_domain(self):
        errors._raise_not_supported("getting the database domain name")

    def get_db_name(self):
        errors._raise_not_supported("getting the database name")

    def get_edition(self):
        errors._raise_not_supported("getting the edition")

    def get_external_name(self):
        errors._raise_not_supported("getting the external name")

    def get_handle(self):
        errors._raise_not_supported("getting the OCI service context handle")

    def get_instance_name(self):
        errors._raise_not_supported("getting the instance name")

    def get_internal_name(self):
        errors._raise_not_supported("getting the internal name")

    def get_ltxid(self):
        errors._raise_not_supported("getting the logical transaction id")

    def get_max_identifier_length(self):
        errors._raise_not_supported("getting the maximum identifier length")

    def get_max_open_cursors(self):
        errors._raise_not_supported(
            "getting the maximum number of open cursors"
        )

    def get_sdu(self):
        errors._raise_not_supported("getting the session data unit (SDU)")

    def get_serial_num(self):
        errors._raise_not_supported("getting the session serial number")

    def get_service_name(self):
        errors._raise_not_supported("getting the service name")

    def get_session_id(self):
        errors._raise_not_supported("getting the session id")

    def get_stmt_cache_size(self):
        errors._raise_not_supported("getting the statement cache size")

    def get_transaction_in_progress(self):
        errors._raise_not_supported("getting if a transaction is in progress")

    def get_type(self, object conn, str name):
        errors._raise_not_supported("getting an object type")

    def ping(self):
        errors._raise_not_supported("pinging the database")

    def rollback(self):
        errors._raise_not_supported("rolling back a transaction")

    def set_action(self, value):
        errors._raise_not_supported("setting the action")

    def set_call_timeout(self, value):
        errors._raise_not_supported("setting the call timeout")

    def set_client_identifier(self, value):
        errors._raise_not_supported("setting the client identifier")

    def set_client_info(self, value):
        errors._raise_not_supported("setting the client info")

    def set_current_schema(self, value):
        errors._raise_not_supported("setting the current schema")

    def set_dbop(self, value):
        errors._raise_not_supported("setting the database operation")

    def set_econtext_id(self, value):
        errors._raise_not_supported("setting the execution context id")

    def set_external_name(self, value):
        errors._raise_not_supported("setting the external name")

    def set_internal_name(self, value):
        errors._raise_not_supported("setting the internal name")

    def set_module(self, value):
        errors._raise_not_supported("setting the module")

    def set_stmt_cache_size(self, value):
        errors._raise_not_supported("setting the statement cache size")

    def shutdown(self, uint32_t mode):
        errors._raise_not_supported("shutting down the database")

    def startup(self, bint force, bint restrict, str pfile):
        errors._raise_not_supported("starting up the database")

    def supports_pipelining(self):
        return False

    def tpc_begin(self, xid, uint32_t flags, uint32_t timeout):
        errors._raise_not_supported(
            "starting a TPC (two-phase commit) transaction"
        )

    def tpc_commit(self, xid, bint one_phase):
        errors._raise_not_supported(
            "committing a TPC (two-phase commit) transaction"
        )

    def tpc_end(self, xid, uint32_t flags):
        errors._raise_not_supported(
            "ending a TPC (two-phase commit) transaction"
        )

    def tpc_forget(self, xid):
        errors._raise_not_supported(
            "forgetting a TPC (two-phase commit) transaction"
        )

    def tpc_prepare(self, xid):
        errors._raise_not_supported(
            "preparing a TPC (two-phase commit) transaction"
        )

    def tpc_rollback(self, xid):
        errors._raise_not_supported(
            "rolling back a TPC (two-phase commit) transaction"
        )


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\connect_params.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2022, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# connect_params.pyx
#
# Cython file defining the base ConnectParams implementation class (embedded in
# base_impl.pyx).
#------------------------------------------------------------------------------

# dictionary of tnsnames.ora files, indexed by the directory in which the file
# is found; the results are cached in order to avoid parsing a file multiple
# times; the modification time of the file is checked each time, though, to
# ensure that no changes were made since the last time that the file was read
# and parsed.
_tnsnames_files = {}

# internal default values
cdef str DEFAULT_PROTOCOL = "tcp"
cdef uint32_t DEFAULT_PORT = 1521
cdef double DEFAULT_TCP_CONNECT_TIMEOUT = 20
cdef uint32_t DEFAULT_RETRY_DELAY = 1
cdef uint32_t DEFAULT_SDU = 8192


cdef class ConnectParamsImpl:

    def __init__(self):
        cdef AddressList address_list
        self.stmtcachesize = C_DEFAULTS.stmtcachesize
        self.config_dir = C_DEFAULTS.config_dir
        self._default_description = Description()
        self._default_address = Address()
        self.description_list = DescriptionList()
        self.description_list.children.append(self._default_description)
        self.debug_jdwp = os.getenv("ORA_DEBUG_JDWP")
        self.edition = os.getenv("ORA_EDITION")
        address_list = AddressList()
        address_list.children.append(self._default_address)
        self._default_description.children.append(address_list)
        self.program = C_DEFAULTS.program
        self.terminal = C_DEFAULTS.terminal
        self.machine = C_DEFAULTS.machine
        self.osuser = C_DEFAULTS.osuser
        self.driver_name = C_DEFAULTS.driver_name
        self.thick_mode_dsn_passthrough = C_DEFAULTS.thick_mode_dsn_passthrough

    def set(self, dict args):
        """
        Sets the property values based on the supplied arguments. All values
        not supplied will be left unchanged.
        """
        cdef:
            Description description
            Address address

        # set parameters found directly on the ConnectParamsImpl object
        self._external_handle = args.get("handle", self._external_handle)
        _set_str_param(args, "user", self)
        _set_str_param(args, "proxy_user", self)
        if self.proxy_user is None and self.user is not None:
            self.parse_user(self.user)
        self._set_password(args.get("password"))
        self._set_new_password(args.get("newpassword"))
        self._set_wallet_password(args.get("wallet_password"))
        _set_bool_param(args, "events", &self.events)
        _set_enum_param(args, "mode", ENUM_AUTH_MODE, &self.mode)
        _set_str_param(args, "edition", self)
        _set_str_param(args, "tag", self)
        _set_bool_param(args, "matchanytag", &self.matchanytag)
        _set_uint_param(args, "stmtcachesize", &self.stmtcachesize)
        _set_bool_param(args, "disable_oob", &self.disable_oob)
        _set_obj_param(args, "ssl_context", self)
        _set_str_param(args, "debug_jdwp", self)
        _set_str_param(args, "config_dir", self)
        _set_app_context_param(args, "appcontext", self)
        _set_obj_param(args, "shardingkey", self)
        _set_obj_param(args, "supershardingkey", self)
        _set_bool_param(args, "externalauth", &self.externalauth)
        _set_str_param(args, "program", self, check_network_character_set=True)
        _set_str_param(args, "terminal", self)
        _set_str_param(args, "machine", self, check_network_character_set=True)
        _set_str_param(args, "osuser", self, check_network_character_set=True)
        _set_str_param(args, "driver_name", self)
        _set_obj_param(args, "extra_auth_params", self)
        _set_bool_param(args, "thick_mode_dsn_passthrough",
                        &self.thick_mode_dsn_passthrough)
        self._set_access_token_param(args.get("access_token"))

        # set parameters found on Description instances
        self._default_description.set_from_args(args)
        for description in self.description_list.children:
            if description is not self._default_description:
                description.set_from_args(args)

        # set parameters found on Address instances
        self._default_address.set_from_args(args)
        for address in self.description_list.get_addresses():
            if address is not self._default_address:
                address.set_from_args(args)

    def set_from_config(self, dict config, bint update_cache=True):
        """
        Internal method for setting the property from the supplied
        configuration.
        """
        connect_string = config.get("connect_descriptor")
        if connect_string is None:
            errors._raise_err(errors.ERR_MISSING_CONNECT_DESCRIPTOR)
        self.parse_connect_string(connect_string)
        if self.user is None and self._password is None \
                and not self.externalauth:
            user = config.get("user")
            password = config.get("password")
            if password is not None and not isinstance(password, dict):
                errors._raise_err(errors.ERR_PLAINTEXT_PASSWORD_IN_CONFIG)
            if user is not None or password is not None:
                self.set(dict(user=user, password=password))
        args = config.get("pyo")
        if args is not None:
            self.set(args)
        if update_cache and self._config_cache_key is not None:
            update_config_cache(self._config_cache_key, config)

    cdef int _check_credentials(self) except -1:
        """
        Check to see that credentials have been supplied: either a password or
        an access token.
        """
        if self._password is None and self._token is None \
                and self.access_token_callback is None:
            errors._raise_err(errors.ERR_NO_CREDENTIALS)

    cdef int _copy(self, ConnectParamsImpl other_params) except -1:
        """
        Internal method for copying attributes from another set of parameters.
        """
        self.config_dir = other_params.config_dir
        self.user = other_params.user
        self.proxy_user = other_params.proxy_user
        self.events = other_params.events
        self.externalauth = other_params.externalauth
        self.mode = other_params.mode
        self.edition = other_params.edition
        self.appcontext = other_params.appcontext
        self.tag = other_params.tag
        self.matchanytag = other_params.matchanytag
        self.shardingkey = other_params.shardingkey
        self.supershardingkey = other_params.supershardingkey
        self.stmtcachesize = other_params.stmtcachesize
        self.disable_oob = other_params.disable_oob
        self.debug_jdwp = other_params.debug_jdwp
        self.ssl_context = other_params.ssl_context
        self.description_list = other_params.description_list
        self.access_token_callback = other_params.access_token_callback
        self.access_token_expires = other_params.access_token_expires
        self._external_handle = other_params._external_handle
        self._default_description = other_params._default_description
        self._default_address = other_params._default_address
        self._password = other_params._password
        self._password_obfuscator = other_params._password_obfuscator
        self._new_password = other_params._new_password
        self._new_password_obfuscator = other_params._new_password_obfuscator
        self._wallet_password = other_params._wallet_password
        self._wallet_password_obfuscator = \
                other_params._wallet_password_obfuscator
        self._token = other_params._token
        self._token_obfuscator = other_params._token_obfuscator
        self._private_key = other_params._private_key
        self._private_key_obfuscator = other_params._private_key_obfuscator
        self.program = other_params.program
        self.terminal = other_params.terminal
        self.machine = other_params.machine
        self.osuser = other_params.osuser
        self.driver_name = other_params.driver_name
        self.extra_auth_params = other_params.extra_auth_params
        self.thick_mode_dsn_passthrough = \
                other_params.thick_mode_dsn_passthrough

    cdef str _get_connect_string(self):
        """
        Returns the connect string to use for the stored components.
        """
        return self.description_list.build_connect_string()

    cdef bytes _get_new_password(self):
        """
        Returns the new password, after removing the obfuscation.
        """
        if self._new_password is not None:
            return bytes(self._xor_bytes(self._new_password,
                                         self._new_password_obfuscator))

    cdef bytearray _get_obfuscator(self, str secret_value):
        """
        Return a byte array suitable for obfuscating the specified secret
        value.
        """
        return bytearray(secrets.token_bytes(len(secret_value.encode())))

    cdef bytes _get_password(self):
        """
        Returns the password, after removing the obfuscation.
        """
        if self._password is not None:
            return bytes(self._xor_bytes(self._password,
                                         self._password_obfuscator))

    cdef str _get_private_key(self):
        """
        Returns the private key, after removing the obfuscation.
        """
        if self._private_key is not None:
            return self._xor_bytes(self._private_key,
                                   self._private_key_obfuscator).decode()

    cdef str _get_token(self):
        """
        Returns the token, after removing the obfuscation.

        If a callable has been registered and there is no token stored yet, the
        callable will be invoked with the refresh parameter set to False. If
        the token returned by the callable is expired, the callable will be
        invoked a second time with the refresh parameter set to True. If this
        token is also expired, an exception will be raised.

        If the stored token has expired and no callable has been registered, an
        exception will be raised; otherwise, the callable will be invoked with
        the refresh parameter set to True.
        """
        cdef:
            object returned_val, current_date = datetime.datetime.utcnow()
            bint expired
        if self._token is None and self.access_token_callback is not None:
            returned_val = self.access_token_callback(False)
            self._set_access_token(returned_val,
                                   errors.ERR_INVALID_ACCESS_TOKEN_RETURNED)
        expired = self.access_token_expires < current_date
        if expired and self.access_token_callback is not None:
            returned_val = self.access_token_callback(True)
            self._set_access_token(returned_val,
                                   errors.ERR_INVALID_ACCESS_TOKEN_RETURNED)
            expired = self.access_token_expires < current_date
        if expired:
            errors._raise_err(errors.ERR_EXPIRED_ACCESS_TOKEN)
        return self._xor_bytes(self._token, self._token_obfuscator).decode()

    cdef object _get_public_instance(self):
        """
        Returns the public instance to use when making calls out to user
        defined code.
        """
        cdef object inst
        if isinstance(self, PoolParamsImpl):
            inst = PY_TYPE_POOL_PARAMS.__new__(PY_TYPE_POOL_PARAMS)
        else:
            inst = PY_TYPE_CONNECT_PARAMS.__new__(PY_TYPE_CONNECT_PARAMS)
        inst._impl = self
        return inst

    cdef object _get_token_expires(self, str token):
        """
        Gets the expiry date from the token.
        """
        cdef:
            str header_seg
            dict header
            int num_pad
        header_seg = token.split(".")[1]
        num_pad = len(header_seg) % 4
        if num_pad != 0:
            header_seg += '=' * num_pad
        header = json.loads(base64.b64decode(header_seg))
        return datetime.datetime.utcfromtimestamp(header["exp"])

    cdef str _get_wallet_password(self):
        """
        Returns the wallet password, after removing the obfuscation.
        """
        if self._wallet_password is not None:
            return self._xor_bytes(self._wallet_password,
                                   self._wallet_password_obfuscator).decode()

    cdef int _parse_connect_string(self, str connect_string) except -1:
        """
        Internal method for parsing a connect string.
        """
        cdef:
            TnsnamesFile tnsnames_file
            ConnectStringParser parser
            TnsnamesFileReader reader

        # attempt to parse the connect string directly
        parser = ConnectStringParser.__new__(ConnectStringParser)
        parser.template_description = self._default_description
        parser.template_address = self._default_address
        parser.params_impl = self
        parser.parse(connect_string)

        # otherwise, see if the name is a connect alias in a tnsnames.ora
        # configuration file
        if parser.description_list is None:
            reader = TnsnamesFileReader()
            tnsnames_file = reader.read_tnsnames(self.config_dir)
            name = connect_string
            connect_string = tnsnames_file.entries.get(name.upper())
            if connect_string is None:
                errors._raise_err(errors.ERR_TNS_ENTRY_NOT_FOUND, name=name,
                                  file_name=tnsnames_file.file_name)
            parser.parse(connect_string)
            if parser.description_list is None:
                errors._raise_err(errors.ERR_CANNOT_PARSE_CONNECT_STRING,
                                  data=connect_string)
        self.description_list = parser.description_list
        if parser.parameters is not None:
            self.set(parser.parameters)

    cdef int _set_access_token(self, object val, int error_num) except -1:
        """
        Sets the access token either supplied directly by the user or
        indirectly via a callback.
        """
        cdef:
            str token, private_key = None
            object token_expires
        if isinstance(val, tuple) and len(val) == 2:
            token, private_key = val
            if token is None or private_key is None:
                errors._raise_err(error_num)
        elif isinstance(val, str):
            token = val
        else:
            errors._raise_err(error_num)
        try:
            token_expires = self._get_token_expires(token)
        except Exception as e:
            errors._raise_err(error_num, cause=e)
        self._token_obfuscator = self._get_obfuscator(token)
        self._token = self._xor_bytes(bytearray(token.encode()),
                                                self._token_obfuscator)
        if private_key is not None:
            self._private_key_obfuscator = self._get_obfuscator(private_key)
            self._private_key = self._xor_bytes(bytearray(private_key.encode()),
                                                self._private_key_obfuscator)
        self.access_token_expires = token_expires

    cdef int _set_access_token_param(self, object val) except -1:
        """
        Sets the access token parameter.
        """
        if val is not None:
            if callable(val):
                self.access_token_callback = val
            else:
                self._set_access_token(val,
                                       errors.ERR_INVALID_ACCESS_TOKEN_PARAM)

    cdef int _set_new_password(self, object password_in) except -1:
        """
        Sets the new password on the instance after first obfuscating it.
        """
        cdef str password
        if password_in is not None:
            password = self._transform_password(password_in)
            self._new_password_obfuscator = self._get_obfuscator(password)
            self._new_password = self._xor_bytes(bytearray(password.encode()),
                                                 self._new_password_obfuscator)

    cdef int _set_password(self, object password_in) except -1:
        """
        Sets the password on the instance after first obfuscating it.
        """
        cdef str password
        if password_in is not None:
            password = self._transform_password(password_in)
            self._password_obfuscator = self._get_obfuscator(password)
            self._password = self._xor_bytes(bytearray(password.encode()),
                                             self._password_obfuscator)

    cdef int _set_wallet_password(self, object password_in) except -1:
        """
        Sets the wallet password on the instance after first obfuscating it.
        """
        cdef str password
        if password_in is not None:
            password = self._transform_password(password_in)
            self._wallet_password_obfuscator = self._get_obfuscator(password)
            self._wallet_password = \
                    self._xor_bytes(bytearray(password.encode()),
                                    self._wallet_password_obfuscator)

    cdef str _transform_password(self, object password):
        """
        Transforms the password by calling any registered password type
        handlers if the password is supplied as a dictionary.
        """
        cdef str password_type
        if isinstance(password, dict):
            password_type = password.get("type")
            fn = REGISTERED_PASSWORD_TYPES.get(password_type)
            if fn is None:
                errors._raise_err(errors.ERR_INVALID_PASSWORD_TYPE,
                                  password_type=password_type)
            try:
                return fn(password)
            except Exception as e:
                errors._raise_err(errors.ERR_PASSWORD_TYPE_HANDLER_FAILED,
                                  password_type=password_type, cause=e)
        return password

    cdef bytearray _xor_bytes(self, bytearray a, bytearray b):
        """
        Perform an XOR of two byte arrays as a means of obfuscating a password
        that is stored on the class. It is assumed that the byte arrays are of
        the same length.
        """
        cdef:
            ssize_t length, i
            bytearray result
        length = len(a)
        result = bytearray(length)
        for i in range(length):
            result[i] = a[i] ^ b[i]
        return result

    def copy(self):
        """
        Creates a copy of the connection parameters and returns it.
        """
        cdef ConnectParamsImpl new_params
        new_params = ConnectParamsImpl.__new__(ConnectParamsImpl)
        new_params._copy(self)
        return new_params

    def _get_addresses(self):
        """
        Return a list of the stored addresses.
        """
        return self.description_list.get_addresses()

    def get_connect_string(self):
        """
        Returns a connect string generated from the parameters.
        """
        return self._get_connect_string()

    def get_full_user(self):
        """
        Internal method used for getting the full user (including any proxy
        user) which is used in thick mode exlusively and which is used in
        the repr() methods for Connection and ConnectionPool.
        """
        if self.proxy_user is not None:
            return f"{self.user}[{self.proxy_user}]"
        return self.user

    def get_network_service_names(self):
        """
        Returns a list of the network service names found in the tnsnames.ora
        file found in the configuration directory associated with the
        parameters. If no such file exists, an error is raised.
        """
        cdef:
            TnsnamesFileReader reader = TnsnamesFileReader()
            TnsnamesFile tnsnames_file
        tnsnames_file = reader.read_tnsnames(self.config_dir)
        return list(tnsnames_file.entries.keys())

    def parse_connect_string(self, str connect_string):
        """
        Internal method for parsing the connect string.
        """
        connect_string = connect_string.strip()
        try:
            self._parse_connect_string(connect_string)
        except exceptions.Error:
            raise
        except Exception as e:
            errors._raise_err(errors.ERR_CANNOT_PARSE_CONNECT_STRING, cause=e,
                              data=connect_string)

    def parse_dsn_with_credentials(self, str dsn):
        """
        Parse a dsn (data source name) string supplied by the user. This can be
        in the form user/password@connect_string or it can be in the form
        user/password. The user, password and connect string are returned in a
        3-tuple.
        """
        pos = dsn.rfind("@")
        if pos >= 0:
            credentials = dsn[:pos]
            connect_string = dsn[pos + 1:] or None
        else:
            credentials = dsn
            connect_string = None
        pos = credentials.find("/")
        if pos > 0 and credentials[pos - 1] != ':' \
                or pos == 0 and len(credentials) == 1:
            user = credentials[:pos] or None
            password = credentials[pos + 1:] or None
        elif connect_string is None:
            connect_string = dsn or None
            user = password = None
        else:
            user = credentials or None
            password = None
        return (user, password, connect_string)

    def parse_user(self, str user):
        """
        Parses a user string into its component parts, if applicable. The user
        string may be in the form user[proxy_user] or it may simply be a simple
        user string.
        """
        start_pos = user.find("[")
        if start_pos > 0 and user.endswith("]"):
            self.proxy_user = user[start_pos + 1:-1]
            self.user = user[:start_pos]
        else:
            self.user = user

    def process_args(self, str dsn, dict kwargs, bint thin):
        """
        Processes the arguments to connect() and create_pool().

            - the keyword arguments are set
            - if no user was specified in the keyword arguments and a dsn is
              specified, it is parsed to determine the user, password and
              connect string and the user and password are stored
            - the connect string is then parsed into its components and stored
            - if no dsn was specified, one is built from the components
            - the connect string is returned
        """
        if kwargs:
            self.set(kwargs)
        if self.user is None and not self.externalauth and dsn is not None:
            user, password, dsn = self.parse_dsn_with_credentials(dsn)
            self.set(dict(user=user, password=password))
        if dsn is None:
            dsn = self._get_connect_string()
        elif thin or not self.thick_mode_dsn_passthrough:
            self.parse_connect_string(dsn)
        if REGISTERED_PARAMS_HOOKS:
            params = self._get_public_instance()
            for hook_fn in REGISTERED_PARAMS_HOOKS:
                try:
                    hook_fn(params)
                except Exception as e:
                    errors._raise_err(errors.ERR_PARAMS_HOOK_HANDLER_FAILED,
                                      cause=e)
        return dsn


cdef class ConnectParamsNode:

    def __init__(self, bint must_have_children):
        self.must_have_children = must_have_children
        self.failover = True
        if must_have_children:
            self.children = []

    cdef int _copy(self, ConnectParamsNode source) except -1:
        """
        Copies data from the source to this node.
        """
        self.must_have_children = source.must_have_children
        if self.must_have_children:
            self.children = []
            self.failover = source.failover
            self.load_balance = source.load_balance
            self.source_route = source.source_route

    cdef list _get_initial_connect_string_parts(self):
        """
        Returns a list of the initial connect strings parts used for container
        nodes.
        """
        cdef list parts = []
        if not self.failover:
            parts.append("(FAILOVER=OFF)")
        if self.load_balance:
            parts.append("(LOAD_BALANCE=ON)")
        if self.source_route:
            parts.append("(SOURCE_ROUTE=ON)")
        return parts

    cdef int _set_active_children(self, list children) except -1:
        """
        Set the active children to process when connecting to the database.
        This call is recursive and will set the active children of each of its
        children.
        """
        cdef ConnectParamsNode child

        # if only one child is present, that child is considered active
        if len(children) == 1:
            self.active_children = children

        # for source route, only the first child is considered active
        elif self.source_route:
            self.active_children = children[:1]

        # for failover with load balance, all of the children are active but
        # are processed in a random order
        elif self.failover and self.load_balance:
            self.active_children = random.sample(children, k=len(children))

        # for failover without load balance, all of the children are active and
        # are processed in the same order
        elif self.failover:
            self.active_children = children

        # without failover, load balance indicates that only one of the
        # children is considered active and which one is selected randomly
        elif self.load_balance:
            self.active_children = random.sample(children, k=1)

        # without failover or load balance, just the first child is navigated
        else:
            self.active_children = children[:1]

        for child in children:
            if child.must_have_children:
                child._set_active_children(child.children)


cdef class Address(ConnectParamsNode):
    """
    Internal class used to hold parameters for an address used to create a
    connection to the database.
    """

    def __init__(self):
        ConnectParamsNode.__init__(self, False)
        self.protocol = DEFAULT_PROTOCOL
        self.port = DEFAULT_PORT

    cdef str build_connect_string(self):
        """
        Build a connect string from the components. If no host is specified,
        None is returned (used for bequeath connections).
        """
        if self.host is not None:
            parts = [f"(PROTOCOL={self.protocol})",
                     f"(HOST={self.host})",
                     f"(PORT={self.port})"]
            if self.https_proxy is not None:
                parts.append(f"(HTTPS_PROXY={self.https_proxy})")
            if self.https_proxy_port != 0:
                parts.append(f"(HTTPS_PROXY_PORT={self.https_proxy_port})")
            return f'(ADDRESS={"".join(parts)})'

    def copy(self):
        """
        Creates a copy of the address and returns it.
        """
        cdef Address address = Address.__new__(Address)
        address._copy(self)
        address.host = self.host
        address.port = self.port
        address.protocol = self.protocol
        address.https_proxy = self.https_proxy
        address.https_proxy_port = self.https_proxy_port
        return address

    @classmethod
    def from_args(cls, dict args):
        """
        Creates an address and sets the arguments before returning it. This is
        used within connect descriptors containing address lists.
        """
        address = cls()
        address.set_from_args(args)
        return address

    cdef list resolve_host_name(self):
        """
        Resolve the host name associated with the address and store the IP
        address and family on the address. If multiple IP addresses are found,
        duplicate the address and return one address for each IP address.
        """
        cdef:
            list results = []
            Address address
            object info
        for info in socket.getaddrinfo(self.host, self.port,
                                       proto=socket.IPPROTO_TCP,
                                       type=socket.SOCK_STREAM):
            address = self.copy()
            address.ip_family = info[0]
            address.ip_address = info[4][0]
            results.append(address)
        return results

    def set_from_args(self, dict args):
        """
        Sets parameter values from an argument dictionary or an (ADDRESS) node
        in a connect descriptor.
        """
        _set_str_param(args, "host", self)
        _set_uint_param(args, "port", &self.port)
        protocol = args.get("protocol")
        if protocol is not None:
            self.set_protocol(protocol)
        _set_str_param(args, "https_proxy", self)
        _set_uint_param(args, "https_proxy_port", &self.https_proxy_port)

    cdef int set_protocol(self, str value) except -1:
        """
        Sets the protocol in the address to the specified value.
        """
        value = value.lower()
        if value not in ("tcp", "tcps"):
            errors._raise_err(errors.ERR_INVALID_PROTOCOL, protocol=value)
        self.protocol = value


cdef class AddressList(ConnectParamsNode):
    """
    Internal class used to hold address list parameters and a list of addresses
    used to create connections to the database.
    """

    def __init__(self):
        ConnectParamsNode.__init__(self, True)

    cdef int _set_active_children(self, list children) except -1:
        """
        Set the active children to process when connecting to the database.
        First, all names are resolved to IP addresses

        This call is recursive and will set the active children of each of its
        children.
        """
        cdef:
            list addresses = []
            Address address
        for address in children:
            addresses.extend(address.resolve_host_name())
        ConnectParamsNode._set_active_children(self, addresses)

    cdef bint _uses_tcps(self):
        """
        Returns a boolean indicating if any of the addresses in the address
        list use the protocol TCPS.
        """
        cdef Address address
        for address in self.children:
            if address.protocol == "tcps":
                return True
        return False

    cdef str build_connect_string(self):
        """
        Build a connect string from the components.
        """
        cdef:
            Address address
            list parts
        parts = self._get_initial_connect_string_parts()
        for address in self.children:
            parts.append(address.build_connect_string())
        if len(parts) == 1:
            return parts[0]
        return f'(ADDRESS_LIST={"".join(parts)})'

    def set_from_args(self, dict args):
        """
        Set paramter values from an argument dictionary or an (ADDRESS_LIST)
        node in a connect descriptor.
        """
        _set_bool_param(args, "failover", &self.failover)
        _set_bool_param(args, "load_balance", &self.load_balance)
        _set_bool_param(args, "source_route", &self.source_route)


cdef class Description(ConnectParamsNode):
    """
    Internal class used to hold description parameters.
    """

    def __init__(self):
        ConnectParamsNode.__init__(self, True)
        self.tcp_connect_timeout = DEFAULT_TCP_CONNECT_TIMEOUT
        self.retry_delay = DEFAULT_RETRY_DELAY
        self.ssl_server_dn_match = True
        self.sdu = DEFAULT_SDU

    cdef str _build_duration_str(self, double value):
        """
        Build up the value to display for a duration in the connect string.
        This must be an integer with the units following it.
        """
        cdef int value_int, value_minutes
        value_int = <int> value
        if value != value_int:
            return f"{int(value * 1000)}ms"
        value_minutes = (value_int // 60)
        if value_minutes * 60 == value_int:
            return f"{value_minutes}min"
        return f"{value_int}"

    cdef str _value_repr(self, object value):
        """
        Returns the representation to use for a value. Strings are returned as
        is but dictionaries are returned as key/value pairs in the format
        expected by the listener.
        """
        if isinstance(value, str):
            return value
        return "".join(f"({k.upper()}={self._value_repr(v)})"
                       for k, v in value.items())

    cdef str build_connect_string(self, str cid=None):
        """
        Build a connect string from the components.
        """
        cdef:
            AddressList address_list
            list parts, temp_parts
            bint uses_tcps = False
            str temp

        # build top-level description parts
        parts = self._get_initial_connect_string_parts()
        if self.retry_count != 0:
            parts.append(f"(RETRY_COUNT={self.retry_count})")
            if self.retry_delay != 0:
                parts.append(f"(RETRY_DELAY={self.retry_delay})")
        if self.expire_time != 0:
            parts.append(f"(EXPIRE_TIME={self.expire_time})")
        if self.tcp_connect_timeout != DEFAULT_TCP_CONNECT_TIMEOUT:
            temp = self._build_duration_str(self.tcp_connect_timeout)
            parts.append(f"(TRANSPORT_CONNECT_TIMEOUT={temp})")
        if self.use_sni:
            parts.append("(USE_SNI=ON)")
        if self.sdu != DEFAULT_SDU:
            parts.append(f"(SDU={self.sdu})")
        if self.extra_args is not None:
            parts.extend(f"({k.upper()}={self._value_repr(v)})"
                         for k, v in self.extra_args.items())

        # add address lists, but if the address list contains only a single
        # entry and that entry does not have a host, the other parts aren't
        # relevant anyway!
        for address_list in self.children:
            temp = address_list.build_connect_string()
            if temp is None:
                return None
            parts.append(temp)
            if not uses_tcps:
                uses_tcps = address_list._uses_tcps()

        # build connect data segment
        temp_parts = []
        if self.service_name is not None:
            temp_parts.append(f"(SERVICE_NAME={self.service_name})")
        if self.instance_name is not None:
            temp_parts.append(f"(INSTANCE_NAME={self.instance_name})")
        elif self.sid is not None:
            temp_parts.append(f"(SID={self.sid})")
        if self.server_type is not None:
            temp_parts.append(f"(SERVER={self.server_type})")
        if self.use_tcp_fast_open:
            temp_parts.append("(USE_TCP_FAST_OPEN=ON)")
        if self.pool_boundary is not None:
            temp_parts.append(f"(POOL_BOUNDARY={self.pool_boundary})")
        if cid is not None:
            temp_parts.append(f"(CID={cid})")
        else:
            if self.cclass is not None:
                temp_parts.append(f"(POOL_CONNECTION_CLASS={self.cclass})")
            if self.purity == PURITY_SELF:
                temp_parts.append(f"(POOL_PURITY=SELF)")
            elif self.purity == PURITY_NEW:
                temp_parts.append(f"(POOL_PURITY=NEW)")
        if self.extra_connect_data_args is not None:
            temp_parts.extend(f"({k.upper()}={self._value_repr(v)})"
                              for k, v in self.extra_connect_data_args.items())
        if self.connection_id is not None:
            temp_parts.append(f"(CONNECTION_ID={self.connection_id})")
        if temp_parts:
            parts.append(f'(CONNECT_DATA={"".join(temp_parts)})')

        # build security segment, if applicable
        if uses_tcps:
            temp_parts = []
            if self.ssl_server_dn_match:
                temp_parts.append("(SSL_SERVER_DN_MATCH=ON)")
            if self.ssl_server_cert_dn is not None:
                temp = f"(SSL_SERVER_CERT_DN={self.ssl_server_cert_dn})"
                temp_parts.append(temp)
            if self.ssl_version is not None:
                if self.ssl_version is ssl.TLSVersion.TLSv1_2:
                    temp_parts.append(f"(SSL_VERSION=TLSv1.2)")
                elif self.ssl_version is ssl.TLSVersion.TLSv1_3:
                    temp_parts.append(f"(SSL_VERSION=TLSv1.3)")
            if self.wallet_location is not None:
                temp = f"(MY_WALLET_DIRECTORY={self.wallet_location})"
                temp_parts.append(temp)
            if self.extra_security_args is not None:
                temp_parts.extend(f"({k.upper()}={self._value_repr(v)})"
                                  for k, v in self.extra_security_args.items())
            parts.append(f'(SECURITY={"".join(temp_parts)})')

        return f'(DESCRIPTION={"".join(parts)})'

    def copy(self):
        """
        Creates a copy of the description (except for the address lists) and
        returns it.
        """
        cdef Description description = Description.__new__(Description)
        description._copy(self)
        description.expire_time = self.expire_time
        description.retry_count = self.retry_count
        description.retry_delay = self.retry_delay
        description.sdu = self.sdu
        description.tcp_connect_timeout = self.tcp_connect_timeout
        description.service_name = self.service_name
        description.instance_name = self.instance_name
        description.server_type = self.server_type
        description.sid = self.sid
        description.cclass = self.cclass
        description.connection_id_prefix = self.connection_id_prefix
        description.pool_boundary = self.pool_boundary
        description.purity = self.purity
        description.ssl_server_dn_match = self.ssl_server_dn_match
        description.use_tcp_fast_open = self.use_tcp_fast_open
        description.ssl_server_cert_dn = self.ssl_server_cert_dn
        description.ssl_version = self.ssl_version
        description.use_sni = self.use_sni
        description.wallet_location = self.wallet_location
        description.extra_args = self.extra_args
        description.extra_connect_data_args = self.extra_connect_data_args
        description.extra_security_args = self.extra_security_args
        return description

    def set_from_args(self, dict args):
        """
        Set parameter values from an argument dictionary.
        """
        self.set_from_connect_data_args(args)
        self.set_from_description_args(args)
        self.set_from_security_args(args)

    def set_from_connect_data_args(self, dict args):
        """
        Set parameter values from an argument dictionary or a (CONNECT_DATA)
        node in a connect descriptor.
        """
        _set_str_param(args, "service_name", self)
        _set_str_param(args, "instance_name", self)
        _set_str_param(args, "sid", self)
        server_type = args.get("server_type")
        if server_type is not None:
            self.set_server_type(server_type)
        _set_str_param(args, "cclass", self)
        _set_enum_param(args, "purity", ENUM_PURITY, &self.purity)
        _set_str_param(args, "pool_boundary", self)
        _set_str_param(args, "connection_id_prefix", self)
        _set_bool_param(args, "use_tcp_fast_open", &self.use_tcp_fast_open)
        extra_args = args.get("extra_connect_data_args")
        if extra_args is not None:
            self.extra_connect_data_args = extra_args

    def set_from_description_args(self, dict args):
        """
        Set parameter values from an argument dictionary or a (DESCRIPTION)
        node in a connect descriptor.
        """
        cdef Address address
        _set_uint_param(args, "expire_time", &self.expire_time)
        _set_bool_param(args, "failover", &self.failover)
        _set_bool_param(args, "load_balance", &self.load_balance)
        _set_bool_param(args, "source_route", &self.source_route)
        _set_uint_param(args, "retry_count", &self.retry_count)
        _set_uint_param(args, "retry_delay", &self.retry_delay)
        _set_bool_param(args, "use_sni", &self.use_sni)
        _set_uint_param(args, "sdu", &self.sdu)
        self.sdu = min(max(self.sdu, 512), 2097152)         # sanitize SDU
        _set_duration_param(args, "tcp_connect_timeout",
                            &self.tcp_connect_timeout)
        extra_args = args.get("extra_args")
        if extra_args is not None:
            self.extra_args = extra_args

    def set_from_security_args(self, dict args):
        """
        Set parameter values from an argument dictionary or a (SECURITY)
        node in a connect descriptor.
        """
        _set_bool_param(args, "ssl_server_dn_match", &self.ssl_server_dn_match)
        _set_str_param(args, "ssl_server_cert_dn", self)
        _set_ssl_version_param(args, "ssl_version", self)
        _set_str_param(args, "wallet_location", self)
        extra_args = args.get("extra_security_args")
        if extra_args is not None:
            self.extra_security_args = extra_args

    cdef int set_server_type(self, str value) except -1:
        """
        Sets the server type in the description to the specified value.
        """
        value = value.lower()
        if value not in ("dedicated", "pooled", "shared"):
            errors._raise_err(errors.ERR_INVALID_SERVER_TYPE,
                              server_type=value)
        self.server_type = value


cdef class DescriptionList(ConnectParamsNode):
    """
    Internal class used to hold description list parameters and a list of
    descriptions.
    """

    def __init__(self):
        ConnectParamsNode.__init__(self, True)

    cdef str build_connect_string(self):
        """
        Build a connect string from the components.
        """
        cdef:
            Description description
            list parts
        parts = self._get_initial_connect_string_parts()
        for description in self.children:
            parts.append(description.build_connect_string())
        if len(parts) == 1:
            return parts[0]
        return f'(DESCRIPTION_LIST={"".join(parts)})'

    cdef list get_addresses(self):
        """
        Return a list of the stored addresses.
        """
        cdef:
            AddressList addr_list
            Description desc
            Address addr
        return [addr for desc in self.children \
                for addr_list in desc.children \
                for addr in addr_list.children]

    cdef int set_active_children(self) except -1:
        """
        Sets the list of active children to process when connecting to the
        database.
        """
        self._set_active_children(self.children)

    def set_from_args(self, dict args):
        """
        Set paramter values from an argument dictionary or a (DESCRIPTION_LIST)
        node in a connect descriptor.
        """
        _set_bool_param(args, "failover", &self.failover)
        _set_bool_param(args, "load_balance", &self.load_balance)
        _set_bool_param(args, "source_route", &self.source_route)


cdef class TnsnamesFile:
    """
    Internal class used to parse and retain connect descriptor entries found in
    a tnsnames.ora file or any included file.
    """
    cdef:
        str file_name
        int mtime
        dict entries
        set included_files

    def __init__(self, str file_name):
        self.file_name = file_name
        self.clear()
        self._get_mtime(&self.mtime)

    cdef int _get_mtime(self, int* mtime) except -1:
        """
        Returns the modification time of the file or throws an exception if the
        file cannot be found.
        """
        try:
            mtime[0] = os.stat(self.file_name).st_mtime
        except Exception as e:
            errors._raise_err(errors.ERR_MISSING_FILE, str(e),
                              file_name=self.file_name)

    cdef int clear(self) except -1:
        """
        Clear all entries in the file.
        """
        self.entries = {}
        self.included_files = set()

    def is_current(self):
        """
        Returns a boolean indicating if the contents are current or not.
        """
        cdef:
            TnsnamesFile included_file
            int mtime
        self._get_mtime(&mtime)
        if mtime != self.mtime:
            return False
        for included_file in self.included_files:
            if not included_file.is_current():
                return False
        return True



cdef class TnsnamesFileReader:
    """
    Internal class used to read a tnsnames.ora file and all of its included
    files.
    """
    cdef:
        TnsnamesFile primary_file
        list files_in_progress
        dict entries

    cdef TnsnamesFile _get_file(self, file_name):
        """
        Get the file from the cache or read it from the file system.
        """
        cdef TnsnamesFile tnsnames_file
        if file_name in self.files_in_progress:
            errors._raise_err(errors.ERR_IFILE_CYCLE_DETECTED,
                              including_file_name=self.files_in_progress[-1],
                              included_file_name=file_name)
        tnsnames_file = _tnsnames_files.get(file_name)
        if tnsnames_file is None:
            tnsnames_file = TnsnamesFile(file_name)
        else:
            if tnsnames_file.is_current():
                return tnsnames_file
            del _tnsnames_files[file_name]
        if self.primary_file is None:
            self.primary_file = tnsnames_file
        self.files_in_progress.append(file_name)
        self._read_file(tnsnames_file)
        _tnsnames_files[file_name] = tnsnames_file
        self.files_in_progress.pop()
        return tnsnames_file

    cdef int _read_file(self, TnsnamesFile tnsnames_file) except -1:
        """
        Reads the file and parses the contents.
        """
        cdef:
            TnsnamesFile included_file
            TnsnamesFileParser parser
            int line_no = 0
        def add_entry(key, value):
            if key == "IFILE":
                if not os.path.isabs(value):
                    dir_name = os.path.dirname(tnsnames_file.file_name)
                    value = os.path.join(dir_name, value)
                included_file = self._get_file(value)
                tnsnames_file.included_files.add(included_file)
            else:
                entry_names = [
                    s.strip().splitlines()[-1] for s in key.split(",")
                ]
                for name in entry_names:
                    self.primary_file.entries[name] = value
                    if tnsnames_file is not self.primary_file:
                        tnsnames_file.entries[name] = value
        tnsnames_file.clear()
        parser = TnsnamesFileParser.__new__(TnsnamesFileParser)
        with open(tnsnames_file.file_name) as f:
            parser.parse(f.read(), add_entry)

    cdef TnsnamesFile read_tnsnames(self, str dir_name):
        """
        Read the tnsnames.ora file found in the given directory or raise an
        exception if no such file can be found.
        """
        self.primary_file = None
        self.files_in_progress = []
        if dir_name is None:
            errors._raise_err(errors.ERR_NO_CONFIG_DIR)
        file_name = os.path.join(dir_name, "tnsnames.ora")
        return self._get_file(file_name)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\converters.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2024, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# converters.pyx
#
# Cython file defining the low-level methods for converting the intermediate
# form returned by the decoders to an appropriate Python value.
#------------------------------------------------------------------------------

cdef object convert_date_to_python(OracleDataBuffer *buffer):
    """
    Converts a DATE, TIMESTAMP, TIMESTAMP WITH LOCAL TIME ZONE or TIMESTAMP
    WITH TIMEZONE value stored in the buffer to Python datetime.datetime().
    """
    cdef:
        OracleDate *value = &buffer.as_date
        int32_t seconds
    output = cydatetime.datetime_new(value.year, value.month, value.day,
                                     value.hour, value.minute, value.second,
                                     value.fsecond, None)
    if value.tz_hour_offset != 0 or value.tz_minute_offset != 0:
        seconds = value.tz_hour_offset * 3600 + value.tz_minute_offset * 60
        output += cydatetime.timedelta_new(0, seconds, 0)
    return output


cdef object convert_interval_ds_to_python(OracleDataBuffer *buffer):
    """
    Converts an INTERVAL DAYS TO SECONDS value stored in the buffer to Python
    datetime.timedelta().
    """
    cdef:
        OracleIntervalDS *value = &buffer.as_interval_ds
        int32_t total_seconds
    total_seconds = value.hours * 60 * 60 + value.minutes * 60 + value.seconds
    return cydatetime.timedelta_new(value.days, total_seconds,
                                    value.fseconds // 1000)


cdef object convert_interval_ym_to_python(OracleDataBuffer *buffer):
    """
    Converts an INTERVAL YEARS TO MONTHS value stored in the buffer to Python
    oracledb.IntervalYM().
    """
    cdef OracleIntervalYM *value = &buffer.as_interval_ym
    return PY_TYPE_INTERVAL_YM(value.years, value.months)


cdef int convert_number_to_arrow_decimal(OracleArrowArray arrow_array,
                                         OracleDataBuffer *buffer) except -1:
    """
    Converts a NUMBER value stored in the buffer to Arrow DECIMAL128.
    """
    cdef:
        char_type c
        bint has_sign = 0
        char_type digits[39] # 38 digits + sign
        OracleNumber *value = &buffer.as_number
        uint8_t num_chars = 0, decimal_point_index = 0, allowed_max_chars = 0
        int64_t actual_scale = 0

    if value.chars[0] == 45: # minus sign
        has_sign = True

    if value.is_integer:
        if has_sign:
            allowed_max_chars = 39
        else:
            allowed_max_chars = 38
    else: # decimal point
        if has_sign:
            allowed_max_chars = 40
        else:
            allowed_max_chars = 39

    # Arrow Decimal128 can only represent values with 38 decimal digits
    if value.is_max_negative_value or value.num_chars > allowed_max_chars:
        raise ValueError("Value cannot be represented as "
                         "Arrow Decimal128")
    if value.is_integer:
        arrow_array.append_decimal(value.chars, value.num_chars)
    else:
        for i in range(value.num_chars):
            c = value.chars[i]
            # count all characters except the decimal point
            if c != 46:
                digits[num_chars] = c
                num_chars += 1
            else:
                decimal_point_index = i

        # Append any trailing zeros.
        actual_scale = num_chars - decimal_point_index
        for i in range(abs(arrow_array.scale) - actual_scale):
            digits[num_chars] = b'0'
            num_chars += 1
        arrow_array.append_decimal(digits, num_chars)



cdef int convert_number_to_arrow_double(OracleArrowArray arrow_array,
                                        OracleDataBuffer *buffer) except -1:
    """
    Converts a NUMBER value stored in the buffer to Arrow DOUBLE.
    """
    cdef OracleNumber *value = &buffer.as_number
    if value.is_max_negative_value:
        arrow_array.append_double(-1.0e126)
    else:
        arrow_array.append_double(atof(value.chars[:value.num_chars]))


cdef int convert_number_to_arrow_int64(OracleArrowArray arrow_array,
                                       OracleDataBuffer *buffer) except -1:
    """
    Converts a NUMBER value stored in the buffer to Arrow INT64.
    """
    cdef OracleNumber *value = &buffer.as_number
    arrow_array.append_int64(atoi(value.chars[:value.num_chars]))


cdef object convert_number_to_python_decimal(OracleDataBuffer *buffer):
    """
    Converts a NUMBER value stored in the buffer to Python decimal.Decimal().
    """
    cdef OracleNumber *value = &buffer.as_number
    if value.is_max_negative_value:
        return PY_TYPE_DECIMAL("-1e126")
    return PY_TYPE_DECIMAL(value.chars[:value.num_chars].decode())


cdef object convert_number_to_python_float(OracleDataBuffer *buffer):
    """
    Converts a NUMBER value stored in the buffer to Python float.
    """
    cdef OracleNumber *value = &buffer.as_number
    if value.is_max_negative_value:
        return -1.0e126
    return float(value.chars[:value.num_chars])


cdef object convert_number_to_python_int(OracleDataBuffer *buffer):
    """
    Converts a NUMBER value stored in the buffer to Python integer, if
    possible. If the value is not an integer, a float is returned instead.
    """
    cdef OracleNumber *value = &buffer.as_number
    if value.is_max_negative_value:
        return -10 ** 126
    elif value.is_integer:
        return int(value.chars[:value.num_chars])
    return float(value.chars[:value.num_chars])


cdef object convert_number_to_python_str(OracleDataBuffer *buffer):
    """
    Converts a NUMBER value stored in the buffer to Python string.
    """
    cdef OracleNumber *value = &buffer.as_number
    if value.is_max_negative_value:
        return "-1e126"
    return value.chars[:value.num_chars].decode()


cdef object convert_raw_to_python(OracleDataBuffer *buffer):
    """
    Converts a RAW or LONG RAW value stored in the buffer to Python bytes.
    """
    cdef OracleRawBytes *rb = &buffer.as_raw_bytes
    return rb.ptr[:rb.num_bytes]


cdef object convert_str_to_python(OracleDataBuffer *buffer, uint8_t csfrm,
                                  const char* encoding_errors):
    """
    Converts a CHAR, NCHAR, LONG, VARCHAR, or NVARCHAR value stored in the
    buffer to Python string.
    """
    cdef OracleRawBytes *rb = &buffer.as_raw_bytes
    if csfrm == CS_FORM_IMPLICIT:
        return rb.ptr[:rb.num_bytes].decode(ENCODING_UTF8, encoding_errors)
    return rb.ptr[:rb.num_bytes].decode(ENCODING_UTF16, encoding_errors)


cdef int convert_oracle_data_to_arrow(OracleMetadata from_metadata,
                                      OracleMetadata to_metadata,
                                      OracleData* data,
                                      OracleArrowArray arrow_array) except -1:
    """
    Converts the value stored in OracleData to Arrow format.
    """
    cdef:
        ArrowType arrow_type
        uint32_t db_type_num
        OracleRawBytes* rb
        int64_t ts

    # NULL values
    if data.is_null:
        return arrow_array.append_null()

    arrow_type = to_metadata._arrow_type
    db_type_num = from_metadata.dbtype.num
    if arrow_type == NANOARROW_TYPE_INT64:
        convert_number_to_arrow_int64(arrow_array, &data.buffer)
    elif arrow_type == NANOARROW_TYPE_DOUBLE:
        if db_type_num == DB_TYPE_NUM_NUMBER:
            convert_number_to_arrow_double(arrow_array, &data.buffer)
        else:
            arrow_array.append_double(data.buffer.as_double)
    elif arrow_type == NANOARROW_TYPE_FLOAT:
        arrow_array.append_float(data.buffer.as_float)
    elif arrow_type == NANOARROW_TYPE_BOOL:
        arrow_array.append_int64(data.buffer.as_bool)
    elif arrow_type in (
            NANOARROW_TYPE_BINARY,
            NANOARROW_TYPE_STRING,
            NANOARROW_TYPE_LARGE_BINARY,
            NANOARROW_TYPE_LARGE_STRING
    ):
        rb = &data.buffer.as_raw_bytes
        arrow_array.append_bytes(<void*> rb.ptr, rb.num_bytes)
    elif arrow_type == NANOARROW_TYPE_TIMESTAMP:
        ts = int(convert_date_to_python(&data.buffer).timestamp() *
                 arrow_array.factor)
        arrow_array.append_int64(ts)
    elif arrow_type == NANOARROW_TYPE_DECIMAL128:
        convert_number_to_arrow_decimal(arrow_array, &data.buffer)


cdef object convert_oracle_data_to_python(OracleMetadata from_metadata,
                                          OracleMetadata to_metadata,
                                          OracleData* data,
                                          const char* encoding_errors,
                                          bint from_dbobject):
    """
    Converts the value stored in OracleData to a Python object.
    """
    cdef:
        uint8_t py_type_num, ora_type_num, csfrm

    # NULL values
    if data.is_null:
        return None

    # reduce typing
    ora_type_num = from_metadata.dbtype._ora_type_num
    csfrm = from_metadata.dbtype._csfrm
    py_type_num = to_metadata._py_type_num

    # Python bytes
    if py_type_num == PY_TYPE_NUM_BYTES:

        # Oracle RAW, LONG RAW
        # Oracle CHAR, LONG and VARCHAR (bypass decode)
        if ora_type_num in (
            ORA_TYPE_NUM_CHAR,
            ORA_TYPE_NUM_LONG,
            ORA_TYPE_NUM_LONG_RAW,
            ORA_TYPE_NUM_RAW,
            ORA_TYPE_NUM_VARCHAR
        ):
            return convert_raw_to_python(&data.buffer)

    # Python string
    elif py_type_num == PY_TYPE_NUM_STR:

        # Oracle CHAR, LONG and VARCHAR
        if ora_type_num in (
            ORA_TYPE_NUM_CHAR,
            ORA_TYPE_NUM_LONG,
            ORA_TYPE_NUM_VARCHAR
        ):
            return convert_str_to_python(&data.buffer, csfrm, encoding_errors)

        # Oracle NUMBER
        elif ora_type_num == ORA_TYPE_NUM_NUMBER:
            return convert_number_to_python_str(&data.buffer)

        # Oracle BINARY_DOUBLE
        elif ora_type_num == ORA_TYPE_NUM_BINARY_DOUBLE:
            return str(data.buffer.as_double)

        # Oracle BINARY_FLOAT
        elif ora_type_num == ORA_TYPE_NUM_BINARY_FLOAT:
            return str(data.buffer.as_float)

        # Oracle DATE, TIMESTAMP (WITH (LOCAL) TIME ZONE)
        elif ora_type_num in (
            ORA_TYPE_NUM_DATE,
            ORA_TYPE_NUM_TIMESTAMP,
            ORA_TYPE_NUM_TIMESTAMP_LTZ,
            ORA_TYPE_NUM_TIMESTAMP_TZ
        ):
            return str(convert_date_to_python(&data.buffer))

        # Oracle INTERVAL DAY TO SECOND
        elif ora_type_num == ORA_TYPE_NUM_INTERVAL_DS:
            return str(convert_interval_ds_to_python(&data.buffer))

        # Oracle INTERVAL YEAR TO MONTH
        elif ora_type_num == ORA_TYPE_NUM_INTERVAL_DS:
            return str(convert_interval_ym_to_python(&data.buffer))

    # Python integer (or float if data is not an integer)
    elif py_type_num == PY_TYPE_NUM_INT:

        # Oracle BINARY_INTEGER within a DbObject
        if from_dbobject and ora_type_num == ORA_TYPE_NUM_BINARY_INTEGER:
            return data.buffer.as_integer

        # Oracle NUMBER, BINARY_INTEGER
        elif ora_type_num in (ORA_TYPE_NUM_NUMBER,
                              ORA_TYPE_NUM_BINARY_INTEGER):
            if to_metadata.dbtype._ora_type_num != ORA_TYPE_NUM_BINARY_INTEGER:
                return convert_number_to_python_int(&data.buffer)
            value = convert_number_to_python_str(&data.buffer)
            return int(PY_TYPE_DECIMAL(value))

        # Oracle CHAR, LONG, VARCHAR
        elif ora_type_num in (
            ORA_TYPE_NUM_CHAR,
            ORA_TYPE_NUM_LONG,
            ORA_TYPE_NUM_VARCHAR
        ):
            value = convert_str_to_python(&data.buffer, csfrm, encoding_errors)
            return int(PY_TYPE_DECIMAL(value))

        # Oracle BINARY_DOUBLE
        elif ora_type_num == ORA_TYPE_NUM_BINARY_DOUBLE:
            return int(PY_TYPE_DECIMAL(data.buffer.as_double))

        # Oracle BINARY_FLOAT
        elif ora_type_num == ORA_TYPE_NUM_BINARY_FLOAT:
            return int(PY_TYPE_DECIMAL(data.buffer.as_float))

    # Python decimal.Decimal
    elif py_type_num == PY_TYPE_NUM_DECIMAL:

        # Oracle NUMBER
        if ora_type_num == ORA_TYPE_NUM_NUMBER:
            return convert_number_to_python_decimal(&data.buffer)

    # Python float
    elif py_type_num == PY_TYPE_NUM_FLOAT:

        # Oracle NUMBER
        if ora_type_num == ORA_TYPE_NUM_NUMBER:
            return convert_number_to_python_float(&data.buffer)

        # Oracle BINARY_DOUBLE
        elif ora_type_num == ORA_TYPE_NUM_BINARY_DOUBLE:
            return data.buffer.as_double

        # Oracle BINARY_FLOAT
        elif ora_type_num == ORA_TYPE_NUM_BINARY_FLOAT:
            return data.buffer.as_float

        # Oracle CHAR, LONG, VARCHAR
        elif ora_type_num in (
            ORA_TYPE_NUM_CHAR,
            ORA_TYPE_NUM_LONG,
            ORA_TYPE_NUM_VARCHAR
        ):
            rb = &data.buffer.as_raw_bytes
            return float(rb.ptr[:rb.num_bytes])

    # Python datetime.datetime
    elif py_type_num == PY_TYPE_NUM_DATETIME:

        # Oracle DATE, TIMESTAMP, TIMESTAMP WITH LOCAL TIMEZONE,
        # TIMESTAMP WITH TIMEZONE
        if ora_type_num in (
            ORA_TYPE_NUM_DATE,
            ORA_TYPE_NUM_TIMESTAMP,
            ORA_TYPE_NUM_TIMESTAMP_LTZ,
            ORA_TYPE_NUM_TIMESTAMP_TZ
        ):
            return convert_date_to_python(&data.buffer)

    # Python datetime.timedelta
    elif py_type_num == PY_TYPE_NUM_TIMEDELTA:

        # Oracle INTERVAL DAY TO SECOND
        if ora_type_num == ORA_TYPE_NUM_INTERVAL_DS:
            return convert_interval_ds_to_python(&data.buffer)

    # Python oracledb.OracleIntervalYM
    elif py_type_num == PY_TYPE_NUM_ORACLE_INTERVAL_YM:

        # Oracle INTERVAL YEAR TO MONTH
        if ora_type_num == ORA_TYPE_NUM_INTERVAL_YM:
            return convert_interval_ym_to_python(&data.buffer)

    # Python boolean
    elif py_type_num == PY_TYPE_NUM_BOOL:

        # Oracle BOOLEAN
        if ora_type_num == ORA_TYPE_NUM_BOOLEAN:
            return data.buffer.as_bool

    errors._raise_err(errors.ERR_INCONSISTENT_DATATYPES,
                      input_type=from_metadata.dbtype.name,
                      output_type=to_metadata.dbtype.name)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\cursor.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# cursor.pyx
#
# Cython file defining the base Cursor implementation class (embedded in
# base_impl.pyx).
#------------------------------------------------------------------------------

cdef class BaseCursorImpl:

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef int _bind_values(self,
                          object cursor,
                          object type_handler,
                          object params,
                          uint32_t num_rows,
                          uint32_t row_num,
                          bint defer_type_assignment) except -1:
        """
        Internal method used for binding values.
        """
        if self.bind_vars is None:
            self.bind_vars = []
        if isinstance(params, dict):
            if self.bind_style is None:
                self.bind_style = dict
                self.bind_vars_by_name = {}
            elif self.bind_style is not dict:
                errors._raise_err(errors.ERR_MIXED_POSITIONAL_AND_NAMED_BINDS)
            self._bind_values_by_name(cursor, type_handler, <dict> params,
                                      num_rows, row_num, defer_type_assignment)
        elif cpython.PySequence_Check(params):
            if self.bind_style is None:
                self.bind_style = list
            elif self.bind_style is not list:
                errors._raise_err(errors.ERR_MIXED_POSITIONAL_AND_NAMED_BINDS)
            self._bind_values_by_position(cursor, type_handler, params,
                                          num_rows, row_num,
                                          defer_type_assignment)
        else:
            errors._raise_err(errors.ERR_WRONG_EXECUTEMANY_PARAMETERS_TYPE)

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef int _bind_values_by_name(self,
                                  object cursor,
                                  object type_handler,
                                  dict params,
                                  uint32_t num_rows,
                                  uint32_t row_num,
                                  bint defer_type_assignment) except -1:
        """
        Internal method used for binding values by name.
        """
        cdef:
            BindVar bind_var
            object conn
            ssize_t pos
        conn = cursor.connection
        for name, value in params.items():
            bind_var = <BindVar> self.bind_vars_by_name.get(name)
            if bind_var is None:
                pos = len(self.bind_vars_by_name)
                if pos < len(self.bind_vars):
                    bind_var = <BindVar> self.bind_vars[pos]
                else:
                    bind_var = BindVar.__new__(BindVar)
                    self.bind_vars.append(bind_var)
                bind_var.name = name
                self.bind_vars_by_name[name] = bind_var
            bind_var._set_by_value(conn, self, cursor, value, type_handler,
                                   row_num, num_rows, defer_type_assignment)

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef int _bind_values_by_position(self,
                                      object cursor,
                                      object type_handler,
                                      object params,
                                      uint32_t num_rows,
                                      uint32_t row_num,
                                      bint defer_type_assignment) except -1:
        """
        Internal method used for binding values by position.
        """
        cdef:
            BindVar bind_var
            object conn
            ssize_t i
        conn = cursor.connection
        for i, value in enumerate(params):
            if i < len(self.bind_vars):
                bind_var = <BindVar> self.bind_vars[i]
            else:
                bind_var = BindVar.__new__(BindVar)
                bind_var.pos = i + 1
                self.bind_vars.append(bind_var)
            bind_var._set_by_value(conn, self, cursor, value, type_handler,
                                   row_num, num_rows, defer_type_assignment)

    def _build_json_converter_fn(self):
        """
        Internal method for building a JSON converter function.
        """
        def converter(value):
            if isinstance(value, PY_TYPE_LOB):
                value = value.read()
            if isinstance(value, bytes):
                value = value.decode()
            if value:
                return json.loads(value)
        return converter

    cdef int _check_binds(self, uint32_t num_execs) except -1:
        """
        Checks that all binds are capable of handling the number of executions
        provided.
        """
        cdef BindVar bind_var
        for bind_var in self.bind_vars:
            if bind_var is None or bind_var.var_impl is None:
                continue
            if bind_var.var_impl.num_elements < num_execs:
                errors._raise_err(errors.ERR_INCORRECT_VAR_ARRAYSIZE,
                                  var_arraysize=bind_var.var_impl.num_elements,
                                  required_arraysize=num_execs)

    cdef int _close(self, bint in_del) except -1:
        """
        Internal method for closing the cursor.
        """
        raise NotImplementedError()

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef BaseVarImpl _create_fetch_var(self, object conn, object cursor,
                                       object type_handler, bint uses_metadata,
                                       ssize_t pos, OracleMetadata metadata):
        """
        Create the fetch variable for the given position and fetch information.
        The output type handler is consulted, if present, to make any necessary
        adjustments.
        """
        cdef:
            object var, pub_metadata
            BaseConnImpl conn_impl
            BaseVarImpl var_impl
            uint32_t db_type_num

        # add the fetch info to the list used for handling the cursor
        # description attribute
        self.fetch_metadata[pos] = metadata

        # if an output type handler is specified, call it; the output type
        # handler should return a variable or None; the value None implies that
        # the default processing should take place just as if no output type
        # handler was defined
        if type_handler is not None:
            if uses_metadata:
                pub_metadata = PY_TYPE_FETCHINFO._from_impl(metadata)
                var = type_handler(cursor, pub_metadata)
            else:
                var = type_handler(cursor, metadata.name, metadata.dbtype,
                                   metadata.max_size, metadata.precision,
                                   metadata.scale)
            if var is not None:
                self._verify_var(var)
                var_impl = var._impl
                var_impl._fetch_metadata = metadata
                var_impl.metadata.name = metadata.name
                if var_impl.metadata.dbtype is not metadata.dbtype:
                    var_impl.metadata.dbtype = \
                            var_impl._check_fetch_conversion()
                if var_impl.num_elements < self._fetch_array_size:
                    var_impl.num_elements = self._fetch_array_size
                var_impl._finalize_init()
                self.fetch_vars[pos] = var
                self.fetch_var_impls[pos] = var_impl
                return var_impl

        # otherwise, create a new variable using the provided fetch metadata
        var_impl = self._create_var_impl(conn)
        var_impl.num_elements = self._fetch_array_size
        var_impl.metadata = metadata.copy()
        var_impl._fetch_metadata = metadata

        # adjust the variable based on the defaults specified by the user, if
        # applicable
        db_type_num = metadata.dbtype.num
        if db_type_num == DB_TYPE_NUM_NUMBER:
            if C_DEFAULTS.fetch_decimals:
                var_impl.metadata._py_type_num = PY_TYPE_NUM_DECIMAL
        elif metadata.is_oson and db_type_num != DB_TYPE_NUM_JSON:
            conn_impl = self._get_conn_impl()
            var_impl.metadata.dbtype = DB_TYPE_LONG_RAW
            var_impl._fetch_metadata.dbtype = DB_TYPE_LONG_RAW
            var_impl.outconverter = conn_impl.decode_oson
        elif metadata.is_json and db_type_num != DB_TYPE_NUM_JSON:
            var_impl.outconverter = self._build_json_converter_fn()
        elif not C_DEFAULTS.fetch_lobs or self.fetching_arrow:
            if db_type_num == DB_TYPE_NUM_BLOB:
                var_impl.metadata.dbtype = DB_TYPE_LONG_RAW
                var_impl._fetch_metadata.dbtype = DB_TYPE_LONG_RAW
            elif db_type_num == DB_TYPE_NUM_CLOB:
                var_impl.metadata.dbtype = DB_TYPE_LONG
                var_impl._fetch_metadata.dbtype = DB_TYPE_LONG
            elif db_type_num == DB_TYPE_NUM_NCLOB:
                var_impl.metadata.dbtype = DB_TYPE_LONG_NVARCHAR
                var_impl._fetch_metadata.dbtype = DB_TYPE_LONG_NVARCHAR

        # finalize variable and store in arrays
        var_impl._finalize_init()
        if self.fetching_arrow:
            var_impl._create_arrow_array()
        self.fetch_var_impls[pos] = var_impl
        return var_impl

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef object _create_row(self):
        """
        Internal method for creating a row from the fetched data.
        """
        cdef:
            Py_ssize_t i, num_vars
            BaseVarImpl var_impl
            object row, value
        num_vars = cpython.PyList_GET_SIZE(self.fetch_var_impls)
        row = cpython.PyTuple_New(num_vars)
        for i in range(num_vars):
            var_impl = self.fetch_var_impls[i]
            value = var_impl._get_scalar_value(self._buffer_index)
            cpython.Py_INCREF(value)
            cpython.PyTuple_SET_ITEM(row, i, value)
        if self.rowfactory is not None:
            row = self.rowfactory(*row)
        self._buffer_index += 1
        self._buffer_rowcount -= 1
        self.rowcount += 1
        return row

    cdef BaseVarImpl _create_var_impl(self, object conn):
        """
        Internal method for creating a variable.
        """
        raise NotImplementedError()

    cdef int _fetch_rows(self, object cursor) except -1:
        """
        Internal method used for fetching rows from a cursor.
        """
        raise NotImplementedError()

    cdef BaseConnImpl _get_conn_impl(self):
        """
        Internal method used to return the connection implementation associated
        with the cursor implementation.
        """
        raise NotImplementedError()

    cdef object _get_input_type_handler(self):
        """
        Return the input type handler to use for the cursor. If one is not
        directly defined on the cursor then the one defined on the connection
        is used instead.
        """
        cdef BaseConnImpl conn_impl
        if self.inputtypehandler is not None:
            return self.inputtypehandler
        conn_impl = self._get_conn_impl()
        return conn_impl.inputtypehandler

    def _get_oci_attr(self, uint32_t attr_num, uint32_t attr_type):
        errors._raise_not_supported("getting a cursor OCI attribute")

    cdef object _get_output_type_handler(self, bint *uses_metadata):
        """
        Return the output type handler to use for the cursor. If one is not
        directly defined on the cursor then the one defined on the connection
        is used instead.
        """
        cdef:
            BaseConnImpl conn_impl
            object type_handler
        if self.outputtypehandler is not None:
            type_handler = self.outputtypehandler
        else:
            conn_impl = self._get_conn_impl()
            type_handler = conn_impl.outputtypehandler
        if type_handler is not None:
            try:
                sig = inspect.signature(type_handler)
                uses_metadata[0] = (len(sig.parameters) == 2)
            except (ValueError, TypeError):
                uses_metadata[0] = False
        return type_handler

    cdef int _init_fetch_vars(self, uint32_t num_columns) except -1:
        """
        Initializes the fetch variable lists in preparation for creating the
        fetch variables used in fetching rows from the database.
        """
        self.fetch_metadata = [None] * num_columns
        self.fetch_vars = [None] * num_columns
        self.fetch_var_impls = [None] * num_columns

    cdef bint _is_plsql(self):
        """
        Internal method that indicates whether the currently prepared statement
        is a PL/SQL statement or not.
        """
        raise NotImplementedError()

    cdef int _perform_binds(self, object conn, uint32_t num_execs) except -1:
        """
        Perform all binds on the cursor.
        """
        cdef:
            BindVar bind_var
            ssize_t i
        for i, bind_var in enumerate(self.bind_vars):
            if bind_var is not None and bind_var.var_impl is not None:
                bind_var.var_impl._bind(conn, self, num_execs, bind_var.name,
                                        bind_var.pos)

    cdef int _prepare(self, str statement, str tag,
                      bint cache_statement) except -1:
        """
        Prepares a statement for execution.
        """
        self.statement = statement
        self.rowfactory = None
        self.fetch_vars = None
        if not self.set_input_sizes:
            self.bind_vars = None
            self.bind_vars_by_name = None
            self.bind_style = None

    cdef int _create_arrow_arrays(self) except -1:
        cdef BaseVarImpl var_impl
        for var_impl in self.fetch_var_impls:
            if var_impl._arrow_array is None:
                var_impl._create_arrow_array()

    def _prepare_for_execute(self, object cursor, str statement,
                             object parameters, object keyword_parameters):
        """
        Internal method for preparing a statement for execution.
        """
        cdef:
            bint prepare_needed

        # verify parameters
        if statement is None and self.statement is None:
            errors._raise_err(errors.ERR_NO_STATEMENT)
        if keyword_parameters:
            if parameters:
                errors._raise_err(errors.ERR_ARGS_AND_KEYWORD_ARGS)
            parameters = keyword_parameters
        elif parameters is not None and not isinstance(
            parameters, (list, tuple, dict)
        ):
            errors._raise_err(errors.ERR_WRONG_EXECUTE_PARAMETERS_TYPE)
        prepare_needed = statement and statement != self.statement
        if (
            not (prepare_needed and not self.set_input_sizes)
            and self.bind_vars is not None
            and parameters is not None
        ):
            if (
                self.bind_style is dict and not isinstance(parameters, dict)
                or self.bind_style is not dict and isinstance(parameters, dict)
            ):
                self.set_input_sizes = False
                errors._raise_err(errors.ERR_MIXED_POSITIONAL_AND_NAMED_BINDS)

        # prepare statement, if necessary
        try:
            if prepare_needed:
                self._prepare(statement, None, True)
        finally:
            self.set_input_sizes = False

        # perform bind
        if parameters is not None:
            self.bind_one(cursor, parameters)

        # clear any warning and reset rowcount
        self.warning = None
        self.rowcount = 0

    def _prepare_for_executemany(self, object cursor, str statement,
                                 object parameters):
        """
        Internal method for preparing a statement for execution multiple times.
        """

        # prepare statement, if necessary
        if statement is None and self.statement is None:
            errors._raise_err(errors.ERR_NO_STATEMENT)
        try:
            if statement is not None and statement != self.statement:
                self._prepare(statement, None, True)
        finally:
            self.set_input_sizes = False

        # perform bind, if applicable
        if isinstance(parameters, int):
            num_execs = parameters
            if self.bind_vars is not None:
                self._check_binds(num_execs)
        elif isinstance(parameters, list):
            num_execs = len(parameters)
            if parameters:
                self.bind_many(cursor, parameters)
        else:
            errors._raise_err(errors.ERR_WRONG_EXECUTEMANY_PARAMETERS_TYPE)

        # clear any warning and reset rowcount
        self.warning = None
        self.rowcount = 0

        return num_execs

    cdef int _reset_bind_vars(self, uint32_t num_rows) except -1:
        """
        Reset all of the existing bind variables. If any bind variables don't
        have enough space to store the number of rows specified, expand and
        then reinitialize that bind variable.
        """
        cdef:
            BindVar bind_var
            ssize_t i
        if self.bind_vars is not None:
            for i in range(len(self.bind_vars)):
                bind_var = <BindVar> self.bind_vars[i]
                if bind_var.var_impl is not None:
                    bind_var.var_impl._on_reset_bind(num_rows)
                bind_var.has_value = False

    def _set_oci_attr(self, uint32_t attr_num, uint32_t attr_type,
                      object value):
        errors._raise_not_supported("setting a cursor OCI attribute")

    cdef int _verify_var(self, object var) except -1:
        """
        Internal method used for verifying if an outputtypehandler returns a
        valid var object.
        """
        if not isinstance(var, PY_TYPE_VAR):
            errors._raise_err(errors.ERR_EXPECTING_VAR)
        if self.arraysize > var.num_elements:
            errors._raise_err(errors.ERR_INCORRECT_VAR_ARRAYSIZE,
                              var_arraysize=var.num_elements,
                              required_arraysize=self.arraysize)

    cdef int bind_many(self, object cursor, list parameters) except -1:
        """
        Internal method used for binding multiple rows of data.
        """
        cdef:
            bint defer_type_assignment
            ssize_t i, num_rows
            object params_row
        type_handler = self._get_input_type_handler()
        num_rows = len(parameters)
        self._reset_bind_vars(num_rows)
        for i, params_row in enumerate(parameters):
            defer_type_assignment = (i < num_rows - 1)
            self._bind_values(cursor, type_handler, params_row, num_rows, i,
                              defer_type_assignment)

    cdef int bind_one(self, object cursor, object parameters) except -1:
        """
        Internal method used for binding a single row of data.
        """
        cdef:
            bint defer_type_assignment = False
            uint32_t row_num = 0, num_rows = 1
            ssize_t num_bind_vars, pos
            object name, value
            BindVar bind_var
            dict dict_params
        type_handler = self._get_input_type_handler()
        self._reset_bind_vars(num_rows)
        self._bind_values(cursor, type_handler, parameters, num_rows, row_num,
                          defer_type_assignment)

    cdef object _finish_building_arrow_arrays(self):
        """
        Flush all buffers and return an Oracle Data frame.
        """
        cdef:
            BaseVarImpl var_impl
            list columns = []
        for var_impl in self.fetch_var_impls:
            columns.append(var_impl._finish_building_arrow_array())
        return PY_TYPE_DATAFRAME(columns)

    def close(self, bint in_del=False):
        """
        Closes the cursor and makes it unusable for further operations.
        """
        self.bind_vars = None
        self.bind_vars_by_name = None
        self.bind_style = None
        self.fetch_vars = None
        self._close(in_del)

    def create_var(self, object conn, object typ, uint32_t size=0,
                   uint32_t num_elements=1, object inconverter=None,
                   object outconverter=None, str encoding_errors=None,
                   bint bypass_decode=False, bint is_array=False,
                   bint convert_nulls=False):
        cdef BaseVarImpl var_impl
        var_impl = self._create_var_impl(conn)
        var_impl._set_metadata_from_type(typ)
        var_impl.metadata.max_size = size
        var_impl.num_elements = num_elements
        var_impl.inconverter = inconverter
        var_impl.outconverter = outconverter
        var_impl.bypass_decode = bypass_decode
        if bypass_decode:
            var_impl.metadata._py_type_num = PY_TYPE_NUM_BYTES
        if encoding_errors is not None:
            var_impl.encoding_errors = encoding_errors
            var_impl._encoding_error_bytes = encoding_errors.encode()
            var_impl._encoding_errors = var_impl._encoding_error_bytes
        var_impl.is_array = is_array
        var_impl.convert_nulls = convert_nulls
        var_impl._finalize_init()
        return PY_TYPE_VAR._from_impl(var_impl)

    def execute(self, cursor):
        errors._raise_not_supported("executing a statement")

    def executemany(self, cursor, num_execs, batcherrors, arraydmlrowcounts):
        errors._raise_not_supported("executing a statement in batch")

    def fetch_next_row(self, cursor):
        """
        Internal method used for fetching the next row from a cursor.
        """
        if self._buffer_rowcount == 0 and self._more_rows_to_fetch:
            self._fetch_rows(cursor)
        if self._buffer_rowcount > 0:
            return self._create_row()

    def fetch_df_all(self, cursor):
        """
        Internal method used for fetching all data as OracleDataFrame
        """
        while self._more_rows_to_fetch:
            self._fetch_rows(cursor)
        return self._finish_building_arrow_arrays()

    def fetch_df_batches(self, cursor, int batch_size):
        """
        Internal method used for fetching next batch as OracleDataFrame
        cursor.arraysize = batchsize
        """
        cdef:
            BaseConnImpl conn_impl = self._get_conn_impl()
            bint returned = False

        # Return the prefetched batch (thin mode)
        if conn_impl.thin:
            returned = True
            yield self._finish_building_arrow_arrays()

        while self._more_rows_to_fetch:
            self._create_arrow_arrays()
            self._fetch_rows(cursor)
            if not returned or self._buffer_rowcount > 0:
                returned = True
                yield self._finish_building_arrow_arrays()

    def get_array_dml_row_counts(self):
        errors._raise_not_supported("getting a list of array DML row counts")

    def get_batch_errors(self):
        errors._raise_not_supported("getting a list of batch errors")

    def get_bind_names(self):
        errors._raise_not_supported("getting a list of bind variable names")

    def get_bind_vars(self):
        """
        Return a list (when binding by position) or a dictionary (when binding
        by name) of the bind variables associated with the cursor.
        """
        cdef:
            BindVar bind_var
            ssize_t i
        if self.bind_vars is None:
            return []
        for bind_var in self.bind_vars:
            if bind_var.var is None and bind_var.var_impl is not None:
                bind_var.var = PY_TYPE_VAR._from_impl(bind_var.var_impl)
        if self.bind_style is list:
            return [bind_var.var for bind_var in self.bind_vars]
        return dict([(bind_var.name, bind_var.var) \
                for bind_var in self.bind_vars])

    def get_fetch_vars(self):
        """
        Return a list of fetch variables. Initially the list contains all
        empty values except where a fetch type handler was used. This will
        populate any remaining fetch variables that are needed.
        """
        cdef:
            BaseVarImpl var_impl
            ssize_t i
        if self.fetch_vars is not None:
            for i, var in enumerate(self.fetch_vars):
                if var is None:
                    var_impl = <BaseVarImpl> self.fetch_var_impls[i]
                    self.fetch_vars[i] = PY_TYPE_VAR._from_impl(var_impl)
        return self.fetch_vars

    def get_implicit_results(self, connection):
        errors._raise_not_supported("getting implicit results from PL/SQL")

    def get_lastrowid(self):
        errors._raise_not_supported(
            "getting the rowid of the row last modified"
        )

    def is_query(self, cursor):
        errors._raise_not_supported(
            "determining if the cursor last executed a query"
        )

    def parse(self, cursor):
        errors._raise_not_supported("parsing a statement without executing it")

    def prepare(self, str statement, str tag, bint cache_statement):
        """
        Prepares a statement for execution.
        """
        self._prepare(statement, tag, cache_statement)

    def scroll(self, cursor, value, mode):
        """
        Scrolls a scrollable cursor.
        """
        errors._raise_not_supported("scrolling a scrollable cursor")

    def setinputsizes(self, object conn, tuple args, dict kwargs):
        """
        Sets type information for bind variables in advance of executing a
        statement (and binding values).
        """
        cdef:
            object name, value
            BindVar bind_var
            ssize_t pos
        self.bind_vars = []
        self.set_input_sizes = True
        if kwargs:
            self.bind_style = dict
            self.bind_vars_by_name = {}
            for name, value in kwargs.items():
                bind_var = BindVar.__new__(BindVar)
                self.bind_vars.append(bind_var)
                self.bind_vars_by_name[name] = bind_var
                bind_var._set_by_type(conn, self, value)
                bind_var.name = name
        else:
            self.bind_style = list
            for pos, value in enumerate(args):
                bind_var = BindVar.__new__(BindVar)
                self.bind_vars.append(bind_var)
                bind_var._set_by_type(conn, self, value)
                bind_var.pos = pos + 1
        return self.get_bind_vars()


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\dbobject.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# dbobject.pyx
#
# Cython file defining the base DbObjectType, DbObjectAttr and DbObject
# implementation classes (embedded in base_impl.pyx).
#------------------------------------------------------------------------------

cdef class BaseDbObjectImpl:

    cdef int _check_max_size(self, object value, uint32_t max_size,
                             ssize_t* actual_size, bint* violated) except -1:
        """
        Checks to see if the maximum size has been violated.
        """
        violated[0] = False
        if max_size > 0 and value is not None:
            if isinstance(value, str):
                actual_size[0] = len((<str> value).encode())
            else:
                actual_size[0] = len(<bytes> value)
            if actual_size[0] > max_size:
                violated[0] = True

    def append(self, object value):
        """
        Appends a value to the collection after first checking to see if the
        value is acceptable.
        """
        cdef:
            BaseConnImpl conn_impl = self.type._conn_impl
            ssize_t actual_size
            bint violated
        value = conn_impl._check_value(self.type.element_metadata, value, NULL)
        self._check_max_size(value, self.type.element_metadata.max_size,
                             &actual_size, &violated)
        if violated:
            errors._raise_err(errors.ERR_DBOBJECT_ELEMENT_MAX_SIZE_VIOLATED,
                              index=self.get_size(),
                              type_name=self.type._get_fqn(),
                              actual_size=actual_size,
                              max_size=self.type.element_metadata.max_size)
        self.append_checked(value)

    def append_checked(self, object value):
        errors._raise_not_supported("appending a value to a collection")

    def copy(self):
        errors._raise_not_supported("creating a copy of an object")

    def delete_by_index(self, int32_t index):
        errors._raise_not_supported("deleting an element in a collection")

    def exists_by_index(self, int32_t index):
        errors._raise_not_supported(
            "determining if an entry exists in a collection"
        )

    def get_attr_value(self, BaseDbObjectAttrImpl attr):
        errors._raise_not_supported("getting an attribute value")

    def get_element_by_index(self, int32_t index):
        errors._raise_not_supported("getting an element of a collection")

    def get_first_index(self):
        errors._raise_not_supported("getting the first index of a collection")

    def get_last_index(self):
        errors._raise_not_supported("getting the last index of a collection")

    def get_next_index(self, int32_t index):
        errors._raise_not_supported("getting the next index of a collection")

    def get_prev_index(self, int32_t index):
        errors._raise_not_supported(
            "getting the previous index of a collection"
        )

    def get_size(self):
        errors._raise_not_supported("getting the size of a collection")

    def set_attr_value(self, BaseDbObjectAttrImpl attr, object value):
        """
        Sets the attribute value after first checking to see if the value is
        acceptable.
        """
        cdef:
            BaseConnImpl conn_impl = self.type._conn_impl
            ssize_t actual_size
            bint violated
        value = conn_impl._check_value(attr, value, NULL)
        self._check_max_size(value, attr.max_size, &actual_size, &violated)
        if violated:
            errors._raise_err(errors.ERR_DBOBJECT_ATTR_MAX_SIZE_VIOLATED,
                              attr_name=attr.name,
                              type_name=self.type._get_fqn(),
                              actual_size=actual_size, max_size=attr.max_size)
        self.set_attr_value_checked(attr, value)

    def set_attr_value_checked(self, BaseDbObjectAttrImpl attr, object value):
        errors._raise_not_supported("setting an attribute value")

    def set_element_by_index(self, int32_t index, object value):
        """
        Sets the element value after first checking to see if the value is
        acceptable.
        """
        cdef:
            BaseConnImpl conn_impl = self.type._conn_impl
            ssize_t actual_size
            bint violated
        value = conn_impl._check_value(self.type.element_metadata, value, NULL)
        self._check_max_size(value, self.type.element_metadata.max_size,
                             &actual_size, &violated)
        if violated:
            errors._raise_err(errors.ERR_DBOBJECT_ELEMENT_MAX_SIZE_VIOLATED,
                              index=index, type_name=self.type._get_fqn(),
                              actual_size=actual_size,
                              max_size=self.type.element_metadata.max_size)
        self.set_element_by_index_checked(index, value)

    def set_element_by_index_checked(self, int32_t index, object value):
        errors._raise_not_supported("setting an element of a collection")

    def trim(self, int32_t num_to_trim):
        errors._raise_not_supported("trimming elements from a collection")


cdef class BaseDbObjectAttrImpl(OracleMetadata):
    pass


cdef class BaseDbObjectTypeImpl:

    def __eq__(self, other):
        if isinstance(other, BaseDbObjectTypeImpl):
            return other._conn_impl is self._conn_impl \
                    and other.schema == self.schema \
                    and other.name == self.name
        return NotImplemented

    cpdef str _get_fqn(self):
        """
        Return the fully qualified name of the type.
        """
        if self.package_name is not None:
            return f"{self.schema}.{self.package_name}.{self.name}"
        return f"{self.schema}.{self.name}"

    def create_new_object(self):
        errors._raise_not_supported("creating a new object")


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\decoders.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# decoders.pyx
#
# Cython file defining the low-level decoding routines used by the driver.
#------------------------------------------------------------------------------

cdef int decode_binary_double(const uint8_t *ptr, ssize_t num_bytes,
                              OracleDataBuffer *buffer) except -1:
    """
    Decode a binary double from raw bytes.
    """
    cdef:
        uint8_t b0, b1, b2, b3, b4, b5, b6, b7
        uint64_t high_bits, low_bits, all_bits
    b0 = ptr[0]
    b1 = ptr[1]
    b2 = ptr[2]
    b3 = ptr[3]
    b4 = ptr[4]
    b5 = ptr[5]
    b6 = ptr[6]
    b7 = ptr[7]
    if b0 & 0x80:
        b0 = b0 & 0x7f
    else:
        b0 = ~b0
        b1 = ~b1
        b2 = ~b2
        b3 = ~b3
        b4 = ~b4
        b5 = ~b5
        b6 = ~b6
        b7 = ~b7
    high_bits = b0 << 24 | b1 << 16 | b2 << 8 | b3
    low_bits = b4 << 24 | b5 << 16 | b6 << 8 | b7
    all_bits = high_bits << 32 | (low_bits & <uint64_t> 0xffffffff)
    memcpy(&buffer.as_double, &all_bits, 8)


cdef int decode_binary_float(const uint8_t *ptr, ssize_t num_bytes,
                             OracleDataBuffer *buffer) except -1:
    """
    Decode a binary float from raw bytes.
    """
    cdef:
        uint8_t b0, b1, b2, b3
        uint64_t all_bits
    b0 = ptr[0]
    b1 = ptr[1]
    b2 = ptr[2]
    b3 = ptr[3]
    if b0 & 0x80:
        b0 = b0 & 0x7f
    else:
        b0 = ~b0
        b1 = ~b1
        b2 = ~b2
        b3 = ~b3
    all_bits = (b0 << 24) | (b1 << 16) | (b2 << 8) | b3
    memcpy(&buffer.as_float, &all_bits, 4)


cdef int decode_bool(const uint8_t* ptr, ssize_t num_bytes,
                     OracleDataBuffer *buffer) except -1:
    """
    Decode a boolean value from raw bytes.
    """
    buffer.as_bool = (ptr[num_bytes - 1] == 1)


cdef int decode_date(const uint8_t* ptr, ssize_t num_bytes,
                     OracleDataBuffer *buffer) except -1:
    """
    Decode a date from the raw bytes making up the Oracle Date.
    """
    cdef OracleDate *output = &buffer.as_date
    output.year = (ptr[0] - 100) * 100 + ptr[1] - 100
    output.month = ptr[2]
    output.day = ptr[3]
    output.hour = ptr[4] - 1
    output.minute = ptr[5] - 1
    output.second = ptr[6] - 1
    if num_bytes < 11:
        output.fsecond = 0
    else:
        output.fsecond = decode_uint32be(&ptr[7]) // 1000
    if num_bytes <= 11 or ptr[11] == 0 or ptr[12] == 0:
        output.tz_hour_offset = output.tz_minute_offset = 0
    else:
        if ptr[11] & TNS_HAS_REGION_ID:
            errors._raise_err(errors.ERR_NAMED_TIMEZONE_NOT_SUPPORTED)
        output.tz_hour_offset = ptr[11] - TZ_HOUR_OFFSET
        output.tz_minute_offset = ptr[12] - TZ_MINUTE_OFFSET


cdef uint64_t decode_integer(const uint8_t* ptr, ssize_t num_bytes):
    """
    Decodes an integer from raw bytes.
    """
    if num_bytes == 1:
        return ptr[0]
    elif num_bytes == 2:
        return decode_uint16be(ptr)
    elif num_bytes == 3:
        return decode_uint24be(ptr)
    elif num_bytes == 4:
        return decode_uint32be(ptr)
    elif num_bytes == 5:
        return decode_uint40be(ptr)
    elif num_bytes == 6:
        return decode_uint48be(ptr)
    elif num_bytes == 7:
        return decode_uint56be(ptr)
    elif num_bytes == 8:
        return decode_uint64be(ptr)


cdef int decode_interval_ds(const uint8_t *ptr, ssize_t num_bytes,
                            OracleDataBuffer *buffer) except -1:
    """
    Decode an interval days to seconds from raw bytes.
    """
    cdef OracleIntervalDS *output = &buffer.as_interval_ds
    output.days = decode_uint32be(ptr) - TNS_DURATION_MID
    output.hours = ptr[4] - TNS_DURATION_OFFSET
    output.minutes = ptr[5] - TNS_DURATION_OFFSET
    output.seconds = ptr[6] - TNS_DURATION_OFFSET
    output.fseconds = decode_uint32be(&ptr[7]) - TNS_DURATION_MID


cdef int decode_interval_ym(const uint8_t *ptr, ssize_t num_bytes,
                            OracleDataBuffer *buffer) except -1:
    """
    Decode an interval years to months from raw bytes.
    """
    cdef OracleIntervalYM *output = &buffer.as_interval_ym
    output.years = decode_uint32be(ptr) - TNS_DURATION_MID
    output.months = ptr[4] - TNS_DURATION_OFFSET


cdef int decode_number(const uint8_t* ptr, ssize_t num_bytes,
                       OracleDataBuffer *buffer) except -1:
    """
    Decode a number from the raw bytes making up the Oracle number.
    """
    cdef:
        OracleNumber *output = &buffer.as_number
        uint8_t byte, digit, num_digits
        int16_t decimal_point_index
        uint8_t digits[40]
        bint is_positive
        int8_t exponent

    # the first byte is the exponent; positive numbers have the highest
    # order bit set, whereas negative numbers have the highest order bit
    # cleared and the bits inverted
    exponent = <int8_t> ptr[0]
    is_positive = (exponent & 0x80)
    if not is_positive:
        exponent = ~exponent
    exponent -= 193
    decimal_point_index = exponent * 2 + 2

    # initialize output structure
    output.is_max_negative_value = False
    output.is_integer = True
    output.num_chars = 0

    # a mantissa length of 0 implies a value of 0 (if positive) or a value
    # of -1e126 (if negative)
    if num_bytes == 1:
        if is_positive:
            output.num_chars = 1
            output.chars[0] = 48                    # zero
        else:
            output.is_max_negative_value = True
        return 0

    # check for the trailing 102 byte for negative numbers and, if present,
    # reduce the number of mantissa digits
    if not is_positive and ptr[num_bytes - 1] == 102:
        num_bytes -= 1

    # process the mantissa bytes which are the remaining bytes; each
    # mantissa byte is a base-100 digit
    num_digits = 0
    for i in range(1, num_bytes):

        # positive numbers have 1 added to them; negative numbers are
        # subtracted from the value 101
        byte = ptr[i]
        if is_positive:
            byte -= 1
        else:
            byte = 101 - byte

        # process the first digit; leading zeroes are ignored
        digit = <uint8_t> byte // 10
        if digit == 0 and num_digits == 0:
            decimal_point_index -= 1
        elif digit == 10:
            digits[num_digits] = 1
            digits[num_digits + 1] = 0
            num_digits += 2
            decimal_point_index += 1
        elif digit != 0 or i > 0:
            digits[num_digits] = digit
            num_digits += 1

        # process the second digit; trailing zeroes are ignored
        digit = byte % 10
        if digit != 0 or i < num_bytes - 1:
            digits[num_digits] = digit
            num_digits += 1

    # create string of digits for transformation to Python value
    # if negative, include the sign
    if not is_positive:
        output.chars[output.num_chars] = 45         # minus sign
        output.num_chars += 1

    # if the decimal point index is 0 or less, add the decimal point and
    # any leading zeroes that are needed
    if decimal_point_index <= 0:
        output.chars[output.num_chars] = 48         # zero
        output.chars[output.num_chars + 1] = 46     # decimal point
        output.num_chars += 2
        output.is_integer = 0
        for i in range(decimal_point_index, 0):
            output.chars[output.num_chars] = 48     # zero
            output.num_chars += 1

    # add each of the digits
    for i in range(num_digits):
        if i > 0 and i == decimal_point_index:
            output.chars[output.num_chars] = 46     # decimal point
            output.is_integer = 0
            output.num_chars += 1
        output.chars[output.num_chars] = 48 + digits[i]
        output.num_chars += 1

    # if the decimal point index exceeds the number of digits, add any
    # trailing zeroes that are needed
    if decimal_point_index > num_digits:
        for i in range(num_digits, decimal_point_index):
            output.chars[output.num_chars] = 48     # zero
            output.num_chars += 1


cdef inline uint16_t decode_uint16be(const char_type *buf):
    """
    Decodes a 16-bit integer in big endian order (most significant byte first).
    """
    return (
        (<uint16_t> buf[0] << 8) |
        (<uint16_t> buf[1])
    )


cdef inline uint16_t decode_uint16le(const char_type *buf):
    """
    Decodes a 16-bit integer in little endian order (least significant byte
    first).
    """
    return (
        (<uint16_t> buf[1] << 8) |
        (<uint16_t> buf[0])
    )


cdef inline uint32_t decode_uint24be(const char_type *buf):
    """
    Decodes a 24-bit integer in big endian order (most significant byte first).
    """
    return (
        (<uint32_t> buf[0] << 16) |
        (<uint32_t> buf[1] << 8) |
        (<uint32_t> buf[2])
    )


cdef inline uint32_t decode_uint32be(const char_type *buf):
    """
    Decodes a 32-bit integer in big endian order (most significant byte first).
    """
    return (
        (<uint32_t> buf[0] << 24) |
        (<uint32_t> buf[1] << 16) |
        (<uint32_t> buf[2] << 8) |
        (<uint32_t> buf[3])
    )


cdef inline uint64_t decode_uint40be(const char_type *buf):
    """
    Decodes a 40-bit integer in big endian order (most significant byte first).
    """
    return (
        (<uint64_t> buf[0] << 32) |
        (<uint64_t> buf[1] << 24) |
        (<uint64_t> buf[2] << 16) |
        (<uint64_t> buf[3] << 8) |
        (<uint64_t> buf[4])
    )


cdef inline uint64_t decode_uint48be(const char_type *buf):
    """
    Decodes a 48-bit integer in big endian order (most significant byte first).
    """
    return (
        (<uint64_t> buf[0] << 40) |
        (<uint64_t> buf[1] << 32) |
        (<uint64_t> buf[2] << 24) |
        (<uint64_t> buf[3] << 16) |
        (<uint64_t> buf[4] << 8) |
        (<uint64_t> buf[5])
    )


cdef inline uint64_t decode_uint56be(const char_type *buf):
    """
    Decodes a 56-bit integer in big endian order (most significant byte first).
    """
    return (
        (<uint64_t> buf[0] << 48) |
        (<uint64_t> buf[1] << 40) |
        (<uint64_t> buf[2] << 32) |
        (<uint64_t> buf[3] << 24) |
        (<uint64_t> buf[4] << 16) |
        (<uint64_t> buf[5] << 8) |
        (<uint64_t> buf[6])
    )


cdef inline uint64_t decode_uint64be(const char_type *buf):
    """
    Decodes a 64-bit integer in big endian order (most significant byte first).
    """
    return (
        (<uint64_t> buf[0] << 56) |
        (<uint64_t> buf[1] << 48) |
        (<uint64_t> buf[2] << 40) |
        (<uint64_t> buf[3] << 32) |
        (<uint64_t> buf[4] << 24) |
        (<uint64_t> buf[5] << 16) |
        (<uint64_t> buf[6] << 8) |
        (<uint64_t> buf[7])
    )


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\defaults.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2024, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# defaults.pyx
#
# Cython file defining the DefaultsImpl class (embedded in base_impl.pyx).
#------------------------------------------------------------------------------

cdef class DefaultsImpl:

    def __init__(self):
        self.arraysize = 100
        self.config_dir = os.environ.get("TNS_ADMIN")
        if self.config_dir is None:
            oracle_home = os.environ.get("ORACLE_HOME")
            if oracle_home is not None:
                self.config_dir = os.path.join(oracle_home, "network", "admin")
        self.fetch_lobs = True
        self.fetch_decimals = False
        self.prefetchrows = 2
        self.stmtcachesize = 20
        self.program = sanitize(sys.executable)
        self.machine = sanitize(socket.gethostname())
        self.terminal = "unknown"
        try:
            self.osuser = sanitize(getpass.getuser())
        except:
            self.osuser = ""
        self.driver_name = None
        self.thick_mode_dsn_passthrough = True

cdef DefaultsImpl C_DEFAULTS = DefaultsImpl()
DEFAULTS = C_DEFAULTS


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\encoders.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# encoders.pyx
#
# Cython file defining the low-level encoding routines used by the driver.
#------------------------------------------------------------------------------

cdef inline void encode_uint16be(char_type *buf, uint16_t value):
    """
    Encodes a 16-bit integer in big endian order (most significant byte first).
    """
    buf[0] = <char_type> ((value >> 8) & 0xff)
    buf[1] = <char_type> (value & 0xff)


cdef inline void encode_uint16le(char_type *buf, uint16_t value):
    """
    Encodes a 16-bit integer in big endian order (most significant byte first).
    """
    buf[1] = <char_type> ((value >> 8) & 0xff)
    buf[0] = <char_type> (value & 0xff)


cdef inline void encode_uint32be(char_type *buf, uint32_t value):
    """
    Encodes a 32-bit integer in big endian order (most significant byte first).
    """
    buf[0] = <char_type> ((value >> 24) & 0xff)
    buf[1] = <char_type> ((value >> 16) & 0xff)
    buf[2] = <char_type> ((value >> 8) & 0xff)
    buf[3] = <char_type> (value & 0xff)


cdef inline void encode_uint64be(char_type *buf, uint64_t value):
    """
    Decodes a 64-bit integer in big endian order (most significant byte first).
    """
    buf[0] = <char_type> ((value >> 56) & 0xff)
    buf[1] = <char_type> ((value >> 48) & 0xff)
    buf[2] = <char_type> ((value >> 40) & 0xff)
    buf[3] = <char_type> ((value >> 32) & 0xff)
    buf[4] = <char_type> ((value >> 24) & 0xff)
    buf[5] = <char_type> ((value >> 16) & 0xff)
    buf[6] = <char_type> ((value >> 8) & 0xff)
    buf[7] = <char_type> (value & 0xff)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\lob.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# lob.pyx
#
# Cython file defining the base Lob implementation class (embedded in
# base_impl.pyx).
#------------------------------------------------------------------------------

cdef class BaseLobImpl:

    def close(self):
        errors._raise_not_supported("closing a LOB")

    def file_exists(self):
        errors._raise_not_supported("checking if a BFILE exists")

    def free_lob(self):
        errors._raise_not_supported("freeing the lob object")

    def get_chunk_size(self):
        errors._raise_not_supported("getting the chunk size of a LOB")

    def get_file_name(self):
        errors._raise_not_supported(
            "getting the file name and directory alias of a BFILE"
        )

    def get_is_open(self):
        errors._raise_not_supported("getting whether a LOB is open or not")

    def get_max_amount(self):
        errors._raise_not_supported(
            "getting the maximum amount that can be read from a LOB"
        )

    def get_size(self):
        errors._raise_not_supported("getting the size of a LOB")

    def open(self):
        errors._raise_not_supported("opening a LOB")

    def read(self, uint64_t offset, uint64_t amount):
        errors._raise_not_supported("reading data from a LOB")

    def set_file_name(self, str dir_alias, str name):
        errors._raise_not_supported(
            "setting the file name an directory alias of a BFILE"
        )

    def trim(self, uint64_t new_size):
        errors._raise_not_supported("trimming a LOB")

    def write(self, object value, uint64_t offset):
        errors._raise_not_supported("writing data to a LOB")


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\metadata.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2024, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# metadata.pyx
#
# Cython file defining the OracleMetadata class (embedded in base_impl.pyx).
#------------------------------------------------------------------------------

@cython.freelist(30)
cdef class OracleMetadata:

    cdef int _finalize_init(self) except -1:
        """
        Internal method that finalizes the initialization of metadata by
        setting the buffer size, max size and default Python type (if they have
        not already been set).
        """
        if self.dbtype.default_size == 0:
            self.max_size = 0
            self.buffer_size = self.dbtype._buffer_size_factor
        else:
            if self.max_size == 0:
                self.max_size = self.dbtype.default_size
            self.buffer_size = self.max_size * self.dbtype._buffer_size_factor
        if self._py_type_num == 0:
            if self.dbtype._ora_type_num != ORA_TYPE_NUM_NUMBER:
                self._py_type_num = self.dbtype._default_py_type_num
            else:
                if self.scale == 0 or \
                        (self.scale == -127 and self.precision == 0):
                    self._py_type_num = PY_TYPE_NUM_INT
                else:
                    self._py_type_num = PY_TYPE_NUM_FLOAT

    cdef int _set_arrow_type(self) except -1:
        """
        Determine the arrow type to use for the data.
        """
        cdef:
            uint8_t py_type_num = self._py_type_num
            uint32_t db_type_num = self.dbtype.num
        if db_type_num == DB_TYPE_NUM_NUMBER:
            if py_type_num == PY_TYPE_NUM_DECIMAL and self.precision > 0:
                self._arrow_type = NANOARROW_TYPE_DECIMAL128
            elif py_type_num == PY_TYPE_NUM_STR:
                self._arrow_type = NANOARROW_TYPE_STRING
            elif py_type_num == PY_TYPE_NUM_INT and self.scale == 0 \
                    and self.precision <= 18:
                self._arrow_type = NANOARROW_TYPE_INT64
            else:
                self._arrow_type = NANOARROW_TYPE_DOUBLE
        elif db_type_num in (DB_TYPE_NUM_CHAR, DB_TYPE_NUM_VARCHAR):
            self._arrow_type = NANOARROW_TYPE_STRING
        elif db_type_num == DB_TYPE_NUM_BINARY_FLOAT:
            self._arrow_type = NANOARROW_TYPE_FLOAT
        elif db_type_num == DB_TYPE_NUM_BINARY_DOUBLE:
            self._arrow_type = NANOARROW_TYPE_DOUBLE
        elif db_type_num == DB_TYPE_NUM_BOOLEAN:
            self._arrow_type = NANOARROW_TYPE_BOOL
        elif db_type_num in (DB_TYPE_NUM_DATE,
                             DB_TYPE_NUM_TIMESTAMP,
                             DB_TYPE_NUM_TIMESTAMP_LTZ,
                             DB_TYPE_NUM_TIMESTAMP_TZ):
            self._arrow_type = NANOARROW_TYPE_TIMESTAMP
        elif db_type_num == DB_TYPE_NUM_LONG_RAW:
            self._arrow_type = NANOARROW_TYPE_LARGE_BINARY
        elif db_type_num == DB_TYPE_NUM_LONG_VARCHAR:
            self._arrow_type = NANOARROW_TYPE_LARGE_STRING
        elif db_type_num == DB_TYPE_NUM_RAW:
            self._arrow_type = NANOARROW_TYPE_BINARY
        else:
            errors._raise_err(errors.ERR_ARROW_UNSUPPORTED_DATA_TYPE,
                              db_type_name=self.dbtype.name)

    cdef OracleMetadata copy(self):
        """
        Create a copy of the metadata and return it.
        """
        cdef OracleMetadata metadata = OracleMetadata.__new__(OracleMetadata)
        metadata.name = self.name
        metadata.dbtype = self.dbtype
        metadata.objtype = self.objtype
        metadata.precision = self.precision
        metadata.scale = self.scale
        metadata.max_size = self.max_size
        metadata.nulls_allowed = self.nulls_allowed
        metadata.is_json = self.is_json
        metadata.is_oson = self.is_oson
        metadata.domain_schema = self.domain_schema
        metadata.domain_name = self.domain_name
        metadata.annotations = self.annotations
        metadata.vector_dimensions = self.vector_dimensions
        metadata.vector_format = self.vector_format
        metadata.vector_flags = self.vector_flags
        return metadata

    @staticmethod
    cdef OracleMetadata from_type(object typ):
        """
        Returns a new OracleMetadata instance with attributes set according to
        the Python type.
        """
        cdef:
            OracleMetadata metadata = OracleMetadata.__new__(OracleMetadata)
            ApiType apitype
        if isinstance(typ, DbType):
            metadata.dbtype = typ
        elif isinstance(typ, ApiType):
            apitype = typ
            metadata.dbtype = apitype.dbtypes[0]
        elif isinstance(typ, PY_TYPE_DB_OBJECT_TYPE):
            metadata.dbtype = DB_TYPE_OBJECT
            metadata.objtype = typ._impl
        elif not isinstance(typ, type):
            errors._raise_err(errors.ERR_EXPECTING_TYPE)
        elif typ is int:
            metadata.dbtype = DB_TYPE_NUMBER
            metadata._py_type_num = PY_TYPE_NUM_INT
        elif typ is float:
            metadata.dbtype = DB_TYPE_NUMBER
            metadata._py_type_num = PY_TYPE_NUM_FLOAT
        elif typ is str:
            metadata.dbtype = DB_TYPE_VARCHAR
        elif typ is bytes:
            metadata.dbtype = DB_TYPE_RAW
        elif typ is PY_TYPE_DECIMAL:
            metadata.dbtype = DB_TYPE_NUMBER
            metadata._py_type_num = PY_TYPE_NUM_DECIMAL
        elif typ is PY_TYPE_BOOL:
            metadata.dbtype = DB_TYPE_BOOLEAN
        elif typ is PY_TYPE_DATE:
            metadata.dbtype = DB_TYPE_DATE
        elif typ is PY_TYPE_DATETIME:
            metadata.dbtype = DB_TYPE_TIMESTAMP
        elif typ is PY_TYPE_TIMEDELTA:
            metadata.dbtype = DB_TYPE_INTERVAL_DS
        else:
            errors._raise_err(errors.ERR_PYTHON_TYPE_NOT_SUPPORTED, typ=typ)
        return metadata

    @staticmethod
    cdef OracleMetadata from_value(object value):
        """
        Returns a new OracleMetadata instance with attributes set according to
        the Python type.
        """
        cdef OracleMetadata metadata = OracleMetadata.__new__(OracleMetadata)
        if value is None:
            metadata.dbtype = DB_TYPE_VARCHAR
            metadata.max_size = 1
        elif isinstance(value, PY_TYPE_BOOL):
            metadata.dbtype = DB_TYPE_BOOLEAN
        elif isinstance(value, str):
            metadata.dbtype = DB_TYPE_VARCHAR
            metadata.max_size = <uint32_t> len((<str> value).encode())
        elif isinstance(value, bytes):
            metadata.max_size = <uint32_t> len(value)
            metadata.dbtype = DB_TYPE_RAW
        elif isinstance(value, int):
            metadata.dbtype = DB_TYPE_NUMBER
            metadata._py_type_num = PY_TYPE_NUM_INT
        elif isinstance(value, float):
            metadata.dbtype = DB_TYPE_NUMBER
            metadata._py_type_num = PY_TYPE_NUM_FLOAT
        elif isinstance(value, PY_TYPE_DECIMAL):
            metadata.dbtype = DB_TYPE_NUMBER
            metadata._py_type_num = PY_TYPE_NUM_DECIMAL
        elif isinstance(value, (PY_TYPE_DATE, PY_TYPE_DATETIME)):
            metadata.dbtype = DB_TYPE_DATE
        elif isinstance(value, PY_TYPE_TIMEDELTA):
            metadata.dbtype = DB_TYPE_INTERVAL_DS
        elif isinstance(value, PY_TYPE_DB_OBJECT):
            metadata.dbtype = DB_TYPE_OBJECT
            metadata.objtype = value.type._impl
        elif isinstance(value, (PY_TYPE_LOB, PY_TYPE_ASYNC_LOB)):
            metadata.dbtype = value.type
        elif isinstance(value, (PY_TYPE_CURSOR, PY_TYPE_ASYNC_CURSOR)):
            metadata.dbtype = DB_TYPE_CURSOR
        elif isinstance(value, (array.array, PY_TYPE_SPARSE_VECTOR)):
            metadata.dbtype = DB_TYPE_VECTOR
        elif isinstance(value, PY_TYPE_INTERVAL_YM):
            metadata.dbtype = DB_TYPE_INTERVAL_YM
        else:
            errors._raise_err(errors.ERR_PYTHON_VALUE_NOT_SUPPORTED,
                              type_name=type(value).__name__)
        return metadata


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\oson.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2022, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# json.pyx
#
# Cython file defining the classes and methods used for encoding and decoding
# OSON (Oracle's extensions to JSON) (embedded in base_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class OsonDecoder(Buffer):

    cdef object _decode_container_node(self, uint8_t node_type):
        """
        Parses a container node (object or array) and returns it.
        """
        cdef:
            bint is_shared, is_object = (node_type & 0x40) == 0
            ssize_t field_ids_pos = 0, offsets_pos = 0, pos
            uint32_t container_offset, offset, temp32
            uint32_t i, num_children = 0
            uint16_t temp16
            uint8_t temp8
            object value
            str name

        # determine the number of children by examining the 4th and 5th most
        # significant bits of the node type; determine the offsets in the tree
        # segment to the field ids array and the value offsets array
        container_offset = self._pos - self.tree_seg_pos - 1
        self._get_num_children(node_type, &num_children, &is_shared)
        if is_shared:
            value = {}
            self._get_offset(node_type, &offset)
            offsets_pos = self._pos
            self.skip_to(self.tree_seg_pos + offset)
            self.read_ub1(&temp8)
            self._get_num_children(temp8, &num_children, &is_shared)
            field_ids_pos = self._pos
        elif is_object:
            value = {}
            field_ids_pos = self._pos
            offsets_pos = self._pos + self.field_id_length * num_children
        else:
            value = [None] * num_children
            offsets_pos = self._pos

        # process each of the children
        for i in range(num_children):
            if is_object:
                self.skip_to(field_ids_pos)
                if self.field_id_length == 1:
                    self.read_ub1(&temp8)
                    name = self.field_names[temp8 - 1]
                elif self.field_id_length == 2:
                    self.read_uint16be(&temp16)
                    name = self.field_names[temp16 - 1]
                else:
                    self.read_uint32be(&temp32)
                    name = self.field_names[temp32 - 1]
                field_ids_pos = self._pos
            self.skip_to(offsets_pos)
            self._get_offset(node_type, &offset)
            if self.relative_offsets:
                offset += container_offset
            offsets_pos = self._pos
            self.skip_to(self.tree_seg_pos + offset)
            if is_object:
                value[name] = self._decode_node()
            else:
                value[i] = self._decode_node()

        return value

    cdef object _decode_node(self):
        """
        Parses a node from the tree segment and returns the Python equivalent.
        """
        cdef:
            VectorDecoder vector_decoder
            uint8_t node_type, temp8
            OracleDataBuffer data
            const char_type* ptr
            uint16_t temp16
            uint32_t temp32

        # if the most significant bit is set the node refers to a container
        self.read_ub1(&node_type)
        if node_type & 0x80:
            return self._decode_container_node(node_type)

        # handle simple scalars
        if node_type == TNS_JSON_TYPE_NULL:
            return None
        elif node_type == TNS_JSON_TYPE_TRUE:
            return True
        elif node_type == TNS_JSON_TYPE_FALSE:
            return False

        # handle fixed length scalars
        elif node_type in (TNS_JSON_TYPE_DATE, TNS_JSON_TYPE_TIMESTAMP7):
            decode_date(self._get_raw(7), 7, &data)
            return convert_date_to_python(&data)
        elif node_type == TNS_JSON_TYPE_TIMESTAMP:
            decode_date(self._get_raw(11), 11, &data)
            return convert_date_to_python(&data)
        elif node_type == TNS_JSON_TYPE_TIMESTAMP_TZ:
            decode_date(self._get_raw(13), 13, &data)
            return convert_date_to_python(&data)
        elif node_type == TNS_JSON_TYPE_BINARY_FLOAT:
            decode_binary_float(self._get_raw(4), 4, &data)
            return data.as_float
        elif node_type == TNS_JSON_TYPE_BINARY_DOUBLE:
            decode_binary_double(self._get_raw(8), 8, &data)
            return data.as_double
        elif node_type == TNS_JSON_TYPE_INTERVAL_DS:
            decode_interval_ds(self._get_raw(11), 11, &data)
            return convert_interval_ds_to_python(&data)
        elif node_type == TNS_JSON_TYPE_INTERVAL_YM:
            errors._raise_err(errors.ERR_DB_TYPE_NOT_SUPPORTED,
                              name="DB_TYPE_INTERVAL_YM")

        # handle scalars with lengths stored outside the node itself
        elif node_type == TNS_JSON_TYPE_STRING_LENGTH_UINT8:
            self.read_ub1(&temp8)
            ptr = self._get_raw(temp8)
            return ptr[:temp8].decode()
        elif node_type == TNS_JSON_TYPE_STRING_LENGTH_UINT16:
            self.read_uint16be(&temp16)
            ptr = self._get_raw(temp16)
            return ptr[:temp16].decode()
        elif node_type == TNS_JSON_TYPE_STRING_LENGTH_UINT32:
            self.read_uint32be(&temp32)
            ptr = self._get_raw(temp32)
            return ptr[:temp32].decode()
        elif node_type == TNS_JSON_TYPE_NUMBER_LENGTH_UINT8:
            self.read_ub1(&temp8)
            ptr = self._get_raw(temp8)
            decode_number(ptr, temp8, &data)
            return convert_number_to_python_decimal(&data)
        elif node_type == TNS_JSON_TYPE_ID:
            self.read_ub1(&temp8)
            ptr = self._get_raw(temp8)
            return PY_TYPE_JSON_ID(ptr[:temp8])
        elif node_type == TNS_JSON_TYPE_BINARY_LENGTH_UINT16:
            self.read_uint16be(&temp16)
            ptr = self._get_raw(temp16)
            return ptr[:temp16]
        elif node_type == TNS_JSON_TYPE_BINARY_LENGTH_UINT32:
            self.read_uint32be(&temp32)
            ptr = self._get_raw(temp32)
            return ptr[:temp32]

        # handle extended types
        elif node_type == TNS_JSON_TYPE_EXTENDED:
            self.read_ub1(&node_type)
            if node_type == TNS_JSON_TYPE_VECTOR:
                self.read_uint32be(&temp32)
                ptr = self._get_raw(temp32)
                vector_decoder = VectorDecoder.__new__(VectorDecoder)
                return vector_decoder.decode(ptr[:temp32])

        # handle number/decimal with length stored inside the node itself
        if (node_type & 0xf0) in (0x20, 0x60):
            temp8 = node_type & 0x0f
            decode_number(self._get_raw(temp8 + 1), temp8 + 1, &data)
            return convert_number_to_python_decimal(&data)

        # handle integer with length stored inside the node itself
        elif (node_type & 0xf0) in (0x40, 0x50):
            temp8 = node_type & 0x0f
            decode_number(self._get_raw(temp8), temp8, &data)
            return convert_number_to_python_decimal(&data)

        # handle string with length stored inside the node itself
        elif (node_type & 0xe0) == 0:
            if node_type == 0:
                return ''
            ptr = self._get_raw(node_type)
            return ptr[:node_type].decode()

        errors._raise_err(errors.ERR_OSON_NODE_TYPE_NOT_SUPPORTED,
                          node_type=node_type)

    cdef list _get_long_field_names(self, uint32_t num_fields,
                                    ssize_t offsets_size,
                                    uint32_t field_names_seg_size):
        """
        Read the long field names from the buffer.
        """
        cdef:
            ssize_t offsets_pos, final_pos
            const char_type* ptr
            uint32_t offset, i
            list field_names
            uint16_t temp16
            uint8_t temp8

        # skip the hash id array (2 bytes for each field)
        self.skip_raw_bytes(num_fields * 2)

        # skip the field name offsets array for now
        offsets_pos = self._pos
        self.skip_raw_bytes(num_fields * offsets_size)
        ptr = self._get_raw(field_names_seg_size)
        final_pos = self._pos

        # determine the names of the fields
        self.skip_to(offsets_pos)
        field_names = [None] * num_fields
        for i in range(num_fields):
            if offsets_size == 2:
                self.read_uint16be(&temp16)
                offset = temp16
            else:
                self.read_uint32be(&offset)
            temp16 = decode_uint16be(&ptr[offset])
            field_names[i] = ptr[offset + 2:offset + temp16 + 2].decode()
        self.skip_to(final_pos)
        return field_names

    cdef int _get_num_children(self, uint8_t node_type, uint32_t* num_children,
                               bint* is_shared) except -1:
        """
        Return the number of children the container has. This is determined by
        examining the 4th and 5th signficant bits of the node type:

            00 - number of children is uint8_t
            01 - number of children is uint16_t
            10 - number of children is uint32_t
            11 - field ids are shared with another object whose offset follows

        In the latter case the flag is_shared is set and the number of children
        is read by the caller instead as it must examine the offset and then
        retain the location for later use.
        """
        cdef:
            uint8_t temp8, children_bits = (node_type & 0x18)
            uint16_t temp16
        is_shared[0] = (children_bits == 0x18)
        if children_bits == 0:
            self.read_ub1(&temp8)
            num_children[0] = temp8
        elif children_bits == 0x08:
            self.read_uint16be(&temp16)
            num_children[0] = temp16
        elif children_bits == 0x10:
            self.read_uint32be(num_children)

    cdef int _get_offset(self, uint8_t node_type, uint32_t* offset) except -1:
        """
        Return an offset. The offset will be either a 16-bit or 32-bit value
        depending on the value of the 3rd significant bit of the node type.
        """
        cdef uint16_t temp16
        if node_type & 0x20:
            self.read_uint32be(offset)
        else:
            self.read_uint16be(&temp16)
            offset[0] = temp16

    cdef list _get_short_field_names(self, uint32_t num_fields,
                                     ssize_t offsets_size,
                                     uint32_t field_names_seg_size):
        """
        Read the short field names from the buffer.
        """
        cdef:
            ssize_t offsets_pos, final_pos
            const char_type* ptr
            uint32_t offset, i
            list field_names
            uint16_t temp16
            uint8_t temp8

        # skip the hash id array (1 byte for each field)
        self.skip_raw_bytes(num_fields)

        # skip the field name offsets array for now
        offsets_pos = self._pos
        self.skip_raw_bytes(num_fields * offsets_size)
        ptr = self._get_raw(field_names_seg_size)
        final_pos = self._pos

        # determine the names of the fields
        self.skip_to(offsets_pos)
        field_names = [None] * num_fields
        for i in range(num_fields):
            if offsets_size == 2:
                self.read_uint16be(&temp16)
                offset = temp16
            else:
                self.read_uint32be(&offset)
            temp8 = ptr[offset]
            field_names[i] = ptr[offset + 1:offset + temp8 + 1].decode()
        self.skip_to(final_pos)
        return field_names

    cdef object decode(self, bytes data):
        """
        Returns a Python object corresponding to the encoded OSON bytes.
        """
        cdef:
            uint32_t short_field_names_seg_size, long_field_names_seg_size = 0
            uint32_t num_short_field_names, num_long_field_names = 0
            ssize_t hash_id_size, short_field_name_offsets_size
            ssize_t long_field_name_offsets_size = 0
            uint16_t num_tiny_nodes, temp16
            ssize_t field_name_offsets_pos
            uint32_t tree_seg_size, i
            uint8_t version, temp8
            const char_type* ptr
            uint32_t offset

        # populate the buffer with the data
        self._populate_from_bytes(data)

        # parse root header
        ptr = self._get_raw(3)
        if ptr[0] != TNS_JSON_MAGIC_BYTE_1 or \
                ptr[1] != TNS_JSON_MAGIC_BYTE_2 or \
                ptr[2] != TNS_JSON_MAGIC_BYTE_3:
            errors._raise_err(errors.ERR_UNEXPECTED_DATA, data=ptr[:3])
        self.read_ub1(&self.version)
        if self.version not in (
            TNS_JSON_VERSION_MAX_FNAME_255,
            TNS_JSON_VERSION_MAX_FNAME_65535
        ):
            errors._raise_err(errors.ERR_OSON_VERSION_NOT_SUPPORTED,
                              version=self.version)
        self.read_uint16be(&self.primary_flags)
        self.relative_offsets = \
                self.primary_flags & TNS_JSON_FLAG_REL_OFFSET_MODE

        # if value is a scalar value, the header is much smaller
        if self.primary_flags & TNS_JSON_FLAG_IS_SCALAR:
            if self.primary_flags & TNS_JSON_FLAG_TREE_SEG_UINT32:
                self.skip_raw_bytes(4)
            else:
                self.skip_raw_bytes(2)
            return self._decode_node()

        # determine the number of field names
        if self.primary_flags & TNS_JSON_FLAG_NUM_FNAMES_UINT32:
            self.read_uint32be(&num_short_field_names)
            self.field_id_length = 4
        elif self.primary_flags & TNS_JSON_FLAG_NUM_FNAMES_UINT16:
            self.read_uint16be(&temp16)
            num_short_field_names = temp16
            self.field_id_length = 2
        else:
            self.read_ub1(&temp8)
            num_short_field_names = temp8
            self.field_id_length = 1

        # determine the size of the field names segment
        if self.primary_flags & TNS_JSON_FLAG_FNAMES_SEG_UINT32:
            short_field_name_offsets_size = 4
            self.read_uint32be(&short_field_names_seg_size)
        else:
            short_field_name_offsets_size = 2
            self.read_uint16be(&temp16)
            short_field_names_seg_size = temp16

        # if the version indicates that field names > 255 bytes exist, parse
        # the information about that segment
        if self.version == TNS_JSON_VERSION_MAX_FNAME_65535:
            self.read_uint16be(&self.secondary_flags)
            if self.secondary_flags & TNS_JSON_FLAG_SEC_FNAMES_SEG_UINT16:
                long_field_name_offsets_size = 2
            else:
                long_field_name_offsets_size = 4
            self.read_uint32be(&num_long_field_names)
            self.read_uint32be(&long_field_names_seg_size)

        # determine the size of the tree segment
        if self.primary_flags & TNS_JSON_FLAG_TREE_SEG_UINT32:
            self.read_uint32be(&tree_seg_size)
        else:
            self.read_uint16be(&temp16)
            tree_seg_size = temp16

        # determine the number of "tiny" nodes
        self.read_uint16be(&num_tiny_nodes)

        # if there are any short names, read them now
        self.field_names = []
        if num_short_field_names > 0:
            self.field_names.extend(
                self._get_short_field_names(
                    num_short_field_names,
                    short_field_name_offsets_size,
                    short_field_names_seg_size
                )
            )

        # if there are any long names, read them now
        if num_long_field_names > 0:
            self.field_names.extend(
                self._get_long_field_names(
                    num_long_field_names,
                    long_field_name_offsets_size,
                    long_field_names_seg_size
                )
            )

        # get tree segment
        self.tree_seg_pos = self._pos

        # return root node
        return self._decode_node()


@cython.final
cdef class OsonFieldName:

    cdef int _calc_hash_id(self) except -1:
        """
        Calculates the hash id to use for the field name. This is based on
        Bernstein's hash function.
        """
        cdef:
            const char_type *ptr = self.name_bytes
            ssize_t i
        self.hash_id = 0x811C9DC5
        for i in range(self.name_bytes_len):
            self.hash_id = (self.hash_id ^ ptr[i]) * 16777619

    @staticmethod
    cdef OsonFieldName create(str name, ssize_t max_fname_size):
        """
        Creates and initializes the field name.
        """
        cdef OsonFieldName field_name
        field_name = OsonFieldName.__new__(OsonFieldName)
        field_name.name = name
        field_name.name_bytes = name.encode()
        field_name.name_bytes_len = len(field_name.name_bytes)
        if field_name.name_bytes_len > max_fname_size:
            errors._raise_err(errors.ERR_OSON_FIELD_NAME_LIMITATION,
                              max_fname_size=max_fname_size)
        field_name._calc_hash_id()
        return field_name

    def sort_key(self):
        """
        Returns the sort key to use when sorting field names.
        """
        return ((self.hash_id & 0xff), self.name_bytes_len, self.name_bytes)


@cython.final
cdef class OsonFieldNamesSegment(GrowableBuffer):

    cdef int add_name(self, OsonFieldName field_name) except -1:
        """
        Adds a name to the field names segment.
        """
        field_name.offset = self._pos
        if field_name.name_bytes_len <= 255:
            self.write_uint8(field_name.name_bytes_len)
        else:
            self.write_uint16be(field_name.name_bytes_len)
        self.write_bytes(field_name.name_bytes)
        self.field_names.append(field_name)

    @staticmethod
    cdef OsonFieldNamesSegment create():
        """
        Creates and initializes the segment. The value (and all of its
        children) are examined for dictionaries and the keys retained as
        required by OSON.
        """
        cdef OsonFieldNamesSegment seg
        seg = OsonFieldNamesSegment.__new__(OsonFieldNamesSegment)
        seg._initialize(TNS_CHUNK_SIZE)
        seg.field_names = []
        return seg

    cdef int process_field_names(self, ssize_t field_id_offset) except -1:
        """
        Processes the field names in preparation for encoding within OSON.
        """
        cdef:
            OsonFieldName field_name
            ssize_t i
        self.field_names.sort(key=OsonFieldName.sort_key)
        for i, field_name in enumerate(self.field_names):
            field_name.field_id = field_id_offset + i + 1
        self.num_field_names = <uint32_t> len(self.field_names)


@cython.final
cdef class OsonTreeSegment(GrowableBuffer):

    cdef int _encode_container(self, uint8_t node_type,
                               ssize_t num_children) except -1:
        """
        Encodes the first part of a container.
        """
        node_type |= 0x20                   # use uint32_t for offsets
        if num_children > 65535:
            node_type |= 0x10               # num children is uint32_t
        elif num_children > 255:
            node_type |= 0x08               # num children is uint16_t
        self.write_uint8(node_type)
        if num_children < 256:
            self.write_uint8(<uint8_t> num_children)
        elif num_children < 65536:
            self.write_uint16be(<uint16_t> num_children)
        else:
            self.write_uint32be(<uint32_t> num_children)

    cdef int encode_array(self, object value, OsonEncoder encoder) except -1:
        """
        Encode an array in the OSON tree segment.
        """
        cdef:
            ssize_t num_children
            uint8_t node_type
            uint32_t offset
        num_children = len(value)
        self._encode_container(TNS_JSON_TYPE_ARRAY, num_children)
        offset = self._pos
        self._reserve_space(num_children * sizeof(uint32_t))
        for element in value:
            encode_uint32be(&self._data[offset], self._pos)
            offset += sizeof(uint32_t)
            self.encode_node(element, encoder)

    cdef int encode_object(self, dict value, OsonEncoder encoder) except -1:
        """
        Encode an object in the OSON tree segment.
        """
        cdef:
            uint32_t field_id_offset, value_offset, final_offset
            OsonFieldName field_name
            ssize_t num_children
            object child_value
            uint8_t node_type
            str key
        num_children = len(value)
        self._encode_container(TNS_JSON_TYPE_OBJECT, num_children)
        field_id_offset = self._pos
        value_offset = self._pos + num_children * encoder.field_id_size
        final_offset = value_offset + num_children * sizeof(uint32_t)
        self._reserve_space(final_offset - self._pos)
        for key, child_value in value.items():
            field_name = encoder.field_names_dict[key]
            if encoder.field_id_size == 1:
                self._data[field_id_offset] = <uint8_t> field_name.field_id
            elif encoder.field_id_size == 2:
                encode_uint16be(&self._data[field_id_offset],
                            <uint16_t> field_name.field_id)
            else:
                encode_uint32be(&self._data[field_id_offset],
                              field_name.field_id)
            encode_uint32be(&self._data[value_offset], self._pos)
            field_id_offset += encoder.field_id_size
            value_offset += sizeof(uint32_t)
            self.encode_node(child_value, encoder)

    cdef int encode_node(self, object value, OsonEncoder encoder) except -1:
        """
        Encode a value (node) in the OSON tree segment.
        """
        cdef:
            VectorEncoder vector_encoder
            uint32_t value_len
            bytes value_bytes

        # handle null
        if value is None:
            self.write_uint8(TNS_JSON_TYPE_NULL)

        # handle booleans
        elif isinstance(value, bool):
            if value is True:
                self.write_uint8(TNS_JSON_TYPE_TRUE)
            else:
                self.write_uint8(TNS_JSON_TYPE_FALSE)

        # handle numeric types
        elif isinstance(value, (int, float, PY_TYPE_DECIMAL)):
            value_bytes = (<str> cpython.PyObject_Str(value)).encode()
            self.write_uint8(TNS_JSON_TYPE_NUMBER_LENGTH_UINT8)
            self.write_oracle_number(value_bytes)

        # handle bytes
        elif isinstance(value, bytes):
            value_len = len(<bytes> value)
            if isinstance(value, PY_TYPE_JSON_ID):
                self.write_uint8(TNS_JSON_TYPE_ID)
                self.write_uint8(<uint8_t> value_len)
            elif value_len < 65536:
                self.write_uint8(TNS_JSON_TYPE_BINARY_LENGTH_UINT16)
                self.write_uint16be(<uint16_t> value_len)
            else:
                self.write_uint8(TNS_JSON_TYPE_BINARY_LENGTH_UINT32)
                self.write_uint32be(value_len)
            self.write_bytes(<bytes> value)

        # handle timestamps
        elif isinstance(value, PY_TYPE_DATETIME):
            if cydatetime.PyDateTime_DATE_GET_MICROSECOND(value) == 0:
                self.write_uint8(TNS_JSON_TYPE_TIMESTAMP7)
                self.write_oracle_date(value, 7, write_length=False)
            else:
                self.write_uint8(TNS_JSON_TYPE_TIMESTAMP)
                self.write_oracle_date(value, 11, write_length=False)

        # handle dates
        elif isinstance(value, PY_TYPE_DATE):
            self.write_uint8(TNS_JSON_TYPE_DATE)
            self.write_oracle_date(value, 7, write_length=False)

        # handle timedeltas
        elif isinstance(value, PY_TYPE_TIMEDELTA):
            self.write_uint8(TNS_JSON_TYPE_INTERVAL_DS)
            self.write_interval_ds(value, write_length=False)

        # handle strings
        elif isinstance(value, str):
            value_bytes = (<str> value).encode()
            value_len = len(value_bytes)
            if value_len < 256:
                self.write_uint8(TNS_JSON_TYPE_STRING_LENGTH_UINT8)
                self.write_uint8(<uint8_t> value_len)
            elif value_len < 65536:
                self.write_uint8(TNS_JSON_TYPE_STRING_LENGTH_UINT16)
                self.write_uint16be(<uint16_t> value_len)
            else:
                self.write_uint8(TNS_JSON_TYPE_STRING_LENGTH_UINT32)
                self.write_uint32be(value_len)
            if value_len > 0:
                self.write_bytes(value_bytes)

        # handle lists/tuples
        elif isinstance(value, (list, tuple)):
            self.encode_array(value, encoder)

        # handle dictionaries
        elif isinstance(value, dict):
            self.encode_object(value, encoder)

        # handle arrays (vectors)
        elif isinstance(value, array.array):
            self.write_uint8(TNS_JSON_TYPE_EXTENDED)
            self.write_uint8(TNS_JSON_TYPE_VECTOR)
            vector_encoder = VectorEncoder.__new__(VectorEncoder)
            vector_encoder.encode(value)
            self.write_uint32be(vector_encoder._pos)
            self.write_raw(vector_encoder._data, vector_encoder._pos)

        # other types are not supported
        else:
            errors._raise_err(errors.ERR_PYTHON_TYPE_NOT_SUPPORTED,
                              typ=type(value).__name__)


@cython.final
cdef class OsonEncoder(GrowableBuffer):

    cdef int _add_field_name(self, str name) except -1:
        """
        Add a field with the given name.
        """
        cdef OsonFieldName field_name
        field_name = OsonFieldName.create(name, self.max_fname_size)
        self.field_names_dict[name] = field_name
        if field_name.name_bytes_len <= 255:
            self.short_fnames_seg.add_name(field_name)
        else:
            if self.long_fnames_seg is None:
                self.long_fnames_seg = OsonFieldNamesSegment.create()
            self.long_fnames_seg.add_name(field_name)

    cdef int _determine_flags(self, object value, uint16_t *flags) except -1:
        """
        Determine the flags to use for the OSON image.
        """

        # if value is a simple scalar, nothing more needs to be done
        flags[0] = TNS_JSON_FLAG_INLINE_LEAF
        if not isinstance(value, (list, tuple, dict)):
            flags[0] |= TNS_JSON_FLAG_IS_SCALAR
            return 0

        # examine all values recursively to determine the unique set of field
        # names and whether they need to be added to the long field names
        # segment (> 255 bytes) or short field names segment (<= 255 bytes)
        self.field_names_dict = {}
        self.short_fnames_seg = OsonFieldNamesSegment.create()
        self._examine_node(value)

        # perform processing of field names segments and determine the total
        # number of unique field names in the value
        if self.short_fnames_seg is not None:
            self.short_fnames_seg.process_field_names(0)
            self.num_field_names += self.short_fnames_seg.num_field_names
        if self.long_fnames_seg is not None:
            self.long_fnames_seg.process_field_names(self.num_field_names)
            self.num_field_names += self.long_fnames_seg.num_field_names

        # determine remaining flags and field id size
        flags[0] |= TNS_JSON_FLAG_HASH_ID_UINT8 | \
                TNS_JSON_FLAG_TINY_NODES_STAT
        if self.num_field_names > 65535:
            flags[0] |= TNS_JSON_FLAG_NUM_FNAMES_UINT32
            self.field_id_size = 4
        elif self.num_field_names > 255:
            flags[0] |= TNS_JSON_FLAG_NUM_FNAMES_UINT16
            self.field_id_size = 2
        else:
            self.field_id_size = 1
        if self.short_fnames_seg._pos > 65535:
            flags[0] |= TNS_JSON_FLAG_FNAMES_SEG_UINT32

    cdef int _examine_node(self, object value) except -1:
        """
        Examines the value. If it is a dictionary, all keys are extracted and
        unique names retained. Elements in lists and tuples and values in
        dictionaries are then examined to determine if they contain
        dictionaries as well.
        """
        cdef str key
        if isinstance(value, (list, tuple)):
            for child_value in value:
                self._examine_node(child_value)
        elif isinstance(value, dict):
            for key, child_value in (<dict> value).items():
                if key not in self.field_names_dict:
                    self._add_field_name(key)
                self._examine_node(child_value)

    cdef int _write_extended_header(self) except -1:
        """
        Write the extended header containing information about the short and
        long field name segments.
        """
        cdef uint16_t secondary_flags = 0

        # write number of short field names
        if self.field_id_size == 1:
            self.write_uint8(<uint8_t> self.short_fnames_seg.num_field_names)
        elif self.field_id_size == 2:
            self.write_uint16be(
                <uint16_t> self.short_fnames_seg.num_field_names
            )
        else:
            self.write_uint32be(self.short_fnames_seg.num_field_names)

        # write size of short field names segment
        if self.short_fnames_seg._pos < 65536:
            self.write_uint16be(<uint16_t> self.short_fnames_seg._pos)
        else:
            self.write_uint32be(self.short_fnames_seg._pos)

        # write fields for long field names segment, if applicable
        if self.long_fnames_seg is not None:
            if self.long_fnames_seg._pos < 65536:
                secondary_flags = TNS_JSON_FLAG_SEC_FNAMES_SEG_UINT16
            self.write_uint16be(secondary_flags)
            self.write_uint32be(self.long_fnames_seg.num_field_names)
            self.write_uint32be(self.long_fnames_seg._pos)

    cdef int _write_fnames_seg(self, OsonFieldNamesSegment seg) except -1:
        """
        Write the contents of the field names segment to the buffer.
        """
        cdef OsonFieldName field_name

        # write array of hash ids
        for field_name in seg.field_names:
            if field_name.name_bytes_len <= 255:
                self.write_uint8(field_name.hash_id & 0xff)
            else:
                self.write_uint16be(field_name.hash_id & 0xffff)

        # write array of field name offsets for the short field names
        for field_name in seg.field_names:
            if seg._pos < 65536:
                self.write_uint16be(<uint16_t> field_name.offset)
            else:
                self.write_uint32be(field_name.offset)

        # write field names
        if seg._pos > 0:
            self.write_raw(seg._data, seg._pos)

    cdef int encode(self, object value, ssize_t max_fname_size) except -1:
        """
        Encodes the given value to OSON.
        """
        cdef:
            OsonFieldName field_name
            OsonTreeSegment tree_seg
            uint16_t flags

        # determine the flags to use
        self.max_fname_size = max_fname_size
        self._determine_flags(value, &flags)

        # encode values into tree segment
        tree_seg = OsonTreeSegment.__new__(OsonTreeSegment)
        tree_seg._initialize(TNS_CHUNK_SIZE)
        tree_seg.encode_node(value, self)
        if tree_seg._pos > 65535:
            flags |= TNS_JSON_FLAG_TREE_SEG_UINT32

        # write initial header
        self.write_uint8(TNS_JSON_MAGIC_BYTE_1)
        self.write_uint8(TNS_JSON_MAGIC_BYTE_2)
        self.write_uint8(TNS_JSON_MAGIC_BYTE_3)
        if self.long_fnames_seg is not None:
            self.write_uint8(TNS_JSON_VERSION_MAX_FNAME_65535)
        else:
            self.write_uint8(TNS_JSON_VERSION_MAX_FNAME_255)
        self.write_uint16be(flags)

        # write extended header (when value is not scalar)
        if self.short_fnames_seg is not None:
            self._write_extended_header()

        # write size of tree segment
        if tree_seg._pos < 65536:
            self.write_uint16be(<uint16_t> tree_seg._pos)
        else:
            self.write_uint32be(tree_seg._pos)

        # write remainder of header and any data (when value is not scalar)
        if self.short_fnames_seg is not None:

            # write number of "tiny" nodes (always zero)
            self.write_uint16be(0)

            # write field name segments
            self._write_fnames_seg(self.short_fnames_seg)
            if self.long_fnames_seg is not None:
                self._write_fnames_seg(self.long_fnames_seg)

        # write tree segment data
        self.write_raw(tree_seg._data, tree_seg._pos)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\parsers.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2024, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# parsers.pyx
#
# Cython file defining the classes used for parsing connect strings and
# statements (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

# a set of alternative parameter names that are used in connect descriptors
# the key is the parameter name used in connect descriptors and the value is
# the key used in argument dictionaries (and stored in the parameter objects)
ALTERNATIVE_PARAM_NAMES = {
    "pool_connection_class": "cclass",
    "pool_purity": "purity",
    "server": "server_type",
    "transport_connect_timeout": "tcp_connect_timeout",
    "my_wallet_directory": "wallet_location"
}

# a set of parameter names used as containers for storing additional parameters
CONTAINER_PARAM_NAMES = set([
    "address",
    "address_list",
    "connect_data",
    "description",
    "description_list",
    "security",
])

# DESCRIPTION parameter names that are supported by the driver; all other
# key/value pairs are passed unchanged to the database
DESCRIPTION_PARAM_NAMES = set([
    "address",
    "address_list",
    "connect_data",
    "expire_time",
    "failover",
    "load_balance",
    "source_route",
    "retry_count",
    "retry_delay",
    "sdu",
    "tcp_connect_timeout",
    "use_sni",
    "security",
])

# extra DESCRIPTION parameter names that are passed through when detected in an
# easy connect string
EXTRA_DESCRIPTION_PARAM_NAMES = set([
    "enable",
    "recv_buf_size",
    "send_buf_size"
])

# CONNECT_DATA parameter names that are supported by the driver; all other
# key/value pairs are passed unchanged to the database
CONNECT_DATA_PARAM_NAMES = set([
    "cclass",
    "connection_id_prefix",
    "instance_name",
    "pool_boundary",
    "purity",
    "server_type",
    "service_name",
    "sid",
    "use_tcp_fast_open",
])

# SECURITY parameter names that are supported by the driver; all other
# key/value pairs are passed unchanged to the database
SECURITY_PARAM_NAMES = set([
    "ssl_server_cert_dn",
    "ssl_server_dn_match",
    "ssl_version",
    "wallet_location",
])

# a set of parameter names supported by the driver in EasyConnect strings that
# are common to all drivers
COMMON_PARAM_NAMES = set([
    "expire_time",
    "failover",
    "https_proxy",
    "https_proxy_port",
    "load_balance",
    "pool_boundary",
    "pool_connection_class",
    "pool_purity",
    "retry_count",
    "retry_delay",
    "sdu",
    "source_route",
    "ssl_server_cert_dn",
    "ssl_server_dn_match",
    "transport_connect_timeout",
    "use_sni",
    "wallet_location",
])

# extended parameter prefix
EXTENDED_PARAM_PREFIX = "pyo."

# a set of parameter names that can be specified in EasyConnect strings using
# the extended parameter prefix; these are specific to python-oracledb
EXTENDED_PARAM_NAMES = set([

    # ConnectParams
    "connection_id_prefix",
    "disable_oob",
    "driver_name",
    "edition",
    "events",
    "externalauth",
    "machine",
    "mode",
    "osuser",
    "program",
    "stmtcachesize",
    "terminal",
    "use_tcp_fast_open",

    # PoolParams
    "getmode",
    "homogeneous",
    "increment",
    "max",
    "max_lifetime_session",
    "max_sessions_per_shard",
    "min",
    "ping_interval",
    "ping_timeout",
    "soda_metadata_cache",
    "timeout",
    "wait_timeout",

])

# this cache stores the configurations acquired from one of the configuration
# stores
cdef dict cached_configs = {}

# add all of the common parameters to the extended parameters using the
# python-oracledb specific name
for name in COMMON_PARAM_NAMES:
    EXTENDED_PARAM_NAMES.add(ALTERNATIVE_PARAM_NAMES.get(name, name))


cdef class BaseParser:

    cdef Py_UCS4 get_current_char(self):
        """
        Returns the current character in the data being parsed. This method
        assumes that the end of the stream has not been encountered.
        """
        return cpython.PyUnicode_READ(self.data_kind, self.data, self.temp_pos)

    cdef int initialize(self, str data_to_parse) except -1:
        """
        Initializes the parser with the data to parse.
        """
        self.pos = 0
        self.temp_pos = 0
        self.data_as_str = data_to_parse
        self.num_chars = cpython.PyUnicode_GET_LENGTH(data_to_parse)
        self.data = cpython.PyUnicode_DATA(data_to_parse)
        self.data_kind = cpython.PyUnicode_KIND(data_to_parse)

    cdef int parse_keyword(self) except -1:
        """
        Parse a keyword from the data to parse.
        """
        cdef Py_UCS4 ch
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if not cpython.Py_UNICODE_ISALPHA(ch) \
                    and not cpython.Py_UNICODE_ISDIGIT(ch) \
                    and ch != '_' and ch != '.':
                break
            self.temp_pos += 1

    cdef int parse_quoted_string(self, Py_UCS4 quote_type) except -1:
        """
        Parses a quoted string with the given quote type. All characters until
        the quote type is detected are discarded.
        """
        cdef Py_UCS4 ch
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            self.temp_pos += 1
            if ch == quote_type:
                self.pos = self.temp_pos
                return 0
        if quote_type == "'":
            errors._raise_err(errors.ERR_MISSING_ENDING_SINGLE_QUOTE)
        else:
            errors._raise_err(errors.ERR_MISSING_ENDING_DOUBLE_QUOTE)

    cdef int skip_spaces(self) except -1:
        """
        Skip any spaces that are present in the string.
        """
        cdef Py_UCS4 ch
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if not cpython.Py_UNICODE_ISSPACE(ch):
                break
            self.temp_pos += 1


cdef int update_config_cache(str config_cache_key, dict config) except -1:
    """
    Updates the cache with the specified configuration.
    """
    cdef:
        double current_time, soft_expiry_time, hard_expiry_time
        uint32_t time_to_live, time_to_live_grace_period
        object setting

    # the config can include config_time_to_live; the default value is 86400
    # (24 hours); an explicit value of 0 disables caching
    setting = config.get("config_time_to_live")
    if setting is None:
        time_to_live = 86400
    else:
        time_to_live = int(setting)
    if time_to_live == 0:
        return 0

    # the config settings can also include config_time_to_live_grace_period;
    # the default value is 1800 (30 minutes)
    setting = config.get("config_time_to_live_grace_period")
    if setting is None:
        time_to_live_grace_period = 1800
    else:
        time_to_live_grace_period = int(setting)

    # calculate soft and hard expiry times and keep them with the config
    current_time = time.monotonic()
    soft_expiry_time = current_time + time_to_live
    hard_expiry_time = soft_expiry_time + time_to_live_grace_period
    config = copy.deepcopy(config)
    config["config_cache_soft_expiry_time"] = soft_expiry_time
    config["config_cache_hard_expiry_time"] = hard_expiry_time
    cached_configs[config_cache_key] = config


cdef class ConnectStringParser(BaseParser):

    cdef:
        DescriptionList description_list
        Description template_description
        ConnectParamsImpl params_impl
        Address template_address
        Description description
        dict parameters

    cdef int _call_protocol_hook(self, str protocol, str arg,
                                 object fn) except -1:
        """
        Check if the config cache has an entry; if an extry exists and it has
        not expired, use it; otherwise, call the protocol hook function.
        """
        cdef:
            double current_time = 0, expiry_time = 0
            dict config

        # check to see if the cache has a value and that it has not reached the
        # soft expiry time
        config = cached_configs.get(self.data_as_str)
        if config is not None:
            current_time = time.monotonic()
            expiry_time = config["config_cache_soft_expiry_time"]
            if current_time <= expiry_time:
                self.params_impl.set_from_config(config, update_cache=False)
                return 0

        # call the protocol hook function; the cache key is set on the
        # parameters instance so that calls by the hook function to
        # set_from_config() will update the cache
        params = self.params_impl._get_public_instance()
        self.params_impl._config_cache_key = self.data_as_str
        try:
            fn(protocol, arg, params)
        except Exception as e:

            # if the hook fails but a config exists in the cache and the hard
            # expiry time has not been reached the existing config is used
            if config is not None:
                expiry_time = config["config_cache_hard_expiry_time"]
                if current_time <= expiry_time:
                    self.params_impl.set_from_config(config, update_cache=False)
                    return 0
                del cached_configs[self.params_impl._config_cache_key]
            errors._raise_err(errors.ERR_PROTOCOL_HANDLER_FAILED,
                              protocol=protocol, arg=arg, cause=e)
        finally:
            self.params_impl._config_cache_key = None

    cdef bint _is_host_or_service_name_char(self, Py_UCS4 ch):
        """
        Returns whether or not the given character is allowed to be used inside
        a host name or service name.
        """
        return cpython.Py_UNICODE_ISALPHA(ch) \
                or cpython.Py_UNICODE_ISDIGIT(ch) \
                or ch in ('-', '_', '.')

    cdef int _parse_descriptor(self) except -1:
        """
        Parses a connect descriptor.
        """
        cdef:
            AddressList address_list
            Description description
            Address address
            dict args = {}
        self._parse_descriptor_key_value_pair(args)
        self.description_list = DescriptionList()
        list_args = args.get("description_list")
        if list_args is not None:
            self.description_list.set_from_args(list_args)
        else:
            list_args = args
        descriptions = list_args.get("description", list_args)
        if not isinstance(descriptions, list):
            descriptions = [descriptions]
        for desc_args in descriptions:
            description = self.template_description.copy()
            description.set_from_description_args(desc_args)
            self.description_list.children.append(description)
            sub_args = desc_args.get("connect_data")
            if sub_args is not None:
                description.set_from_connect_data_args(sub_args)
            sub_args = desc_args.get("security")
            if sub_args is not None:
                description.set_from_security_args(sub_args)
            address_lists = desc_args.get("address_list", desc_args)
            if not isinstance(address_lists, list):
                address_lists = [address_lists]
            for list_args in address_lists:
                address_list = AddressList()
                address_list.set_from_args(list_args)
                description.children.append(address_list)
                addresses = list_args.get("address", [])
                if not isinstance(addresses, list):
                    addresses = [addresses]
                for addr_args in addresses:
                    address = self.template_address.copy()
                    address.set_from_args(addr_args)
                    address_list.children.append(address)
        if not self.description_list.get_addresses():
            errors._raise_err(errors.ERR_MISSING_ADDRESS,
                              connect_string=self.data_as_str)

    cdef int _parse_descriptor_key_value_pair(self, dict args) except -1:
        """
        Parses a key-value pair from the connect string. At this point it is
        assumed that the character previously read was an opening parenthesis.
        """
        cdef:
            bint is_simple_value = False
            object value = None
            ssize_t start_pos
            Py_UCS4 ch = 0
            str name

        # parse keyword
        self.skip_spaces()
        start_pos = self.temp_pos
        self.parse_keyword()
        if self.temp_pos == start_pos:
            errors._raise_err(errors.ERR_INVALID_CONNECT_DESCRIPTOR,
                              data=self.data_as_str)
        name = self.data_as_str[start_pos:self.temp_pos].lower()
        name = ALTERNATIVE_PARAM_NAMES.get(name, name)

        # look for equals sign
        self.skip_spaces()
        if self.temp_pos < self.num_chars:
            ch = self.get_current_char()
        if ch != '=':
            errors._raise_err(errors.ERR_INVALID_CONNECT_DESCRIPTOR,
                              data=self.data_as_str)
        self.temp_pos += 1
        self.skip_spaces()

        # parse value
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if ch == '"':
                if is_simple_value:
                    errors._raise_err(errors.ERR_INVALID_CONNECT_DESCRIPTOR,
                                      data=self.data_as_str)
                self.temp_pos += 1
                start_pos = self.temp_pos
                self.parse_quoted_string(ch)
                if self.temp_pos > start_pos + 1:
                    value = self.data_as_str[start_pos:self.temp_pos - 1]
                break
            elif ch == '(':
                if is_simple_value:
                    errors._raise_err(errors.ERR_INVALID_CONNECT_DESCRIPTOR,
                                      data=self.data_as_str)
                self.temp_pos += 1
                if value is None:
                    value = {}
                self._parse_descriptor_key_value_pair(value)
                continue
            elif ch == ')':
                break
            elif not is_simple_value and not cpython.Py_UNICODE_ISSPACE(ch):
                if value is not None or name in CONTAINER_PARAM_NAMES:
                    errors._raise_err(errors.ERR_INVALID_CONNECT_DESCRIPTOR,
                                      data=self.data_as_str)
                start_pos = self.temp_pos
                is_simple_value = True
            self.temp_pos += 1
        if is_simple_value:
            value = self.data_as_str[start_pos:self.temp_pos].strip()
        self.skip_spaces()
        if self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if ch != ')':
                errors._raise_err(errors.ERR_INVALID_CONNECT_DESCRIPTOR,
                                  data=self.data_as_str)
            self.temp_pos += 1
        self.skip_spaces()
        self.pos = self.temp_pos

        # store value in dictionary
        if value is not None:
            self._set_descriptor_arg(args, name, value)

    cdef int _parse_easy_connect(self) except -1:
        """
        Parses an easy connect string.
        """
        cdef:
            object fn
            str protocol, arg
        protocol = self._parse_easy_connect_protocol()
        if protocol is not None:
            fn = REGISTERED_PROTOCOLS.get(protocol)
            if fn is not None:
                arg = self.data_as_str[self.temp_pos:]
                self._call_protocol_hook(protocol, arg, fn)
                self.description_list = self.params_impl.description_list
                self.pos = self.num_chars
                return 0
            elif protocol != self.template_address.protocol:
                self.template_address = self.template_address.copy()
                self.template_address.set_protocol(protocol)
        self._parse_easy_connect_hosts()
        self._parse_easy_connect_service_name()
        self._parse_easy_connect_instance_name()
        if self.description_list is not None:
            self._parse_easy_connect_parameters()

    cdef int _parse_easy_connect_host(self, Address address) except -1:
        """
        Parses a host name from the easy connect string.
        """
        cdef:
            bint found_bracket = False, found_host = False
            ssize_t start_pos = self.temp_pos
            Py_UCS4 ch
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if not found_bracket and not found_host and ch == '[':
                found_bracket = True
                start_pos = self.temp_pos + 1
            elif found_bracket and ch == ']':
                address.host = self.data_as_str[start_pos:self.temp_pos]
                self.temp_pos = self.temp_pos + 1
                self.pos = self.temp_pos
                break
            elif found_bracket or self._is_host_or_service_name_char(ch):
                self.temp_pos += 1
                found_host = True
            else:
                if found_host:
                    address.host = self.data_as_str[start_pos:self.temp_pos]
                    self.pos = self.temp_pos
                break

    cdef int _parse_easy_connect_hosts(self) except -1:
        """
        Parses the list of hosts from an easy connect string. This should be a
        series of host names separated by commas or semicolons.
        """
        cdef:
            Address temp_address, address = None
            ssize_t i, port_index = 0
            AddressList address_list
            Py_UCS4 ch
        self.description = self.template_description.copy()
        address_list = AddressList()
        self.description.children.append(address_list)
        self.temp_pos = self.pos
        while True:
            address = self.template_address.copy()
            self._parse_easy_connect_host(address)
            if self.temp_pos != self.pos or self.pos >= self.num_chars:
                break
            self.pos = self.temp_pos
            address_list.children.append(address)
            ch = self.get_current_char()
            if ch == ':':
                self.temp_pos += 1
                self._parse_easy_connect_port(address)
                self.pos = self.temp_pos
                if self.pos >= self.num_chars:
                    break
                for i in range(port_index, len(address_list.children) - 1):
                    temp_address = address_list.children[i]
                    temp_address.port = address.port
                port_index = len(address_list.children)
                ch = self.get_current_char()
            if ch == ';':
                address_list = AddressList()
                self.description.children.append(address_list)
                port_index = 0
            elif ch != ',':
                break
            self.temp_pos += 1

    cdef int _parse_easy_connect_parameter(self) except -1:
        """
        Parses a single parameter from the easy connect string. This is
        expected to be a keyword followed by a value seprated by an equals
        sign.
        """
        cdef:
            ssize_t start_pos, end_pos = 0
            str name, value
            Py_UCS4 ch = 0
            bint keep

        # get parameter name
        self.skip_spaces()
        start_pos = self.temp_pos
        self.parse_keyword()
        if self.temp_pos == start_pos or self.temp_pos >= self.num_chars:
            return 0
        name = self.data_as_str[start_pos:self.temp_pos].lower()
        if name.startswith(EXTENDED_PARAM_PREFIX):
            name = name[len(EXTENDED_PARAM_PREFIX):]
            keep = name in EXTENDED_PARAM_NAMES
        else:
            keep = name in COMMON_PARAM_NAMES \
                    or name in EXTRA_DESCRIPTION_PARAM_NAMES
            name = ALTERNATIVE_PARAM_NAMES.get(name, name)

        # look for the equals sign
        self.skip_spaces()
        if self.temp_pos >= self.num_chars:
            return 0
        ch = self.get_current_char()
        if ch != '=':
            return 0
        self.temp_pos += 1

        # get the parameter value
        found_value = False
        self.skip_spaces()
        start_pos = self.temp_pos
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if ch == '"':
                # if the quote is not the first character in the value, this is
                # not a valid easy connect parameter
                if self.temp_pos > start_pos:
                    return 0
                self.temp_pos += 1
                start_pos = self.temp_pos
                self.parse_quoted_string(ch)
                end_pos = self.temp_pos - 1
                break
            elif ch == '&':
                end_pos = self.temp_pos
                break
            self.temp_pos += 1
            end_pos = self.temp_pos
        if end_pos > start_pos and keep:
            if self.parameters is None:
                self.parameters = {}
            value = self.data_as_str[start_pos:end_pos]
            if name in EXTRA_DESCRIPTION_PARAM_NAMES:
                self.parameters.setdefault("extra_args", {})[name] = value
            else:
                self.parameters[name] = value
        self.skip_spaces()
        self.pos = self.temp_pos

    cdef int _parse_easy_connect_parameters(self) except -1:
        """
        Parses the parameters from the easy connect string. This is expected to
        be a question mark followed by a series of key-value pairs separated by
        ampersands.
        """
        cdef:
            Py_UCS4 ch, expected_sep
            Address address
        expected_sep = '?'
        self.temp_pos = self.pos
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if ch != expected_sep:
                break
            expected_sep = '&'
            self.temp_pos += 1
            self._parse_easy_connect_parameter()

    cdef int _parse_easy_connect_port(self, Address address) except -1:
        """
        Parses a port number from the easy connect string. This consists of one
        or more digits.
        """
        cdef:
            ssize_t pos = self.temp_pos
            bint found_port = False
            Py_UCS4 ch
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if not cpython.Py_UNICODE_ISDIGIT(ch):
                break
            found_port = True
            self.temp_pos += 1
        if found_port:
            address.port = int(self.data_as_str[pos:self.temp_pos])

    cdef str _parse_easy_connect_protocol(self):
        """
        Parses the protocol from an easy connect string. This should be a
        series of alphabetic characters or dashes, followed by a colon and two
        slashes. If such a string is found, it is saved on the template address
        associated with the parser; otherwise, the default protocol of "tcp" is
        saved on the template address associated with the parser. If no
        protocol is found, the separator (two slashes) may still be found and
        will be disarded.
        """
        cdef:
            ssize_t start_sep_pos = self.pos
            int num_sep_chars = 0
            str protocol = None
            Py_UCS4 ch
        self.temp_pos = self.pos
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if ch == ':':
                protocol = self.data_as_str[self.pos:self.temp_pos].lower()
                start_sep_pos = self.temp_pos + 1
            elif ch == '/' and self.temp_pos - start_sep_pos == num_sep_chars:
                num_sep_chars += 1
                if num_sep_chars == 2:
                    self.temp_pos += 1
                    self.pos = self.temp_pos
                    break
            elif not cpython.Py_UNICODE_ISALPHA(ch) and ch not in ('-', '_'):
                break
            self.temp_pos += 1
        if protocol is not None and num_sep_chars == 2:
            return protocol

    cdef str _parse_easy_connect_service_name(self):
        """
        Parses the service name from an easy connect string. This is expected
        to be a slash followed by a series of alphanumeric characters. If such
        a string is found, it is returned.
        """
        cdef:
            bint found_service_name = False, found_server_type = False
            bint found_slash = False, found_colon = False
            ssize_t service_name_end_pos = 0
            Py_UCS4 ch
            str value
        self.temp_pos = self.pos
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if not found_slash and ch == '/':
                found_slash = True
            elif found_service_name and not found_colon and ch == ':':
                found_colon = True
            elif found_slash and not found_colon \
                    and self._is_host_or_service_name_char(ch):
                found_service_name = True
                service_name_end_pos = self.temp_pos + 1
            elif found_colon and cpython.Py_UNICODE_ISALPHA(ch):
                found_server_type = True
            else:
                break
            self.temp_pos += 1
        if found_service_name:
            self.description.service_name = \
                    self.data_as_str[self.pos + 1:service_name_end_pos]
        if found_slash:
            self.pos = self.temp_pos
            self.description_list = DescriptionList()
            self.description_list.children.append(self.description)
        if found_server_type:
            value = self.data_as_str[service_name_end_pos + 1:self.temp_pos]
            self.description.set_server_type(value)

    cdef str _parse_easy_connect_instance_name(self):
        """
        Parses the instance name from an easy connect string. This is expected
        to be a slash followed by a series of alphanumeric characters. If such
        a string is found, it is returned.
        """
        cdef:
            ssize_t instance_name_end_pos = 0
            bint found_instance_name = False
            bint found_slash = False
            Py_UCS4 ch
            str value
        self.temp_pos = self.pos
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if not found_slash and ch == '/':
                found_slash = True
            elif found_slash and self._is_host_or_service_name_char(ch):
                found_instance_name = True
                instance_name_end_pos = self.temp_pos + 1
            else:
                break
            self.temp_pos += 1
        if found_instance_name:
            self.description.instance_name = \
                    self.data_as_str[self.pos + 1:instance_name_end_pos]
            self.pos = self.temp_pos

    cdef dict _process_args_with_extras(self, dict args, set allowed_names,
                                        str extras_name):
        """
        Processes arguments which contain a set of known attributes and any
        number of unknown attributes. The known attributes are left untouched
        whereas the unknown ones are put in a separate dictionary with the
        given name.
        """
        cdef:
            dict extras, result = {}
            object value
            str key
        for key, value in args.items():
            if key in allowed_names:
                result[key] = value
            else:
                extras = result.setdefault(extras_name, {})
                extras[key] = value
        return result

    cdef int _set_descriptor_arg(
        self, dict args, str name, object value
    ) except -1:
        """
        Sets the arg in the dictionary. If the value is already present,
        however, a list is created and both values stored. In addition, if an
        address is being added but an address list already exists, it is simply
        added to that address list instead. Similarly, if an address list is
        being added and addresses already exist, those addresses are first
        added to the address list before the new value is added.
        """
        # process unrecognized parameters, if applicable
        if name == "description":
            value = self._process_args_with_extras(
                value, DESCRIPTION_PARAM_NAMES, "extra_args"
            )
        elif name == "connect_data":
            value = self._process_args_with_extras(
                value, CONNECT_DATA_PARAM_NAMES, "extra_connect_data_args"
            )
        elif name == "security":
            value = self._process_args_with_extras(
                value, SECURITY_PARAM_NAMES, "extra_security_args"
            )

        # add value to arguments, creating a list if encountered multiple times
        orig_value = args.get(name)
        if orig_value is None:
            if name == "address" and "address_list" in args:
                return self._set_descriptor_arg(args, "address_list",
                                                dict(address=value))
            elif name == "address_list" and "address" in args:
                addresses = args.pop("address")
                if not isinstance(addresses, list):
                    addresses = [addresses]
                value = [dict(address=a) for a in addresses] + [value]
            args[name] = value
        elif isinstance(orig_value, list):
            args[name].append(value)
        else:
            args[name] = [orig_value, value]

    cdef int parse(self, str connect_string) except -1:
        """
        Parses a connect string. If the first character is an opening
        parenthesis, the connect string is assumed to be a connect descriptor
        and any failures to parse the string as a connect descriptor will
        result in an exception. If the connect string contains key elements
        identifying it as an easy connect string, any failures to parse the
        connect string as an easy connect string will result in an exception.
        If the connect string doesn't seem to be either option, the value None
        is returned.
        """
        cdef Py_UCS4 ch
        self.initialize(connect_string)
        ch = self.get_current_char()
        if ch == '(':
            self.temp_pos += 1
            self._parse_descriptor()
        else:
            self._parse_easy_connect()
        if self.description_list is not None and self.pos != self.num_chars:
            if self.pos > 0:
                errors._raise_err(errors.ERR_CANNOT_PARSE_CONNECT_STRING,
                                  data=connect_string)
            self.description_list = None


cdef class TnsnamesFileParser(BaseParser):

    cdef int _skip_to_end_of_line(self) except -1:
        """
        Skips all characters until the next line break is found and then
        discards all whitespace after that.
        """
        cdef Py_UCS4 ch
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            self.temp_pos += 1
            if cpython.Py_UNICODE_ISLINEBREAK(ch):
                break
        self.pos = self.temp_pos
        self.skip_spaces()

    cdef str _parse_key(self):
        """
        Parses a key from the file and returns it. This consists of any number
        of non-whitespace characters until an equals sign is found. Any
        comments are discarded. If no characters are found before the equals
        sign, the line is discarded. Similarly, if an opening or closing
        parenthesis is discovered, the line is discarded.
        """
        cdef:
            bint found_key = False
            ssize_t start_pos = 0
            Py_UCS4 ch
        self.skip_spaces()
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if ch in ('(', ')', '#'):
                self._skip_to_end_of_line()
                found_key = False
                continue
            elif ch == '=':
                if not found_key:
                    self._skip_to_end_of_line()
                    continue
                self.temp_pos += 1
                self.pos = self.temp_pos
                return self.data_as_str[start_pos:self.temp_pos - 1].strip()
            elif not found_key:
                found_key = True
                start_pos = self.temp_pos
            self.temp_pos += 1

    cdef str _parse_value_part(self, ssize_t* num_parens):
        """
        Parses part of a value. This consists of all characters from the first
        non-whitespace character to the end of the value or the first comment.
        The number of parentheses are updated.
        """
        cdef:
            ssize_t start_pos = 0, end_pos = 0
            bint found_part = False
            Py_UCS4 ch
        self.skip_spaces()
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if ch == '#':
                end_pos = self.temp_pos
                self._skip_to_end_of_line()
                if found_part:
                    break
                continue
            if found_part and num_parens[0] == 0:
                if cpython.Py_UNICODE_ISLINEBREAK(ch):
                    end_pos = self.temp_pos
                    break
            elif ch == '(':
                num_parens[0] += 1
            elif ch == ')' and num_parens[0] > 0:
                num_parens[0] -= 1
            if not found_part:
                found_part = True
                start_pos = self.temp_pos
            self.temp_pos += 1
            end_pos = self.temp_pos
        if found_part:
            return self.data_as_str[start_pos:end_pos].strip()

    cdef str _parse_value(self):
        """
        Parses a value from the file and returns it. This consists of all data
        after the first non-whitespace character until the end of the line on
        which it is found, or if the first non-whitespace character is an
        opening parenthesis, then all data until the number of opening and
        closing parentheses are equal.
        """
        cdef:
            ssize_t num_parens = 0
            list parts = []
            str part
        while self.temp_pos < self.num_chars:
            part = self._parse_value_part(&num_parens)
            if part is not None:
                parts.append(part)
            if num_parens == 0:
                break
        if parts:
            return "\n".join(parts)

    cdef int parse(self, str file_contents, object on_add_entry) except -1:
        """
        Parses the contents of a tnsnames.ora file. This consists of a series
        of key-value pairs where the keys can consist of comma-separated alias
        names and the values can be descriptors or easy connect strings. The
        method "on_add_entry" is called for each key-value pair that is
        discovered. No errors are thrown for improperly formatted files in
        order to be consistent with other drivers.
        """
        cdef str key, value
        self.initialize(file_contents)
        while self.temp_pos < self.num_chars:
            key = self._parse_key()
            value = self._parse_value()
            if key and value:
                on_add_entry(key.upper(), value.strip())


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\pipeline.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# pipeline.pyx
#
# Cython file defining the PipelineImpl, PipelineOpImpl and
# PipelineOpResultImpl classes (embedded in base_impl.pyx).
#------------------------------------------------------------------------------

cdef class PipelineImpl:

    def __init__(self):
        self.operations = []


cdef class PipelineOpImpl:

    def __init__(
        self,
        uint8_t op_type,
        str statement = None,
        str name = None,
        object parameters = None,
        object keyword_parameters = None,
        object return_type = None,
        object rowfactory = None,
        uint32_t arraysize = 0,
        uint32_t num_rows = 0,
    ):
        self.op_type = op_type
        self.statement = statement
        self.name = name
        self.parameters = parameters
        self.keyword_parameters = keyword_parameters
        self.return_type = return_type
        self.rowfactory = rowfactory
        self.arraysize = arraysize
        self.num_rows = num_rows


cdef class PipelineOpResultImpl:

    def __init__(self, PipelineOpImpl op):
        self.operation = op

    cdef int _capture_err(self, Exception exc) except -1:
        """
        Captures the error in the result. If the error is not an error
        generated by the driver itself, wrap it so that the value in the error
        attribute is always an instance of the _Error class.
        """
        if isinstance(exc, exceptions.Error):
            self.error = exc.args[0]
        else:
            self.error = errors._create_err(
                errors.ERR_UNEXPECTED_PIPELINE_FAILURE, cause=exc
            )


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\pool.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# pool.pyx
#
# Cython file defining the base Pool implementation class (embedded in
# base_impl.pyx).
#------------------------------------------------------------------------------

cdef class BasePoolImpl:

    def acquire(self, str user, str password, str cclass, uint32_t purity,
                str tag, bint matchanytag, list shardingkey,
                list supershardingkey):
        errors._raise_not_supported("acquiring a connection from a pool")

    def close(self, bint force):
        errors._raise_not_supported("closing a pool")

    def drop(self, conn_impl):
        errors._raise_not_supported("dropping a connection from a pool")

    def get_busy_count(self):
        errors._raise_not_supported(
            "getting the number of busy connections in a pool"
        )

    def get_getmode(self):
        errors._raise_not_supported("getting the 'get' mode of a pool")

    def get_max_lifetime_session(self):
        errors._raise_not_supported(
            "getting the maximum lifetime of a connection in a pool"
        )

    def get_max_sessions_per_shard(self):
        errors._raise_not_supported(
            "getting the maximum sessions per shard in a pool"
        )

    def get_open_count(self):
        errors._raise_not_supported(
            "getting the number of connections open in a pool"
        )

    def get_ping_interval(self):
        errors._raise_not_supported("getting the ping interval of a pool")

    def get_soda_metadata_cache(self):
        errors._raise_not_supported(
            "getting whether the SODA metadata cache is enabled"
        )

    def get_stmt_cache_size(self):
        errors._raise_not_supported(
            "getting the size of the statement cache in a pool"
        )

    def get_timeout(self):
        errors._raise_not_supported(
            "getting the timeout for idle connections in a pool"
        )

    def get_wait_timeout(self):
        errors._raise_not_supported("getting the wait timeout for a pool")

    def reconfigure(self, uint32_t min, uint32_t max, uint32_t increment):
        errors._raise_not_supported("reconfiguring a pool")

    def set_getmode(self, uint8_t value):
        errors._raise_not_supported("setting the 'get' mode of a pool")

    def set_max_lifetime_session(self, uint32_t value):
        errors._raise_not_supported(
            "setting the maximum lifetime of a connection a pool"
        )

    def set_max_sessions_per_shard(self, uint32_t value):
        errors._raise_not_supported("setting the maximum sessions per shard")

    def set_ping_interval(self, int value):
        errors._raise_not_supported("setting the ping interval")

    def set_soda_metadata_cache(self, bint value):
        errors._raise_not_supported(
            "setting whether the SODA metadata cache is enabled"
        )

    def set_stmt_cache_size(self, uint32_t value):
        errors._raise_not_supported(
            "setting the size of the statement cache in a pool"
        )

    def set_timeout(self, uint32_t value):
        errors._raise_not_supported(
            "setting the timeout for idle connections in a pool"
        )

    def set_wait_timeout(self, uint32_t value):
        errors._raise_not_supported("setting the wait timeout for a pool")


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\pool_params.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2022, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# pool_params.pyx
#
# Cython file defining the base PoolParams implementation class (embedded in
# base_impl.pyx).
#------------------------------------------------------------------------------

cdef class PoolParamsImpl(ConnectParamsImpl):

    def __init__(self):
        ConnectParamsImpl.__init__(self)
        self.min = 1
        self.max = 2
        self.increment = 1
        self.getmode = POOL_GETMODE_WAIT
        self.homogeneous = True
        self.ping_interval = 60
        self.ping_timeout = 5000

    cdef int _copy(self, ConnectParamsImpl other_params) except -1:
        """
        Internal method for copying attributes from another set of parameters.
        """
        cdef PoolParamsImpl pool_params = <PoolParamsImpl> other_params
        ConnectParamsImpl._copy(self, other_params)
        self.min = pool_params.min
        self.max = pool_params.max
        self.increment = pool_params.increment
        self.connectiontype = pool_params.connectiontype
        self.getmode = pool_params.getmode
        self.homogeneous = pool_params.homogeneous
        self.timeout = pool_params.timeout
        self.wait_timeout = pool_params.wait_timeout
        self.max_lifetime_session = pool_params.max_lifetime_session
        self.session_callback = pool_params.session_callback
        self.max_sessions_per_shard = pool_params.max_sessions_per_shard
        self.soda_metadata_cache = pool_params.soda_metadata_cache
        self.ping_interval = pool_params.ping_interval
        self.ping_timeout = pool_params.ping_timeout

    def copy(self):
        """
        Creates a copy of the connection parameters and returns it.
        """
        cdef PoolParamsImpl new_params
        new_params = PoolParamsImpl.__new__(PoolParamsImpl)
        new_params._copy(self)
        return new_params

    def set(self, dict args):
        """
        Sets the property values based on the supplied arguments. All values
        not supplied will be left unchanged.
        """
        ConnectParamsImpl.set(self, args)
        _set_uint_param(args, "min", &self.min)
        _set_uint_param(args, "max", &self.max)
        _set_uint_param(args, "increment", &self.increment)
        _set_obj_param(args, "connectiontype", self)
        _set_enum_param(args, "getmode", ENUM_POOL_GET_MODE, &self.getmode)
        _set_bool_param(args, "homogeneous", &self.homogeneous)
        _set_uint_param(args, "timeout", &self.timeout)
        _set_uint_param(args, "wait_timeout", &self.wait_timeout)
        _set_uint_param(args, "max_lifetime_session",
                        &self.max_lifetime_session)
        _set_obj_param(args, "session_callback", self)
        _set_uint_param(args, "max_sessions_per_shard",
                        &self.max_sessions_per_shard)
        _set_bool_param(args, "soda_metadata_cache", &self.soda_metadata_cache)
        _set_int_param(args, "ping_interval", &self.ping_interval)
        _set_uint_param(args, "ping_timeout", &self.ping_timeout)

        # if the pool is dynamically sized (min != max) then ensure that the
        # increment value is non-zero (as otherwise the pool would never grow!)
        if self.max != self.min and self.increment == 0:
            self.increment = 1


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\queue.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# queue.pyx
#
# Cython file defining the base Queue implementation class (embedded in
# base_impl.pyx).
#------------------------------------------------------------------------------

cdef class BaseQueueImpl:

    def deq_many(self, uint32_t max_num_messages):
        errors._raise_not_supported("dequeuing multiple messages")

    def deq_one(self):
        errors._raise_not_supported("dequeuing a single message")

    def enq_many(self, list props_impls):
        errors._raise_not_supported("enqueueing multiple messages")

    def enq_one(self, BaseMsgPropsImpl props_impl):
        errors._raise_not_supported("enqueuing a single message")

    def initialize(self, BaseConnImpl conn_impl, str name,
                   BaseDbObjectImpl payload_type, bint is_json):
        errors._raise_not_supported("initializing a queue")


cdef class BaseDeqOptionsImpl:

    def get_condition(self):
        errors._raise_not_supported("getting the condition")

    def get_consumer_name(self):
        errors._raise_not_supported("getting the consumer name")

    def get_correlation(self):
        errors._raise_not_supported("getting the correlation")

    def get_message_id(self):
        errors._raise_not_supported("getting the message id")

    def get_mode(self):
        errors._raise_not_supported("getting the mode")

    def get_navigation(self):
        errors._raise_not_supported("getting the navigation")

    def get_transformation(self):
        errors._raise_not_supported("getting the transformation")

    def get_visibility(self):
        errors._raise_not_supported("getting the visibility")

    def get_wait(self):
        errors._raise_not_supported("getting the wait time")

    def set_condition(self, str value):
        errors._raise_not_supported("setting the condition")

    def set_consumer_name(self, str value):
        errors._raise_not_supported("setting the consumer name")

    def set_correlation(self, str value):
        errors._raise_not_supported("setting the correlation")

    def set_delivery_mode(self, uint16_t value):
        errors._raise_not_supported("setting the delivery mode")

    def set_mode(self, uint32_t value):
        errors._raise_not_supported("setting the mode")

    def set_message_id(self, bytes value):
        errors._raise_not_supported("setting the message id")

    def set_navigation(self, uint32_t value):
        errors._raise_not_supported("setting the navigation")

    def set_transformation(self, str value):
        errors._raise_not_supported("setting the transformation")

    def set_visibility(self, uint32_t value):
        errors._raise_not_supported("setting the visibility")

    def set_wait(self, uint32_t value):
        errors._raise_not_supported("setting the wait time")


cdef class BaseEnqOptionsImpl:

    def get_transformation(self):
        errors._raise_not_supported("getting the transformation")

    def get_visibility(self):
        errors._raise_not_supported("getting the visibility")

    def set_delivery_mode(self, uint16_t value):
        errors._raise_not_supported("setting the delivery mode")

    def set_transformation(self, str value):
        errors._raise_not_supported("setting the transformation")

    def set_visibility(self, uint32_t value):
        errors._raise_not_supported("setting the visibility")


cdef class BaseMsgPropsImpl:

    def get_num_attempts(self):
        errors._raise_not_supported("getting the number of attempts")

    def get_correlation(self):
        errors._raise_not_supported("getting the correlation")

    def get_delay(self):
        errors._raise_not_supported("getting the delay")

    def get_delivery_mode(self):
        errors._raise_not_supported("getting the delivery mode")

    def get_enq_time(self):
        errors._raise_not_supported("getting the enqueue time")

    def get_exception_queue(self):
        errors._raise_not_supported("getting the name of the exception queue")

    def get_expiration(self):
        errors._raise_not_supported("getting the expiration")

    def get_message_id(self):
        errors._raise_not_supported("getting the message id")

    def get_priority(self):
        errors._raise_not_supported("getting the priority")

    def get_state(self):
        errors._raise_not_supported("getting the message state")

    def set_correlation(self, str value):
        errors._raise_not_supported("setting the correlation")

    def set_delay(self, int32_t value):
        errors._raise_not_supported("setting the delay")

    def set_exception_queue(self, str value):
        errors._raise_not_supported("setting the name of the exception queue")

    def set_expiration(self, int32_t value):
        errors._raise_not_supported("setting the expiration")

    def set_payload_bytes(self, bytes value):
        errors._raise_not_supported("setting the payload from bytes")

    def set_payload_object(self, BaseDbObjectImpl value):
        errors._raise_not_supported(
            "setting the payload from a database object"
        )

    def set_priority(self, int32_t value):
        errors._raise_not_supported("setting the priority")

    def set_recipients(self, list value):
        errors._raise_not_supported("setting recipients list")


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\soda.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# soda.pyx
#
# Cython file defining the base SODA implementation classes (embedded in
# base_impl.pyx).
#------------------------------------------------------------------------------

cdef class BaseSodaDbImpl:

    def create_collection(self, str name, str metadata, bint map_mode):
        errors._raise_not_supported("creating a SODA collection")

    def create_document(self, bytes content, str key, str media_type):
        errors._raise_not_supported("creating a SODA binary/text document")

    def create_json_document(self, object content, str key):
        errors._raise_not_supported("creating a SODA JSON document")

    def get_collection_names(self, str start_name, uint32_t limit):
        errors._raise_not_supported("getting a list of SODA collection names")

    def open_collection(self, str name):
        errors._raise_not_supported("opening a SODA collection")


cdef class BaseSodaCollImpl:

    def create_index(self, str spec):
        errors._raise_not_supported("creating an index on a SODA collection")

    def drop(self):
        errors._raise_not_supported("dropping a SODA collection")

    def drop_index(self, str name, bint force):
        errors._raise_not_supported("dropping an index on a SODA collection")

    def get_count(self, object op):
        errors._raise_not_supported(
            "getting the count of documents in a SODA collection"
        )

    def get_cursor(self, object op):
        errors._raise_not_supported(
            "getting a cursor for documents in a SODA collection"
        )

    def get_data_guide(self):
        errors._raise_not_supported(
            "getting the data guide for a SODA collection"
        )

    def get_metadata(self):
        errors._raise_not_supported(
            "getting the metadata of a SODA collection"
        )

    def get_one(self, object op):
        errors._raise_not_supported(
            "getting a document from a SODA collection"
        )

    def insert_many(self, list documents, str hint, bint return_docs):
        errors._raise_not_supported(
            "inserting multiple documents into a SODA collection"
        )

    def insert_one(self, BaseSodaDocImpl doc, str hint, bint return_doc):
        errors._raise_not_supported(
            "inserting a single document into a SODA collection"
        )

    def remove(self, object op):
        errors._raise_not_supported(
            "removing documents from a SODA collection"
        )

    def replace_one(self, BaseSodaDocImpl doc_impl, bint return_doc):
        errors._raise_not_supported(
            "replacing a document in a SODA collection"
        )

    def save(self, BaseSodaDocImpl doc, str hint, bint return_doc):
        errors._raise_not_supported("saving a document in a SODA collection")

    def truncate(self):
        errors._raise_not_supported("truncating a SODA collection")


cdef class BaseSodaDocImpl:

    def get_content(self):
        errors._raise_not_supported("getting the content of a SODA document")

    def get_created_on(self):
        errors._raise_not_supported(
            "getting the created on date of a SODA document"
        )

    def get_key(self):
        errors._raise_not_supported("getting the key of a SODA document")

    def get_last_modified(self):
        errors._raise_not_supported(
            "getting the last modified date of a SODA document"
        )

    def get_media_type(self):
        errors._raise_not_supported(
            "getting the media type of a SODA document"
        )

    def get_version(self):
        errors._raise_not_supported("getting the version of a SODA document")


cdef class BaseSodaDocCursorImpl:

    def close(self):
        errors._raise_not_supported("closing a SODA document cursor")

    def get_next_doc(self):
        errors._raise_not_supported(
            "getting the next document from a SODA document cursor"
        )


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\subscr.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# subscr.pyx
#
# Cython file defining the base Subscription implementation class (embedded in
# base_impl.pyx).
#------------------------------------------------------------------------------

cdef class BaseSubscrImpl:

    def register_query(self, str sql, object args):
        errors._raise_not_supported("registering a query on a subscription")

    def subscribe(self, object subscr, BaseConnImpl conn_impl):
        errors._raise_not_supported("creating a subscription")

    def unsubscribe(self, BaseConnImpl conn_impl):
        errors._raise_not_supported("destroying a subscription")


cdef class Message:
    pass


cdef class MessageQuery:
    pass


cdef class MessageRow:
    pass


cdef class MessageTable:
    pass


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\types.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# types.pyx
#
# Cython file defining the API types mandated by the Python Database API as
# well as the database types specific to Oracle (embedded in base_impl.pyx).
#------------------------------------------------------------------------------

cdef class ApiType:

    def __init__(self, name, *dbtypes):
        self.name = name
        self.dbtypes = dbtypes

    def __eq__(self, other):
        if isinstance(other, DbType):
            return other in self.dbtypes
        return NotImplemented

    def __hash__(self):
        return hash(self.name)

    def __reduce__(self):
        return self.name

    def __repr__(self):
        return f"<ApiType {self.name}>"


cdef list db_type_by_num = [None] * (DB_TYPE_NUM_MAX - DB_TYPE_NUM_MIN + 1)
cdef dict db_type_by_ora_name = {}
cdef dict db_type_by_ora_type_num = {}

cdef class DbType:

    def __init__(self, num, name, ora_name, native_num=0, ora_type_num=0,
                 default_py_type_num=0, default_size=0, csfrm=0,
                 buffer_size_factor=0):
        cdef uint16_t ora_type_key = csfrm * 256 + ora_type_num
        self.num = num
        self.name = name
        self.default_size = default_size
        self._native_num = native_num
        self._ora_name = ora_name
        self._ora_type_num = ora_type_num
        self._default_py_type_num = default_py_type_num
        self._csfrm = csfrm
        self._buffer_size_factor = buffer_size_factor
        if num != 0:
            num -= DB_TYPE_NUM_MIN
        db_type_by_num[num] = self
        db_type_by_ora_name[ora_name] = self
        db_type_by_ora_type_num[ora_type_key] = self

    def __reduce__(self):
        return self.name

    def __repr__(self):
        return f"<DbType {self.name}>"

    @staticmethod
    cdef DbType _from_num(uint32_t num):
        try:
            if num != 0:
                num -= DB_TYPE_NUM_MIN
            return db_type_by_num[num]
        except KeyError:
            pass
        errors._raise_err(errors.ERR_ORACLE_TYPE_NOT_SUPPORTED, num=num)

    @staticmethod
    cdef DbType _from_ora_name(str name):
        try:
            return db_type_by_ora_name[name]
        except KeyError:
            pass
        errors._raise_err(errors.ERR_ORACLE_TYPE_NAME_NOT_SUPPORTED, name=name)

    @staticmethod
    cdef DbType _from_ora_type_and_csfrm(uint8_t ora_type_num, uint8_t csfrm):
        cdef uint16_t ora_type_key = csfrm * 256 + ora_type_num
        try:
            return db_type_by_ora_type_num[ora_type_key]
        except KeyError:
            pass
        errors._raise_err(errors.ERR_ORACLE_TYPE_NOT_SUPPORTED,
                          num=ora_type_num)


# database types
DB_TYPE_BFILE = DbType(
    DB_TYPE_NUM_BFILE,
    "DB_TYPE_BFILE",
    "BFILE",
    NATIVE_TYPE_NUM_LOB,
    ORA_TYPE_NUM_BFILE,
    PY_TYPE_NUM_ORACLE_LOB,
    buffer_size_factor=4000
)

DB_TYPE_BINARY_DOUBLE = DbType(
    DB_TYPE_NUM_BINARY_DOUBLE,
    "DB_TYPE_BINARY_DOUBLE",
    "BINARY_DOUBLE",
    NATIVE_TYPE_NUM_DOUBLE,
    ORA_TYPE_NUM_BINARY_DOUBLE,
    PY_TYPE_NUM_FLOAT,
    buffer_size_factor=8
)

DB_TYPE_BINARY_FLOAT = DbType(
    DB_TYPE_NUM_BINARY_FLOAT,
    "DB_TYPE_BINARY_FLOAT",
    "BINARY_FLOAT",
    NATIVE_TYPE_NUM_FLOAT,
    ORA_TYPE_NUM_BINARY_FLOAT,
    PY_TYPE_NUM_FLOAT,
    buffer_size_factor=4
)

DB_TYPE_BINARY_INTEGER = DbType(
    DB_TYPE_NUM_BINARY_INTEGER,
    "DB_TYPE_BINARY_INTEGER",
    "BINARY_INTEGER",
    NATIVE_TYPE_NUM_INT64,
    ORA_TYPE_NUM_BINARY_INTEGER,
    PY_TYPE_NUM_INT,
    buffer_size_factor=22
)

DB_TYPE_BLOB = DbType(
    DB_TYPE_NUM_BLOB,
    "DB_TYPE_BLOB",
    "BLOB",
    NATIVE_TYPE_NUM_LOB,
    ORA_TYPE_NUM_BLOB,
    PY_TYPE_NUM_ORACLE_LOB,
    buffer_size_factor=112
)

DB_TYPE_BOOLEAN = DbType(
    DB_TYPE_NUM_BOOLEAN,
    "DB_TYPE_BOOLEAN",
    "BOOLEAN",
    NATIVE_TYPE_NUM_BOOLEAN,
    ORA_TYPE_NUM_BOOLEAN,
    PY_TYPE_NUM_BOOL,
    buffer_size_factor=4
)

DB_TYPE_CHAR = DbType(
    DB_TYPE_NUM_CHAR,
    "DB_TYPE_CHAR",
    "CHAR",
    NATIVE_TYPE_NUM_BYTES,
    ORA_TYPE_NUM_CHAR,
    PY_TYPE_NUM_STR,
    default_size=2000,
    csfrm=CS_FORM_IMPLICIT,
    buffer_size_factor=4
)

DB_TYPE_CLOB = DbType(
    DB_TYPE_NUM_CLOB,
    "DB_TYPE_CLOB",
    "CLOB",
    NATIVE_TYPE_NUM_LOB,
    ORA_TYPE_NUM_CLOB,
    PY_TYPE_NUM_ORACLE_LOB,
    csfrm=CS_FORM_IMPLICIT,
    buffer_size_factor=112
)

DB_TYPE_CURSOR = DbType(
    DB_TYPE_NUM_CURSOR,
    "DB_TYPE_CURSOR",
    "CURSOR",
    NATIVE_TYPE_NUM_STMT,
    ORA_TYPE_NUM_CURSOR,
    PY_TYPE_NUM_ORACLE_CURSOR,
    buffer_size_factor=4
)

DB_TYPE_DATE = DbType(
    DB_TYPE_NUM_DATE,
    "DB_TYPE_DATE",
    "DATE",
    NATIVE_TYPE_NUM_TIMESTAMP,
    ORA_TYPE_NUM_DATE,
    PY_TYPE_NUM_DATETIME,
    buffer_size_factor=7
)

DB_TYPE_INTERVAL_DS = DbType(
    DB_TYPE_NUM_INTERVAL_DS,
    "DB_TYPE_INTERVAL_DS",
    "INTERVAL DAY TO SECOND",
    NATIVE_TYPE_NUM_INTERVAL_DS,
    ORA_TYPE_NUM_INTERVAL_DS,
    PY_TYPE_NUM_TIMEDELTA,
    buffer_size_factor=11
)

DB_TYPE_INTERVAL_YM = DbType(
    DB_TYPE_NUM_INTERVAL_YM,
    "DB_TYPE_INTERVAL_YM",
    "INTERVAL YEAR TO MONTH",
    NATIVE_TYPE_NUM_INTERVAL_YM,
    ORA_TYPE_NUM_INTERVAL_YM,
    PY_TYPE_NUM_ORACLE_INTERVAL_YM,
    buffer_size_factor=5
)

DB_TYPE_JSON = DbType(
    DB_TYPE_NUM_JSON,
    "DB_TYPE_JSON",
    "JSON",
    NATIVE_TYPE_NUM_JSON,
    ORA_TYPE_NUM_JSON,
    PY_TYPE_NUM_OBJECT
)

DB_TYPE_LONG = DbType(
    DB_TYPE_NUM_LONG_VARCHAR,
    "DB_TYPE_LONG",
    "LONG",
    NATIVE_TYPE_NUM_BYTES,
    ORA_TYPE_NUM_LONG,
    PY_TYPE_NUM_STR,
    csfrm=CS_FORM_IMPLICIT,
    buffer_size_factor=2147483647
)

DB_TYPE_LONG_NVARCHAR = DbType(
    DB_TYPE_NUM_LONG_NVARCHAR,
    "DB_TYPE_LONG_NVARCHAR",
    "LONG NVARCHAR",
    NATIVE_TYPE_NUM_BYTES,
    ORA_TYPE_NUM_LONG,
    PY_TYPE_NUM_STR,
    csfrm=CS_FORM_NCHAR,
    buffer_size_factor=2147483647
)

DB_TYPE_LONG_RAW = DbType(
    DB_TYPE_NUM_LONG_RAW,
    "DB_TYPE_LONG_RAW",
    "LONG RAW",
    NATIVE_TYPE_NUM_BYTES,
    ORA_TYPE_NUM_LONG_RAW,
    PY_TYPE_NUM_BYTES,
    buffer_size_factor=2147483647
)

DB_TYPE_NCHAR = DbType(
    DB_TYPE_NUM_NCHAR,
    "DB_TYPE_NCHAR",
    "NCHAR",
    NATIVE_TYPE_NUM_BYTES,
    ORA_TYPE_NUM_CHAR,
    PY_TYPE_NUM_STR,
    default_size=2000,
    csfrm=CS_FORM_NCHAR,
    buffer_size_factor=4
)

DB_TYPE_NCLOB = DbType(
    DB_TYPE_NUM_NCLOB,
    "DB_TYPE_NCLOB",
    "NCLOB",
    NATIVE_TYPE_NUM_LOB,
    ORA_TYPE_NUM_CLOB,
    PY_TYPE_NUM_ORACLE_LOB,
    csfrm=CS_FORM_NCHAR,
    buffer_size_factor=112
)

DB_TYPE_NUMBER = DbType(
    DB_TYPE_NUM_NUMBER,
    "DB_TYPE_NUMBER",
    "NUMBER",
    NATIVE_TYPE_NUM_BYTES,
    ORA_TYPE_NUM_NUMBER,
    PY_TYPE_NUM_FLOAT,
    buffer_size_factor=22
)

DB_TYPE_NVARCHAR = DbType(
    DB_TYPE_NUM_NVARCHAR,
    "DB_TYPE_NVARCHAR",
    "NVARCHAR2",
    NATIVE_TYPE_NUM_BYTES,
    ORA_TYPE_NUM_VARCHAR,
    PY_TYPE_NUM_STR,
    default_size=4000,
    csfrm=CS_FORM_NCHAR,
    buffer_size_factor=4
)

DB_TYPE_OBJECT = DbType(
    DB_TYPE_NUM_OBJECT,
    "DB_TYPE_OBJECT",
    "OBJECT",
    NATIVE_TYPE_NUM_OBJECT,
    ORA_TYPE_NUM_OBJECT,
    PY_TYPE_NUM_ORACLE_OBJECT
)

DB_TYPE_RAW = DbType(
    DB_TYPE_NUM_RAW,
    "DB_TYPE_RAW",
    "RAW",
    NATIVE_TYPE_NUM_BYTES,
    ORA_TYPE_NUM_RAW,
    PY_TYPE_NUM_BYTES,
    default_size=4000,
    buffer_size_factor=1
)

DB_TYPE_ROWID = DbType(
    DB_TYPE_NUM_ROWID,
    "DB_TYPE_ROWID",
    "ROWID",
    NATIVE_TYPE_NUM_ROWID,
    ORA_TYPE_NUM_ROWID,
    PY_TYPE_NUM_STR,
    buffer_size_factor=18
)

DB_TYPE_TIMESTAMP = DbType(
    DB_TYPE_NUM_TIMESTAMP,
    "DB_TYPE_TIMESTAMP",
    "TIMESTAMP",
    NATIVE_TYPE_NUM_TIMESTAMP,
    ORA_TYPE_NUM_TIMESTAMP,
    PY_TYPE_NUM_DATETIME,
    buffer_size_factor=11
)

DB_TYPE_TIMESTAMP_LTZ = DbType(
    DB_TYPE_NUM_TIMESTAMP_LTZ,
    "DB_TYPE_TIMESTAMP_LTZ",
    "TIMESTAMP WITH LOCAL TIME ZONE",
    NATIVE_TYPE_NUM_TIMESTAMP,
    ORA_TYPE_NUM_TIMESTAMP_LTZ,
    PY_TYPE_NUM_DATETIME,
    buffer_size_factor=11
)

DB_TYPE_TIMESTAMP_TZ = DbType(
    DB_TYPE_NUM_TIMESTAMP_TZ,
    "DB_TYPE_TIMESTAMP_TZ",
    "TIMESTAMP WITH TIME ZONE",
    NATIVE_TYPE_NUM_TIMESTAMP,
    ORA_TYPE_NUM_TIMESTAMP_TZ,
    PY_TYPE_NUM_DATETIME,
    buffer_size_factor=13
)

DB_TYPE_UNKNOWN = DbType(
    DB_TYPE_NUM_UNKNOWN,
    "DB_TYPE_UNKNOWN",
    "UNKNOWN"
)

DB_TYPE_UROWID = DbType(
    DB_TYPE_NUM_UROWID,
    "DB_TYPE_UROWID",
    "UROWID",
    NATIVE_TYPE_NUM_BYTES,
    ORA_TYPE_NUM_UROWID,
    PY_TYPE_NUM_STR
)

DB_TYPE_VARCHAR = DbType(
    DB_TYPE_NUM_VARCHAR,
    "DB_TYPE_VARCHAR",
    "VARCHAR2",
    NATIVE_TYPE_NUM_BYTES,
    ORA_TYPE_NUM_VARCHAR,
    PY_TYPE_NUM_STR,
    default_size=4000,
    csfrm=CS_FORM_IMPLICIT,
    buffer_size_factor=4
)

DB_TYPE_VECTOR = DbType(
    DB_TYPE_NUM_VECTOR,
    "DB_TYPE_VECTOR",
    "VECTOR",
    NATIVE_TYPE_NUM_VECTOR,
    ORA_TYPE_NUM_VECTOR,
    PY_TYPE_NUM_ARRAY
)

DB_TYPE_XMLTYPE = DbType(
    DB_TYPE_NUM_XMLTYPE,
    "DB_TYPE_XMLTYPE",
    "XMLTYPE",
    NATIVE_TYPE_NUM_BYTES,
    ORA_TYPE_NUM_OBJECT,
    PY_TYPE_NUM_STR,
    csfrm=CS_FORM_IMPLICIT,
    buffer_size_factor=2147483647
)

# additional aliases
db_type_by_ora_name["PL/SQL BOOLEAN"] = DB_TYPE_BOOLEAN
db_type_by_ora_name["PL/SQL BINARY INTEGER"] = DB_TYPE_BINARY_INTEGER
db_type_by_ora_name["PL/SQL PLS INTEGER"] = DB_TYPE_BINARY_INTEGER
db_type_by_ora_name["TIMESTAMP WITH TZ"] = DB_TYPE_TIMESTAMP_TZ
db_type_by_ora_name["TIMESTAMP WITH LOCAL TZ"] = DB_TYPE_TIMESTAMP_LTZ

# DB API types
BINARY = ApiType("BINARY", DB_TYPE_RAW, DB_TYPE_LONG_RAW)
DATETIME = ApiType("DATETIME", DB_TYPE_DATE, DB_TYPE_TIMESTAMP,
                   DB_TYPE_TIMESTAMP_LTZ, DB_TYPE_TIMESTAMP_TZ)
NUMBER = ApiType("NUMBER", DB_TYPE_NUMBER, DB_TYPE_BINARY_DOUBLE,
                 DB_TYPE_BINARY_FLOAT, DB_TYPE_BINARY_INTEGER)
ROWID = ApiType("ROWID", DB_TYPE_ROWID, DB_TYPE_UROWID)
STRING = ApiType("STRING", DB_TYPE_VARCHAR, DB_TYPE_NVARCHAR, DB_TYPE_CHAR,
                 DB_TYPE_NCHAR, DB_TYPE_LONG)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\utils.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2022, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# utils.pyx
#
# Cython file defining utility methods (embedded in base_impl.pyx).
#------------------------------------------------------------------------------

cdef int _set_app_context_param(dict args, str name, object target) except -1:
    """
    Sets an application context parameter to the value provided in the
    dictionary, if a value is provided. This value is then set directly on the
    target.
    """
    in_val = args.get(name)
    if in_val is not None:
        message = (
            "appcontext should be a list of 3-tuples and each 3-tuple should "
            "contain three strings"
        )
        if not isinstance(in_val, list):
            raise TypeError(message)
        for entry in in_val:
            if not isinstance(entry, tuple) or len(entry) != 3:
                raise TypeError(message)
            for value in entry:
                if not isinstance(value, str):
                    raise TypeError(message)
        setattr(target, name, in_val)


cdef int _set_bool_param(dict args, str name, bint *out_val) except -1:
    """
    Sets a boolean parameter to the value provided in the dictionary. This can
    be a case-insenstive string matching on/off, yes/no or true/false (such as
    when parsed from a connect string). It can also be a directly passed
    argument which will be explicitly converted to a boolean value.
    """
    in_val = args.get(name)
    if in_val is not None:
        if isinstance(in_val, str):
            out_val[0] = (in_val.strip().lower() in ("on", "yes", "true"))
        else:
            out_val[0] = bool(in_val)


cdef int _set_duration_param(dict args, str name, double *out_val) except -1:
    """
    Sets a duration parameter to the value provided in the dictionary. This can
    be a string (such as when parsed from a connect string) containing a
    floating point value followed by an otional unit: ms (milliseconds), sec
    (seconds) or min (minutes). It can also be a directly passed argument which
    will be explicitly converted to a floating point value.
    """
    in_val = args.get(name)
    if in_val is not None:
        if isinstance(in_val, str):
            in_val = in_val.strip().lower()
            if in_val.endswith("sec"):
                out_val[0] = float(in_val[:-3].strip())
            elif in_val.endswith("ms"):
                out_val[0] = float(in_val[:-2].strip()) / 1000
            elif in_val.endswith("min"):
                out_val[0] = float(in_val[:-3].strip()) * 60
            else:
                out_val[0] = float(in_val.strip())
        else:
            out_val[0] = float(in_val)


cdef int _set_enum_param(dict args, str name, object enum_obj,
                         uint32_t* out_val) except -1:
    """
    Sets an unsigned integer parameter to the value provided in the dictionary.
    If digits are not provided, the value is looked up in the provided
    enumeration.
    """
    in_val = args.get(name)
    if in_val is not None:
        if not isinstance(in_val, str) or in_val.isdigit():
            out_val[0] = int(in_val)
            if isinstance(in_val, enum_obj):
                return 0
            try:
                enum_obj(out_val[0])
                return 0
            except ValueError:
                pass
        else:
            enum_val = getattr(enum_obj, in_val.upper(), None)
            if enum_val is not None:
                out_val[0] = enum_val.value
                return 0
        errors._raise_err(errors.ERR_INVALID_ENUM_VALUE,
                          name=enum_obj.__name__, value=in_val)


cdef int _set_int_param(dict args, str name, int* out_val) except -1:
    """
    Sets an integer parameter to the value provided in the dictionary. This
    can be a string (such as when parsed from a connect string). It can also be
    a directly passed argument which will be explicitly converted to an integer
    value.
    """
    in_val = args.get(name)
    if in_val is not None:
        out_val[0] = int(in_val)


cdef int _set_uint_param(dict args, str name, uint32_t* out_val) except -1:
    """
    Sets an unsigned integer parameter to the value provided in the dictionary.
    This can be a string (such as when parsed from a connect string). It can
    also be a directly passed argument which will be explicitly converted to an
    integer value.
    """
    in_val = args.get(name)
    if in_val is not None:
        out_val[0] = int(in_val)


cdef int _set_obj_param(dict args, str name, object target) except -1:
    """
    Sets an object parameter to the value provided in the dictionary, if a
    value is provided. This value is then set directly on the target.
    """
    in_val = args.get(name)
    if in_val is not None:
        setattr(target, name, in_val)


cdef int _set_ssl_version_param(dict args, str name, object target) except -1:
    """
    Sets a SSL version parameter to the value specified. This must be one of
    the values "tlsv1.2" or "tlsv1.3". If it is not one of these values
    an error is raised. If a value is specified and meets the criteria it is
    set directly on the target (since strings are treated as Python objects).
    """
    in_val = args.get(name)
    if in_val is not None:
        if isinstance(in_val, str):
            in_val = in_val.lower()
            if in_val == "tlsv1.2":
                in_val = ssl.TLSVersion.TLSv1_2
            elif in_val == "tlsv1.3":
                in_val = ssl.TLSVersion.TLSv1_3
        if in_val is not ssl.TLSVersion.TLSv1_2 \
                and in_val is not ssl.TLSVersion.TLSv1_3:
            errors._raise_err(errors.ERR_INVALID_SSL_VERSION,
                              ssl_version=in_val)
        setattr(target, name, in_val)


cdef int _set_str_param(dict args, str name, object target, bint check_network_character_set = False) except -1:
    """
    Sets a string parameter to the value provided in the dictionary. If a value
    is specified it is set directly on the target (since strings are treated as
    Python objects). Note that if check_network_character_set is True, an
    exception is thrown if the sanitized value does not match the input value.
    """
    in_val = args.get(name)
    if in_val:
        in_val = str(in_val)
        if check_network_character_set:
            if sanitize(in_val) != in_val:
                errors._raise_err(errors.ERR_INVALID_NETWORK_NAME, name=name)
        setattr(target, name, in_val)


def get_array_type_code_uint32():
    """
    Returns the type code to use for array.array that will store uint32_t.
    """
    cdef:
        array.array temp_array
        str type_code
    global ARRAY_TYPE_CODE_UINT32
    if ARRAY_TYPE_CODE_UINT32 is None:
        for type_code in ("I", "L"):
            temp_array = array.array(type_code)
            if temp_array.itemsize == 4:
                ARRAY_TYPE_CODE_UINT32 = type_code
                break
    return ARRAY_TYPE_CODE_UINT32


def init_base_impl(package):
    """
    Initializes globals after the package has been completely initialized. This
    is to avoid circular imports and eliminate the need for global lookups.
    """
    global \
        errors, \
        exceptions, \
        utils, \
        DRIVER_VERSION, \
        ENUM_AUTH_MODE, \
        ENUM_POOL_GET_MODE, \
        ENUM_PURITY, \
        PY_TYPE_ASYNC_CURSOR, \
        PY_TYPE_ASYNC_LOB, \
        PY_TYPE_CONNECT_PARAMS, \
        PY_TYPE_CURSOR, \
        PY_TYPE_DATAFRAME, \
        PY_TYPE_DB_OBJECT, \
        PY_TYPE_DB_OBJECT_TYPE, \
        PY_TYPE_FETCHINFO, \
        PY_TYPE_INTERVAL_YM, \
        PY_TYPE_JSON_ID, \
        PY_TYPE_LOB, \
        PY_TYPE_MESSAGE, \
        PY_TYPE_MESSAGE_QUERY, \
        PY_TYPE_MESSAGE_ROW, \
        PY_TYPE_MESSAGE_TABLE, \
        PY_TYPE_POOL_PARAMS, \
        PY_TYPE_SPARSE_VECTOR, \
        PY_TYPE_VAR

    errors = package.errors
    exceptions = package.exceptions
    utils = package.utils
    DRIVER_VERSION = package.__version__
    ENUM_AUTH_MODE = package.AuthMode
    ENUM_PURITY = package.Purity
    ENUM_POOL_GET_MODE = package.PoolGetMode
    PY_TYPE_ASYNC_CURSOR = package.AsyncCursor
    PY_TYPE_ASYNC_LOB = package.AsyncLOB
    PY_TYPE_CONNECT_PARAMS = package.ConnectParams
    PY_TYPE_CURSOR = package.Cursor
    PY_TYPE_DATAFRAME = package.OracleDataFrame
    PY_TYPE_DB_OBJECT = package.DbObject
    PY_TYPE_DB_OBJECT_TYPE = package.DbObjectType
    PY_TYPE_FETCHINFO = package.FetchInfo
    PY_TYPE_INTERVAL_YM = package.IntervalYM
    PY_TYPE_JSON_ID = package.JsonId
    PY_TYPE_LOB = package.LOB
    PY_TYPE_MESSAGE = package.Message
    PY_TYPE_MESSAGE_QUERY = package.MessageQuery
    PY_TYPE_MESSAGE_ROW = package.MessageRow
    PY_TYPE_MESSAGE_TABLE = package.MessageTable
    PY_TYPE_POOL_PARAMS = package.PoolParams
    PY_TYPE_SPARSE_VECTOR = package.SparseVector
    PY_TYPE_VAR = package.Var


def sanitize(str value):
    """
    Replaces invalid characters in a string with characters guaranteed to be in
    the network character set.
    """
    cdef str sanitized_value = value

    # strip single or double quotes from the start and end
    if sanitized_value.startswith(("'", '"')):
        sanitized_value = sanitized_value[1:]
    if sanitized_value.endswith(("'", '"')):
        sanitized_value = sanitized_value[:-1]

    # replace invalid characters with '?'
    sanitized_value = "".join(
        char if char in VALID_NETWORK_NAME_CHARS else "?"
        for char in sanitized_value
    )

    # if the last character is a backslash, replace it with '?'
    if sanitized_value.endswith("\\"):
        sanitized_value = sanitized_value[:-1] + "?"

    return sanitized_value


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\var.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# var.pyx
#
# Cython file defining the base Variable implementation class (embedded in
# base_impl.pyx).
#------------------------------------------------------------------------------

@cython.freelist(20)
cdef class BaseVarImpl:

    cdef int _bind(self, object conn, BaseCursorImpl cursor,
                   uint32_t num_execs, object name, uint32_t pos) except -1:
        """
        Binds a variable to the cursor.
        """
        raise NotImplementedError()


    cdef int _check_and_set_scalar_value(self, uint32_t pos, object value,
                                         bint* was_set) except -1:
        """
        Sets a scalar value in the variable at the given position, but first
        checks the type of Python value to see if it is acceptable. The value
        may be modified by the in converter (if one has been set) or adjusted
        to be acceptable (for some cases). If the was_set pointer is NULL, an
        exception is raised when the Python value is found to be unacceptable;
        otherwise, the flag is cleared if the Python value is unacceptable.
        """
        cdef uint32_t size

        # call in converter, if applicable
        if self.inconverter is not None:
            value = self.inconverter(value)

        # check the value and verify it is acceptable
        value = self._conn_impl._check_value(self.metadata, value, was_set)
        if was_set != NULL and not was_set[0]:
            return 0

        # resize variable, if applicable
        if value is not None and self.metadata.dbtype.default_size != 0:
            size = <uint32_t> len(value)
            if size > self.metadata.max_size:
                self._resize(size)

        # set value
        self._set_scalar_value(pos, value)
        self._is_value_set = True

    cdef int _check_and_set_value(self, uint32_t pos, object value,
                                  bint* was_set) except -1:
        """
        Sets the value in the variable at the given position, but first checks
        the type of Python value to see if it is acceptable.
        """
        cdef:
            uint32_t i, num_elements_in_array
            object element_value

        # scalar variables can be checked directly
        if not self.is_array:
            return self._check_and_set_scalar_value(pos, value, was_set)

        # array variables must have a list supplied to them
        if not isinstance(value, list):
            if was_set != NULL:
                was_set[0] = False
                return 0
            errors._raise_err(errors.ERR_EXPECTING_LIST_FOR_ARRAY_VAR)

        # the size of the array must be sufficient to hold all of the
        # elements
        num_elements_in_array = len(<list> value)
        if num_elements_in_array > self.num_elements:
            if was_set != NULL:
                was_set[0] = False
                return 0
            errors._raise_err(errors.ERR_INCORRECT_VAR_ARRAYSIZE,
                              var_arraysize=self.num_elements,
                              required_arraysize=num_elements_in_array)

        # check and set each of the element's values
        for i, element_value in enumerate(<list> value):
            self._check_and_set_scalar_value(i, element_value, was_set)
            if was_set != NULL and not was_set[0]:
                return 0
        self._set_num_elements_in_array(num_elements_in_array)

    cdef DbType _check_fetch_conversion(self):
        """
        Checks to see if the fetch type can be transformed into the requested
        type. This is only called during fetch when an output type handler is
        specified and the supplied variable has a type other than the fetch
        type. All matches are done using the underlying Oracle type and the
        character set form of the variable metadata is adjusted to
        use the character set form of the fetch metadata where applicable. The
        type to use for the metadata is returned.
        """
        cdef uint8_t from_ora_type_num, to_ora_type_num
        from_ora_type_num = self._fetch_metadata.dbtype._ora_type_num
        to_ora_type_num = self.metadata.dbtype._ora_type_num

        # Oracle BINARY_DOUBLE, BINARY_FLOAT
        if from_ora_type_num in (ORA_TYPE_NUM_BINARY_DOUBLE,
                                 ORA_TYPE_NUM_BINARY_FLOAT):
            if to_ora_type_num == ORA_TYPE_NUM_BINARY_INTEGER:
                self.metadata._py_type_num = PY_TYPE_NUM_INT
                return self._get_adjusted_type(to_ora_type_num)
            elif to_ora_type_num in (ORA_TYPE_NUM_BINARY_DOUBLE,
                                     ORA_TYPE_NUM_BINARY_FLOAT,
                                     ORA_TYPE_NUM_NUMBER):
                self.metadata._py_type_num = PY_TYPE_NUM_FLOAT
                return self._get_adjusted_type(to_ora_type_num)
            elif to_ora_type_num in (ORA_TYPE_NUM_CHAR,
                                     ORA_TYPE_NUM_LONG,
                                     ORA_TYPE_NUM_VARCHAR):
                return self._get_adjusted_type(to_ora_type_num)

        # Oracle BINARY_INTEGER
        elif from_ora_type_num == ORA_TYPE_NUM_BINARY_INTEGER:
            if to_ora_type_num == ORA_TYPE_NUM_NUMBER:
                self.metadata._py_type_num = PY_TYPE_NUM_FLOAT
                return self._get_adjusted_type(to_ora_type_num)
            elif to_ora_type_num in (ORA_TYPE_NUM_CHAR,
                                     ORA_TYPE_NUM_LONG,
                                     ORA_TYPE_NUM_VARCHAR):
                return self._get_adjusted_type(to_ora_type_num)

        # Oracle BLOB
        elif from_ora_type_num == ORA_TYPE_NUM_BLOB:
            if to_ora_type_num in (ORA_TYPE_NUM_RAW, ORA_TYPE_NUM_LONG_RAW):
                self._fetch_metadata.dbtype = DB_TYPE_LONG_RAW
                return self._fetch_metadata.dbtype

        # Oracle CHAR, LONG or VARCHAR
        elif from_ora_type_num in (ORA_TYPE_NUM_CHAR,
                                   ORA_TYPE_NUM_LONG,
                                   ORA_TYPE_NUM_VARCHAR):
            if to_ora_type_num in (ORA_TYPE_NUM_BINARY_DOUBLE,
                                   ORA_TYPE_NUM_BINARY_FLOAT,
                                   ORA_TYPE_NUM_NUMBER):
                self.metadata._py_type_num = PY_TYPE_NUM_FLOAT
                return self._get_adjusted_type(to_ora_type_num)
            elif to_ora_type_num == ORA_TYPE_NUM_BINARY_INTEGER:
                self.metadata._py_type_num = PY_TYPE_NUM_INT
                return self._get_adjusted_type(to_ora_type_num)
            elif to_ora_type_num in (ORA_TYPE_NUM_CHAR,
                                     ORA_TYPE_NUM_LONG,
                                     ORA_TYPE_NUM_VARCHAR):
                return self._get_adjusted_type(to_ora_type_num)

        # Oracle CLOB
        elif from_ora_type_num == ORA_TYPE_NUM_CLOB:
            if to_ora_type_num in (ORA_TYPE_NUM_CHAR,
                                   ORA_TYPE_NUM_LONG,
                                   ORA_TYPE_NUM_VARCHAR):
                self._fetch_metadata.dbtype = \
                        self._get_adjusted_type(ORA_TYPE_NUM_LONG)
                return self._fetch_metadata.dbtype

        # Oracle DATE, TIMESTAMP (WITH (LOCAL) TIME ZONE)
        elif from_ora_type_num in (ORA_TYPE_NUM_DATE,
                                   ORA_TYPE_NUM_TIMESTAMP,
                                   ORA_TYPE_NUM_TIMESTAMP_LTZ,
                                   ORA_TYPE_NUM_TIMESTAMP_TZ):
            if to_ora_type_num in (ORA_TYPE_NUM_DATE,
                                   ORA_TYPE_NUM_TIMESTAMP,
                                   ORA_TYPE_NUM_TIMESTAMP_LTZ,
                                   ORA_TYPE_NUM_TIMESTAMP_TZ,
                                   ORA_TYPE_NUM_CHAR,
                                   ORA_TYPE_NUM_LONG,
                                   ORA_TYPE_NUM_VARCHAR):
                return self._get_adjusted_type(to_ora_type_num)

        # Oracle INTERVAL DAY TO SECOND, INTERVAL YEAR TO MONTH, ROWID
        elif from_ora_type_num in (ORA_TYPE_NUM_INTERVAL_DS,
                                   ORA_TYPE_NUM_INTERVAL_YM,
                                   ORA_TYPE_NUM_ROWID):
            if to_ora_type_num in (ORA_TYPE_NUM_CHAR,
                                   ORA_TYPE_NUM_LONG,
                                   ORA_TYPE_NUM_VARCHAR):
                return self._get_adjusted_type(to_ora_type_num)

        # Oracle JSON
        elif from_ora_type_num == ORA_TYPE_NUM_JSON:
            if to_ora_type_num in (ORA_TYPE_NUM_CHAR,
                                   ORA_TYPE_NUM_VARCHAR):
                # the server won't accept LONG being defined but even so it
                # still sends back LONG data!
                self._fetch_metadata.dbtype = DB_TYPE_LONG
                return DB_TYPE_VARCHAR
            elif to_ora_type_num == ORA_TYPE_NUM_RAW:
                self._fetch_metadata.dbtype = DB_TYPE_RAW
                return self._fetch_metadata.dbtype

        # Oracle NUMBER
        elif from_ora_type_num == ORA_TYPE_NUM_NUMBER:
            if to_ora_type_num == ORA_TYPE_NUM_BINARY_INTEGER:
                self.metadata._py_type_num = PY_TYPE_NUM_INT
                return self._get_adjusted_type(to_ora_type_num)
            elif to_ora_type_num in (ORA_TYPE_NUM_BINARY_DOUBLE,
                                     ORA_TYPE_NUM_BINARY_FLOAT):
                self.metadata._py_type_num = PY_TYPE_NUM_FLOAT
                return self._get_adjusted_type(to_ora_type_num)
            elif to_ora_type_num in (ORA_TYPE_NUM_CHAR,
                                     ORA_TYPE_NUM_LONG,
                                     ORA_TYPE_NUM_VARCHAR):
                return self._get_adjusted_type(to_ora_type_num)

        # Oracle VECTOR
        elif from_ora_type_num == ORA_TYPE_NUM_VECTOR:
            if to_ora_type_num in (ORA_TYPE_NUM_CHAR,
                                   ORA_TYPE_NUM_LONG,
                                   ORA_TYPE_NUM_VARCHAR):
                self._fetch_metadata.dbtype = DB_TYPE_LONG
                return self._fetch_metadata.dbtype
            elif to_ora_type_num == ORA_TYPE_NUM_CLOB:
                self._fetch_metadata.dbtype = DB_TYPE_CLOB
                return self._fetch_metadata.dbtype

        # conversion not supported
        errors._raise_err(errors.ERR_INCONSISTENT_DATATYPES,
                          input_type=self._fetch_metadata.dbtype.name,
                          output_type=self.metadata.dbtype.name)

    cdef int _create_arrow_array(self) except -1:
        """
        Creates an Arrow array based on the type information selected by the
        user.
        """
        cdef ArrowTimeUnit time_unit = NANOARROW_TIME_UNIT_SECOND
        self.metadata._set_arrow_type()
        if self.metadata._arrow_type == NANOARROW_TYPE_TIMESTAMP:
            if self.metadata.scale > 0 and self.metadata.scale <= 3:
                time_unit = NANOARROW_TIME_UNIT_MILLI
            elif self.metadata.scale > 3 and self.metadata.scale <= 6:
                time_unit = NANOARROW_TIME_UNIT_MICRO
            elif self.metadata.scale > 6 and self.metadata.scale <= 9:
                time_unit = NANOARROW_TIME_UNIT_NANO
        self._arrow_array = OracleArrowArray(
            arrow_type=self.metadata._arrow_type,
            name=self.metadata.name,
            precision=self.metadata.precision,
            scale=self.metadata.scale,
            time_unit=time_unit,
        )

    cdef int _finalize_init(self) except -1:
        """
        Internal method that finalizes initialization of the variable.
        """
        self.metadata._finalize_init()
        if self.num_elements == 0:
            self.num_elements = 1
        self._has_returned_data = False

    cdef OracleArrowArray _finish_building_arrow_array(self):
        """
        Finish building the Arrow array associated with the variable and then
        return that array (after clearing it in the variable so that a new
        array will be built if more rows are fetched).
        """
        cdef OracleArrowArray array = self._arrow_array
        array.finish_building()
        self._arrow_array = None
        return array

    cdef DbType _get_adjusted_type(self, uint8_t ora_type_num):
        """
        Returns an adjusted type based on the desired Oracle type and the
        character set form from the fetch metadata. The intent of this function
        is to ensure that the character set form is not changed. For example,
        if the user requests the use of NVARCHAR but the data being fetched is
        of type CLOB, the type will be adjusted to VARCHAR. For those types
        which do not require a character set form, CS_FORM_IMPLICIT is always
        used.
        """
        cdef uint8_t csfrm
        if self.metadata.dbtype._csfrm == 0:
            csfrm = 0
        elif self._fetch_metadata.dbtype._csfrm == 0:
            csfrm = CS_FORM_IMPLICIT
        else:
            csfrm = self._fetch_metadata.dbtype._csfrm
        return DbType._from_ora_type_and_csfrm(ora_type_num, csfrm)

    cdef list _get_array_value(self):
        """
        Internal method to return the value of the array.
        """
        raise NotImplementedError()

    cdef object _get_scalar_value(self, uint32_t pos):
        """
        Internal method to return the value of the variable at the given
        position.
        """
        raise NotImplementedError()

    cdef int _on_reset_bind(self, uint32_t num_rows) except -1:
        """
        Called when the bind variable is being reset, just prior to performing
        a bind operation.
        """
        if self.num_elements < num_rows:
            self.num_elements = num_rows
            self._finalize_init()

    cdef int _resize(self, uint32_t new_size) except -1:
        """
        Resize the variable to the new size provided.
        """
        self.metadata.max_size = new_size
        self.metadata.buffer_size = 0
        self.metadata._finalize_init()

    cdef int _set_metadata_from_type(self, object typ) except -1:
        """
        Sets the type and size of the variable given a Python type.
        """
        self.metadata = OracleMetadata.from_type(typ)

    cdef int _set_metadata_from_value(self, object value,
                                      bint is_plsql) except -1:
        """
        Sets the type and size of the variable given a Python value. This
        method is called once for scalars and once per element in a list for
        array values. If a different type is detected an error is raised.
        """
        cdef OracleMetadata metadata
        metadata = OracleMetadata.from_value(value)
        if metadata.dbtype is DB_TYPE_BOOLEAN \
                and not self._conn_impl.supports_bool and not is_plsql:
            metadata.dbtype = DB_TYPE_BINARY_INTEGER
        if self.metadata is None:
            self.metadata = metadata
        elif metadata.dbtype is not self.metadata.dbtype \
                or metadata.objtype is not self.metadata.objtype:
            errors._raise_err(errors.ERR_MIXED_ELEMENT_TYPES, element=value)
        elif metadata.max_size > self.metadata.max_size:
            self.metadata.max_size = metadata.max_size

    cdef int _set_num_elements_in_array(self, uint32_t num_elements) except -1:
        """
        Sets the number of elements in the array.
        """
        self.num_elements_in_array = num_elements

    cdef int _set_scalar_value(self, uint32_t pos, object value) except -1:
        """
        Set the value of the variable at the given position. At this point it
        is assumed that all checks have been performed!
        """
        raise NotImplementedError()

    def get_all_values(self):
        """
        Internal method for returning an array of all of the values stored in
        the variable.
        """
        cdef uint32_t i
        if self.is_array:
            return self._get_array_value()
        return [self._get_scalar_value(i) for i in range(self.num_elements)]

    def get_value(self, uint32_t pos):
        """
        Internal method for getting the value of a variable.
        """
        if self.is_array:
            return self._get_array_value()
        if pos >= self.num_elements:
            raise IndexError("position out of range")
        return self._get_scalar_value(pos)

    def set_value(self, uint32_t pos, object value):
        """
        Internal method for setting a variable's value at the specified
        position.
        """
        if self.is_array:
            if pos > 0:
                errors._raise_err(errors.ERR_ARRAYS_OF_ARRAYS)
        elif pos >= self.num_elements:
            raise IndexError("position out of range")
        self._check_and_set_value(pos, value, NULL)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\base\vector.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2023, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# vector.pyx
#
# Cython file defining the classes and methods used for encoding and decoding
# VECTOR data (embedded in base_impl.pyx).
#------------------------------------------------------------------------------

cdef array.array float_template = array.array('f')
cdef array.array double_template = array.array('d')
cdef array.array int8_template = array.array('b')
cdef array.array uint8_template = array.array('B')

@cython.final
cdef class SparseVectorImpl:

    @classmethod
    def from_values(cls, num_dimensions, indices, values):
        """
        Creates an implementation from its component values.
        """
        cdef SparseVectorImpl impl = cls.__new__(cls)
        impl.num_dimensions = num_dimensions
        impl.indices = indices
        impl.values = values
        return impl


@cython.final
cdef class VectorDecoder(Buffer):

    cdef array.array _decode_values(self, uint32_t num_elements,
                                    uint8_t vector_format):
        """
        Returns an array containing the decoded values.
        """
        cdef:
            uint8_t *uint8_buf = NULL
            double *double_buf = NULL
            uint8_t element_size = 0
            int8_t *int8_buf = NULL
            float *float_buf = NULL
            OracleDataBuffer buffer
            array.array result
            uint32_t i

        # set up buffers based on vector storage format
        if vector_format == VECTOR_FORMAT_FLOAT32:
            result = array.clone(float_template, num_elements, False)
            float_buf = result.data.as_floats
        elif vector_format == VECTOR_FORMAT_FLOAT64:
            result = array.clone(double_template, num_elements, False)
            double_buf = result.data.as_doubles
        elif vector_format == VECTOR_FORMAT_INT8:
            result = array.clone(int8_template, num_elements, False)
            int8_buf = result.data.as_schars
        elif vector_format == VECTOR_FORMAT_BINARY:
            num_elements = num_elements // 8
            result = array.clone(uint8_template, num_elements, False)
            uint8_buf = result.data.as_uchars
        else:
            errors._raise_err(errors.ERR_VECTOR_FORMAT_NOT_SUPPORTED,
                              vector_format=vector_format)

        # parse data
        for i in range(num_elements):
            if vector_format == VECTOR_FORMAT_FLOAT32:
                decode_binary_float(self._get_raw(4), 4, &buffer)
                float_buf[i] = buffer.as_float
            elif vector_format == VECTOR_FORMAT_FLOAT64:
                decode_binary_double(self._get_raw(8), 8, &buffer)
                double_buf[i] = buffer.as_double
            elif vector_format == VECTOR_FORMAT_INT8:
                self.read_sb1(&int8_buf[i])
            else:
                self.read_ub1(&uint8_buf[i])

        return result

    cdef object decode(self, bytes data):
        """
        Returns a Python object corresponding to the encoded VECTOR bytes.
        """
        cdef:
            uint8_t magic_byte, version, vector_format
            uint16_t flags, num_sparse_elements
            SparseVectorImpl sparse_impl
            array.array uint32_template
            uint32_t* sparse_indices
            uint32_t num_elements, i

        # populate the buffer with the data
        self._populate_from_bytes(data)

        # parse header
        self.read_ub1(&magic_byte)
        if magic_byte != TNS_VECTOR_MAGIC_BYTE:
            errors._raise_err(errors.ERR_UNEXPECTED_DATA,
                              data=bytes([magic_byte]))
        self.read_ub1(&version)
        if version > TNS_VECTOR_VERSION_WITH_SPARSE:
            errors._raise_err(errors.ERR_VECTOR_VERSION_NOT_SUPPORTED,
                              version=version)
        self.read_uint16be(&flags)
        self.read_ub1(&vector_format)
        self.read_uint32be(&num_elements)
        if flags & TNS_VECTOR_FLAG_NORM_RESERVED \
                or flags & TNS_VECTOR_FLAG_NORM:
            self.skip_raw_bytes(8)

        # for sparse vectors, only non-zero elements are found in the image
        if flags & TNS_VECTOR_FLAG_SPARSE:
            sparse_impl = SparseVectorImpl.__new__(SparseVectorImpl)
            sparse_impl.num_dimensions = num_elements
            self.read_uint16be(&num_sparse_elements)
            num_elements = num_sparse_elements
            uint32_template = array.array(ARRAY_TYPE_CODE_UINT32)
            sparse_impl.indices = array.clone(uint32_template,
                                              num_sparse_elements, False)
            sparse_indices = <uint32_t*> sparse_impl.indices.data.as_voidptr
            for i in range(num_sparse_elements):
                self.read_uint32be(&sparse_indices[i])
            sparse_impl.values = self._decode_values(num_sparse_elements,
                                                     vector_format)
            return PY_TYPE_SPARSE_VECTOR._from_impl(sparse_impl)

        # all other vectors have just the values
        return self._decode_values(num_elements, vector_format)


@cython.final
cdef class VectorEncoder(GrowableBuffer):

    cdef int _encode_values(self, array.array value, uint32_t num_elements,
                            uint8_t vector_format) except -1:
        """
        Encode the values into the image using the given vector storage format.
        """
        cdef:
            double *double_ptr = value.data.as_doubles
            uint8_t *uint8_ptr = value.data.as_uchars
            float *float_ptr = value.data.as_floats
            int8_t *int8_ptr = value.data.as_schars
            uint32_t i
        if vector_format == VECTOR_FORMAT_INT8:
            self.write_raw(<char_type*> int8_ptr, num_elements)
        elif vector_format == VECTOR_FORMAT_BINARY:
            self.write_raw(<char_type*> uint8_ptr, num_elements // 8)
        else:
            for i in range(num_elements):
                if vector_format == VECTOR_FORMAT_FLOAT32:
                    self.write_binary_float(float_ptr[i], write_length=False)
                elif vector_format == VECTOR_FORMAT_FLOAT64:
                    self.write_binary_double(double_ptr[i], write_length=False)

    cdef uint8_t _get_vector_format(self, array.array value):
        """
        Returns the vector storage format used by the array.
        """
        if value.typecode == 'd':
            return VECTOR_FORMAT_FLOAT64
        elif value.typecode == 'f':
            return VECTOR_FORMAT_FLOAT32
        elif value.typecode == 'b':
            return VECTOR_FORMAT_INT8
        return VECTOR_FORMAT_BINARY

    cdef int encode(self, object value) except -1:
        """
        Encodes the given value to the internal VECTOR format.
        """
        cdef:
            uint16_t flags = TNS_VECTOR_FLAG_NORM_RESERVED
            uint8_t vector_format, vector_version
            SparseVectorImpl sparse_impl = None
            uint16_t num_sparse_elements, i
            uint32_t* sparse_indices
            uint32_t num_elements

        # determine metadatda about the vector to write
        if isinstance(value, PY_TYPE_SPARSE_VECTOR):
            sparse_impl = value._impl
            num_elements = sparse_impl.num_dimensions
            vector_format = self._get_vector_format(sparse_impl.values)
            vector_version = TNS_VECTOR_VERSION_WITH_SPARSE
            flags |= TNS_VECTOR_FLAG_SPARSE | TNS_VECTOR_FLAG_NORM
        else:
            vector_format = self._get_vector_format(value)
            if vector_format == VECTOR_FORMAT_BINARY:
                num_elements = (<uint32_t> len(value)) * 8
                vector_version = TNS_VECTOR_VERSION_WITH_BINARY
            else:
                num_elements = <uint32_t> len(value)
                vector_version = TNS_VECTOR_VERSION_BASE
                flags |= TNS_VECTOR_FLAG_NORM

        # write header
        self.write_uint8(TNS_VECTOR_MAGIC_BYTE)
        self.write_uint8(vector_version)
        self.write_uint16be(flags)
        self.write_uint8(vector_format)
        self.write_uint32be(num_elements)
        self._reserve_space(8)              # reserve space for norm

        # write data
        if sparse_impl is None:
            self._encode_values(value, num_elements, vector_format)
        else:
            sparse_indices = <uint32_t*> sparse_impl.indices.data.as_voidptr
            num_sparse_elements = len(sparse_impl.indices)
            self.write_uint16be(num_sparse_elements)
            for i in range(num_sparse_elements):
                self.write_uint32be(sparse_indices[i])
            self._encode_values(sparse_impl.values, num_sparse_elements,
                                vector_format)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thick\buffer.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# buffer.pyx
#
# Cython file defining the StringBuffer class, used for transforming Python
# "str" and "bytes" objects into the C buffer representation required by ODPI-C
# (embedded in thick_impl.pyx).
#------------------------------------------------------------------------------

@cython.freelist(20)
cdef class StringBuffer:
    cdef:
        bytes obj
        char *ptr
        uint32_t length
        uint32_t size_in_chars

    cdef int set_value(self, value) except -1:
        if value is None:
            self.obj = None
            self.ptr = NULL
            self.length = self.size_in_chars = 0
            return 0
        elif isinstance(value, str):
            self.obj = (<str> value).encode()
            self.size_in_chars = <uint32_t> len(<str> value)
        elif isinstance(value, bytes):
            self.obj = <bytes> value
            self.size_in_chars = <uint32_t> len(<bytes> value)
        else:
            raise TypeError("expecting string or bytes")
        self.ptr = self.obj
        self.length = <uint32_t> len(self.obj)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thick\connection.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# connection.pyx
#
# Cython file defining the thick Connection implementation class (embedded in
# thick_impl.pyx).
#------------------------------------------------------------------------------

ctypedef int (*dpiConnSetTextAttrFunc)(dpiConn*, const char*, uint32_t) nogil

cdef class ConnectionParams:
    cdef:
        bytes connect_string
        bytes username
        bytes password
        bytes cclass
        bytes new_password
        bytes edition
        bytes tag
        bytes token
        bytes private_key
        bytes driver_name

        const char *connect_string_ptr
        const char *username_ptr
        const char *password_ptr
        const char *cclass_ptr
        const char *new_password_ptr
        const char *edition_ptr
        const char *tag_ptr
        const char *token_ptr
        const char *private_key_ptr
        const char *driver_name_ptr

        uint32_t connect_string_len
        uint32_t username_len
        uint32_t password_len
        uint32_t cclass_len
        uint32_t new_password_len
        uint32_t edition_len
        uint32_t tag_len
        uint32_t token_len
        uint32_t private_key_len
        uint32_t driver_name_len

        uint32_t num_app_context
        list bytes_references
        dpiAppContext *app_context

        uint32_t num_sharding_key_columns
        dpiShardingKeyColumn *sharding_key_columns
        uint32_t num_super_sharding_key_columns
        dpiShardingKeyColumn *super_sharding_key_columns

    def __dealloc__(self):
        if self.app_context is not NULL:
            cpython.PyMem_Free(self.app_context)
        if self.sharding_key_columns is not NULL:
            cpython.PyMem_Free(self.sharding_key_columns)
        if self.super_sharding_key_columns is not NULL:
            cpython.PyMem_Free(self.super_sharding_key_columns)

    cdef int _process_context_str(self, str value, const char **ptr,
                                  uint32_t *length) except -1:
        cdef bytes temp
        temp = value.encode()
        self.bytes_references.append(temp)
        ptr[0] = temp
        length[0] = <uint32_t> len(temp)

    cdef int _process_sharding_value(self, object value,
                                     dpiShardingKeyColumn *column) except -1:
        """
        Process a sharding column value and place it in the format required by
        ODPI-C.
        """
        cdef:
            dpiTimestamp* timestamp
            bytes temp
        if isinstance(value, str):
            temp = value.encode()
            self.bytes_references.append(temp)
            column.oracleTypeNum = DPI_ORACLE_TYPE_VARCHAR
            column.nativeTypeNum = DPI_NATIVE_TYPE_BYTES
            column.value.asBytes.ptr = temp
            column.value.asBytes.length = <uint32_t> len(temp)
        elif isinstance(value, (int, float, PY_TYPE_DECIMAL)):
            temp = str(value).encode()
            self.bytes_references.append(temp)
            column.oracleTypeNum = DPI_ORACLE_TYPE_NUMBER
            column.nativeTypeNum = DPI_NATIVE_TYPE_BYTES
            column.value.asBytes.ptr = temp
            column.value.asBytes.length = <uint32_t> len(temp)
        elif isinstance(value, bytes):
            self.bytes_references.append(value)
            column.oracleTypeNum = DPI_ORACLE_TYPE_RAW
            column.nativeTypeNum = DPI_NATIVE_TYPE_BYTES
            column.value.asBytes.ptr = <bytes> value
            column.value.asBytes.length = <uint32_t> len(value)
        elif isinstance(value, PY_TYPE_DATETIME):
            column.oracleTypeNum = DPI_ORACLE_TYPE_DATE
            column.nativeTypeNum = DPI_NATIVE_TYPE_TIMESTAMP
            timestamp = &column.value.asTimestamp
            memset(timestamp, 0, sizeof(dpiTimestamp))
            timestamp.year = cydatetime.datetime_year(value)
            timestamp.month = cydatetime.datetime_month(value)
            timestamp.day = cydatetime.datetime_day(value)
            timestamp.hour = cydatetime.datetime_hour(value)
            timestamp.minute = cydatetime.datetime_minute(value)
            timestamp.second = cydatetime.datetime_second(value)
            timestamp.fsecond = cydatetime.datetime_microsecond(value) * 1000
        elif isinstance(value, PY_TYPE_DATE):
            column.oracleTypeNum = DPI_ORACLE_TYPE_DATE
            column.nativeTypeNum = DPI_NATIVE_TYPE_TIMESTAMP
            timestamp = &column.value.asTimestamp
            memset(timestamp, 0, sizeof(dpiTimestamp))
            timestamp.year = cydatetime.date_year(value)
            timestamp.month = cydatetime.date_month(value)
            timestamp.day = cydatetime.date_day(value)
        else:
            errors._raise_err(errors.ERR_PYTHON_VALUE_NOT_SUPPORTED,
                              type_name=type(value).__name__)

    cdef process_appcontext(self, list entries):
        cdef:
            object namespace, name, value
            dpiAppContext *entry
            ssize_t num_bytes
            bytes temp
            uint32_t i
        if self.bytes_references is None:
            self.bytes_references = []
        self.num_app_context = <uint32_t> len(entries)
        num_bytes = self.num_app_context * sizeof(dpiAppContext)
        self.app_context = <dpiAppContext*> cpython.PyMem_Malloc(num_bytes)
        for i in range(self.num_app_context):
            namespace, name, value = entries[i]
            entry = &self.app_context[i]
            self._process_context_str(namespace, &entry.namespaceName,
                                      &entry.namespaceNameLength)
            self._process_context_str(name, &entry.name, &entry.nameLength)
            self._process_context_str(value, &entry.value, &entry.valueLength)

    cdef int process_sharding_key(self, list entries, bint is_super) except -1:
        """
        Process the (super) sharding key and place it in the format required by
        ODPI-C.
        """
        cdef:
            dpiShardingKeyColumn *columns
            uint32_t num_columns
            ssize_t num_bytes, i
        if self.bytes_references is None:
            self.bytes_references = []
        num_columns = <uint32_t> len(entries)
        num_bytes = num_columns * sizeof(dpiShardingKeyColumn)
        columns = <dpiShardingKeyColumn*> cpython.PyMem_Malloc(num_bytes)
        if is_super:
            self.super_sharding_key_columns = columns
            self.num_super_sharding_key_columns = num_columns
        else:
            self.sharding_key_columns = columns
            self.num_sharding_key_columns = num_columns
        for i, entry in enumerate(entries):
            self._process_sharding_value(entry, &columns[i])


@cython.freelist(8)
cdef class ThickXid:
    cdef:
        StringBuffer global_transaction_id_buf
        StringBuffer branch_qualifier_buf
        dpiXid* xid_ptr
        dpiXid xid_buf

    def __init__(self, xid):
        if xid is not None:
            self.global_transaction_id_buf = StringBuffer()
            self.global_transaction_id_buf.set_value(xid.global_transaction_id)
            self.branch_qualifier_buf = StringBuffer()
            self.branch_qualifier_buf.set_value(xid.branch_qualifier)
            self.xid_buf.formatId = xid.format_id
            self.xid_buf.globalTransactionId = \
                    self.global_transaction_id_buf.ptr
            self.xid_buf.globalTransactionIdLength = \
                    self.global_transaction_id_buf.length
            self.xid_buf.branchQualifier = \
                    self.branch_qualifier_buf.ptr
            self.xid_buf.branchQualifierLength = \
                    self.branch_qualifier_buf.length
            self.xid_ptr = &self.xid_buf


cdef class ThickConnImpl(BaseConnImpl):
    cdef:
        dpiConn *_handle
        bint _is_external
        public str tag

    def __dealloc__(self):
        if self._handle != NULL:
            dpiConn_release(self._handle)

    cdef BaseCursorImpl _create_cursor_impl(self):
        """
        Internal method for creating an empty cursor implementation object.
        """
        return ThickCursorImpl.__new__(ThickCursorImpl, self)

    def _get_oci_attr(self, uint32_t handle_type, uint32_t attr_num,
                      uint32_t attr_type):
        """
        Internal method for getting the value of an OCI attribute on the
        connection.
        """
        cdef:
            dpiDataBuffer value
            uint32_t value_len
        if dpiConn_getOciAttr(self._handle, handle_type, attr_num, &value,
                              &value_len) < 0:
            _raise_from_odpi()
        return _convert_oci_attr_to_python(attr_type, &value, value_len)

    def _set_oci_attr(self, uint32_t handle_type, uint32_t attr_num,
                      uint32_t attr_type, object value):
        """
        Internal method for setting the value of an OCI attribute on the
        connection.
        """
        cdef:
            StringBuffer str_buf = StringBuffer()
            void *oci_value = NULL
            dpiDataBuffer oci_buf
            uint32_t oci_len = 0
        _convert_python_to_oci_attr(value, attr_type, str_buf, &oci_buf,
                                    &oci_value, &oci_len)
        if dpiConn_setOciAttr(self._handle, handle_type, attr_num, oci_value,
                              oci_len) < 0:
            _raise_from_odpi()

    cdef int _set_text_attr(self, dpiConnSetTextAttrFunc func,
                            str value) except -1:
        cdef:
            uint32_t value_length
            const char *value_ptr
            bytes value_bytes
        if value is not None:
            value_bytes = value.encode()
            value_ptr = value_bytes
            value_length = len(value_bytes)
        else:
            value_ptr = NULL
            value_length = 0
        if func(self._handle, value_ptr, value_length) < 0:
            _raise_from_odpi()

    def cancel(self):
        cdef int status
        with nogil:
            status = dpiConn_breakExecution(self._handle)
        if status < 0:
            _raise_from_odpi()

    def change_password(self, str old_password, str new_password):
        cdef:
            bytes username_bytes, old_password_bytes, new_password_bytes
            uint32_t username_len = 0, old_password_len = 0
            const char *old_password_ptr = NULL
            const char *new_password_ptr = NULL
            const char *username_ptr = NULL
            uint32_t new_password_len = 0
            int status
        if self.username is not None:
            username_bytes = self.username.encode()
            username_ptr = username_bytes
            username_len = <uint32_t> len(username_bytes)
        old_password_bytes = old_password.encode()
        old_password_ptr = old_password_bytes
        old_password_len = <uint32_t> len(old_password_bytes)
        new_password_bytes = new_password.encode()
        new_password_ptr = new_password_bytes
        new_password_len = <uint32_t> len(new_password_bytes)
        with nogil:
            status = dpiConn_changePassword(self._handle, username_ptr,
                                            username_len, old_password_ptr,
                                            old_password_len, new_password_ptr,
                                            new_password_len)
        if status < 0:
            _raise_from_odpi()

    def get_is_healthy(self):
        cdef bint is_healthy
        if dpiConn_getIsHealthy(self._handle, &is_healthy) < 0:
            _raise_from_odpi()
        return is_healthy

    def close(self, bint in_del=False):
        cdef:
            uint32_t mode = DPI_MODE_CONN_CLOSE_DEFAULT
            const char *tag_ptr = NULL
            uint32_t tag_length = 0
            bytes tag_bytes
            int status
        if in_del and self._is_external:
            return 0
        if self.tag is not None:
            mode = DPI_MODE_CONN_CLOSE_RETAG
            tag_bytes = self.tag.encode()
            tag_ptr = tag_bytes
            tag_length = <uint32_t> len(tag_bytes)
        with nogil:
            status = dpiConn_close(self._handle, mode, tag_ptr, tag_length)
            if status == DPI_SUCCESS:
                dpiConn_release(self._handle)
                self._handle = NULL
        if status < 0 and not in_del:
            _raise_from_odpi()

    def commit(self):
        cdef int status
        with nogil:
            status = dpiConn_commit(self._handle)
        if status < 0:
            _raise_from_odpi()

    def connect(self, ConnectParamsImpl user_params, ThickPoolImpl pool_impl):
        cdef:
            str full_user, cclass, token, private_key, connect_string
            bytes password_bytes, new_password_bytes
            dpiCommonCreateParams common_params
            dpiConnCreateParams conn_params
            ConnectParamsImpl pool_params
            dpiAccessToken access_token
            dpiVersionInfo version_info
            dpiErrorInfo error_info
            ConnectionParams params
            int status

        # specify that binding a string to a LOB value is possible in thick
        # mode (will be removed in a future release)
        self._allow_bind_str_to_lob = True

        # if the connection is part of the pool, get the pool creation params
        if pool_impl is not None:
            pool_params = pool_impl.connect_params
            self.username = pool_impl.username
            self.dsn = pool_impl.dsn

        # set up connection parameters
        params = ConnectionParams()
        password_bytes = user_params._get_password()
        new_password_bytes = user_params._get_new_password()
        full_user = user_params.get_full_user()
        if full_user is not None:
            params.username = full_user.encode()
            params.username_ptr = params.username
            params.username_len = <uint32_t> len(params.username)
        if password_bytes is not None:
            params.password = password_bytes
            params.password_ptr = params.password
            params.password_len = <uint32_t> len(params.password)
        if pool_impl is None:
            if user_params.thick_mode_dsn_passthrough:
                connect_string = self.dsn
            else:
                connect_string = user_params._get_connect_string()
            if connect_string is not None:
                params.connect_string = connect_string.encode()
                params.connect_string_ptr = params.connect_string
                params.connect_string_len = \
                        <uint32_t> len(params.connect_string)
        if pool_impl is None \
                or user_params._default_description.cclass is not None:
            cclass = user_params._default_description.cclass
        else:
            cclass = pool_params._default_description.cclass
        if cclass is not None:
            params.cclass = cclass.encode()
            params.cclass_ptr = params.cclass
            params.cclass_len = <uint32_t> len(params.cclass)
        if new_password_bytes is not None:
            params.new_password = new_password_bytes
            params.new_password_ptr = params.new_password
            params.new_password_len = <uint32_t> len(params.new_password)
        if user_params.edition is not None:
            params.edition = user_params.edition.encode()
            params.edition_ptr = params.edition
            params.edition_len = <uint32_t> len(params.edition)
        if user_params.tag is not None:
            params.tag = user_params.tag.encode()
            params.tag_ptr = params.tag
            params.tag_len = <uint32_t> len(params.tag)
        if user_params.appcontext:
            params.process_appcontext(user_params.appcontext)
        if user_params.shardingkey:
            params.process_sharding_key(user_params.shardingkey, False)
        if user_params.supershardingkey:
            params.process_sharding_key(user_params.supershardingkey, True)
        if user_params._token is not None \
                or user_params.access_token_callback is not None:
            token = user_params._get_token()
            private_key = user_params._get_private_key()
            params.token = token.encode()
            params.token_ptr = params.token
            params.token_len = <uint32_t> len(params.token)
            if private_key is not None:
                params.private_key = private_key.encode()
                params.private_key_ptr = params.private_key
                params.private_key_len = <uint32_t> len(params.private_key)
        if user_params.driver_name is not None:
            params.driver_name = user_params.driver_name.encode()[:30]
            params.driver_name_ptr = params.driver_name
            params.driver_name_len = <uint32_t> len(params.driver_name)

        # set up common creation parameters
        if dpiContext_initCommonCreateParams(driver_info.context,
                                             &common_params) < 0:
            _raise_from_odpi()
        common_params.createMode |= DPI_MODE_CREATE_THREADED
        if user_params.events:
            common_params.createMode |= DPI_MODE_CREATE_EVENTS
        if user_params.edition is not None:
            common_params.edition = params.edition_ptr
            common_params.editionLength = params.edition_len
        if params.token is not None:
            access_token.token = params.token_ptr
            access_token.tokenLength = params.token_len
            access_token.privateKey = params.private_key_ptr
            access_token.privateKeyLength = params.private_key_len
            common_params.accessToken = &access_token
        if user_params.driver_name is not None:
            common_params.driverName = params.driver_name_ptr
            common_params.driverNameLength = params.driver_name_len

        # set up connection specific creation parameters
        if dpiContext_initConnCreateParams(driver_info.context,
                                           &conn_params) < 0:
            _raise_from_odpi()
        if params.username_len == 0 and params.password_len == 0:
            conn_params.externalAuth = 1
        else:
            conn_params.externalAuth = user_params.externalauth
        if params.cclass is not None:
            conn_params.connectionClass = params.cclass_ptr
            conn_params.connectionClassLength = params.cclass_len
        if new_password_bytes is not None:
            conn_params.newPassword = params.new_password_ptr
            conn_params.newPasswordLength = params.new_password_len
        if user_params.appcontext:
            conn_params.appContext = params.app_context
            conn_params.numAppContext = params.num_app_context
        if user_params.shardingkey:
            conn_params.shardingKeyColumns = params.sharding_key_columns
            conn_params.numShardingKeyColumns = params.num_sharding_key_columns
        if user_params.supershardingkey:
            conn_params.superShardingKeyColumns = \
                    params.super_sharding_key_columns
            conn_params.numSuperShardingKeyColumns = \
                    params.num_super_sharding_key_columns
        if user_params.tag is not None:
            conn_params.tag = params.tag_ptr
            conn_params.tagLength = params.tag_len
        if user_params._external_handle != 0:
            conn_params.externalHandle = <void*> user_params._external_handle
            self._is_external = True
        if pool_impl is not None:
            conn_params.pool = pool_impl._handle
        common_params.stmtCacheSize = user_params.stmtcachesize
        conn_params.authMode = user_params.mode
        conn_params.matchAnyTag = user_params.matchanytag
        if user_params._default_description.purity != PURITY_DEFAULT:
            conn_params.purity = user_params._default_description.purity
        elif pool_impl is not None:
            conn_params.purity = pool_params._default_description.purity

        # perform connection
        with nogil:
            status = dpiConn_create(driver_info.context, params.username_ptr,
                                    params.username_len, params.password_ptr,
                                    params.password_len,
                                    params.connect_string_ptr,
                                    params.connect_string_len,
                                    &common_params, &conn_params,
                                    &self._handle)
            dpiContext_getError(driver_info.context, &error_info)
        if status < 0:
            _raise_from_info(&error_info)
        elif error_info.isWarning:
            self.warning = _create_new_from_info(&error_info)
        if conn_params.outNewSession and pool_impl is not None \
                and self.warning is None:
            self.warning = pool_impl.warning
        if dpiConn_getServerVersion(self._handle, NULL, NULL,
                                    &version_info) < 0:
            _raise_from_odpi()
        self.server_version = (
            version_info.versionNum,
            version_info.releaseNum,
            version_info.updateNum,
            version_info.portReleaseNum,
            version_info.portUpdateNum
        )
        if driver_info.client_version_info.versionNum >= 23 \
                and version_info.versionNum >= 23:
            self.supports_bool = True
            self._oson_max_fname_size = 65535

        # determine if session callback should be invoked; this takes place if
        # the connection is newly created by the pool or if the requested tag
        # does not match the actual tag
        if (conn_params.outNewSession \
                or conn_params.outTagLength != params.tag_len \
                or (params.tag_len > 0 \
                and conn_params.outTag[:conn_params.outTagLength] !=  \
                params.tag_ptr[:conn_params.outTagLength])):
            self.invoke_session_callback = True

        # set tag property, if applicable
        if conn_params.outTagLength > 0:
            self.tag = conn_params.outTag[:conn_params.outTagLength].decode()

    def create_msg_props_impl(self):
        cdef ThickMsgPropsImpl impl
        impl = ThickMsgPropsImpl.__new__(ThickMsgPropsImpl)
        impl._conn_impl = self
        if dpiConn_newMsgProps(self._handle, &impl._handle) < 0:
            _raise_from_odpi()
        return impl

    def create_queue_impl(self):
        return ThickQueueImpl.__new__(ThickQueueImpl)

    def create_soda_database_impl(self, conn):
        cdef ThickSodaDbImpl impl = ThickSodaDbImpl.__new__(ThickSodaDbImpl)
        impl.supports_json = driver_info.soda_use_json_desc
        impl._conn = conn
        if dpiConn_getSodaDb(self._handle, &impl._handle) < 0:
            _raise_from_odpi()
        return impl

    def create_subscr_impl(self, object conn, object callback,
                           uint32_t namespace, str name, uint32_t protocol,
                           str ip_address, uint32_t port, uint32_t timeout,
                           uint32_t operations, uint32_t qos,
                           uint8_t grouping_class, uint32_t grouping_value,
                           uint8_t grouping_type, bint client_initiated):
        cdef ThickSubscrImpl impl = ThickSubscrImpl.__new__(ThickSubscrImpl)
        impl.connection = conn
        impl.callback = callback
        impl.namespace = namespace
        impl.name = name
        impl.protocol = protocol
        impl.ip_address = ip_address
        impl.port = port
        impl.timeout = timeout
        impl.operations = operations
        impl.qos = qos
        impl.grouping_class = grouping_class
        impl.grouping_value = grouping_value
        impl.grouping_type = grouping_type
        impl.client_initiated = client_initiated
        return impl

    def create_temp_lob_impl(self, DbType dbtype):
        return ThickLobImpl._create(self, dbtype, NULL)

    def get_call_timeout(self):
        cdef uint32_t value
        if dpiConn_getCallTimeout(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_current_schema(self):
        cdef:
            uint32_t value_length
            const char *value
        if dpiConn_getCurrentSchema(self._handle, &value, &value_length) < 0:
            _raise_from_odpi()
        if value is not NULL:
            return value[:value_length].decode()

    def get_db_domain(self):
        cdef:
            uint32_t value_length
            const char *value
        if dpiConn_getDbDomain(self._handle, &value, &value_length) < 0:
            _raise_from_odpi()
        if value is not NULL:
            return value[:value_length].decode()

    def get_db_name(self):
        cdef:
            uint32_t value_length
            const char *value
        if dpiConn_getDbName(self._handle, &value, &value_length) < 0:
            _raise_from_odpi()
        if value is not NULL:
            return value[:value_length].decode()

    def get_edition(self):
        cdef:
            uint32_t value_length
            const char *value
        if dpiConn_getEdition(self._handle, &value, &value_length) < 0:
            _raise_from_odpi()
        if value is not NULL:
            return value[:value_length].decode()

    def get_external_name(self):
        cdef:
            uint32_t value_length
            const char *value
        if dpiConn_getExternalName(self._handle, &value, &value_length) < 0:
            _raise_from_odpi()
        if value is not NULL:
            return value[:value_length].decode()

    def get_handle(self):
        cdef void* handle
        if dpiConn_getHandle(self._handle, &handle) < 0:
            _raise_from_odpi()
        return <uint64_t> handle

    def get_instance_name(self):
        cdef:
            uint32_t value_length
            const char *value
        if dpiConn_getInstanceName(self._handle, &value, &value_length) < 0:
            _raise_from_odpi()
        if value is not NULL:
            return value[:value_length].decode()

    def get_internal_name(self):
        cdef:
            uint32_t value_length
            const char *value
        if dpiConn_getInternalName(self._handle, &value, &value_length) < 0:
            _raise_from_odpi()
        if value is not NULL:
            return value[:value_length].decode()

    def get_ltxid(self):
        cdef:
            uint32_t value_length
            const char *value
        if dpiConn_getLTXID(self._handle, &value, &value_length) < 0:
            _raise_from_odpi()
        return value[:value_length]

    def get_max_identifier_length(self):
        cdef dpiConnInfo info
        if dpiConn_getInfo(self._handle, &info) < 0:
            _raise_from_odpi()
        if info.maxIdentifierLength != 0:
            return info.maxIdentifierLength

    def get_max_open_cursors(self):
        cdef uint32_t value
        if dpiConn_getMaxOpenCursors(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_service_name(self):
        cdef:
            uint32_t value_length
            const char *value
        if dpiConn_getServiceName(self._handle, &value, &value_length) < 0:
            _raise_from_odpi()
        if value is not NULL:
            return value[:value_length].decode()

    def get_stmt_cache_size(self):
        cdef uint32_t value
        if dpiConn_getStmtCacheSize(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_transaction_in_progress(self):
        cdef bint value
        if dpiConn_getTransactionInProgress(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_type(self, object conn, str name):
        cdef:
            dpiObjectType *handle
            const char *name_ptr
            uint32_t name_len
            bytes name_bytes
            int status
        name_bytes = name.encode()
        name_ptr = name_bytes
        name_len = <uint32_t> len(name_bytes)
        with nogil:
            status = dpiConn_getObjectType(self._handle, name_ptr, name_len,
                                           &handle)
        if status < 0:
            _raise_from_odpi()
        try:
            return ThickDbObjectTypeImpl._from_handle(self, handle)
        finally:
            dpiObjectType_release(handle)

    def set_action(self, str value):
        self._set_text_attr(dpiConn_setAction, value)

    def set_call_timeout(self, uint32_t value):
        if dpiConn_setCallTimeout(self._handle, value) < 0:
            _raise_from_odpi()

    def set_client_identifier(self, str value):
        self._set_text_attr(dpiConn_setClientIdentifier, value)

    def set_client_info(self, str value):
        self._set_text_attr(dpiConn_setClientInfo, value)

    def set_current_schema(self, str value):
        self._set_text_attr(dpiConn_setCurrentSchema, value)

    def set_dbop(self, str value):
        self._set_text_attr(dpiConn_setDbOp, value)

    def ping(self):
        cdef int status
        with nogil:
            status = dpiConn_ping(self._handle)
        if status < 0:
            _raise_from_odpi()

    def rollback(self):
        cdef int status
        with nogil:
            status = dpiConn_rollback(self._handle)
        if status < 0:
            _raise_from_odpi()

    def set_econtext_id(self, value):
        self._set_text_attr(dpiConn_setEcontextId, value)

    def set_external_name(self, str value):
        self._set_text_attr(dpiConn_setExternalName, value)

    def set_internal_name(self, str value):
        self._set_text_attr(dpiConn_setInternalName, value)

    def set_module(self, str value):
        self._set_text_attr(dpiConn_setModule, value)

    def set_stmt_cache_size(self, uint32_t value):
        if dpiConn_setStmtCacheSize(self._handle, value) < 0:
            _raise_from_odpi()

    def shutdown(self, uint32_t mode):
        cdef int status
        with nogil:
            status = dpiConn_shutdownDatabase(self._handle, mode)
        if status < 0:
            _raise_from_odpi()

    def startup(self, bint force, bint restrict, str pfile):
        cdef:
            uint32_t mode, pfile_length = 0
            const char *pfile_ptr = NULL
            bytes temp
            int status

        mode = DPI_MODE_STARTUP_DEFAULT
        if force:
            mode |= DPI_MODE_STARTUP_FORCE
        if restrict:
            mode |= DPI_MODE_STARTUP_RESTRICT
        if pfile is not None:
            temp = pfile.encode()
            pfile_ptr = temp
            pfile_length = len(pfile_ptr)
        with nogil:
            status = dpiConn_startupDatabaseWithPfile(self._handle, pfile_ptr,
                                                      pfile_length, mode)
        if status < 0:
            _raise_from_odpi()

    def tpc_begin(self, xid, uint32_t flags, uint32_t timeout):
        cdef:
            ThickXid thick_xid = ThickXid(xid)
            int status
        with nogil:
            status = dpiConn_tpcBegin(self._handle, thick_xid.xid_ptr,
                                      timeout, flags)
        if status < 0:
            _raise_from_odpi()

    def tpc_commit(self, xid, bint one_phase):
        cdef:
            ThickXid thick_xid = ThickXid(xid)
            int status
        with nogil:
            status = dpiConn_tpcCommit(self._handle, thick_xid.xid_ptr,
                                       one_phase)
        if status < 0:
            _raise_from_odpi()

    def tpc_end(self, xid, uint32_t flags):
        cdef:
            ThickXid thick_xid = ThickXid(xid)
            int status
        with nogil:
            status = dpiConn_tpcEnd(self._handle, thick_xid.xid_ptr, flags)
        if status < 0:
            _raise_from_odpi()

    def tpc_forget(self, xid):
        cdef:
            ThickXid thick_xid = ThickXid(xid)
            int status
        with nogil:
            status = dpiConn_tpcForget(self._handle, thick_xid.xid_ptr)
        if status < 0:
            _raise_from_odpi()

    def tpc_prepare(self, xid):
        cdef:
            ThickXid thick_xid = ThickXid(xid)
            bint commit_needed
            int status
        with nogil:
            status = dpiConn_tpcPrepare(self._handle, thick_xid.xid_ptr,
                                        &commit_needed)
        if status < 0:
            _raise_from_odpi()
        return commit_needed

    def tpc_rollback(self, xid):
        cdef:
            ThickXid thick_xid = ThickXid(xid)
            int status
        with nogil:
            status = dpiConn_tpcRollback(self._handle, thick_xid.xid_ptr)
        if status < 0:
            _raise_from_odpi()


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thick\cursor.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# cursor.pyx
#
# Cython file defining the thick Cursor implementation class (embedded in
# thick_impl.pyx).
#------------------------------------------------------------------------------


cdef class ThickCursorImpl(BaseCursorImpl):
    cdef:
        ThickConnImpl _conn_impl
        bint _is_implicit_cursor
        bint _fixup_ref_cursor
        dpiStmtInfo _stmt_info
        dpiStmt *_handle
        str _tag

    def __cinit__(self, conn_impl):
        self._conn_impl = conn_impl

    def __dealloc__(self):
        if self._handle != NULL:
            dpiStmt_release(self._handle)

    cdef int _close(self, bint in_del) except -1:
        """
        Internal method for closing the cursor.
        """
        if self._handle != NULL:
            if not in_del and self._conn_impl._handle != NULL \
                    and not self._is_implicit_cursor:
                if dpiStmt_close(self._handle, NULL, 0) < 0:
                    _raise_from_odpi()
            dpiStmt_release(self._handle)
            self._handle = NULL

    cdef BaseVarImpl _create_var_impl(self, object conn):
        """
        Internal method for creating a variable.
        """
        cdef ThickVarImpl var_impl = ThickVarImpl.__new__(ThickVarImpl)
        var_impl._conn = conn
        var_impl._conn_impl = self._conn_impl
        return var_impl

    cdef int _define_var(self, object conn, object cursor, object type_handler,
                         bint uses_metadata, ssize_t pos) except -1:
        """
        Internal method that creates the variable using the query info (unless
        an output type handler has been specified) and then performs the define
        in ODPI-C.
        """
        cdef:
            ThickDbObjectTypeImpl typ_impl
            OracleMetadata metadata
            ThickConnImpl conn_impl
            dpiQueryInfo query_info
            dpiDataTypeInfo *info
            ThickVarImpl var_impl
            uint32_t i, temp_len
            str key, value

        # build metadata based on query info provided by ODPI-C
        if dpiStmt_getQueryInfo(self._handle, pos + 1, &query_info) < 0:
            _raise_from_odpi()
        info = &query_info.typeInfo
        metadata = OracleMetadata.__new__(OracleMetadata)
        metadata.dbtype = DbType._from_num(info.oracleTypeNum)
        if info.sizeInChars > 0:
            metadata.max_size = info.sizeInChars
        else:
            metadata.max_size = info.clientSizeInBytes
        metadata.buffer_size = info.clientSizeInBytes
        metadata.name = query_info.name[:query_info.nameLength].decode()
        metadata.scale = <int8_t> info.scale + info.fsPrecision
        metadata.precision = <int8_t> info.precision
        metadata.nulls_allowed = query_info.nullOk
        metadata.is_json = info.isJson
        metadata.is_oson = info.isOson
        if info.domainSchema:
            temp_len = info.domainSchemaLength
            metadata.domain_schema = info.domainSchema[:temp_len].decode()
        if info.domainName:
            metadata.domain_name = \
                    info.domainName[:info.domainNameLength].decode()
        if info.numAnnotations > 0:
            metadata.annotations = {}
            for i in range(info.numAnnotations):
                temp_len = info.annotations[i].keyLength
                key = info.annotations[i].key[:temp_len].decode()
                temp_len = info.annotations[i].valueLength
                value = info.annotations[i].value[:temp_len].decode()
                metadata.annotations[key] = value
        if info.objectType != NULL:
            typ_impl = ThickDbObjectTypeImpl._from_handle(self._conn_impl,
                                                          info.objectType)
            metadata.objtype = typ_impl
        if metadata.dbtype.num == DPI_ORACLE_TYPE_VECTOR:
            metadata.vector_dimensions = info.vectorDimensions
            metadata.vector_format = info.vectorFormat
            metadata.vector_flags = info.vectorFlags

        # create variable and call define in ODPI-C
        var_impl = <ThickVarImpl> self._create_fetch_var(
            conn, cursor, type_handler, uses_metadata, pos, metadata
        )
        if dpiStmt_define(self._handle, pos + 1, var_impl._handle) < 0:
            _raise_from_odpi()

    cdef int _fetch_rows(self, object cursor) except -1:
        """
        Internal method for fetching rows from a cursor.
        """
        cdef:
            uint32_t temp_buffer_row_index, num_rows_in_buffer
            bint more_rows_to_fetch
            ThickVarImpl var_impl
            int status
        with nogil:
            status = dpiStmt_fetchRows(self._handle,
                                       self._fetch_array_size,
                                       &temp_buffer_row_index,
                                       &num_rows_in_buffer,
                                       &more_rows_to_fetch)
        if status < 0:
            _raise_from_odpi()
        self._buffer_index = 0
        self._buffer_rowcount = num_rows_in_buffer
        self._more_rows_to_fetch = more_rows_to_fetch
        if self.fetching_arrow:
            self._populate_arrow_arrays()

    cdef BaseConnImpl _get_conn_impl(self):
        """
        Internal method used to return the connection implementation associated
        with the cursor implementation.
        """
        return self._conn_impl

    cdef bint _is_plsql(self):
        return <bint> self._stmt_info.isPLSQL

    def _get_oci_attr(self, uint32_t attr_num, uint32_t attr_type):
        """
        Internal method for getting the value of an OCI attribute on the
        cursor.
        """
        cdef:
            dpiDataBuffer value
            uint32_t value_len
        if dpiStmt_getOciAttr(self._handle, attr_num, &value, &value_len) < 0:
            _raise_from_odpi()
        return _convert_oci_attr_to_python(attr_type, &value, value_len)

    cdef int _perform_define(self, object cursor,
                             uint32_t num_query_cols) except -1:
        """
        Internal method for performing defines. At this point it is assumed
        that the statement executed was in fact a query.
        """
        cdef:
            ThickCursorImpl cursor_impl = <ThickCursorImpl> cursor._impl
            object var, type_handler, conn
            ThickVarImpl var_impl
            bint uses_metadata
            ssize_t i

        # initialize fetching variables; these are used to reduce the number of
        # times that the GIL is released/acquired -- as there is a significant
        # amount of overhead in doing so
        self._buffer_rowcount = 0
        self._more_rows_to_fetch = True

        # if fetch variables already exist, nothing to do (the same statement
        # is being executed and therefore all defines have already been
        # performed
        if self.fetch_vars is not None:
            return 0

        # populate list to contain fetch variables that are created
        self._fetch_array_size = self.arraysize
        self._init_fetch_vars(num_query_cols)
        type_handler = self._get_output_type_handler(&uses_metadata)
        conn = cursor.connection
        for i in range(num_query_cols):
            self._define_var(conn, cursor, type_handler, uses_metadata, i)

    cdef int _prepare(self, str statement, str tag,
                      bint cache_statement) except -1:
        """
        Internal method used for preparing statements for execution.
        """
        cdef:
            uint32_t statement_bytes_length, tag_bytes_length = 0
            ThickConnImpl conn_impl = self._conn_impl
            bytes statement_bytes, tag_bytes
            const char *tag_ptr = NULL
            const char *statement_ptr
            int status
        BaseCursorImpl._prepare(self, statement, tag, cache_statement)
        statement_bytes = statement.encode()
        statement_ptr = <const char*> statement_bytes
        statement_bytes_length = <uint32_t> len(statement_bytes)
        if tag is not None:
            self._tag = tag
            tag_bytes = tag.encode()
            tag_bytes_length = <uint32_t> len(tag_bytes)
            tag_ptr = <const char*> tag_bytes
        with nogil:
            if self._handle != NULL:
                dpiStmt_release(self._handle)
                self._handle = NULL
            status = dpiConn_prepareStmt(conn_impl._handle, self.scrollable,
                                         statement_ptr, statement_bytes_length,
                                         tag_ptr, tag_bytes_length,
                                         &self._handle)
            if status == DPI_SUCCESS and not cache_statement:
                status = dpiStmt_deleteFromCache(self._handle)
            if status == DPI_SUCCESS:
                status = dpiStmt_getInfo(self._handle, &self._stmt_info)
            if status == DPI_SUCCESS and self._stmt_info.isQuery:
                status = dpiStmt_setFetchArraySize(self._handle,
                                                   self.arraysize)
                if status == DPI_SUCCESS \
                        and self.prefetchrows != DPI_DEFAULT_PREFETCH_ROWS:
                    status = dpiStmt_setPrefetchRows(self._handle,
                                                     self.prefetchrows)
        if status < 0:
            _raise_from_odpi()

    cdef int _populate_arrow_arrays(self) except -1:
        """
        Populate Arrow arrays with fetched data.
        """
        cdef:
            ThickVarImpl var_impl
            uint32_t i
        for var_impl in self.fetch_var_impls:
            for i in range(self._buffer_rowcount):
                var_impl._transform_element_to_arrow(i)

    def _set_oci_attr(self, uint32_t attr_num, uint32_t attr_type,
                      object value):
        """
        Internal method for setting the value of an OCI attribute on the
        cursor.
        """
        cdef:
            StringBuffer str_buf = StringBuffer()
            void *oci_value = NULL
            dpiDataBuffer oci_buf
            uint32_t oci_len = 0
        _convert_python_to_oci_attr(value, attr_type, str_buf, &oci_buf,
                                    &oci_value, &oci_len)
        if dpiStmt_setOciAttr(self._handle, attr_num, oci_value, oci_len) < 0:
            _raise_from_odpi()

    cdef int _transform_binds(self) except -1:
        cdef:
            ThickVarImpl var_impl
            uint32_t num_elements
            BindVar bind_var
        if self.bind_vars is not None:
            for bind_var in self.bind_vars:
                var_impl = <ThickVarImpl> bind_var.var_impl
                if var_impl.is_array:
                    if dpiVar_getNumElementsInArray(var_impl._handle,
                                                    &num_elements) < 0:
                        _raise_from_odpi()
                    var_impl.num_elements_in_array = num_elements

    def execute(self, cursor):
        """
        Internal method for executing a statement.
        """
        cdef:
            uint32_t mode, num_query_cols
            dpiErrorInfo error_info
            uint64_t rowcount = 0
            int status
        if self.bind_vars is not None:
            self._perform_binds(cursor.connection, 1)
        if self._conn_impl.autocommit:
            mode = DPI_MODE_EXEC_COMMIT_ON_SUCCESS
        else:
            mode = DPI_MODE_EXEC_DEFAULT
        with nogil:
            status = dpiStmt_execute(self._handle, mode, &num_query_cols)
            if status == DPI_SUCCESS:
                dpiContext_getError(driver_info.context, &error_info)
                if not self._stmt_info.isPLSQL:
                    status = dpiStmt_getRowCount(self._handle, &rowcount)
        if status < 0:
            _raise_from_odpi()
        elif error_info.isWarning:
            self.warning = _create_new_from_info(&error_info)
        self.rowcount = rowcount
        if num_query_cols > 0:
            self._perform_define(cursor, num_query_cols)
        elif self._stmt_info.isReturning or self._stmt_info.isPLSQL:
            self._transform_binds()

    def executemany(self, cursor, num_execs, batcherrors, arraydmlrowcounts):
        """
        Internal method for executing a statement multiple times.
        """
        cdef:
            uint32_t mode, num_execs_int = num_execs
            dpiErrorInfo error_info
            uint64_t rowcount = 0
            int status

        if self._conn_impl.autocommit:
            mode = DPI_MODE_EXEC_COMMIT_ON_SUCCESS
        else:
            mode = DPI_MODE_EXEC_DEFAULT
        if arraydmlrowcounts:
            mode |= DPI_MODE_EXEC_ARRAY_DML_ROWCOUNTS
        if batcherrors:
            mode |= DPI_MODE_EXEC_BATCH_ERRORS

        if self.bind_vars is not None:
            self._perform_binds(cursor.connection, num_execs_int)

        if num_execs_int > 0:
            with nogil:
                status = dpiStmt_executeMany(self._handle, mode, num_execs_int)
                dpiContext_getError(driver_info.context, &error_info)
                dpiStmt_getRowCount(self._handle, &rowcount)
            if not self._stmt_info.isPLSQL:
                self.rowcount = rowcount
            if status < 0:
                error = _create_new_from_info(&error_info)
                if self._stmt_info.isPLSQL and error_info.offset == 0:
                    error.offset = rowcount
                raise error.exc_type(error)
            elif error_info.isWarning:
                self.warning = _create_new_from_info(&error_info)
            if self._stmt_info.isReturning or self._stmt_info.isPLSQL:
                self._transform_binds()

    def get_array_dml_row_counts(self):
        """
        Internal method for returning a list of array DML row counts for the
        last operation executed.
        """
        cdef:
            uint32_t num_row_count, i
            uint64_t *rowcount
            int status

        status = dpiStmt_getRowCounts(self._handle, &num_row_count, &rowcount)
        if status < 0:
            _raise_from_odpi()

        result = []
        for i in range(num_row_count):
            result.append(rowcount[i])
        return result

    def get_batch_errors(self):
        """
        Internal method for returning a list of batch errors.
        """
        cdef:
            uint32_t num_errors, i
            dpiErrorInfo *errors

        if dpiStmt_getBatchErrorCount(self._handle, &num_errors) < 0:
            _raise_from_odpi()
        if num_errors == 0:
            return []

        errors = <dpiErrorInfo*> \
                cpython.PyMem_Malloc(num_errors * sizeof(dpiErrorInfo))

        try:
            if dpiStmt_getBatchErrors(self._handle, num_errors, errors) < 0:
                _raise_from_odpi()
            result = cpython.PyList_New(num_errors)
            for i in range(num_errors):
                error = _create_new_from_info(&errors[i])
                cpython.Py_INCREF(error)
                cpython.PyList_SET_ITEM(result, i, error)
        finally:
            cpython.PyMem_Free(errors)

        return result

    def get_bind_names(self):
        cdef:
            uint32_t *name_lengths = NULL
            const char **names = NULL
            uint32_t num_binds, i
            ssize_t num_bytes
            list result
        if dpiStmt_getBindCount(self._handle, &num_binds) < 0:
            _raise_from_odpi()
        if num_binds == 0:
            return []
        try:
            num_bytes = num_binds * sizeof(char*)
            names = <const char**> cpython.PyMem_Malloc(num_bytes)
            num_bytes = num_binds * sizeof(uint32_t)
            name_lengths = <uint32_t*> cpython.PyMem_Malloc(num_bytes)
            if dpiStmt_getBindNames(self._handle, &num_binds, names,
                                    name_lengths) < 0:
                _raise_from_odpi()
            result = [None] * num_binds
            for i in range(num_binds):
                result[i] = names[i][:name_lengths[i]].decode()
            return result
        finally:
            if names:
                cpython.PyMem_Free(names)
            if name_lengths:
                cpython.PyMem_Free(name_lengths)

    def get_implicit_results(self, connection):
        cdef:
            ThickCursorImpl child_cursor_impl
            object child_cursor
            dpiStmt *child_stmt
            list result = []
        if self._handle == NULL:
            errors._raise_err(errors.ERR_NO_STATEMENT_EXECUTED)
        while True:
            if dpiStmt_getImplicitResult(self._handle, &child_stmt) < 0:
                _raise_from_odpi()
            if child_stmt == NULL:
                break
            child_cursor = connection.cursor()
            child_cursor_impl = child_cursor._impl
            child_cursor_impl._handle = child_stmt
            child_cursor_impl._fixup_ref_cursor = True
            child_cursor_impl._is_implicit_cursor = True
            result.append(child_cursor)
        return result

    def get_lastrowid(self):
        """
        Internal method for returning the rowid of the row that was last
        modified by an operation.
        """
        cdef:
            uint32_t rowid_length
            const char *rowid_ptr
            dpiRowid *rowid
        if self._handle is not NULL:
            if dpiStmt_getLastRowid(self._handle, &rowid) < 0:
                _raise_from_odpi()
            if rowid:
                if dpiRowid_getStringValue(rowid, &rowid_ptr,
                                           &rowid_length) < 0:
                    _raise_from_odpi()
                return rowid_ptr[:rowid_length].decode()

    def is_query(self, cursor):
        cdef uint32_t num_query_cols
        if self._fixup_ref_cursor:
            self._fetch_array_size = self.arraysize
            if dpiStmt_setFetchArraySize(self._handle,
                                         self._fetch_array_size) < 0:
                _raise_from_odpi()
            if dpiStmt_getNumQueryColumns(self._handle, &num_query_cols) < 0:
                _raise_from_odpi()
            self._perform_define(cursor, num_query_cols)
            self._fixup_ref_cursor = False
        return self.fetch_vars is not None

    def parse(self, cursor):
        """
        Internal method for parsing a statement.
        """
        cdef:
            uint32_t mode, num_query_cols
            int status
        if self._stmt_info.isQuery:
            mode = DPI_MODE_EXEC_DESCRIBE_ONLY
        else:
            mode = DPI_MODE_EXEC_PARSE_ONLY
        with nogil:
            status = dpiStmt_execute(self._handle, mode, &num_query_cols)
        if status < 0:
            _raise_from_odpi()
        if num_query_cols > 0:
            self._perform_define(cursor, num_query_cols)

    def scroll(self, object cursor, int32_t offset, object mode):
        cdef:
            uint32_t temp_buffer_row_index = 0, num_rows_in_buffer = 0
            bint more_rows_to_fetch = False
            ThickVarImpl var_impl
            uint32_t int_mode = 0
            int status
        if mode == "relative":
            int_mode = DPI_MODE_FETCH_RELATIVE
        elif mode == "absolute":
            int_mode = DPI_MODE_FETCH_ABSOLUTE
        elif mode == "first":
            int_mode = DPI_MODE_FETCH_FIRST
        elif mode == "last":
            int_mode = DPI_MODE_FETCH_LAST
        else:
            errors._raise_err(errors.ERR_WRONG_SCROLL_MODE)
        with nogil:
            status = dpiStmt_scroll(self._handle, int_mode, offset,
                                    0 - self._buffer_rowcount)
            if status == 0:
                status = dpiStmt_fetchRows(self._handle,
                                           self._fetch_array_size,
                                           &temp_buffer_row_index,
                                           &num_rows_in_buffer,
                                           &more_rows_to_fetch)
            if status == 0:
                status = dpiStmt_getRowCount(self._handle, &self.rowcount)
        if status < 0:
            _raise_from_odpi()
        self._buffer_index = temp_buffer_row_index
        self._buffer_rowcount = num_rows_in_buffer
        self._more_rows_to_fetch = more_rows_to_fetch
        self.rowcount -= num_rows_in_buffer


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thick\dbobject.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2023, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# dbobject.pyx
#
# Cython file defining the thick DbObjectType, DbObjectAttr and DbObject
# implementation classes (embedded in thick_impl.pyx).
#------------------------------------------------------------------------------

cdef class ThickDbObjectImpl(BaseDbObjectImpl):
    cdef:
        dpiObject *_handle

    def __dealloc__(self):
        if self._handle != NULL:
            dpiObject_release(self._handle)

    cdef int _convert_from_python(self, object value, OracleMetadata metadata,
                                  dpiData *data, StringBuffer buf):
        """
        Internal method for converting a value from Python to the value
        required by ODPI-C.
        """
        if value is None:
            data.isNull = 1
        else:
            data.isNull = 0
            _convert_from_python(value, metadata, &data.value, buf)

    def append_checked(self, object value):
        """
        Internal method for appending a value to a collection object.
        """
        cdef:
            StringBuffer buf = StringBuffer()
            ThickDbObjectTypeImpl objtype
            dpiData data
        objtype = <ThickDbObjectTypeImpl> self.type
        self._convert_from_python(value, objtype.element_metadata, &data, buf)
        if dpiObject_appendElement(self._handle,
                                   objtype.element_metadata.dbtype._native_num,
                                   &data) < 0:
            _raise_from_odpi()

    def copy(self):
        """
        Internal method for creating a copy of an object.
        """
        cdef ThickDbObjectImpl copied_impl
        copied_impl = ThickDbObjectImpl.__new__(ThickDbObjectImpl)
        if dpiObject_copy(self._handle, &copied_impl._handle) < 0:
            _raise_from_odpi()
        copied_impl.type = self.type
        return copied_impl

    def delete_by_index(self, int32_t index):
        """
        Internal method for deleting an entry from a collection that is indexed
        by integers.
        """
        if dpiObject_deleteElementByIndex(self._handle, index) < 0:
            _raise_from_odpi()

    def exists_by_index(self, int32_t index):
        """
        Internal method for determining if an entry exists in a collection that
        is indexed by integers.
        """
        cdef bint exists
        if dpiObject_getElementExistsByIndex(self._handle, index, &exists) < 0:
            _raise_from_odpi()
        return exists

    def get_attr_value(self, ThickDbObjectAttrImpl attr):
        """
        Internal method for getting an attribute value.
        """
        cdef:
            char number_as_string_buffer[200]
            ThickDbObjectTypeImpl type_impl
            dpiData data
        if attr.dbtype._native_num == DPI_NATIVE_TYPE_BYTES \
                and attr.dbtype.num == DPI_ORACLE_TYPE_NUMBER:
            data.value.asBytes.ptr = number_as_string_buffer
            data.value.asBytes.length = sizeof(number_as_string_buffer)
            data.value.asBytes.encoding = NULL
        if dpiObject_getAttributeValue(self._handle, attr._handle,
                                       attr.dbtype._native_num, &data) < 0:
            _raise_from_odpi()
        if data.isNull:
            return None
        type_impl = self.type
        try:
            return _convert_to_python(type_impl._conn_impl, attr, &data.value)
        finally:
            if attr.objtype is not None:
                dpiObject_release(data.value.asObject)

    def get_element_by_index(self, int32_t index):
        """
        Internal method for getting an entry from a collection that is indexed
        by integers.
        """
        cdef:
            char number_as_string_buffer[200]
            ThickDbObjectTypeImpl objtype
            DbType dbtype
            dpiData data
        objtype = self.type
        dbtype = objtype.element_metadata.dbtype
        if dbtype._native_num == DPI_NATIVE_TYPE_BYTES \
                and dbtype.num == DPI_ORACLE_TYPE_NUMBER:
            data.value.asBytes.ptr = number_as_string_buffer
            data.value.asBytes.length = sizeof(number_as_string_buffer)
            data.value.asBytes.encoding = NULL
        if dpiObject_getElementValueByIndex(self._handle, index,
                                            dbtype._native_num, &data) < 0:
            _raise_from_odpi()
        if data.isNull:
            return None
        try:
            return _convert_to_python(objtype._conn_impl,
                                      objtype.element_metadata, &data.value)
        finally:
            if objtype.element_metadata.objtype is not None:
                dpiObject_release(data.value.asObject)

    def get_first_index(self):
        """
        Internal method for getting the first index from a collection that is
        indexed by integers.
        """
        cdef:
            int32_t index
            bint exists
        if dpiObject_getFirstIndex(self._handle, &index, &exists) < 0:
            _raise_from_odpi()
        if exists:
            return index

    def get_last_index(self):
        """
        Internal method for getting the last index from a collection that is
        indexed by integers.
        """
        cdef:
            int32_t index
            bint exists
        if dpiObject_getLastIndex(self._handle, &index, &exists) < 0:
            _raise_from_odpi()
        if exists:
            return index

    def get_next_index(self, int32_t index):
        """
        Internal method for getting the next index from a collection that is
        indexed by integers.
        """
        cdef:
            int32_t next_index
            bint exists
        if dpiObject_getNextIndex(self._handle, index, &next_index,
                                  &exists) < 0:
            _raise_from_odpi()
        if exists:
            return next_index

    def get_prev_index(self, int32_t index):
        """
        Internal method for getting the next index from a collection that is
        indexed by integers.
        """
        cdef:
            int32_t prev_index
            bint exists
        if dpiObject_getPrevIndex(self._handle, index, &prev_index,
                                  &exists) < 0:
            _raise_from_odpi()
        if exists:
            return prev_index

    def get_size(self):
        """
        Internal method for getting the size of a collection.
        """
        cdef int32_t size
        if dpiObject_getSize(self._handle, &size) < 0:
            _raise_from_odpi()
        return size

    def set_attr_value_checked(self, ThickDbObjectAttrImpl attr, object value):
        """
        Internal method for setting an attribute value.
        """
        cdef:
            StringBuffer buf = StringBuffer()
            uint32_t native_type_num
            dpiData data
        self._convert_from_python(value, attr, &data, buf)
        native_type_num = attr.dbtype._native_num
        if native_type_num == DPI_NATIVE_TYPE_LOB \
                and not isinstance(value, PY_TYPE_LOB):
            native_type_num = DPI_NATIVE_TYPE_BYTES
        if dpiObject_setAttributeValue(self._handle, attr._handle,
                                       native_type_num, &data) < 0:
            _raise_from_odpi()

    def set_element_by_index_checked(self, int32_t index, object value):
        """
        Internal method for setting an entry in a collection that is indexed by
        integers.
        """
        cdef:
            StringBuffer buf = StringBuffer()
            ThickDbObjectTypeImpl objtype
            uint32_t native_type_num
            dpiData data
        objtype = self.type
        self._convert_from_python(value, objtype.element_metadata, &data, buf)
        native_type_num = objtype.element_metadata.dbtype._native_num
        if native_type_num == DPI_NATIVE_TYPE_LOB \
                and not isinstance(value, PY_TYPE_LOB):
            native_typeNum = DPI_NATIVE_TYPE_BYTES
        if dpiObject_setElementValueByIndex(self._handle, index,
                                            native_type_num, &data) < 0:
            _raise_from_odpi()

    def trim(self, int32_t num_to_trim):
        """
        Internal method for trimming a number of entries from a collection.
        """
        if dpiObject_trim(self._handle, num_to_trim) < 0:
            _raise_from_odpi()


cdef class ThickDbObjectAttrImpl(BaseDbObjectAttrImpl):
    cdef:
        dpiObjectAttr *_handle

    def __dealloc__(self):
        if self._handle != NULL:
            dpiObjectAttr_release(self._handle)

    @staticmethod
    cdef ThickDbObjectAttrImpl _from_handle(ThickConnImpl conn_impl,
                                            dpiObjectAttr *handle):
        """
        Create a new DbObjectAttr implementation object given an ODPI-C handle.
        """
        cdef:
            ThickDbObjectAttrImpl impl
            dpiObjectType *typ_handle
            dpiObjectAttrInfo info
        impl = ThickDbObjectAttrImpl.__new__(ThickDbObjectAttrImpl)
        impl._handle = handle
        if dpiObjectAttr_getInfo(handle, &info) < 0:
            _raise_from_odpi()
        impl.name = info.name[:info.nameLength].decode()
        impl.dbtype = DbType._from_num(info.typeInfo.oracleTypeNum)
        impl.precision = <int8_t> info.typeInfo.precision
        impl.scale = <int8_t> info.typeInfo.scale
        impl.max_size = info.typeInfo.dbSizeInBytes
        if info.typeInfo.objectType:
            typ_handle = info.typeInfo.objectType
            impl.objtype = ThickDbObjectTypeImpl._from_handle(conn_impl,
                                                              typ_handle)
        impl._finalize_init()
        return impl


cdef class ThickDbObjectTypeImpl(BaseDbObjectTypeImpl):
    cdef:
        dpiObjectType *_handle

    def __dealloc__(self):
        if self._handle != NULL:
            dpiObjectType_release(self._handle)

    @staticmethod
    cdef ThickDbObjectTypeImpl _from_handle(ThickConnImpl conn_impl,
                                            dpiObjectType *handle):
        """
        Create a new DbObjectType implementation object given an ODPI-C handle.
        """
        cdef:
            dpiObjectAttr **attributes = NULL
            ThickDbObjectAttrImpl attr_impl
            ThickDbObjectTypeImpl impl
            OracleMetadata metadata
            dpiObjectTypeInfo info
            ssize_t num_bytes
            uint16_t i
            object typ
        impl = ThickDbObjectTypeImpl.__new__(ThickDbObjectTypeImpl)
        if dpiObjectType_addRef(handle) < 0:
            _raise_from_odpi()
        impl._conn_impl = conn_impl
        impl._handle = handle
        if dpiObjectType_getInfo(impl._handle, &info) < 0:
            _raise_from_odpi()
        impl.schema = info.schema[:info.schemaLength].decode()
        impl.name = info.name[:info.nameLength].decode()
        if info.packageNameLength > 0:
            impl.package_name = \
                    info.packageName[:info.packageNameLength].decode()
        impl.is_collection = info.isCollection
        if impl.is_collection:
            metadata = OracleMetadata.__new__(OracleMetadata)
            impl.element_metadata = metadata
            metadata.dbtype = \
                    DbType._from_num(info.elementTypeInfo.oracleTypeNum)
            metadata.precision = <int8_t> info.elementTypeInfo.precision
            metadata.scale = <int8_t> info.elementTypeInfo.scale
            metadata.max_size = info.elementTypeInfo.dbSizeInBytes
            if info.elementTypeInfo.objectType != NULL:
                handle = info.elementTypeInfo.objectType
                metadata.objtype = \
                        ThickDbObjectTypeImpl._from_handle(conn_impl, handle)
            metadata._finalize_init()
        impl.attrs_by_name = {}
        impl.attrs = [None] * info.numAttributes
        try:
            num_bytes = info.numAttributes * sizeof(dpiObjectAttr*)
            attributes = <dpiObjectAttr**> cpython.PyMem_Malloc(num_bytes)
            if dpiObjectType_getAttributes(impl._handle, info.numAttributes,
                                           attributes) < 0:
                _raise_from_odpi()
            for i in range(info.numAttributes):
                attr_impl = ThickDbObjectAttrImpl._from_handle(conn_impl,
                                                               attributes[i])
                impl.attrs[i] = attr_impl
                impl.attrs_by_name[attr_impl.name] = attr_impl
        finally:
            if attributes != NULL:
                cpython.PyMem_Free(attributes)
        return impl

    def create_new_object(self):
        """
        Internal method for creating a new object.
        """
        cdef ThickDbObjectImpl obj_impl
        obj_impl = ThickDbObjectImpl.__new__(ThickDbObjectImpl)
        obj_impl.type = self
        if dpiObjectType_createObject(self._handle, &obj_impl._handle) < 0:
            _raise_from_odpi()
        return obj_impl


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thick\json.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# json.pyx
#
# Cython file defining methods and classes used for processing JSON data
# (embedded in thick_impl.pyx).
#------------------------------------------------------------------------------

cdef class JsonBuffer:
    cdef:
        dpiJsonNode _top_node
        dpiDataBuffer _top_node_buf
        list _buffers

    def __dealloc__(self):
        _free_node(&self._top_node)

    cdef int _add_buf(self, object value, char **ptr,
                      uint32_t *length) except -1:
        cdef StringBuffer buf = StringBuffer()
        buf.set_value(value)
        if self._buffers is None:
            self._buffers = []
        self._buffers.append(buf)
        ptr[0] = buf.ptr
        length[0] = buf.length

    cdef int _populate_array_node(self, dpiJsonNode *node,
                                  list value) except -1:
        cdef:
            dpiJsonArray *array
            object child_value
            uint32_t i
        node.oracleTypeNum = DPI_ORACLE_TYPE_JSON_ARRAY
        node.nativeTypeNum = DPI_NATIVE_TYPE_JSON_ARRAY
        array = &node.value.asJsonArray
        array.numElements = <uint32_t> len(value)
        array.elements = <dpiJsonNode*> _calloc(array.numElements,
                                                sizeof(dpiJsonNode))
        array.elementValues = <dpiDataBuffer*> _calloc(array.numElements,
                                                       sizeof(dpiDataBuffer))
        for i, child_value in enumerate(value):
            array.elements[i].value = &array.elementValues[i]
            self._populate_node(&array.elements[i], child_value)

    cdef int _populate_obj_node(self, dpiJsonNode *node, dict value) except -1:
        cdef:
            object child_key, child_value
            dpiJsonObject *obj
            uint32_t i
        node.oracleTypeNum = DPI_ORACLE_TYPE_JSON_OBJECT
        node.nativeTypeNum = DPI_NATIVE_TYPE_JSON_OBJECT
        obj = &node.value.asJsonObject
        obj.numFields = <uint32_t> len(value)
        obj.fieldNames = <char**> _calloc(obj.numFields, sizeof(char*))
        obj.fieldNameLengths = <uint32_t*> _calloc(obj.numFields,
                                                   sizeof(uint32_t))
        obj.fields = <dpiJsonNode*> _calloc(obj.numFields, sizeof(dpiJsonNode))
        obj.fieldValues = <dpiDataBuffer*> _calloc(obj.numFields,
                                                   sizeof(dpiDataBuffer))
        i = 0
        for child_key, child_value in value.items():
            obj.fields[i].value = &obj.fieldValues[i]
            self._add_buf(child_key, &obj.fieldNames[i],
                          &obj.fieldNameLengths[i])
            self._populate_node(&obj.fields[i], child_value)
            i += 1

    cdef int _populate_node(self, dpiJsonNode *node, object value) except -1:
        cdef:
            VectorEncoder vector_encoder
            dpiTimestamp *timestamp
            dpiIntervalDS *interval
            int seconds
        if value is None:
            node.oracleTypeNum = DPI_ORACLE_TYPE_NONE
            node.nativeTypeNum = DPI_NATIVE_TYPE_NULL
        elif isinstance(value, list):
            self._populate_array_node(node, value)
        elif isinstance(value, dict):
            self._populate_obj_node(node, value)
        elif isinstance(value, str):
            node.oracleTypeNum = DPI_ORACLE_TYPE_VARCHAR
            node.nativeTypeNum = DPI_NATIVE_TYPE_BYTES
            self._add_buf(value, &node.value.asBytes.ptr,
                          &node.value.asBytes.length)
        elif isinstance(value, bytes):
            node.oracleTypeNum = DPI_ORACLE_TYPE_JSON_ID \
                    if isinstance(value, PY_TYPE_JSON_ID) \
                    else DPI_ORACLE_TYPE_RAW
            node.nativeTypeNum = DPI_NATIVE_TYPE_BYTES
            self._add_buf(value, &node.value.asBytes.ptr,
                          &node.value.asBytes.length)
        elif isinstance(value, bool):
            node.oracleTypeNum = DPI_ORACLE_TYPE_BOOLEAN
            node.nativeTypeNum = DPI_NATIVE_TYPE_BOOLEAN
            node.value.asBoolean = <bint> value
        elif isinstance(value, (int, PY_TYPE_DECIMAL)):
            node.oracleTypeNum = DPI_ORACLE_TYPE_NUMBER
            node.nativeTypeNum = DPI_NATIVE_TYPE_BYTES
            self._add_buf(str(value), &node.value.asBytes.ptr,
                          &node.value.asBytes.length)
        elif isinstance(value, float):
            node.oracleTypeNum = DPI_ORACLE_TYPE_NUMBER
            node.nativeTypeNum = DPI_NATIVE_TYPE_DOUBLE
            node.value.asDouble = <double> value
        elif isinstance(value, PY_TYPE_DATETIME):
            node.oracleTypeNum = DPI_ORACLE_TYPE_TIMESTAMP
            node.nativeTypeNum = DPI_NATIVE_TYPE_TIMESTAMP
            memset(&node.value.asTimestamp, 0, sizeof(node.value.asTimestamp))
            timestamp = &node.value.asTimestamp
            timestamp.year = cydatetime.datetime_year(value)
            timestamp.month = cydatetime.datetime_month(value)
            timestamp.day = cydatetime.datetime_day(value)
            timestamp.hour = cydatetime.datetime_hour(value)
            timestamp.minute = cydatetime.datetime_minute(value)
            timestamp.second = cydatetime.datetime_second(value)
            timestamp.fsecond = cydatetime.datetime_microsecond(value) * 1000
        elif isinstance(value, PY_TYPE_DATE):
            node.oracleTypeNum = DPI_ORACLE_TYPE_DATE
            node.nativeTypeNum = DPI_NATIVE_TYPE_TIMESTAMP
            memset(&node.value.asTimestamp, 0, sizeof(node.value.asTimestamp))
            timestamp = &node.value.asTimestamp
            timestamp = &node.value.asTimestamp
            timestamp.year = cydatetime.date_year(value)
            timestamp.month = cydatetime.date_month(value)
            timestamp.day = cydatetime.date_day(value)
        elif isinstance(value, datetime.timedelta):
            node.oracleTypeNum = DPI_ORACLE_TYPE_INTERVAL_DS
            node.nativeTypeNum = DPI_NATIVE_TYPE_INTERVAL_DS
            interval = &node.value.asIntervalDS
            seconds = cydatetime.timedelta_seconds(value)
            interval.days = cydatetime.timedelta_days(value)
            interval.hours = seconds // 3600
            seconds = seconds % 3600
            interval.minutes = seconds // 60
            interval.seconds = seconds % 60
            interval.fseconds = cydatetime.timedelta_microseconds(value) * 1000
        elif isinstance(value, array.array):
            node.oracleTypeNum = DPI_ORACLE_TYPE_VECTOR
            node.nativeTypeNum = DPI_NATIVE_TYPE_BYTES
            vector_encoder = VectorEncoder.__new__(VectorEncoder)
            vector_encoder.encode(value)
            self._add_buf(vector_encoder._data[:vector_encoder._pos],
                          &node.value.asBytes.ptr, &node.value.asBytes.length)
        else:
            errors._raise_err(errors.ERR_PYTHON_TYPE_NOT_SUPPORTED,
                              typ=type(value))

    cdef int from_object(self, object value) except -1:
        self._top_node.value = &self._top_node_buf
        self._populate_node(&self._top_node, value)


cdef void* _calloc(size_t num_elements, size_t size) except NULL:
    cdef:
        size_t num_bytes = num_elements * size
        void *ptr
    ptr = cpython.PyMem_Malloc(num_bytes)
    memset(ptr, 0, num_bytes)
    return ptr

cdef void _free_node(dpiJsonNode *node):
    cdef:
        dpiJsonArray *array
        dpiJsonObject *obj
        uint32_t i
    if node.nativeTypeNum == DPI_NATIVE_TYPE_JSON_ARRAY:
        array = &node.value.asJsonArray
        if array.elements != NULL:
            for i in range(array.numElements):
                if array.elements[i].value != NULL:
                    _free_node(&array.elements[i])
            cpython.PyMem_Free(array.elements)
            array.elements = NULL
        if array.elementValues != NULL:
            cpython.PyMem_Free(array.elementValues)
            array.elementValues = NULL
    elif node.nativeTypeNum == DPI_NATIVE_TYPE_JSON_OBJECT:
        obj = &node.value.asJsonObject
        if obj.fields != NULL:
            for i in range(obj.numFields):
                if obj.fields[i].value != NULL:
                    _free_node(&obj.fields[i])
            cpython.PyMem_Free(obj.fields)
            obj.fields = NULL
        if obj.fieldNames != NULL:
            cpython.PyMem_Free(obj.fieldNames)
            obj.fieldNames = NULL
        if obj.fieldNameLengths != NULL:
            cpython.PyMem_Free(obj.fieldNameLengths)
            obj.fieldNameLengths = NULL
        if obj.fieldValues != NULL:
            cpython.PyMem_Free(obj.fieldValues)
            obj.fieldValues = NULL


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thick\lob.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2022, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# lob.pyx
#
# Cython file defining the thick Lob implementation class (embedded in
# thick_impl.pyx).
#------------------------------------------------------------------------------

cdef class ThickLobImpl(BaseLobImpl):
    cdef:
        dpiLob *_handle

    @staticmethod
    cdef ThickLobImpl _create(ThickConnImpl conn_impl, DbType dbtype,
                             dpiLob *handle):
        cdef:
            ThickLobImpl impl = ThickLobImpl.__new__(ThickLobImpl)
            int status
        impl.dbtype = dbtype
        if handle == NULL:
            with nogil:
                status = dpiConn_newTempLob(conn_impl._handle, dbtype.num,
                                            &handle)
            if status < 0:
                _raise_from_odpi()
        elif dpiLob_addRef(handle) < 0:
            _raise_from_odpi()
        impl._handle = handle
        return impl

    def close(self):
        """
        Internal method for closing a LOB that was opened earlier.
        """
        cdef int status
        with nogil:
            status = dpiLob_closeResource(self._handle)
        if status < 0:
            _raise_from_odpi()

    def file_exists(self):
        """
        Internal method for returning whether the file referenced by a BFILE
        exists.
        """
        cdef:
            bint exists
            int status
        with nogil:
            status = dpiLob_getFileExists(self._handle, &exists)
        if status < 0:
            _raise_from_odpi()
        return exists

    def free_lob(self):
        """
        Internal method for releasing the handle
        """
        if self._handle != NULL:
            dpiLob_release(self._handle)

    def get_chunk_size(self):
        """
        Internal method for returning the chunk size of the LOB.
        """
        cdef uint32_t chunk_size
        if dpiLob_getChunkSize(self._handle, &chunk_size) < 0:
            _raise_from_odpi()
        return chunk_size

    def get_file_name(self):
        """
        Internal method for returning a 2-tuple constaining the directory alias
        and file name of a BFILE type LOB.
        """
        cdef:
            uint32_t dir_alias_len, file_name_len
            const char *dir_alias
            const char *file_name
            int status
        with nogil:
            status = dpiLob_getDirectoryAndFileName(self._handle, &dir_alias,
                                                    &dir_alias_len,
                                                    &file_name, &file_name_len)
        if status < 0:
            _raise_from_odpi()
        return (dir_alias[:dir_alias_len].decode(),
                file_name[:file_name_len].decode())

    def get_is_open(self):
        """
        Internal method for returning whether the LOB is open or not.
        """
        cdef:
            bint is_open
            int status
        with nogil:
            status = dpiLob_getIsResourceOpen(self._handle, &is_open)
        if status < 0:
            _raise_from_odpi()
        return is_open

    def get_max_amount(self):
        """
        Internal method for returning the maximum amount that can be read.
        """
        return self.get_size()

    def get_size(self):
        """
        Internal method for returning the size of a LOB.
        """
        cdef uint64_t size
        if dpiLob_getSize(self._handle, &size) < 0:
            _raise_from_odpi()
        return size

    def open(self):
        """
        Internal method for opening a LOB.
        """
        cdef int status
        with nogil:
            status = dpiLob_openResource(self._handle)
        if status < 0:
            _raise_from_odpi()

    def read(self, uint64_t offset, uint64_t amount):
        """
        Internal method for reading a portion (or all) of the data in the LOB.
        """
        cdef:
            uint64_t buf_size
            object result
            char *buf
            int status
        if dpiLob_getBufferSize(self._handle, amount, &buf_size) < 0:
            _raise_from_odpi()
        buf = <char*> cpython.PyMem_Malloc(buf_size)
        with nogil:
            status = dpiLob_readBytes(self._handle, offset, amount, buf,
                                      &buf_size)
        try:
            if status < 0:
                _raise_from_odpi()
            result = buf[:buf_size]
            if self.dbtype.num == DPI_ORACLE_TYPE_CLOB \
                    or self.dbtype.num == DPI_ORACLE_TYPE_NCLOB:
                result = result.decode()
            return result
        finally:
            cpython.PyMem_Free(buf)

    def set_file_name(self, str dir_alias, str name):
        """
        Internal method for setting the directory alias and file name
        associated with a BFILE LOB.
        """
        cdef:
            bytes dir_alias_bytes, name_bytes
            uint32_t dir_alias_len, name_len
            const char *dir_alias_ptr
            const char *name_ptr
            int status
        dir_alias_bytes = dir_alias.encode()
        dir_alias_ptr = dir_alias_bytes
        dir_alias_len = <uint32_t> len(dir_alias_bytes)
        name_bytes = name.encode()
        name_ptr = name_bytes
        name_len = <uint32_t> len(name_bytes)
        with nogil:
            status = dpiLob_setDirectoryAndFileName(self._handle,
                                                    dir_alias_ptr,
                                                    dir_alias_len,
                                                    name_ptr, name_len)
        if status < 0:
            _raise_from_odpi()

    def trim(self, uint64_t new_size):
        """
        Internal method for trimming the data in the LOB to the new size
        """
        cdef int status
        with nogil:
            status = dpiLob_trim(self._handle, new_size)
        if status < 0:
            _raise_from_odpi()

    def write(self, object value, uint64_t offset):
        """
        Internal method for writing data to the LOB object.
        """
        cdef:
            StringBuffer buf = StringBuffer()
            int status
        buf.set_value(value)
        with nogil:
            status = dpiLob_writeBytes(self._handle, offset, buf.ptr,
                                       buf.length)
        if status < 0:
            _raise_from_odpi()


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thick\pool.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# pool.pyx
#
# Cython file defining the thick Pool implementation class (embedded in
# thick_impl.pyx).
#------------------------------------------------------------------------------

cdef int _token_callback_handler(void *context,
                                 dpiAccessToken *refresh_token) with gil:
    cdef:
        ThickPoolImpl pool_impl = <object> context
    pool_impl._token_handler(refresh_token, pool_impl.connect_params)


cdef class ThickPoolImpl(BasePoolImpl):
    cdef:
        dpiPool *_handle
        object warning

    def __init__(self, str dsn, PoolParamsImpl params):
        cdef:
            uint32_t password_len = 0, user_len = 0, connect_string_len = 0
            bytes token_bytes, private_key_bytes, connect_string_bytes
            bytes session_callback_bytes, name_bytes, driver_name_bytes
            bytes edition_bytes, user_bytes, password_bytes
            const char *connect_string_ptr = NULL
            str token, private_key, connect_string
            dpiCommonCreateParams common_params
            dpiPoolCreateParams create_params
            const char *password_ptr = NULL
            const char *user_ptr = NULL
            uint32_t token_len = 0, private_key_len = 0
            const char *token_ptr = NULL
            const char *private_key_ptr = NULL
            dpiAccessToken access_token
            dpiErrorInfo error_info
            int status

        # save parameters
        self.connect_params = params
        self.username = params.user
        self.dsn = dsn
        self.min = params.min
        self.max = params.max
        self.increment = params.increment
        self.homogeneous = params.homogeneous

        # set up token parameters if provided
        if params._token is not None \
                or params.access_token_callback is not None:
            token = params._get_token()
            token_bytes = token.encode()
            token_ptr = token_bytes
            token_len = <uint32_t> len(token_bytes)
            private_key = params._get_private_key()
            if private_key is not None:
                private_key_bytes = private_key.encode()
                private_key_ptr = private_key_bytes
                private_key_len = <uint32_t> len(private_key_bytes)

        # set up common creation parameters
        if dpiContext_initCommonCreateParams(driver_info.context,
                                             &common_params) < 0:
            _raise_from_odpi()
        common_params.createMode |= DPI_MODE_CREATE_THREADED
        if params.events:
            common_params.createMode |= DPI_MODE_CREATE_EVENTS
        if params.edition is not None:
            edition_bytes = params.edition.encode()
            common_params.edition = edition_bytes
            common_params.editionLength = <uint32_t> len(edition_bytes)
        if params._token is not None:
            access_token.token = token_ptr
            access_token.tokenLength = token_len
            access_token.privateKey = private_key_ptr
            access_token.privateKeyLength = private_key_len
            common_params.accessToken = &access_token
        if params.driver_name is not None:
            driver_name_bytes = params.driver_name.encode()[:30]
            common_params.driverName = driver_name_bytes
            common_params.driverNameLength = <uint32_t> len(driver_name_bytes)

        # set up pool creation parameters
        if dpiContext_initPoolCreateParams(driver_info.context,
                                           &create_params) < 0:
            _raise_from_odpi()
        create_params.minSessions = self.min
        create_params.maxSessions = self.max
        create_params.sessionIncrement = self.increment
        create_params.homogeneous = self.homogeneous
        create_params.getMode = params.getmode
        if params.session_callback is not None \
                and not callable(params.session_callback):
            session_callback_bytes = params.session_callback.encode()
            create_params.plsqlFixupCallback = session_callback_bytes
            create_params.plsqlFixupCallbackLength = \
                    <uint32_t> len(session_callback_bytes)
        if params.access_token_callback is not None:
            create_params.accessTokenCallback = _token_callback_handler
            create_params.accessTokenCallbackContext = <void*> self
        create_params.timeout = params.timeout
        create_params.waitTimeout = params.wait_timeout
        create_params.maxSessionsPerShard = params.max_sessions_per_shard
        create_params.maxLifetimeSession = params.max_lifetime_session
        create_params.pingInterval = params.ping_interval
        create_params.pingTimeout = params.ping_timeout
        common_params.stmtCacheSize = params.stmtcachesize
        common_params.sodaMetadataCache = params.soda_metadata_cache
        create_params.externalAuth = params.externalauth

        # prepare user, password and connect string for use
        if self.username is not None:
            user_bytes = params.get_full_user().encode()
            user_ptr = user_bytes
            user_len = <uint32_t> len(user_bytes)
        password_bytes = params._get_password()
        if password_bytes is not None:
            password_ptr = password_bytes
            password_len = <uint32_t> len(password_bytes)
        if params.thick_mode_dsn_passthrough:
            connect_string = self.dsn
        else:
            connect_string = params._get_connect_string()
        if connect_string is not None:
            connect_string_bytes = connect_string.encode()
            connect_string_ptr = connect_string_bytes
            connect_string_len = <uint32_t> len(connect_string_bytes)

        # create pool
        with nogil:
            status = dpiPool_create(driver_info.context, user_ptr, user_len,
                                    password_ptr, password_len,
                                    connect_string_ptr, connect_string_len,
                                    &common_params, &create_params,
                                    &self._handle)
            dpiContext_getError(driver_info.context, &error_info)
        if status < 0:
            _raise_from_info(&error_info)
        elif error_info.isWarning:
            self.warning = _create_new_from_info(&error_info)

        name_bytes = create_params.outPoolName[:create_params.outPoolNameLength]
        self.name = name_bytes.decode()

    def __dealloc__(self):
        if self._handle != NULL:
            dpiPool_release(self._handle)

    cdef object _token_handler(self, dpiAccessToken *access_token,
                               ConnectParamsImpl params):
        cdef:
            str token, private_key
            bytes token_bytes, private_key_bytes
            uint32_t token_len = 0, private_key_len = 0
            const char *token_ptr = NULL
            const char *private_key_ptr = NULL
        token = params._get_token()
        token_bytes = token.encode()
        token_ptr = token_bytes
        token_len = <uint32_t> len(token_bytes)
        private_key = params._get_private_key()
        if private_key is not None:
            private_key_bytes = private_key.encode()
            private_key_ptr = private_key_bytes
            private_key_len = <uint32_t> len(private_key_bytes)
        access_token.token = token_ptr
        access_token.tokenLength = token_len
        access_token.privateKey = private_key_ptr
        access_token.privateKeyLength = private_key_len

    def close(self, bint force):
        """
        Internal method for closing the pool.
        """
        cdef:
            uint32_t close_mode
            int status
        close_mode = DPI_MODE_POOL_CLOSE_FORCE if force \
                     else DPI_MODE_POOL_CLOSE_DEFAULT
        with nogil:
            status = dpiPool_close(self._handle, close_mode);
        if status < 0:
            _raise_from_odpi()

    def drop(self, ThickConnImpl conn_impl):
        """
        Internal method for dropping a connection from the pool.
        """
        cdef int status
        with nogil:
            status = dpiConn_close(conn_impl._handle, DPI_MODE_CONN_CLOSE_DROP,
                                   NULL, 0)
        if status < 0:
            _raise_from_odpi()
        dpiConn_release(conn_impl._handle)
        conn_impl._handle = NULL

    def get_busy_count(self):
        """
        Internal method for getting the number of busy connections in the pool.
        """
        cdef uint32_t value
        if dpiPool_getBusyCount(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_getmode(self):
        """
        Internal method for getting the method by which connections are
        acquired from the pool.
        """
        cdef uint8_t value
        if dpiPool_getGetMode(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_max_lifetime_session(self):
        """
        Internal method for getting the maximum lifetime of each session.
        """
        cdef uint32_t value
        if dpiPool_getMaxLifetimeSession(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_max_sessions_per_shard(self):
        """
        Internal method for getting the maximum sessions per shard in the pool.
        """
        cdef uint32_t value
        if dpiPool_getMaxSessionsPerShard(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_open_count(self):
        """
        Internal method for getting the number of connections in the pool.
        """
        cdef uint32_t value
        if dpiPool_getOpenCount(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_ping_interval(self):
        """
        Internal method for getting the value of the pool-ping-interval.
        """
        cdef int value
        if dpiPool_getPingInterval(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_soda_metadata_cache(self):
        """
        Internal method for getting the value of soda metadata cache.
        """
        cdef bint value
        if dpiPool_getSodaMetadataCache(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_stmt_cache_size(self):
        """
        Internal method for getting the size of the statement cache.
        """
        cdef uint32_t value
        if dpiPool_getStmtCacheSize(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_timeout(self):
        """
        Internal method for getting the timeout for idle sessions.
        """
        cdef uint32_t value
        if dpiPool_getTimeout(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_wait_timeout(self):
        """
        Internal method for getting the wait timeout for acquiring sessions.
        """
        cdef uint32_t value
        if dpiPool_getWaitTimeout(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def reconfigure(self, uint32_t min, uint32_t max, uint32_t increment):
        """
        Internal method for reconfiguring the size of the pool.
        """
        if dpiPool_reconfigure(self._handle, min, max, increment) < 0:
            _raise_from_odpi()
        self.min = min
        self.max = max
        self.increment = increment

    def set_getmode(self, uint8_t value):
        """
        Internal method for setting the method by which connections are
        acquired from the pool.
        """
        if dpiPool_setGetMode(self._handle, value) < 0:
            _raise_from_odpi()

    def set_max_lifetime_session(self, uint32_t value):
        """
        Internal method for setting the maximum lifetime of each session.
        """
        if dpiPool_setMaxLifetimeSession(self._handle, value) < 0:
            _raise_from_odpi()

    def set_max_sessions_per_shard(self, uint32_t value):
        """
        Internal method for setting the maximum sessions per shard in the pool.
        """
        if dpiPool_setMaxSessionsPerShard(self._handle, value) < 0:
            _raise_from_odpi()

    def set_ping_interval(self, int value):
        """
        Internal method for setting the value of the pool-ping-interval.
        """
        if dpiPool_setPingInterval(self._handle, value) < 0:
            _raise_from_odpi()

    def set_soda_metadata_cache(self, bint value):
        """
        Internal method for enabling or disabling the soda metadata cache.
        """
        if dpiPool_setSodaMetadataCache(self._handle, value) < 0:
            _raise_from_odpi()

    def set_stmt_cache_size(self, uint32_t value):
        """
        Internal method for setting the size of the statement cache.
        """
        if dpiPool_setStmtCacheSize(self._handle, value) < 0:
            _raise_from_odpi()

    def set_timeout(self, uint32_t value):
        """
        Internal method for setting the timeout for idle sessions.
        """
        if dpiPool_setTimeout(self._handle, value) < 0:
            _raise_from_odpi()

    def set_wait_timeout(self, uint32_t value):
        """
        Internal method for setting the wait timeout for acquiring sessions.
        """
        if dpiPool_setWaitTimeout(self._handle, value) < 0:
            _raise_from_odpi()


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thick\queue.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2022, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# queue.pyx
#
# Cython file defining the thick Queue implementation class (embedded in
# thick_impl.pyx).
#------------------------------------------------------------------------------

cdef class ThickQueueImpl(BaseQueueImpl):
    cdef:
        dpiQueue* _handle
        ThickConnImpl _conn_impl

    def __dealloc__(self):
        if self._handle != NULL:
            dpiQueue_release(self._handle)

    def deq_many(self, uint32_t max_num_messages):
        """
        Internal method for dequeuing multiple message from a queue.
        """
        cdef:
            uint32_t num_props = max_num_messages, processed_props = 0, i
            dpiMsgProps** handles
            ThickMsgPropsImpl props
            ssize_t num_bytes
            list result
            int status
        result = []
        num_bytes = num_props * sizeof(dpiMsgProps*)
        handles = <dpiMsgProps**> cpython.PyMem_Malloc(num_bytes)
        try:
            with nogil:
                status = dpiQueue_deqMany(self._handle, &num_props, handles)
            if status < 0:
                _raise_from_odpi()
            for i in range(num_props):
                props = ThickMsgPropsImpl.__new__(ThickMsgPropsImpl)
                props._handle = handles[i]
                processed_props += 1
                props._initialize(self)
                result.append(props)
        finally:
            for i in range(processed_props, num_props):
                dpiMsgProps_release(handles[i])
            cpython.PyMem_Free(handles)
        return result

    def deq_one(self):
        """
        Internal method for dequeuing a single message from a queue.
        """
        cdef:
            ThickMsgPropsImpl props
            int status
        props = ThickMsgPropsImpl.__new__(ThickMsgPropsImpl)
        with nogil:
            status = dpiQueue_deqOne(self._handle, &props._handle)
        if status < 0:
            _raise_from_odpi()
        if props._handle != NULL:
            props._initialize(self)
            return props

    def enq_many(self, list props_impls):
        """
        Internal method for enqueuing many messages into a queue.
        """
        cdef:
            uint32_t i, num_props = 0
            ThickMsgPropsImpl props
            dpiMsgProps **handles
            ssize_t num_bytes
            int status
        num_props = <uint32_t> len(props_impls)
        num_bytes = num_props * sizeof(dpiMsgProps*)
        handles = <dpiMsgProps**> cpython.PyMem_Malloc(num_bytes)
        for i, props in enumerate(props_impls):
            handles[i] = props._handle
        with nogil:
            status = dpiQueue_enqMany(self._handle, num_props, handles)
        cpython.PyMem_Free(handles)
        if status < 0:
            _raise_from_odpi()

    def enq_one(self, ThickMsgPropsImpl props_impl):
        """
        Internal method for enqueuing a single message into a queue.
        """
        cdef int status
        with nogil:
            status = dpiQueue_enqOne(self._handle, props_impl._handle)
        if status < 0:
            _raise_from_odpi()

    def initialize(self, ThickConnImpl conn_impl, str name,
                   ThickDbObjectTypeImpl payload_type, bint is_json):
        """
        Internal method for initializing the queue.
        """
        cdef:
            ThickDeqOptionsImpl deq_options_impl
            ThickEnqOptionsImpl enq_options_impl
            dpiObjectType* type_handle = NULL
            StringBuffer buf = StringBuffer()
        self._conn_impl = conn_impl
        self.is_json = is_json
        buf.set_value(name)
        if is_json:
            if dpiConn_newJsonQueue(conn_impl._handle, buf.ptr, buf.length,
                                    &self._handle) < 0:
                _raise_from_odpi()
        else:
            if payload_type is not None:
                type_handle = payload_type._handle
            if dpiConn_newQueue(conn_impl._handle, buf.ptr, buf.length,
                                type_handle, &self._handle) < 0:
                _raise_from_odpi()
        deq_options_impl = ThickDeqOptionsImpl.__new__(ThickDeqOptionsImpl)
        if dpiQueue_getDeqOptions(self._handle, &deq_options_impl._handle) < 0:
            _raise_from_odpi()
        self.deq_options_impl = deq_options_impl
        enq_options_impl = ThickEnqOptionsImpl.__new__(ThickEnqOptionsImpl)
        if dpiQueue_getEnqOptions(self._handle, &enq_options_impl._handle) < 0:
            _raise_from_odpi()
        self.enq_options_impl = enq_options_impl
        self.payload_type = payload_type
        self.name = name


cdef class ThickDeqOptionsImpl(BaseDeqOptionsImpl):
    cdef:
        dpiDeqOptions* _handle

    def __dealloc__(self):
        if self._handle != NULL:
            dpiDeqOptions_release(self._handle)

    def get_condition(self):
        """
        Internal method for getting the condition.
        """
        cdef:
            uint32_t value_length
            const char *value
        if dpiDeqOptions_getCondition(self._handle, &value, &value_length) < 0:
            _raise_from_odpi()
        if value != NULL:
            return value[:value_length].decode()

    def get_consumer_name(self):
        """
        Internal method for getting the consumer name.
        """
        cdef:
            uint32_t value_length
            const char *value
        if dpiDeqOptions_getConsumerName(self._handle, &value,
                                         &value_length) < 0:
            _raise_from_odpi()
        if value != NULL:
            return value[:value_length].decode()

    def get_correlation(self):
        """
        Internal method for getting the correlation.
        """
        cdef:
            uint32_t value_length
            const char *value
        if dpiDeqOptions_getCorrelation(self._handle, &value,
                                        &value_length) < 0:
            _raise_from_odpi()
        if value != NULL:
            return value[:value_length].decode()

    def get_message_id(self):
        """
        Internal method for getting the message id.
        """
        cdef:
            uint32_t value_length
            const char *value
        if dpiDeqOptions_getMsgId(self._handle, &value, &value_length) < 0:
            _raise_from_odpi()
        if value != NULL:
            return value[:value_length]

    def get_mode(self):
        """
        Internal method for getting the mode.
        """
        cdef uint32_t value
        if dpiDeqOptions_getMode(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_navigation(self):
        """
        Internal method for getting the navigation.
        """
        cdef uint32_t value
        if dpiDeqOptions_getNavigation(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_transformation(self):
        """
        Internal method for getting the transformation.
        """
        cdef:
            uint32_t value_length
            const char *value
        if dpiDeqOptions_getTransformation(self._handle, &value,
                                           &value_length) < 0:
            _raise_from_odpi()
        if value != NULL:
            return value[:value_length].decode()

    def get_visibility(self):
        """
        Internal method for getting the visibility.
        """
        cdef uint32_t value
        if dpiDeqOptions_getVisibility(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_wait(self):
        """
        Internal method for getting the wait.
        """
        cdef uint32_t value
        if dpiDeqOptions_getWait(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def set_condition(self, str value):
        """
        Internal method for setting the condition.
        """
        cdef StringBuffer buf = StringBuffer()
        buf.set_value(value)
        if dpiDeqOptions_setCondition(self._handle, buf.ptr, buf.length) < 0:
            _raise_from_odpi()

    def set_consumer_name(self, str value):
        """
        Internal method for setting the consumer name.
        """
        cdef StringBuffer buf = StringBuffer()
        buf.set_value(value)
        if dpiDeqOptions_setConsumerName(self._handle, buf.ptr,
                                         buf.length) < 0:
            _raise_from_odpi()

    def set_correlation(self, str value):
        """
        Internal method for setting the correlation.
        """
        cdef StringBuffer buf = StringBuffer()
        buf.set_value(value)
        if dpiDeqOptions_setCorrelation(self._handle, buf.ptr, buf.length) < 0:
            _raise_from_odpi()

    def set_delivery_mode(self, uint16_t value):
        """
        Internal method for setting the delivery mode.
        """
        if dpiDeqOptions_setDeliveryMode(self._handle, value) < 0:
            _raise_from_odpi()

    def set_mode(self, uint32_t value):
        """
        Internal method for setting the mode.
        """
        if dpiDeqOptions_setMode(self._handle, value) < 0:
            _raise_from_odpi()

    def set_message_id(self, bytes value):
        """
        Internal method for setting the message id.
        """
        cdef StringBuffer buf = StringBuffer()
        buf.set_value(value)
        if dpiDeqOptions_setMsgId(self._handle, buf.ptr, buf.length) < 0:
            _raise_from_odpi()

    def set_navigation(self, uint32_t value):
        """
        Internal method for setting the navigation.
        """
        if dpiDeqOptions_setNavigation(self._handle, value) < 0:
            _raise_from_odpi()

    def set_transformation(self, str value):
        """
        Internal method for setting the transformation.
        """
        cdef StringBuffer buf = StringBuffer()
        buf.set_value(value)
        if dpiDeqOptions_setTransformation(self._handle, buf.ptr,
                                           buf.length) < 0:
            _raise_from_odpi()

    def set_visibility(self, uint32_t value):
        """
        Internal method for setting the visibility.
        """
        if dpiDeqOptions_setVisibility(self._handle, value) < 0:
            _raise_from_odpi()

    def set_wait(self, uint32_t value):
        """
        Internal method for setting the wait.
        """
        if dpiDeqOptions_setWait(self._handle, value) < 0:
            _raise_from_odpi()


cdef class ThickEnqOptionsImpl(BaseEnqOptionsImpl):
    cdef:
        dpiEnqOptions* _handle

    def __dealloc__(self):
        if self._handle != NULL:
            dpiEnqOptions_release(self._handle)

    def get_transformation(self):
        """
        Internal method for getting the transformation.
        """
        cdef:
            uint32_t value_length
            const char *value
        if dpiEnqOptions_getTransformation(self._handle, &value,
                                           &value_length) < 0:
            _raise_from_odpi()
        if value != NULL:
            return value[:value_length].decode()

    def get_visibility(self):
        """
        Internal method for getting the visibility.
        """
        cdef uint32_t value
        if dpiEnqOptions_getVisibility(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def set_delivery_mode(self, uint16_t value):
        """
        Internal method for setting the delivery mode.
        """
        if dpiEnqOptions_setDeliveryMode(self._handle, value) < 0:
            _raise_from_odpi()

    def set_transformation(self, str value):
        """
        Internal method for setting the transformation.
        """
        cdef StringBuffer buf = StringBuffer()
        buf.set_value(value)
        if dpiEnqOptions_setTransformation(self._handle, buf.ptr,
                                           buf.length) < 0:
            _raise_from_odpi()

    def set_visibility(self, uint32_t value):
        """
        Internal method for setting the visibility.
        """
        if dpiEnqOptions_setVisibility(self._handle, value) < 0:
            _raise_from_odpi()


cdef class ThickMsgPropsImpl(BaseMsgPropsImpl):
    cdef:
        dpiMsgProps* _handle
        ThickConnImpl _conn_impl

    def __dealloc__(self):
        if self._handle != NULL:
            dpiMsgProps_release(self._handle)

    cdef int _initialize(self, ThickQueueImpl queue_impl) except -1:
        cdef:
            dpiObject *payload_obj_handle
            ThickDbObjectImpl obj_impl
            const char *payload_ptr
            uint32_t payload_len
            dpiJsonNode *node
            dpiJson *json

        self._conn_impl = queue_impl._conn_impl
        if queue_impl.is_json:
            if dpiMsgProps_getPayloadJson(self._handle, &json) < 0:
                _raise_from_odpi()
            if dpiJson_getValue(json, DPI_JSON_OPT_NUMBER_AS_STRING,
                                &node) < 0:
                _raise_from_odpi()
            self.payload = _convert_from_json_node(node)
        else:
            if dpiMsgProps_getPayload(self._handle, &payload_obj_handle,
                                      &payload_ptr, &payload_len) < 0:
                _raise_from_odpi()
            if payload_obj_handle != NULL:
                obj_impl = ThickDbObjectImpl.__new__(ThickDbObjectImpl)
                obj_impl.type = queue_impl.payload_type
                if dpiObject_addRef(payload_obj_handle) < 0:
                    _raise_from_odpi()
                obj_impl._handle = payload_obj_handle
                self.payload = PY_TYPE_DB_OBJECT._from_impl(obj_impl)
            else:
                self.payload = payload_ptr[:payload_len]

    def get_num_attempts(self):
        """
        Internal method for getting the number of attempts made.
        """
        cdef int32_t value
        if dpiMsgProps_getNumAttempts(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_correlation(self):
        """
        Internal method for getting the correlation.
        """
        cdef:
            uint32_t value_length
            const char *value
        if dpiMsgProps_getCorrelation(self._handle, &value, &value_length) < 0:
            _raise_from_odpi()
        if value != NULL:
            return value[:value_length].decode()

    def get_delay(self):
        """
        Internal method for getting the delay.
        """
        cdef int32_t value
        if dpiMsgProps_getDelay(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_delivery_mode(self):
        """
        Internal method for getting the delivery mode.
        """
        cdef uint16_t value
        if dpiMsgProps_getDeliveryMode(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_enq_time(self):
        """
        Internal method for getting the enqueue time.
        """
        cdef dpiTimestamp timestamp
        if dpiMsgProps_getEnqTime(self._handle, &timestamp) < 0:
            _raise_from_odpi()
        return cydatetime.datetime_new(timestamp.year, timestamp.month,
                                       timestamp.day, timestamp.hour,
                                       timestamp.minute, timestamp.second,
                                       timestamp.fsecond // 1000, None)

    def get_exception_queue(self):
        """
        Internal method for getting the exception queue.
        """
        cdef:
            uint32_t value_length
            const char *value
        if dpiMsgProps_getExceptionQ(self._handle, &value, &value_length) < 0:
            _raise_from_odpi()
        if value != NULL:
            return value[:value_length].decode()

    def get_expiration(self):
        """
        Internal method for getting the message expiration.
        """
        cdef int32_t value
        if dpiMsgProps_getExpiration(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_message_id(self):
        """
        Internal method for getting the message id.
        """
        cdef:
            uint32_t value_length
            const char *value
        if dpiMsgProps_getMsgId(self._handle, &value, &value_length) < 0:
            _raise_from_odpi()
        if value != NULL:
            return value[:value_length]

    def get_priority(self):
        """
        Internal method for getting the priority.
        """
        cdef int32_t value
        if dpiMsgProps_getPriority(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def get_state(self):
        """
        Internal method for getting the message state.
        """
        cdef uint32_t value
        if dpiMsgProps_getState(self._handle, &value) < 0:
            _raise_from_odpi()
        return value

    def set_correlation(self, str value):
        """
        Internal method for setting the correlation.
        """
        cdef StringBuffer buf = StringBuffer()
        buf.set_value(value)
        if dpiMsgProps_setCorrelation(self._handle, buf.ptr, buf.length) < 0:
            _raise_from_odpi()

    def set_delay(self, int32_t value):
        """
        Internal method for setting the correlation.
        """
        if dpiMsgProps_setDelay(self._handle, value) < 0:
            _raise_from_odpi()

    def set_exception_queue(self, str value):
        """
        Internal method for setting the exception queue.
        """
        cdef StringBuffer buf = StringBuffer()
        buf.set_value(value)
        if dpiMsgProps_setExceptionQ(self._handle, buf.ptr, buf.length) < 0:
            _raise_from_odpi()

    def set_expiration(self, int32_t value):
        """
        Internal method for setting the message expiration.
        """
        if dpiMsgProps_setExpiration(self._handle, value) < 0:
            _raise_from_odpi()

    def set_payload_bytes(self, bytes value):
        """
        Internal method for setting the payload from bytes.
        """
        cdef StringBuffer buf = StringBuffer()
        buf.set_value(value)
        if dpiMsgProps_setPayloadBytes(self._handle, buf.ptr, buf.length) < 0:
            _raise_from_odpi()

    def set_payload_object(self, ThickDbObjectImpl obj_impl):
        """
        Internal method for setting the payload from an object.
        """
        if dpiMsgProps_setPayloadObject(self._handle, obj_impl._handle) < 0:
            _raise_from_odpi()

    def set_payload_json(self, object json_val):
        """
        Internal method for setting the payload from a JSON object
        """
        cdef:
            JsonBuffer json_buf = JsonBuffer()
            dpiJson *json

        json_buf.from_object(json_val)
        if dpiConn_newJson(self._conn_impl._handle, &json) < 0:
            _raise_from_odpi()
        if dpiJson_setValue(json, &json_buf._top_node) < 0:
            _raise_from_odpi()
        if dpiMsgProps_setPayloadJson(self._handle, json) < 0:
            _raise_from_odpi()

    def set_priority(self, int32_t value):
        """
        Internal method for setting the priority.
        """
        if dpiMsgProps_setPriority(self._handle, value) < 0:
            _raise_from_odpi()

    def set_recipients(self, list value):
        """
        Internal method for setting the recipients list.
        """
        cdef:
            dpiMsgRecipient *recipients
            uint32_t num_recipients
            ssize_t num_bytes
            list buffers = []
            StringBuffer buf

        num_recipients = <uint32_t> len(value)
        num_bytes = num_recipients * sizeof(dpiMsgRecipient)
        recipients = <dpiMsgRecipient*> cpython.PyMem_Malloc(num_bytes)
        try:
            for i in range(num_recipients):
                buf = StringBuffer()
                buf.set_value(value[i])
                buffers.append(buf)
                recipients[i].name = buf.ptr
                recipients[i].nameLength = buf.length
            if dpiMsgProps_setRecipients(self._handle, recipients,
                                         num_recipients) < 0:
                _raise_from_odpi()
        finally:
            cpython.PyMem_Free(recipients)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thick\soda.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# soda.pyx
#
# Cython file defining the thick implementation SODA classes (embedded in
# thick_impl.pyx).
#------------------------------------------------------------------------------

cdef class ThickSodaDbImpl(BaseSodaDbImpl):
    cdef:
        dpiSodaDb* _handle

    def __dealloc__(self):
        if self._handle != NULL:
            dpiSodaDb_release(self._handle)

    cdef int _get_flags(self, uint32_t* flags) except -1:
        self._conn._verify_connected()
        if self._conn.autocommit:
            flags[0] = DPI_SODA_FLAGS_ATOMIC_COMMIT
        else:
            flags[0] = DPI_SODA_FLAGS_DEFAULT

    def create_collection(self, str name, str metadata, bint map_mode):
        """
        Internal method for creating a collection.
        """
        cdef:
            StringBuffer metadata_buf = StringBuffer()
            StringBuffer name_buf = StringBuffer()
            ThickSodaCollImpl coll_impl
            uint32_t flags
            int status
        name_buf.set_value(name)
        metadata_buf.set_value(metadata)
        self._get_flags(&flags)
        if map_mode:
            flags |= DPI_SODA_FLAGS_CREATE_COLL_MAP
        coll_impl = ThickSodaCollImpl.__new__(ThickSodaCollImpl)
        coll_impl._db_impl = self
        with nogil:
            status = dpiSodaDb_createCollection(self._handle, name_buf.ptr,
                                                name_buf.length,
                                                metadata_buf.ptr,
                                                metadata_buf.length, flags,
                                                &coll_impl._handle)
        if status < 0:
            _raise_from_odpi()
        coll_impl._get_name()
        return coll_impl

    def create_document(self, bytes content, str key, str media_type):
        """
        Internal method for creating a document containing binary or encoded
        text data.
        """
        cdef:
            StringBuffer media_type_buf = StringBuffer()
            StringBuffer content_buf = StringBuffer()
            StringBuffer key_buf = StringBuffer()
            ThickSodaDocImpl doc_impl
        content_buf.set_value(content)
        key_buf.set_value(key)
        media_type_buf.set_value(media_type)
        doc_impl = ThickSodaDocImpl.__new__(ThickSodaDocImpl)
        if dpiSodaDb_createDocument(self._handle, key_buf.ptr, key_buf.length,
                                    content_buf.ptr, content_buf.length,
                                    media_type_buf.ptr, media_type_buf.length,
                                    DPI_SODA_FLAGS_DEFAULT,
                                    &doc_impl._handle) < 0:
            _raise_from_odpi()
        return doc_impl

    def create_json_document(self, object content, str key):
        """
        Internal method for creating a document containing JSON.
        """
        cdef:
            StringBuffer key_buf = StringBuffer()
            JsonBuffer json_buf = JsonBuffer()
            ThickSodaDocImpl doc_impl
        key_buf.set_value(key)
        json_buf.from_object(content)
        doc_impl = ThickSodaDocImpl.__new__(ThickSodaDocImpl)
        if dpiSodaDb_createJsonDocument(self._handle, key_buf.ptr,
                                        key_buf.length, &json_buf._top_node,
                                        DPI_SODA_FLAGS_DEFAULT,
                                        &doc_impl._handle) < 0:
            _raise_from_odpi()
        return doc_impl

    def get_collection_names(self, str start_name, uint32_t limit):
        """
        Internal method for getting the list of collection names.
        """
        cdef:
            StringBuffer start_name_buf = StringBuffer()
            dpiStringList names
            uint32_t flags
            int status
        start_name_buf.set_value(start_name)
        self._get_flags(&flags)
        with nogil:
            status = dpiSodaDb_getCollectionNames(self._handle,
                                                  start_name_buf.ptr,
                                                  start_name_buf.length,
                                                  limit, flags, &names)
        if status < 0:
            _raise_from_odpi()
        return _string_list_to_python(&names)

    def open_collection(self, str name):
        """
        Internal method for opening a collection.
        """
        cdef:
            StringBuffer name_buf = StringBuffer()
            ThickSodaCollImpl coll_impl
            uint32_t flags
            int status
        name_buf.set_value(name)
        self._get_flags(&flags)
        coll_impl = ThickSodaCollImpl.__new__(ThickSodaCollImpl)
        coll_impl._db_impl = self
        with nogil:
            status = dpiSodaDb_openCollection(self._handle, name_buf.ptr,
                                              name_buf.length, flags,
                                              &coll_impl._handle)
        if status < 0:
            _raise_from_odpi()
        if coll_impl._handle != NULL:
            coll_impl._get_name()
            return coll_impl


cdef class ThickSodaCollImpl(BaseSodaCollImpl):
    cdef:
        ThickSodaDbImpl _db_impl
        dpiSodaColl* _handle

    def __dealloc__(self):
        if self._handle != NULL:
            dpiSodaColl_release(self._handle)

    cdef int _get_name(self) except -1:
        """
        Internal method for getting the name of the collection.
        """
        cdef:
            uint32_t name_len
            const char *name
        if dpiSodaColl_getName(self._handle, &name, &name_len) < 0:
            _raise_from_odpi()
        self.name = name[:name_len].decode()

    cdef int _process_options(self, dpiSodaOperOptions *options,
                              const char *ptr, uint32_t length) except -1:
        """
        Internal method for populating the SODA operations structure with the
        information provided by the user.
        """
        if dpiContext_initSodaOperOptions(driver_info.context, options) < 0:
            _raise_from_odpi()
        options.hint = ptr
        options.hintLength = length

    def create_index(self, str spec):
        """
        Internal method for creating an index on a collection.
        """
        cdef:
            StringBuffer buf = StringBuffer()
            uint32_t flags
            int status
        buf.set_value(spec)
        self._db_impl._get_flags(&flags)
        with nogil:
            status = dpiSodaColl_createIndex(self._handle, buf.ptr, buf.length,
                                             flags)
        if status < 0:
            _raise_from_odpi()

    def drop(self):
        """
        Internal method for dropping a collection.
        """
        cdef:
            bint is_dropped
            uint32_t flags
        self._db_impl._get_flags(&flags)
        if dpiSodaColl_drop(self._handle, flags, &is_dropped) < 0:
            _raise_from_odpi()
        return is_dropped

    def drop_index(self, str name, bint force):
        """
        Internal method for dropping an index on a collection.
        """
        cdef:
            StringBuffer buf = StringBuffer()
            bint is_dropped
            uint32_t flags
            int status
        buf.set_value(name)
        self._db_impl._get_flags(&flags)
        if force:
            flags |= DPI_SODA_FLAGS_INDEX_DROP_FORCE
        with nogil:
            status = dpiSodaColl_dropIndex(self._handle, buf.ptr, buf.length,
                                           flags, &is_dropped)
        if status < 0:
            _raise_from_odpi()
        return is_dropped

    def get_count(self, object op):
        """
        Internal method for getting the count of documents matching the
        criteria.
        """
        cdef:
            ThickSodaOpImpl options = ThickSodaOpImpl._from_op(op)
            uint64_t count
            uint32_t flags
            int status
        self._db_impl._get_flags(&flags)
        with nogil:
            status = dpiSodaColl_getDocCount(self._handle, &options._options,
                                             flags, &count)
        if status < 0:
            _raise_from_odpi()
        return count

    def get_cursor(self, object op):
        """
        Internal method for getting a cursor which will return the documents
        matching the criteria.
        """
        cdef:
            ThickSodaOpImpl options = ThickSodaOpImpl._from_op(op)
            ThickSodaDocCursorImpl cursor_impl
            uint32_t flags
            int status
        self._db_impl._get_flags(&flags)
        cursor_impl = ThickSodaDocCursorImpl.__new__(ThickSodaDocCursorImpl)
        cursor_impl._db_impl = self._db_impl
        with nogil:
            status = dpiSodaColl_find(self._handle, &options._options, flags,
                                      &cursor_impl._handle)
        if status < 0:
            _raise_from_odpi()
        return cursor_impl

    def get_data_guide(self):
        """
        Internal method for getting the data guide for a collection.
        """
        cdef:
            ThickSodaDocImpl doc_impl
            uint32_t flags
            int status
        self._db_impl._get_flags(&flags)
        doc_impl = ThickSodaDocImpl.__new__(ThickSodaDocImpl)
        with nogil:
            status = dpiSodaColl_getDataGuide(self._handle, flags,
                                              &doc_impl._handle)
        if status < 0:
            _raise_from_odpi()
        if doc_impl._handle != NULL:
            return doc_impl

    def get_metadata(self):
        """
        Internal method for getting the metadata for a collection.
        """
        cdef:
            uint32_t value_len
            const char* value
        if dpiSodaColl_getMetadata(self._handle, &value, &value_len) < 0:
            _raise_from_odpi()
        return value[:value_len].decode()

    def get_one(self, object op):
        """
        Internal method for getting a document matching the criteria.
        """
        cdef:
            ThickSodaOpImpl options = ThickSodaOpImpl._from_op(op)
            ThickSodaDocImpl doc_impl
            uint32_t flags
            int status
        self._db_impl._get_flags(&flags)
        doc_impl = ThickSodaDocImpl.__new__(ThickSodaDocImpl)
        with nogil:
            status = dpiSodaColl_findOne(self._handle, &options._options,
                                         flags, &doc_impl._handle)
        if status < 0:
            _raise_from_odpi()
        if doc_impl._handle != NULL:
            return doc_impl

    def insert_many(self, list doc_impls, str hint, bint return_docs):
        """
        Internal method for inserting many documents into a collection at once.
        """
        cdef:
            dpiSodaDoc **output_handles = NULL
            uint32_t i, num_docs, flags
            ThickSodaDocImpl doc_impl
            list output_doc_impls
            dpiSodaDoc **handles
            ssize_t num_bytes
            dpiSodaOperOptions options
            dpiSodaOperOptions *options_ptr = NULL
            StringBuffer hint_buf = StringBuffer()
            int status
        num_docs = <uint32_t> len(doc_impls)
        num_bytes = num_docs * sizeof(dpiSodaDoc *)
        handles = <dpiSodaDoc**> cpython.PyMem_Malloc(num_bytes)
        if return_docs:
            output_handles = <dpiSodaDoc**> _calloc(num_docs,
                                                    sizeof(dpiSodaDoc*))
            if hint is not None:
                hint_buf.set_value(hint)
                options_ptr = &options
                self._process_options(&options, hint_buf.ptr, hint_buf.length)
        for i, doc_impl in enumerate(doc_impls):
            handles[i] = doc_impl._handle
        self._db_impl._get_flags(&flags)
        with nogil:
            status = dpiSodaColl_insertManyWithOptions(self._handle, num_docs,
                                                       handles, options_ptr,
                                                       flags, output_handles)
        if status < 0:
            _raise_from_odpi()
        if return_docs:
            output_doc_impls = []
            for i in range(num_docs):
                doc_impl = ThickSodaDocImpl.__new__(ThickSodaDocImpl)
                doc_impl._handle = output_handles[i]
                output_doc_impls.append(doc_impl)
            return output_doc_impls

    def insert_one(self, ThickSodaDocImpl doc_impl, str hint, bint return_doc):
        """
        Internal method for inserting a single document into a collection.
        """
        cdef:
            dpiSodaDoc **output_handle = NULL
            ThickSodaDocImpl output_doc_impl
            uint32_t flags
            dpiSodaOperOptions options
            dpiSodaOperOptions *options_ptr = NULL
            StringBuffer hint_buf = StringBuffer()
            int status
        if return_doc:
            output_doc_impl = ThickSodaDocImpl.__new__(ThickSodaDocImpl)
            output_handle = &output_doc_impl._handle
            if hint is not None:
               hint_buf.set_value(hint)
               options_ptr = &options
               self._process_options(&options, hint_buf.ptr, hint_buf.length)
        self._db_impl._get_flags(&flags)
        with nogil:
            status = dpiSodaColl_insertOneWithOptions(self._handle,
                                                      doc_impl._handle,
                                                      options_ptr, flags,
                                                      output_handle)
        if status < 0:
            _raise_from_odpi()
        if return_doc:
            return output_doc_impl

    def list_indexes(self):
        """
        Internal method for getting the list of indexes on a collection.
        """
        cdef:
            dpiStringList indexes
            uint32_t flags
            int status
        self._db_impl._get_flags(&flags)
        with nogil:
            status = dpiSodaColl_listIndexes(self._handle, flags, &indexes)
        if status < 0:
            _raise_from_odpi()
        return _string_list_to_python(&indexes)

    def remove(self, object op):
        """
        Internal method for removing all of the documents matching the
        criteria.
        """
        cdef:
            ThickSodaOpImpl options = ThickSodaOpImpl._from_op(op)
            uint64_t count
            uint32_t flags
            int status
        self._db_impl._get_flags(&flags)
        with nogil:
            status = dpiSodaColl_remove(self._handle, &options._options, flags,
                                        &count)
        if status < 0:
            _raise_from_odpi()
        return count

    def replace_one(self, object op, ThickSodaDocImpl doc_impl,
                    bint return_doc):
        """
        Internal method for replacing the document matching the criteria with
        the supplied coument.
        """
        cdef:
            ThickSodaOpImpl options = ThickSodaOpImpl._from_op(op)
            dpiSodaDoc **output_handle = NULL
            ThickSodaDocImpl output_doc_impl
            uint32_t flags
            bint replaced
            int status
        if return_doc:
            output_doc_impl = ThickSodaDocImpl.__new__(ThickSodaDocImpl)
            output_handle = &output_doc_impl._handle
        self._db_impl._get_flags(&flags)
        with nogil:
            status = dpiSodaColl_replaceOne(self._handle, &options._options,
                                            doc_impl._handle, flags, &replaced,
                                            output_handle)
        if status < 0:
            _raise_from_odpi()
        if return_doc:
            return output_doc_impl
        return replaced

    def save(self, ThickSodaDocImpl doc_impl, str hint, bint return_doc):
        """
        Internal method for saving a document into the collection.
        """
        cdef:
            dpiSodaDoc **output_handle = NULL
            ThickSodaDocImpl output_doc_impl
            uint32_t flags
            dpiSodaOperOptions options
            dpiSodaOperOptions *options_ptr = NULL
            StringBuffer hint_buf = StringBuffer()
            int status
        if return_doc:
            output_doc_impl = ThickSodaDocImpl.__new__(ThickSodaDocImpl)
            output_handle = &output_doc_impl._handle
            if hint is not None:
               hint_buf.set_value(hint)
               options_ptr = &options
               self._process_options(&options, hint_buf.ptr, hint_buf.length)
        self._db_impl._get_flags(&flags)
        with nogil:
            status = dpiSodaColl_saveWithOptions(self._handle,
                                                 doc_impl._handle,
                                                 options_ptr, flags,
                                                 output_handle)
        if status < 0:
            _raise_from_odpi()
        if return_doc:
            return output_doc_impl

    def truncate(self):
        """
        Internal method for truncating the collection (removing all documents
        from it).
        """
        cdef int status
        with nogil:
            status = dpiSodaColl_truncate(self._handle)
        if status < 0:
            _raise_from_odpi()


cdef class ThickSodaDocImpl(BaseSodaDocImpl):
    cdef:
        dpiSodaDoc* _handle

    def __dealloc__(self):
        if self._handle != NULL:
            dpiSodaDoc_release(self._handle)

    def get_content(self):
        """
        Internal method for returning the content of the document.
        """
        cdef:
            object out_content = None
            str out_encoding = None
            const char *encoding
            uint32_t content_len
            const char *content
            dpiJson *json
            bint is_json
        if dpiSodaDoc_getIsJson(self._handle, &is_json) < 0:
            _raise_from_odpi()
        if is_json:
            if dpiSodaDoc_getJsonContent(self._handle, &json) < 0:
                _raise_from_odpi()
            out_content = _convert_json_to_python(json)
        else:
            if dpiSodaDoc_getContent(self._handle, &content, &content_len,
                                    &encoding) < 0:
                _raise_from_odpi()
            if content != NULL:
                out_content = content[:content_len]
            if encoding != NULL:
                out_encoding = encoding.decode()
            else:
                out_encoding = "UTF-8"
        return (out_content, out_encoding)

    def get_created_on(self):
        """
        Internal method for getting the date the document was created.
        """
        cdef:
            uint32_t value_len
            const char *value
        if dpiSodaDoc_getCreatedOn(self._handle, &value, &value_len) < 0:
            _raise_from_odpi()
        if value_len > 0:
            return value[:value_len].decode()

    def get_key(self):
        """
        Internal method for getting the key of the document.
        """
        cdef:
            uint32_t value_len
            const char *value
        if dpiSodaDoc_getKey(self._handle, &value, &value_len) < 0:
            _raise_from_odpi()
        if value_len > 0:
            return value[:value_len].decode()

    def get_last_modified(self):
        """
        Internal method for getting the date the document was last modified.
        """
        cdef:
            uint32_t value_len
            const char *value
        if dpiSodaDoc_getLastModified(self._handle, &value, &value_len) < 0:
            _raise_from_odpi()
        if value_len > 0:
            return value[:value_len].decode()

    def get_media_type(self):
        """
        Internal method for getting the media type of the document.
        """
        cdef:
            uint32_t value_len
            const char *value
        if dpiSodaDoc_getMediaType(self._handle, &value, &value_len) < 0:
            _raise_from_odpi()
        if value_len > 0:
            return value[:value_len].decode()

    def get_version(self):
        """
        Internal method for getting the version of the document.
        """
        cdef:
            uint32_t value_len
            const char *value
        if dpiSodaDoc_getVersion(self._handle, &value, &value_len) < 0:
            _raise_from_odpi()
        if value_len > 0:
            return value[:value_len].decode()


cdef class ThickSodaDocCursorImpl(BaseSodaDocCursorImpl):
    cdef:
        dpiSodaDocCursor* _handle
        ThickSodaDbImpl _db_impl

    def __dealloc__(self):
        if self._handle != NULL:
            dpiSodaDocCursor_release(self._handle)

    def close(self):
        """
        Internal method for closing the cursor.
        """
        cdef int status
        with nogil:
            status = dpiSodaDocCursor_close(self._handle)
        if status < 0:
            _raise_from_odpi()

    def get_next_doc(self):
        """
        Internal method for getting the next document from the cursor.
        """
        cdef:
            ThickSodaDocImpl doc_impl
            int status
        doc_impl = ThickSodaDocImpl.__new__(ThickSodaDocImpl)
        with nogil:
            status = dpiSodaDocCursor_getNext(self._handle,
                                              DPI_SODA_FLAGS_DEFAULT,
                                              &doc_impl._handle)
        if status < 0:
            _raise_from_odpi()
        if doc_impl._handle != NULL:
            return doc_impl


cdef class ThickSodaOpImpl:
    cdef:
        dpiSodaOperOptions _options
        const char** _key_values
        uint32_t* _key_lengths
        list _buffers

    def __dealloc__(self):
        if self._key_values != NULL:
            cpython.PyMem_Free(self._key_values)
        if self._key_lengths != NULL:
            cpython.PyMem_Free(self._key_lengths)

    cdef int _add_buf(self, object value, const char **ptr,
                      uint32_t *length) except -1:
        cdef StringBuffer buf = StringBuffer()
        buf.set_value(value)
        self._buffers.append(buf)
        ptr[0] = buf.ptr
        length[0] = buf.length

    @staticmethod
    cdef ThickSodaOpImpl _from_op(object op):
        """
        Internal method for creating a SODA operations implementation object
        given the object supplied by the user.
        """
        cdef:
            ThickSodaOpImpl impl = ThickSodaOpImpl.__new__(ThickSodaOpImpl)
            dpiSodaOperOptions *options
            ssize_t num_bytes
            uint32_t i
        impl._buffers = []
        options = &impl._options
        if dpiContext_initSodaOperOptions(driver_info.context, options) < 0:
            _raise_from_odpi()
        if op._keys:
            options.numKeys = <uint32_t> len(op._keys)
            num_bytes = options.numKeys * sizeof(char*)
            impl._key_values = <const char**> cpython.PyMem_Malloc(num_bytes)
            num_bytes = options.numKeys * sizeof(uint32_t)
            impl._key_lengths = <uint32_t*> cpython.PyMem_Malloc(num_bytes)
            options.keys = impl._key_values
            options.keyLengths = impl._key_lengths
            for i in range(options.numKeys):
                impl._add_buf(op._keys[i], &impl._key_values[i],
                              &impl._key_lengths[i])
        if op._key is not None:
            impl._add_buf(op._key, &options.key, &options.keyLength)
        if op._version is not None:
            impl._add_buf(op._version, &options.version,
                          &options.versionLength)
        if op._filter is not None:
            impl._add_buf(op._filter, &options.filter, &options.filterLength)
        if op._hint is not None:
            impl._add_buf(op._hint, &options.hint, &options.hintLength)
        if op._skip is not None:
            options.skip = op._skip
        if op._limit is not None:
            options.limit = op._limit
        if op._fetch_array_size is not None:
            options.fetchArraySize = op._fetch_array_size
        if op._lock:
            options.lock = True
        return impl


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thick\subscr.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# subscr.pyx
#
# Cython file defining the thick Subscription implementation class (embedded in
# thick_impl.pyx).
#------------------------------------------------------------------------------

cdef int _callback_handler(void* context,
                           dpiSubscrMessage* message) except -1 with gil:
    cdef:
        object subscr = <object> context
        ThickSubscrImpl subscr_impl
        object py_message
    if message.errorInfo:
        _raise_from_info(message.errorInfo)
    else:
        subscr_impl = subscr._impl
        py_message = PY_TYPE_MESSAGE(subscr)
        subscr_impl._populate_message(message, py_message)
        subscr.callback(py_message)


cdef class ThickSubscrImpl(BaseSubscrImpl):
    cdef:
        dpiSubscr* _handle

    def __dealloc__(self):
        if self._handle != NULL:
            dpiSubscr_release(self._handle)

    cdef object _create_message_query(self, dpiSubscrMessageQuery* query):
        cdef:
            object py_query = PY_TYPE_MESSAGE_QUERY()
            uint32_t i
            list temp
        py_query._id = query.id
        py_query._operation = query.operation
        temp = py_query._tables
        for i in range(query.numTables):
            temp.append(self._create_message_table(&query.tables[i]))
        return py_query

    cdef object _create_message_row(self, dpiSubscrMessageRow* row):
        cdef object py_row = PY_TYPE_MESSAGE_ROW()
        py_row._operation = row.operation
        py_row._rowid = row.rowid[:row.rowidLength].decode()
        return py_row

    cdef object _create_message_table(self, dpiSubscrMessageTable* table):
        cdef:
            object py_table = PY_TYPE_MESSAGE_TABLE()
            uint32_t i
            list temp
        py_table._operation = table.operation
        py_table._name = table.name[:table.nameLength].decode()
        temp = py_table._rows
        for i in range(table.numRows):
            temp.append(self._create_message_row(&table.rows[i]))
        return py_table

    cdef object _populate_message(self, dpiSubscrMessage* message,
                                  object py_message):
        cdef:
            const char* txid
            list temp
            uint32_t i
        py_message._type = message.eventType
        py_message._registered = message.registered
        py_message._dbname = message.dbName[:message.dbNameLength].decode()
        if message.txId != NULL:
            txid = <const char*> message.txId
            py_message._txid = txid[:message.txIdLength]
        if message.queueName != NULL:
            py_message._queue_name = \
                    message.queueName[:message.queueNameLength].decode()
        if message.consumerName != NULL:
            py_message._consumer_name = \
                    message.consumerName[:message.consumerNameLength].decode()
        if message.aqMsgId != NULL:
            msgid = <const char*> message.aqMsgId
            py_message._msgid = msgid[:message.aqMsgIdLength]
        if message.eventType == DPI_EVENT_OBJCHANGE:
            temp = py_message._tables
            for i in range(message.numTables):
                temp.append(self._create_message_table(&message.tables[i]))
        elif message.eventType == DPI_EVENT_QUERYCHANGE:
            temp = py_message._queries
            for i in range(message.numQueries):
                temp.append(self._create_message_query(&message.queries[i]))

    def register_query(self, str sql, object args):
        """
        Internal method for registering a query.
        """
        cdef:
            StringBuffer sql_buf = StringBuffer()
            ThickCursorImpl cursor_impl
            uint64_t query_id
            object cursor
        sql_buf.set_value(sql)
        cursor = self.connection.cursor()
        cursor_impl = <ThickCursorImpl> cursor._impl
        if dpiSubscr_prepareStmt(self._handle, sql_buf.ptr, sql_buf.length,
                                 &cursor_impl._handle) < 0:
            _raise_from_odpi()
        if args is not None:
            cursor_impl.bind_one(cursor, args)
        cursor_impl.execute(cursor)
        if self.qos & DPI_SUBSCR_QOS_QUERY:
            if dpiStmt_getSubscrQueryId(cursor_impl._handle, &query_id) < 0:
                _raise_from_odpi()
            return query_id

    def subscribe(self, object subscr, ThickConnImpl conn_impl):
        """
        Internal method for creating the subscription.
        """
        cdef:
            StringBuffer ip_address_buf = StringBuffer()
            StringBuffer name_buf = StringBuffer()
            dpiSubscrCreateParams params
            int status
        name_buf.set_value(self.name)
        ip_address_buf.set_value(self.ip_address)
        if dpiContext_initSubscrCreateParams(driver_info.context, &params) < 0:
            _raise_from_odpi()
        params.subscrNamespace = self.namespace
        params.protocol = self.protocol
        params.qos = self.qos
        params.operations = self.operations
        params.portNumber = self.port
        params.timeout = self.timeout
        params.name = name_buf.ptr
        params.nameLength = name_buf.length
        if self.callback is not None:
            params.callback = <dpiSubscrCallback> _callback_handler
            params.callbackContext = <void*> subscr
        params.ipAddress = ip_address_buf.ptr
        params.ipAddressLength = ip_address_buf.length
        params.groupingClass = self.grouping_class
        params.groupingType = self.grouping_type
        params.groupingValue = self.grouping_value
        params.clientInitiated = self.client_initiated
        with nogil:
            status = dpiConn_subscribe(conn_impl._handle, &params,
                                       &self._handle)
        if status < 0:
            _raise_from_odpi()
        self.id = params.outRegId

    def unsubscribe(self, ThickConnImpl conn_impl):
        """
        Internal method for destroying the subscription.
        """
        cdef int status
        with nogil:
            status = dpiConn_unsubscribe(conn_impl._handle, self._handle)
        if status < 0:
            _raise_from_odpi()


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thick\utils.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# utils.pyx
#
# Cython file for utility functions (embedded in thick_impl.pyx).
#------------------------------------------------------------------------------

cdef array.array float_template = array.array('f')
cdef array.array double_template = array.array('d')
cdef array.array int8_template = array.array('b')
cdef array.array uint8_template = array.array('B')

cdef object _convert_from_json_node(dpiJsonNode *node):
    cdef:
        VectorDecoder vector_decoder
        dpiTimestamp *as_timestamp
        dpiIntervalDS *as_interval
        dpiJsonArray *array
        dpiBytes *as_bytes
        dpiJsonObject *obj
        dict dict_value
        list list_value
        int32_t seconds
        DbType dbtype
        uint32_t i
        bytes temp
        str key
    if node.nativeTypeNum == DPI_NATIVE_TYPE_NULL:
        return None
    elif node.oracleTypeNum == DPI_ORACLE_TYPE_NUMBER:
        if node.nativeTypeNum == DPI_NATIVE_TYPE_DOUBLE:
            return node.value.asDouble
        elif node.nativeTypeNum == DPI_NATIVE_TYPE_FLOAT:
            return node.value.asFloat
        as_bytes = &node.value.asBytes
        return PY_TYPE_DECIMAL(as_bytes.ptr[:as_bytes.length].decode())
    elif node.oracleTypeNum == DPI_ORACLE_TYPE_VARCHAR:
        as_bytes = &node.value.asBytes
        return as_bytes.ptr[:as_bytes.length].decode()
    elif node.oracleTypeNum == DPI_ORACLE_TYPE_RAW:
        return node.value.asBytes.ptr[:node.value.asBytes.length]
    elif node.oracleTypeNum == DPI_ORACLE_TYPE_DATE \
            or node.oracleTypeNum == DPI_ORACLE_TYPE_TIMESTAMP:
        as_timestamp = &node.value.asTimestamp
        return cydatetime.datetime_new(as_timestamp.year, as_timestamp.month,
                                       as_timestamp.day, as_timestamp.hour,
                                       as_timestamp.minute,
                                       as_timestamp.second,
                                       as_timestamp.fsecond // 1000, None)
    elif node.oracleTypeNum == DPI_ORACLE_TYPE_BOOLEAN:
        return node.value.asBoolean
    elif node.oracleTypeNum == DPI_ORACLE_TYPE_INTERVAL_DS:
        as_interval = &node.value.asIntervalDS
        seconds = as_interval.hours * 60 * 60 + as_interval.minutes * 60 + \
                as_interval.seconds
        return cydatetime.timedelta_new(as_interval.days, seconds,
                                        as_interval.fseconds // 1000)
    elif node.oracleTypeNum == DPI_ORACLE_TYPE_JSON_OBJECT:
        obj = &node.value.asJsonObject
        dict_value = {}
        for i in range(obj.numFields):
            key = obj.fieldNames[i][:obj.fieldNameLengths[i]].decode()
            dict_value[key] = _convert_from_json_node(&obj.fields[i])
        return dict_value
    elif node.oracleTypeNum == DPI_ORACLE_TYPE_JSON_ARRAY:
        array = &node.value.asJsonArray
        list_value = [None] * array.numElements
        for i in range(array.numElements):
            list_value[i] = _convert_from_json_node(&array.elements[i])
        return list_value
    elif node.oracleTypeNum == DPI_ORACLE_TYPE_VECTOR:
        as_bytes = &node.value.asBytes
        vector_decoder = VectorDecoder.__new__(VectorDecoder)
        return vector_decoder.decode(as_bytes.ptr[:as_bytes.length])
    elif node.oracleTypeNum == DPI_ORACLE_TYPE_JSON_ID:
        temp = node.value.asBytes.ptr[:node.value.asBytes.length]
        return PY_TYPE_JSON_ID(temp)
    dbtype = DbType._from_num(node.oracleTypeNum)
    errors._raise_err(errors.ERR_DB_TYPE_NOT_SUPPORTED, name=dbtype.name)


cdef int _convert_from_python(object value, OracleMetadata metadata,
                              dpiDataBuffer *dbvalue,
                              StringBuffer buf) except -1:
    cdef:
        uint32_t oracle_type = metadata.dbtype.num
        SparseVectorImpl sparse_impl
        ThickDbObjectImpl obj_impl
        dpiVectorInfo vector_info
        dpiTimestamp *timestamp
        ThickLobImpl lob_impl
        int seconds, status
        JsonBuffer json_buf
        dpiVector *vector
    if oracle_type == DPI_ORACLE_TYPE_NUMBER:
        if isinstance(value, bool):
            if value:
                buf.set_value("1")
            else:
                buf.set_value("0")
        elif isinstance(value, (int, float, PY_TYPE_DECIMAL)):
            buf.set_value((<str> cpython.PyObject_Str(value)).encode())
        else:
            message = f"expecting number, got {type(value)}"
            raise TypeError(message)
        dbvalue.asBytes.ptr = buf.ptr
        dbvalue.asBytes.length = buf.length
    elif oracle_type == DPI_ORACLE_TYPE_NATIVE_DOUBLE \
            or oracle_type == DPI_ORACLE_TYPE_NATIVE_FLOAT:
        if oracle_type == DPI_ORACLE_TYPE_NATIVE_DOUBLE:
            dbvalue.asDouble = <double> value
        else:
            dbvalue.asFloat = <float> value
    elif oracle_type == DPI_ORACLE_TYPE_VARCHAR \
            or oracle_type == DPI_ORACLE_TYPE_NVARCHAR \
            or oracle_type == DPI_ORACLE_TYPE_CHAR \
            or oracle_type == DPI_ORACLE_TYPE_NCHAR \
            or oracle_type == DPI_ORACLE_TYPE_LONG_VARCHAR:
        buf.set_value(value)
        dbvalue.asBytes.ptr = buf.ptr
        dbvalue.asBytes.length = buf.length
    elif oracle_type == DPI_ORACLE_TYPE_RAW \
            or oracle_type == DPI_ORACLE_TYPE_LONG_RAW:
        buf.set_value(value)
        dbvalue.asBytes.ptr = buf.ptr
        dbvalue.asBytes.length = buf.length
    elif oracle_type == DPI_ORACLE_TYPE_DATE \
            or oracle_type == DPI_ORACLE_TYPE_TIMESTAMP \
            or oracle_type == DPI_ORACLE_TYPE_TIMESTAMP_LTZ \
            or oracle_type == DPI_ORACLE_TYPE_TIMESTAMP_TZ:
        memset(&dbvalue.asTimestamp, 0, sizeof(dbvalue.asTimestamp))
        timestamp = &dbvalue.asTimestamp
        timestamp.year = cydatetime.PyDateTime_GET_YEAR(value)
        timestamp.month = cydatetime.PyDateTime_GET_MONTH(value)
        timestamp.day = cydatetime.PyDateTime_GET_DAY(value)
        if cydatetime.PyDateTime_Check(value):
            timestamp.hour = cydatetime.PyDateTime_DATE_GET_HOUR(value)
            timestamp.minute = cydatetime.PyDateTime_DATE_GET_MINUTE(value)
            timestamp.second = cydatetime.PyDateTime_DATE_GET_SECOND(value)
            timestamp.fsecond = \
                    cydatetime.PyDateTime_DATE_GET_MICROSECOND(value) * 1000
    elif oracle_type == DPI_ORACLE_TYPE_BOOLEAN:
        dbvalue.asBoolean = <bint> value
    elif oracle_type == DPI_ORACLE_TYPE_NATIVE_INT:
        if isinstance(value, bool):
            dbvalue.asInt64 = 1 if value else 0
        else:
            dbvalue.asInt64 = <int64_t> value
    elif oracle_type == DPI_ORACLE_TYPE_INTERVAL_DS:
        seconds = cydatetime.timedelta_seconds(value)
        dbvalue.asIntervalDS.days = cydatetime.timedelta_days(value)
        dbvalue.asIntervalDS.hours = seconds // 3600
        seconds = seconds % 3600
        dbvalue.asIntervalDS.minutes = seconds // 60
        dbvalue.asIntervalDS.seconds = seconds % 60
        dbvalue.asIntervalDS.fseconds = \
                cydatetime.timedelta_microseconds(value) * 1000
    elif oracle_type == DPI_ORACLE_TYPE_OBJECT:
        if not isinstance(value, PY_TYPE_DB_OBJECT):
            raise TypeError("expecting DbObject")
        obj_impl = <ThickDbObjectImpl> value._impl
        dbvalue.asObject = obj_impl._handle
    elif oracle_type == DPI_ORACLE_TYPE_CLOB \
            or oracle_type == DPI_ORACLE_TYPE_BLOB \
            or oracle_type == DPI_ORACLE_TYPE_NCLOB \
            or oracle_type == DPI_ORACLE_TYPE_BFILE:
        if isinstance(value, PY_TYPE_LOB):
            lob_impl = value._impl
            dbvalue.asLOB = lob_impl._handle
        else:
            buf.set_value(value)
            dbvalue.asBytes.ptr = buf.ptr
            dbvalue.asBytes.length = buf.length
    elif oracle_type == DPI_ORACLE_TYPE_JSON:
        json_buf = JsonBuffer()
        json_buf.from_object(value)
        if dpiJson_setValue(dbvalue.asJson, &json_buf._top_node) < 0:
            _raise_from_odpi()
    elif oracle_type == DPI_ORACLE_TYPE_VECTOR:
        if isinstance(value, PY_TYPE_SPARSE_VECTOR):
            sparse_impl = <SparseVectorImpl> value._impl
            vector_info.numDimensions = <uint32_t> sparse_impl.num_dimensions
            vector_info.numSparseValues = <uint32_t> len(sparse_impl.indices)
            vector_info.sparseIndices = \
                    <uint32_t*> sparse_impl.indices.data.as_voidptr
            value = sparse_impl.values
        else:
            vector_info.numDimensions = <uint32_t> len(value)
            vector_info.numSparseValues = 0
            vector_info.sparseIndices = NULL
        if value.typecode == 'd':
            vector_info.format = DPI_VECTOR_FORMAT_FLOAT64
        elif value.typecode == 'f':
            vector_info.format = DPI_VECTOR_FORMAT_FLOAT32
        elif value.typecode == 'B':
            vector_info.format = DPI_VECTOR_FORMAT_BINARY
            vector_info.numDimensions *= 8
        else:
            vector_info.format = DPI_VECTOR_FORMAT_INT8
        vector_info.dimensions.asPtr = (<array.array> value).data.as_voidptr
        if dpiVector_setValue(dbvalue.asVector, &vector_info) < 0:
            _raise_from_odpi()
    elif oracle_type == DPI_ORACLE_TYPE_INTERVAL_YM:
        dbvalue.asIntervalYM.years = (<tuple> value)[0]
        dbvalue.asIntervalYM.months = (<tuple> value)[1]
    else:
        errors._raise_err(errors.ERR_DB_TYPE_NOT_SUPPORTED,
                          name=metadata.dbtype.name)


cdef object _convert_json_to_python(dpiJson *json):
    """
    Converts a dpiJson value to its Python equivalent.
    """
    cdef dpiJsonNode *json_node
    if dpiJson_getValue(json, DPI_JSON_OPT_NUMBER_AS_STRING, &json_node) < 0:
        _raise_from_odpi()
    return _convert_from_json_node(json_node)


cdef object _convert_oci_attr_to_python(uint32_t attr_type,
                                        dpiDataBuffer *value,
                                        uint32_t value_len):
    """
    Convert an OCI attribute value to a Python value.
    """
    if attr_type == PYO_OCI_ATTR_TYPE_STRING:
        if value.asString == NULL:
            return None
        return value.asString[:value_len].decode()
    elif attr_type == PYO_OCI_ATTR_TYPE_BOOLEAN:
        return value.asBoolean
    elif attr_type == PYO_OCI_ATTR_TYPE_UINT8:
        return value.asUint8
    elif attr_type == PYO_OCI_ATTR_TYPE_UINT16:
        return value.asUint16
    elif attr_type == PYO_OCI_ATTR_TYPE_UINT32:
        return value.asUint32
    elif attr_type == PYO_OCI_ATTR_TYPE_UINT64:
        return value.asUint64
    errors._raise_err(errors.ERR_INVALID_OCI_ATTR_TYPE, attr_type=attr_type)


cdef int _convert_python_to_oci_attr(object value, uint32_t attr_type,
                                     StringBuffer str_buf,
                                     dpiDataBuffer *oci_buf,
                                     void **oci_value,
                                     uint32_t *oci_len) except -1:
    """
    Convert a Python value to the format required by an OCI attribute.
    """
    if attr_type == PYO_OCI_ATTR_TYPE_STRING:
        str_buf.set_value(value)
        oci_value[0] = str_buf.ptr
        oci_len[0] = str_buf.length
    elif attr_type == PYO_OCI_ATTR_TYPE_BOOLEAN:
        oci_buf.asBoolean = value
        oci_value[0] = &oci_buf.asBoolean
        oci_len[0] = sizeof(oci_buf.asBoolean)
    elif attr_type == PYO_OCI_ATTR_TYPE_UINT8:
        oci_buf.asUint8 = value
        oci_value[0] = &oci_buf.asUint8
        oci_len[0] = sizeof(oci_buf.asUint8)
    elif attr_type == PYO_OCI_ATTR_TYPE_UINT16:
        oci_buf.asUint16 = value
        oci_value[0] = &oci_buf.asUint16
        oci_len[0] = sizeof(oci_buf.asUint16)
    elif attr_type == PYO_OCI_ATTR_TYPE_UINT32:
        oci_buf.asUint32 = value
        oci_value[0] = &oci_buf.asUint32
        oci_len[0] = sizeof(oci_buf.asUint32)
    elif attr_type == PYO_OCI_ATTR_TYPE_UINT64:
        oci_buf.asUint64 = value
        oci_value[0] = &oci_buf.asUint64
        oci_len[0] = sizeof(oci_buf.asUint64)
    else:
        errors._raise_err(errors.ERR_INVALID_OCI_ATTR_TYPE,
                          attr_type=attr_type)


cdef object _convert_to_python(ThickConnImpl conn_impl,
                               OracleMetadata metadata,
                               dpiDataBuffer *dbvalue,
                               bint bypass_decode=False,
                               const char* encoding_errors=NULL):
    cdef:
        uint32_t oracle_type = metadata.dbtype.num
        ThickDbObjectImpl obj_impl
        dpiTimestamp *as_timestamp
        ThickLobImpl lob_impl
        uint32_t rowid_length
        dpiBytes *as_bytes
        const char *rowid
        int32_t seconds
    if bypass_decode:
        oracle_type = DPI_ORACLE_TYPE_RAW
    if oracle_type == DPI_ORACLE_TYPE_CHAR \
            or oracle_type == DPI_ORACLE_TYPE_NCHAR \
            or oracle_type == DPI_ORACLE_TYPE_VARCHAR \
            or oracle_type == DPI_ORACLE_TYPE_NVARCHAR \
            or oracle_type == DPI_ORACLE_TYPE_LONG_VARCHAR \
            or oracle_type == DPI_ORACLE_TYPE_LONG_NVARCHAR \
            or oracle_type == DPI_ORACLE_TYPE_XMLTYPE:
        as_bytes = &dbvalue.asBytes
        return as_bytes.ptr[:as_bytes.length].decode("utf-8", encoding_errors)
    elif oracle_type == DPI_ORACLE_TYPE_NUMBER:
        as_bytes = &dbvalue.asBytes
        if metadata._py_type_num == PY_TYPE_NUM_INT \
                and memchr(as_bytes.ptr, b'.', as_bytes.length) == NULL:
            return int(as_bytes.ptr[:as_bytes.length])
        elif metadata._py_type_num == PY_TYPE_NUM_DECIMAL:
            return PY_TYPE_DECIMAL(as_bytes.ptr[:as_bytes.length].decode())
        return float(as_bytes.ptr[:as_bytes.length])
    elif oracle_type == DPI_ORACLE_TYPE_RAW \
            or oracle_type == DPI_ORACLE_TYPE_LONG_RAW:
        as_bytes = &dbvalue.asBytes
        return as_bytes.ptr[:as_bytes.length]
    elif oracle_type == DPI_ORACLE_TYPE_DATE \
            or oracle_type == DPI_ORACLE_TYPE_TIMESTAMP \
            or oracle_type == DPI_ORACLE_TYPE_TIMESTAMP_LTZ \
            or oracle_type == DPI_ORACLE_TYPE_TIMESTAMP_TZ:
        as_timestamp = &dbvalue.asTimestamp
        return cydatetime.datetime_new(as_timestamp.year, as_timestamp.month,
                                       as_timestamp.day, as_timestamp.hour,
                                       as_timestamp.minute,
                                       as_timestamp.second,
                                       as_timestamp.fsecond // 1000, None)
    elif oracle_type == DPI_ORACLE_TYPE_BOOLEAN:
        return dbvalue.asBoolean == 1
    elif oracle_type == DPI_ORACLE_TYPE_NATIVE_DOUBLE:
        return dbvalue.asDouble
    elif oracle_type == DPI_ORACLE_TYPE_NATIVE_FLOAT:
        return dbvalue.asFloat
    elif oracle_type == DPI_ORACLE_TYPE_NATIVE_INT:
        return dbvalue.asInt64
    elif oracle_type == DPI_ORACLE_TYPE_ROWID:
        if dpiRowid_getStringValue(dbvalue.asRowid, &rowid, &rowid_length) < 0:
            _raise_from_odpi()
        return rowid[:rowid_length].decode()
    elif oracle_type == DPI_ORACLE_TYPE_CLOB \
            or oracle_type == DPI_ORACLE_TYPE_BLOB \
            or oracle_type == DPI_ORACLE_TYPE_NCLOB \
            or oracle_type == DPI_ORACLE_TYPE_BFILE:
        lob_impl = ThickLobImpl._create(conn_impl, metadata.dbtype,
                                        dbvalue.asLOB)
        return PY_TYPE_LOB._from_impl(lob_impl)
    elif oracle_type == DPI_ORACLE_TYPE_OBJECT:
        obj_impl = ThickDbObjectImpl.__new__(ThickDbObjectImpl)
        obj_impl.type = metadata.objtype
        if dpiObject_addRef(dbvalue.asObject) < 0:
            _raise_from_odpi()
        obj_impl._handle = dbvalue.asObject
        return PY_TYPE_DB_OBJECT._from_impl(obj_impl)
    elif oracle_type == DPI_ORACLE_TYPE_INTERVAL_DS:
        seconds = dbvalue.asIntervalDS.hours * 60 * 60 + \
                dbvalue.asIntervalDS.minutes * 60 + \
                dbvalue.asIntervalDS.seconds
        return cydatetime.timedelta_new(dbvalue.asIntervalDS.days, seconds,
                                        dbvalue.asIntervalDS.fseconds // 1000)
    elif oracle_type == DPI_ORACLE_TYPE_JSON:
        return _convert_json_to_python(dbvalue.asJson)
    elif oracle_type == DPI_ORACLE_TYPE_VECTOR:
        return _convert_vector_to_python(dbvalue.asVector)
    elif oracle_type == DPI_ORACLE_TYPE_INTERVAL_YM:
        return PY_TYPE_INTERVAL_YM(dbvalue.asIntervalYM.years,
                                   dbvalue.asIntervalYM.months)
    errors._raise_err(errors.ERR_DB_TYPE_NOT_SUPPORTED,
                      name=metadata.dbtype.name)


cdef object _convert_vector_to_python(dpiVector *vector):
    """
    Converts a vector to a Python array.
    """
    cdef:
        array.array result, indices_template, sparse_indices
        uint32_t num_elements, num_bytes
        SparseVectorImpl sparse_impl
        dpiVectorInfo vector_info
    if dpiVector_getValue(vector, &vector_info) < 0:
        _raise_from_odpi()
    if vector_info.numSparseValues > 0:
        num_elements = vector_info.numSparseValues
    else:
        num_elements = vector_info.numDimensions
    if vector_info.format == DPI_VECTOR_FORMAT_FLOAT32:
        result = array.clone(float_template, num_elements, False)
        num_bytes = num_elements * vector_info.dimensionSize
    elif vector_info.format == DPI_VECTOR_FORMAT_FLOAT64:
        result = array.clone(double_template, num_elements, False)
        num_bytes = num_elements * vector_info.dimensionSize
    elif vector_info.format == DPI_VECTOR_FORMAT_INT8:
        result = array.clone(int8_template, num_elements, False)
        num_bytes = num_elements
    elif vector_info.format == DPI_VECTOR_FORMAT_BINARY:
        num_bytes = num_elements // 8
        result = array.clone(uint8_template, num_bytes, False)
    memcpy(result.data.as_voidptr, vector_info.dimensions.asPtr, num_bytes)
    if vector_info.numSparseValues > 0:
        sparse_impl = SparseVectorImpl.__new__(SparseVectorImpl)
        sparse_impl.num_dimensions = vector_info.numDimensions
        indices_template = array.array(ARRAY_TYPE_CODE_UINT32)
        sparse_indices = array.clone(indices_template,
                                     vector_info.numSparseValues, False)
        memcpy(sparse_indices.data.as_voidptr, vector_info.sparseIndices,
               vector_info.numSparseValues * sizeof(uint32_t))
        sparse_impl.indices = sparse_indices
        sparse_impl.values = result
        return PY_TYPE_SPARSE_VECTOR._from_impl(sparse_impl)
    return result


cdef list _string_list_to_python(dpiStringList *str_list):
    """
    Converts the contents of dpiStringList to a Python list of strings.
    """
    cdef:
        list result
        uint32_t i
        str temp
    try:
        result = cpython.PyList_New(str_list.numStrings)
        for i in range(str_list.numStrings):
            temp = str_list.strings[i][:str_list.stringLengths[i]].decode()
            cpython.Py_INCREF(temp)
            cpython.PyList_SET_ITEM(result, i, temp)
        return result
    finally:
        if dpiContext_freeStringList(driver_info.context, str_list) < 0:
            _raise_from_odpi()

cdef object _create_new_from_info(dpiErrorInfo *error_info):
    """
    Creates a new error object given a dpiErrorInfo structure
    that is already populated with error information.
    """
    cdef bytes msg_bytes = error_info.message[:error_info.messageLength]
    context = "%s: %s" % (error_info.fnName, error_info.action)
    return errors._Error(msg_bytes.decode("utf-8", "replace"), context,
                         code=error_info.code, offset=error_info.offset,
                         isrecoverable=error_info.isRecoverable,
                         iswarning=error_info.isWarning)


cdef int _raise_from_info(dpiErrorInfo *error_info) except -1:
    """
    Raises an exception given a dpiErrorInfo structure that is already
    populated with error information.
    """
    error = _create_new_from_info(error_info)
    raise error.exc_type(error)


cdef int _raise_from_odpi() except -1:
    """
    Raises an exception from ODPI-C, given that an error has been raised by
    ODPI-C (a return code of -1 has been received).
    """
    cdef dpiErrorInfo error_info
    dpiContext_getError(driver_info.context, &error_info)
    _raise_from_info(&error_info)


def clientversion():
    """
    Returns the version of the Oracle Client library being used as a 5-tuple.
    The five values are the major version, minor version, update number, patch
    number and port update number.
    """
    if driver_info.context == NULL:
        errors._raise_err(errors.ERR_INIT_ORACLE_CLIENT_NOT_CALLED)
    return (
        driver_info.client_version_info.versionNum,
        driver_info.client_version_info.releaseNum,
        driver_info.client_version_info.updateNum,
        driver_info.client_version_info.portReleaseNum,
        driver_info.client_version_info.portUpdateNum
    )


def init_oracle_client(lib_dir=None, config_dir=None, error_url=None,
                       driver_name=None):
    """
    Initialize the Oracle Client library. This method is available externally
    in order to be called with parameters that control how the Oracle Client
    library is initialized. If not called earlier, the first usage of the
    Oracle Client library will cause this method to be called internally.
    """
    cdef:
        bytes lib_dir_bytes, config_dir_bytes, driver_name_bytes
        dpiContextCreateParams params
        dpiErrorInfo error_info
        str encoding
    global driver_context_params
    params_tuple = (lib_dir, config_dir, error_url, driver_name)
    if driver_info.context != NULL:
        if params_tuple != driver_context_params:
            errors._raise_err(errors.ERR_LIBRARY_ALREADY_INITIALIZED)
        return
    if sys.version_info[:2] < (3, 11):
        encoding = "utf-8"
    else:
        encoding = locale.getencoding()
    with driver_mode.get_manager(requested_thin_mode=False) as mode_mgr:
        memset(&params, 0, sizeof(dpiContextCreateParams))
        params.defaultEncoding = ENCODING_UTF8
        params.sodaUseJsonDesc = driver_info.soda_use_json_desc
        params.useJsonId = True
        if config_dir is None:
            config_dir = C_DEFAULTS.config_dir
        else:
            C_DEFAULTS.config_dir = config_dir
        if lib_dir is not None:
            if isinstance(lib_dir, bytes):
                lib_dir_bytes = lib_dir
            else:
                lib_dir_bytes = lib_dir.encode(encoding)
            params.oracleClientLibDir = lib_dir_bytes
        if config_dir is not None:
            if isinstance(config_dir, bytes):
                config_dir_bytes = config_dir
            else:
                config_dir_bytes = config_dir.encode(encoding)
            params.oracleClientConfigDir = config_dir_bytes
        if driver_name is None:
            driver_name = C_DEFAULTS.driver_name
        if driver_name is None:
            driver_name = f"{DRIVER_NAME} thk : {DRIVER_VERSION}"
        driver_name_bytes = driver_name.encode()[:30]
        params.defaultDriverName = driver_name_bytes
        if error_url is not None:
            error_url_bytes = error_url.encode()
        else:
            error_url_bytes = DRIVER_INSTALLATION_URL.encode()
        params.loadErrorUrl = error_url_bytes
        if dpiContext_createWithParams(DPI_MAJOR_VERSION, DPI_MINOR_VERSION,
                                       &params, &driver_info.context,
                                       &error_info) < 0:
            _raise_from_info(&error_info)
        if config_dir is None and params.oracleClientConfigDir != NULL:
            C_DEFAULTS.config_dir = params.oracleClientConfigDir.decode()
        if dpiContext_getClientVersion(driver_info.context,
                                       &driver_info.client_version_info) < 0:
            _raise_from_odpi()
        driver_context_params = params_tuple
        driver_info.soda_use_json_desc = params.sodaUseJsonDesc


def init_thick_impl(package):
    """
    Initializes globals after the package has been completely initialized. This
    is to avoid circular imports and eliminate the need for global lookups.
    """
    global driver_mode, errors, exceptions
    driver_mode = package.driver_mode
    errors = package.errors
    exceptions = package.exceptions


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thick\var.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# var.pyx
#
# Cython file defining the thick Variable implementation class (embedded in
# thick_impl.pyx).
#------------------------------------------------------------------------------

cdef class ThickVarImpl(BaseVarImpl):
    cdef:
        dpiVar *_handle
        dpiData *_data
        StringBuffer _buf
        object _conn

    def __dealloc__(self):
        if self._handle != NULL:
            dpiVar_release(self._handle)

    cdef int _bind(self, object conn, BaseCursorImpl cursor_impl,
                   uint32_t num_execs, object name, uint32_t pos) except -1:
        cdef:
            ThickCursorImpl thick_cursor_impl = <ThickCursorImpl> cursor_impl
            uint32_t name_length, i
            dpiDataBuffer *dbvalue
            const char *name_ptr
            bytes name_bytes
            object cursor
        if self.metadata.dbtype.num == DB_TYPE_NUM_CURSOR:
            for i, cursor in enumerate(self._values):
                if cursor is not None and cursor._impl is None:
                    errors._raise_err(errors.ERR_CURSOR_NOT_OPEN)
                if self._data[i].isNull:
                    continue
                dbvalue = &self._data[i].value
                if dbvalue.asStmt == thick_cursor_impl._handle:
                    errors._raise_err(errors.ERR_SELF_BIND_NOT_SUPPORTED)
        if name is not None:
            name_bytes = name.encode()
            name_ptr = name_bytes
            name_length = <uint32_t> len(name_bytes)
            if dpiStmt_bindByName(thick_cursor_impl._handle, name_ptr,
                                  name_length, self._handle) < 0:
                _raise_from_odpi()
        else:
            if dpiStmt_bindByPos(thick_cursor_impl._handle, pos,
                                 self._handle) < 0:
                _raise_from_odpi()
        if thick_cursor_impl._stmt_info.isReturning and not self._is_value_set:
            self._has_returned_data = True
        self._is_value_set = False

    cdef int _create_handle(self) except -1:
        cdef:
             ThickConnImpl conn_impl = self._conn_impl
             dpiObjectType *obj_type_handle = NULL
             ThickDbObjectTypeImpl obj_type_impl
        if self._handle != NULL:
             dpiVar_release(self._handle)
             self._handle = NULL
        if self.metadata.objtype is not None:
             obj_type_impl = <ThickDbObjectTypeImpl> self.metadata.objtype
             obj_type_handle = obj_type_impl._handle
        if dpiConn_newVar(conn_impl._handle, self.metadata.dbtype.num,
                          self.metadata.dbtype._native_num, self.num_elements,
                          self.metadata.max_size, 0, self.is_array,
                          obj_type_handle, &self._handle, &self._data) < 0:
             _raise_from_odpi()

    cdef int _finalize_init(self) except -1:
        """
        Internal method that finalizes initialization of the variable.
        """
        BaseVarImpl._finalize_init(self)
        if self.metadata.dbtype._native_num in (
            DPI_NATIVE_TYPE_LOB,
            DPI_NATIVE_TYPE_OBJECT,
            DPI_NATIVE_TYPE_STMT,
        ):
            self._values = [None] * self.num_elements
        self._create_handle()

    cdef list _get_array_value(self):
        """
        Internal method to return the value of the array.
        """
        cdef uint32_t i
        return [self._get_scalar_value(i) \
                for i in range(self.num_elements_in_array)]

    cdef object _get_cursor_value(self, dpiDataBuffer *dbvalue, uint32_t pos):
        """
        Returns the cursor stored in the variable at the given position. If a
        cursor was previously available, use it instead of creating a new one.
        """
        cdef:
            ThickCursorImpl cursor_impl
            object cursor
        cursor = self._values[pos]
        if cursor is None:
            cursor = self._conn.cursor()
        cursor_impl = <ThickCursorImpl> cursor._impl
        if dpiStmt_addRef(dbvalue.asStmt) < 0:
            _raise_from_odpi()
        cursor_impl._handle = dbvalue.asStmt
        cursor_impl._fixup_ref_cursor = True
        return cursor

    cdef object _get_dbobject_value(self, dpiDataBuffer *dbvalue,
                                    uint32_t pos):
        """
        Returns the DbObject stored in the variable at the given position. If a
        DbObject was previously available, use it instead of creating a new
        one, unless the handle has changed.
        """
        cdef:
            ThickDbObjectImpl obj_impl
            object obj = None
        if not self._has_returned_data:
            obj = self._values[pos]
        if obj is not None:
            obj_impl = <ThickDbObjectImpl> obj._impl
            if obj_impl._handle == dbvalue.asObject:
                return obj
        obj_impl = ThickDbObjectImpl.__new__(ThickDbObjectImpl)
        obj_impl.type = self.metadata.objtype
        if dpiObject_addRef(dbvalue.asObject) < 0:
            _raise_from_odpi()
        obj_impl._handle = dbvalue.asObject
        return PY_TYPE_DB_OBJECT._from_impl(obj_impl)

    cdef object _get_lob_value(self, dpiDataBuffer *dbvalue, uint32_t pos):
        """
        Returns the LOB stored in the variable at the given position. If a LOB
        was previously created, use it instead of creating a new one, unless
        the handle has changed.
        """
        cdef:
            ThickLobImpl lob_impl
            object lob = None
        if not self._has_returned_data:
            lob = self._values[pos]
        if lob is not None:
            lob_impl = <ThickLobImpl> lob._impl
            if lob_impl._handle == dbvalue.asLOB:
                return lob
        lob_impl = ThickLobImpl._create(self._conn_impl, self.metadata.dbtype,
                                        dbvalue.asLOB)
        return PY_TYPE_LOB._from_impl(lob_impl)

    cdef object _get_scalar_value(self, uint32_t pos):
        """
        Internal method to return the value of the variable at the given
        position.
        """
        cdef:
            uint32_t num_returned_rows
            dpiData *returned_data
            object value
        if self._has_returned_data:
            if dpiVar_getReturnedData(self._handle, pos, &num_returned_rows,
                                      &returned_data) < 0:
                _raise_from_odpi()
            return self._transform_array_to_python(num_returned_rows,
                                                   returned_data)
        value = self._transform_element_to_python(pos, self._data)
        if self.metadata.dbtype._native_num in (
            DPI_NATIVE_TYPE_LOB,
            DPI_NATIVE_TYPE_OBJECT,
            DPI_NATIVE_TYPE_STMT,
        ):
            self._values[pos] = value
        return value

    cdef int _on_reset_bind(self, uint32_t num_rows) except -1:
        """
        Called when the bind variable is being reset, just prior to performing
        a bind operation.
        """
        cdef:
            dpiStmtInfo stmt_info
            uint32_t i
        BaseVarImpl._on_reset_bind(self, num_rows)
        if self.metadata.dbtype.num == DB_TYPE_NUM_CURSOR:
            for i in range(self.num_elements):
                if self._data[i].isNull:
                    continue
                if dpiStmt_getInfo(self._data[i].value.asStmt, &stmt_info) < 0:
                    self._create_handle()
                    break

    cdef int _resize(self, uint32_t new_size) except -1:
        """
        Resize the variable to the new size provided.
        """
        cdef:
            dpiVar *orig_handle = NULL
            uint32_t num_elements, i
            dpiData *source_data
            dpiData *orig_data
        BaseVarImpl._resize(self, new_size)
        orig_data = self._data
        orig_handle = self._handle
        self._handle = NULL
        try:
            self._create_handle()
            if self.is_array:
                if dpiVar_getNumElementsInArray(orig_handle,
                                                &num_elements) < 0:
                    _raise_from_odpi()
                if dpiVar_setNumElementsInArray(self._handle,
                                                num_elements) < 0:
                    _raise_from_odpi()
            for i in range(self.num_elements):
                source_data = &orig_data[i]
                if source_data.isNull:
                    continue
                if dpiVar_setFromBytes(self._handle, i,
                        source_data.value.asBytes.ptr,
                        source_data.value.asBytes.length) < 0:
                    _raise_from_odpi()
        finally:
            dpiVar_release(orig_handle)

    cdef int _set_cursor_value(self, object cursor, uint32_t pos) except -1:
        """
        Sets a cursor value in the variable. If the cursor does not have a
        statement handle already, associate the one created by the variable.
        """
        cdef:
            ThickCursorImpl cursor_impl = cursor._impl
            dpiData *data

        # if the cursor already has a handle, use it directly
        if cursor_impl._handle != NULL:
            if dpiVar_setFromStmt(self._handle, pos, cursor_impl._handle) < 0:
                _raise_from_odpi()

        # otherwise, make use of the statement handle allocated by the variable
        else:
            data = &self._data[pos]
            if dpiStmt_addRef(data.value.asStmt) < 0:
                _raise_from_odpi()
            cursor_impl._handle = data.value.asStmt
        self._values[pos] = cursor
        cursor_impl._fixup_ref_cursor = True
        cursor_impl.statement = None

    cdef int _set_dbobject_value(self, object obj, uint32_t pos) except -1:
        """
        Sets an object value in the variable. The object is retained so that
        multiple calls to getvalue() return the same instance.
        """
        cdef ThickDbObjectImpl obj_impl = <ThickDbObjectImpl> obj._impl
        if dpiVar_setFromObject(self._handle, pos, obj_impl._handle) < 0:
            _raise_from_odpi()
        self._values[pos] = obj

    cdef int _set_lob_value(self, object lob, uint32_t pos) except -1:
        """
        Sets a LOB value in the variable. The LOB is retained so that multiple
        calls to getvalue() return the same instance.
        """
        cdef ThickLobImpl lob_impl = <ThickLobImpl> lob._impl
        if dpiVar_setFromLob(self._handle, pos, lob_impl._handle) < 0:
            _raise_from_odpi()
        self._values[pos] = lob

    cdef int _set_num_elements_in_array(self, uint32_t num_elements) except -1:
        """
        Sets the number of elements in the array.
        """
        BaseVarImpl._set_num_elements_in_array(self, num_elements)
        if dpiVar_setNumElementsInArray(self._handle, num_elements) < 0:
            _raise_from_odpi()

    cdef int _set_scalar_value(self, uint32_t pos, object value) except -1:
        """
        Set the value of the variable at the given position. At this point it
        is assumed that all checks have been performed!
        """
        cdef:
            dpiDataBuffer temp_dbvalue
            dpiDataBuffer *dbvalue
            uint32_t native_num
            dpiBytes *as_bytes
            dpiData *data
        data = &self._data[pos]
        data.isNull = (value is None)
        if not data.isNull:
            native_num = self.metadata.dbtype._native_num
            if native_num == DPI_NATIVE_TYPE_STMT:
                self._set_cursor_value(value, pos)
            elif native_num == DPI_NATIVE_TYPE_LOB:
                self._set_lob_value(value, pos)
            elif native_num == DPI_NATIVE_TYPE_OBJECT:
                self._set_dbobject_value(value, pos)
            else:
                if native_num == DPI_NATIVE_TYPE_BYTES:
                    dbvalue = &temp_dbvalue
                else:
                    dbvalue = &data.value
                if self._buf is None:
                    self._buf = StringBuffer.__new__(StringBuffer)
                _convert_from_python(value, self.metadata, dbvalue, self._buf)
                if native_num == DPI_NATIVE_TYPE_BYTES:
                    as_bytes = &dbvalue.asBytes
                    if dpiVar_setFromBytes(self._handle, pos, as_bytes.ptr,
                                           as_bytes.length) < 0:
                        _raise_from_odpi()

    cdef object _transform_array_to_python(self, uint32_t num_elements,
                                           dpiData *data):
        """
        Transforms an array from ODPI-C to a Python list.
        """
        cdef:
            object element_value
            list return_value
            uint32_t i
        return_value = cpython.PyList_New(num_elements)
        for i in range(num_elements):
            element_value = self._transform_element_to_python(i, data)
            cpython.Py_INCREF(element_value)
            cpython.PyList_SET_ITEM(return_value, i, element_value)
        return return_value

    cdef int _transform_element_to_arrow(self, uint32_t pos):
        """
        Transforms a single element from the value supplied by ODPI-C to its
        equivalent Arrow format.
        """
        cdef:
            dpiData *data = &self._data[pos]
            uint32_t ora_type_num
            OracleData ora_data
            dpiBytes *as_bytes
        ora_data.is_null = data.isNull
        if not data.isNull:
            ora_type_num = self._fetch_metadata.dbtype.num
            if ora_type_num == DPI_ORACLE_TYPE_NATIVE_DOUBLE:
                ora_data.buffer.as_double = data.value.asDouble
            elif ora_type_num == DPI_ORACLE_TYPE_NATIVE_FLOAT:
                ora_data.buffer.as_float = data.value.asFloat
            elif ora_type_num == DPI_ORACLE_TYPE_BOOLEAN:
                ora_data.buffer.as_bool = data.value.asBoolean
            elif ora_type_num in (
                DPI_ORACLE_TYPE_CHAR,
                DPI_ORACLE_TYPE_LONG_VARCHAR,
                DPI_ORACLE_TYPE_LONG_RAW,
                DPI_ORACLE_TYPE_RAW,
                DPI_ORACLE_TYPE_VARCHAR,
            ):
                as_bytes = &data.value.asBytes;
                ora_data.buffer.as_raw_bytes.ptr = \
                        <const char_type *> as_bytes.ptr;
                ora_data.buffer.as_raw_bytes.num_bytes = as_bytes.length;
            elif ora_type_num in (
                DPI_ORACLE_TYPE_DATE,
                DPI_ORACLE_TYPE_TIMESTAMP,
                DPI_ORACLE_TYPE_TIMESTAMP_LTZ,
                DPI_ORACLE_TYPE_TIMESTAMP_TZ,
            ):
                ora_data.buffer.as_date.year = data.value.asTimestamp.year;
                ora_data.buffer.as_date.month = data.value.asTimestamp.month;
                ora_data.buffer.as_date.day = data.value.asTimestamp.day;
                ora_data.buffer.as_date.hour = data.value.asTimestamp.hour;
                ora_data.buffer.as_date.minute = data.value.asTimestamp.minute;
                ora_data.buffer.as_date.second = data.value.asTimestamp.second;
                ora_data.buffer.as_date.fsecond = \
                        data.value.asTimestamp.fsecond // 1000;
                ora_data.buffer.as_date.tz_hour_offset = \
                        data.value.asTimestamp.tzHourOffset;
                ora_data.buffer.as_date.tz_minute_offset = \
                        data.value.asTimestamp.tzMinuteOffset;
            elif ora_type_num == DPI_ORACLE_TYPE_INTERVAL_DS:
                ora_data.buffer.as_interval_ds.days = \
                        data.value.asIntervalDS.days;
                ora_data.buffer.as_interval_ds.hours = \
                        data.value.asIntervalDS.hours;
                ora_data.buffer.as_interval_ds.minutes = \
                        data.value.asIntervalDS.minutes;
                ora_data.buffer.as_interval_ds.seconds = \
                        data.value.asIntervalDS.seconds;
                ora_data.buffer.as_interval_ds.fseconds = \
                        data.value.asIntervalDS.fseconds;
            elif ora_type_num == DPI_ORACLE_TYPE_INTERVAL_YM:
                ora_data.buffer.as_interval_ym.years = \
                        data.value.asIntervalYM.years;
                ora_data.buffer.as_interval_ym.months = \
                        data.value.asIntervalYM.months;
            elif ora_type_num == DPI_ORACLE_TYPE_NUMBER:
                as_bytes = &data.value.asBytes;
                ora_data.buffer.as_number.is_max_negative_value = 0;
                ora_data.buffer.as_number.is_integer = \
                        memchr(as_bytes.ptr, b'.', as_bytes.length) == NULL;
                memcpy(ora_data.buffer.as_number.chars, as_bytes.ptr,
                        as_bytes.length);
                ora_data.buffer.as_number.num_chars = as_bytes.length;
            else:
                errors._raise_err(errors.ERR_DB_TYPE_NOT_SUPPORTED,
                                  name=self._fetch_metadata.dbtype.name)
        convert_oracle_data_to_arrow(self._fetch_metadata, self.metadata,
                                     &ora_data, self._arrow_array)

    cdef object _transform_element_to_python(self, uint32_t pos,
                                             dpiData *data):
        """
        Transforms a single element from the value supplied by ODPI-C to its
        equivalent Python value.
        """
        cdef:
            uint32_t native_num
            object value
        data = &data[pos]
        if not data.isNull:
            native_num = self.metadata.dbtype._native_num
            if native_num == DPI_NATIVE_TYPE_STMT:
                value = self._get_cursor_value(&data.value, pos)
            elif native_num == DPI_NATIVE_TYPE_LOB:
                value = self._get_lob_value(&data.value, pos)
            elif native_num == DPI_NATIVE_TYPE_OBJECT:
                value = self._get_dbobject_value(&data.value, pos)
            else:
                value = _convert_to_python(self._conn_impl, self.metadata,
                                           &data.value, self.bypass_decode,
                                           self._encoding_errors)
            if self.outconverter is not None:
                value = self.outconverter(value)
            return value
        elif self.convert_nulls:
            return self.outconverter(None)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\capabilities.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2021, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# capabilities.pyx
#
# Cython file defining the capabilities (neogiated at connect time) that both
# the database server and the client are capable of (embedded in
# thin_impl.pyx).
#------------------------------------------------------------------------------

cdef class Capabilities:
    cdef:
        uint16_t protocol_version
        uint8_t ttc_field_version
        uint16_t charset_id
        uint16_t ncharset_id
        bytearray compile_caps
        bytearray runtime_caps
        uint32_t max_string_size
        bint supports_fast_auth
        bint supports_oob
        bint supports_oob_check
        bint supports_end_of_response
        bint supports_pipelining
        bint supports_request_boundaries
        uint32_t sdu

    def __init__(self):
        self._init_compile_caps()
        self._init_runtime_caps()
        self.sdu = 8192                 # initial value to use

    cdef void _adjust_for_protocol(self, uint16_t protocol_version,
                                   uint16_t protocol_options, uint32_t flags):
        """
        Adjust the capabilities of the protocol based on the server's response
        to the initial connection request.
        """
        self.protocol_version = protocol_version
        self.supports_oob = protocol_options & TNS_GSO_CAN_RECV_ATTENTION
        if flags & TNS_ACCEPT_FLAG_FAST_AUTH:
            self.supports_fast_auth = True
        if flags & TNS_ACCEPT_FLAG_CHECK_OOB:
            self.supports_oob_check = True
        if protocol_version >= TNS_VERSION_MIN_END_OF_RESPONSE:
            if flags & TNS_ACCEPT_FLAG_HAS_END_OF_RESPONSE:
                self.compile_caps[TNS_CCAP_TTC4] |= TNS_CCAP_END_OF_RESPONSE
                self.supports_end_of_response = True
                self.supports_pipelining = True

    @cython.boundscheck(False)
    cdef void _adjust_for_server_compile_caps(self, bytearray server_caps):
        if server_caps[TNS_CCAP_FIELD_VERSION] < self.ttc_field_version:
            self.ttc_field_version = server_caps[TNS_CCAP_FIELD_VERSION]
            self.compile_caps[TNS_CCAP_FIELD_VERSION] = self.ttc_field_version
        if server_caps[TNS_CCAP_TTC4] & TNS_CCAP_EXPLICIT_BOUNDARY:
            self.supports_request_boundaries = True

    @cython.boundscheck(False)
    cdef void _adjust_for_server_runtime_caps(self, bytearray server_caps):
        if server_caps[TNS_RCAP_TTC] & TNS_RCAP_TTC_32K:
            self.max_string_size = 32767
        else:
            self.max_string_size = 4000
        if not (server_caps[TNS_RCAP_TTC] & TNS_RCAP_TTC_SESSION_STATE_OPS):
            self.supports_request_boundaries = False

    cdef int _check_ncharset_id(self) except -1:
        """
        Checks that the national character set id is AL16UTF16, which is the
        only id that is currently supported.
        """
        if self.ncharset_id != TNS_CHARSET_UTF16:
            errors._raise_err(errors.ERR_NCHAR_CS_NOT_SUPPORTED,
                              charset_id=self.ncharset_id)

    @cython.boundscheck(False)
    cdef void _init_compile_caps(self):
        self.ttc_field_version = TNS_CCAP_FIELD_VERSION_MAX
        self.compile_caps = bytearray(TNS_CCAP_MAX)
        self.compile_caps[TNS_CCAP_SQL_VERSION] = TNS_CCAP_SQL_VERSION_MAX
        self.compile_caps[TNS_CCAP_LOGON_TYPES] = \
                TNS_CCAP_O5LOGON | TNS_CCAP_O5LOGON_NP | \
                TNS_CCAP_O7LOGON | TNS_CCAP_O8LOGON_LONG_IDENTIFIER | \
                TNS_CCAP_O9LOGON_LONG_PASSWORD
        self.compile_caps[TNS_CCAP_FEATURE_BACKPORT] = \
                TNS_CCAP_CTB_IMPLICIT_POOL
        self.compile_caps[TNS_CCAP_FIELD_VERSION] = self.ttc_field_version
        self.compile_caps[TNS_CCAP_SERVER_DEFINE_CONV] = 1
        self.compile_caps[TNS_CCAP_DEQUEUE_WITH_SELECTOR] = 1
        self.compile_caps[TNS_CCAP_TTC1] = \
                TNS_CCAP_FAST_BVEC | TNS_CCAP_END_OF_CALL_STATUS | \
                TNS_CCAP_IND_RCD
        self.compile_caps[TNS_CCAP_OCI1] = \
                TNS_CCAP_FAST_SESSION_PROPAGATE | TNS_CCAP_APP_CTX_PIGGYBACK
        self.compile_caps[TNS_CCAP_TDS_VERSION] = TNS_CCAP_TDS_VERSION_MAX
        self.compile_caps[TNS_CCAP_RPC_VERSION] = TNS_CCAP_RPC_VERSION_MAX
        self.compile_caps[TNS_CCAP_RPC_SIG] = TNS_CCAP_RPC_SIG_VALUE
        self.compile_caps[TNS_CCAP_DBF_VERSION] = TNS_CCAP_DBF_VERSION_MAX
        self.compile_caps[TNS_CCAP_LOB] = TNS_CCAP_LOB_UB8_SIZE | \
                TNS_CCAP_LOB_ENCS | TNS_CCAP_LOB_PREFETCH_LENGTH | \
                TNS_CCAP_LOB_TEMP_SIZE | TNS_CCAP_LOB_12C | \
                TNS_CCAP_LOB_PREFETCH_DATA
        self.compile_caps[TNS_CCAP_UB2_DTY] = 1
        self.compile_caps[TNS_CCAP_LOB2] = TNS_CCAP_LOB2_QUASI | \
                TNS_CCAP_LOB2_2GB_PREFETCH
        self.compile_caps[TNS_CCAP_TTC3] = TNS_CCAP_IMPLICIT_RESULTS | \
                TNS_CCAP_BIG_CHUNK_CLR | TNS_CCAP_KEEP_OUT_ORDER | \
                TNS_CCAP_LTXID
        self.compile_caps[TNS_CCAP_TTC2] = TNS_CCAP_ZLNP
        self.compile_caps[TNS_CCAP_OCI2] = TNS_CCAP_DRCP
        self.compile_caps[TNS_CCAP_CLIENT_FN] = TNS_CCAP_CLIENT_FN_MAX
        self.compile_caps[TNS_CCAP_SESS_SIGNATURE_VERSION] = \
                TNS_CCAP_FIELD_VERSION_12_2
        self.compile_caps[TNS_CCAP_TTC4] = TNS_CCAP_INBAND_NOTIFICATION | \
                TNS_CCAP_EXPLICIT_BOUNDARY
        self.compile_caps[TNS_CCAP_TTC5] = TNS_CCAP_VECTOR_SUPPORT | \
                TNS_CCAP_TOKEN_SUPPORTED | TNS_CCAP_PIPELINING_SUPPORT | \
                TNS_CCAP_PIPELINING_BREAK
        self.compile_caps[TNS_CCAP_VECTOR_FEATURES] = \
                TNS_CCAP_VECTOR_FEATURE_BINARY | \
                TNS_CCAP_VECTOR_FEATURE_SPARSE

    @cython.boundscheck(False)
    cdef void _init_runtime_caps(self):
        self.runtime_caps = bytearray(TNS_RCAP_MAX)
        self.runtime_caps[TNS_RCAP_COMPAT] = TNS_RCAP_COMPAT_81
        self.runtime_caps[TNS_RCAP_TTC] = TNS_RCAP_TTC_ZERO_COPY | \
                TNS_RCAP_TTC_32K


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\connection.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# connection.pyx
#
# Cython file defining the thin Connection implementation class (embedded in
# thin_impl.pyx).
#------------------------------------------------------------------------------

cdef class BaseThinConnImpl(BaseConnImpl):

    cdef:
        StatementCache _statement_cache
        BaseProtocol _protocol
        uint32_t _session_id
        uint16_t _serial_num
        str _action
        bint _action_modified
        str _dbop
        bint _dbop_modified
        str _client_info
        bint _client_info_modified
        str _client_identifier
        bint _client_identifier_modified
        str _module
        bint _module_modified
        BaseThinPoolImpl _pool
        bytes _ltxid
        str _current_schema
        bint _current_schema_modified
        uint8_t _max_identifier_length
        uint32_t _max_open_cursors
        str _db_domain
        str _db_name
        str _edition
        str _instance_name
        str _internal_name
        str _external_name
        str _service_name
        bint _drcp_enabled
        bint _drcp_establish_session
        double _time_created
        double _time_returned
        list _temp_lobs_to_close
        uint32_t _temp_lobs_total_size
        uint32_t _call_timeout
        str _cclass
        int _dbobject_type_cache_num
        bytes _combo_key
        str _connection_id
        bint _is_pool_extra
        bytes _transaction_context
        uint8_t pipeline_mode
        uint8_t _session_state_desired

    def __init__(self, str dsn, ConnectParamsImpl params):
        _check_cryptography()
        BaseConnImpl.__init__(self, dsn, params)
        self.thin = True

    cdef int _check_tpc_commit_state(self, uint32_t state,
                                     bint one_phase) except -1:
        """
        Check the state returned by the tpc_commit() call.
        """
        if one_phase and state not in (TNS_TPC_TXN_STATE_READ_ONLY,
                                       TNS_TPC_TXN_STATE_COMMITTED) \
                or not one_phase and state != TNS_TPC_TXN_STATE_FORGOTTEN:
            errors._raise_err(errors.ERR_UNKNOWN_TRANSACTION_STATE,
                              state=state)
        self._transaction_context = None

    cdef BaseThinLobImpl _create_lob_impl(self, DbType dbtype,
                                          bytes locator=None):
        """
        Create and return a LOB implementation object.
        """
        cdef BaseThinLobImpl lob_impl
        if self._protocol._transport._is_async:
            lob_impl = AsyncThinLobImpl.__new__(AsyncThinLobImpl)
        else:
            lob_impl = ThinLobImpl.__new__(ThinLobImpl)
        lob_impl._conn_impl = self
        lob_impl.dbtype = dbtype
        lob_impl._locator = locator
        return lob_impl

    cdef Message _create_message(self, type typ):
        """
        Creates a message object that is used to send a request to the database
        and receive back its response.
        """
        cdef Message message
        message = typ.__new__(typ)
        message._initialize(self)
        return message

    cdef AuthMessage _create_change_password_message(self, str old_password,
                                                     str new_password):
        """
        Creates a change password message which is an authentication message
        with different attributes set.
        """
        cdef AuthMessage message
        message = self._create_message(AuthMessage)
        message.change_password = True
        message.function_code = TNS_FUNC_AUTH_PHASE_TWO
        message.user_bytes = self.username.encode()
        message.user_bytes_len = len(message.user_bytes)
        message.auth_mode = TNS_AUTH_MODE_WITH_PASSWORD | \
                TNS_AUTH_MODE_CHANGE_PASSWORD
        message.password = old_password.encode()
        message.newpassword = new_password.encode()
        message.resend = False
        return message

    cdef TransactionChangeStateMessage _create_tpc_commit_message(
            self, object xid, bint one_phase
    ):
        """
        Creates a two-phase commit message suitable for committing a
        transaction.
        """
        cdef TransactionChangeStateMessage message
        message = self._create_message(TransactionChangeStateMessage)
        message.operation = TNS_TPC_TXN_COMMIT
        message.state = TNS_TPC_TXN_STATE_READ_ONLY if one_phase \
                else TNS_TPC_TXN_STATE_COMMITTED
        message.xid = xid
        message.context = self._transaction_context
        return message

    cdef Message _create_tpc_rollback_message(self, object xid=None):
        """
        Creates a two-phase commit rollback message suitable for use in both
        the close() method and explicitly by the user.
        """
        cdef TransactionChangeStateMessage message
        message = self._create_message(TransactionChangeStateMessage)
        message.operation = TNS_TPC_TXN_ABORT
        message.state = TNS_TPC_TXN_STATE_ABORTED
        message.xid = xid
        message.context = self._transaction_context
        return message

    cdef int _force_close(self) except -1:
        self._pool = None
        if self._dbobject_type_cache_num > 0:
            remove_dbobject_type_cache(self._dbobject_type_cache_num)
            self._dbobject_type_cache_num = 0
        self._protocol._force_close()

    cdef Statement _get_statement(self, str sql = None,
                                  bint cache_statement = False):
        """
        Get a statement from the statement cache, or prepare a new statement
        for use.
        """
        return self._statement_cache.get_statement(
            sql, cache_statement, self._drcp_establish_session
        )

    cdef int _post_connect_phase_one(self, Description description,
                                     ConnectParamsImpl params) except -1:
        """
        Called after the connection has been partially established to perform
        common tasks.
        """
        self._drcp_enabled = description.server_type == "pooled"
        if self._cclass is None:
            self._cclass = description.cclass
        if self._cclass is None and self._pool is not None \
                and self._drcp_enabled:
            gen_uuid = uuid.uuid4()
            self._cclass = f"DPY:{base64.b64encode(gen_uuid.bytes).decode()}"
            params._default_description.cclass = self._cclass

    cdef int _post_connect_phase_two(self, ConnectParamsImpl params) except -1:
        """
        Called after the connection has been fully established to perform
        common tasks.
        """
        self._statement_cache = StatementCache.__new__(StatementCache)
        self._statement_cache.initialize(params.stmtcachesize,
                                         self._max_open_cursors)
        self._dbobject_type_cache_num = create_new_dbobject_type_cache(self)
        self.invoke_session_callback = True

    cdef int _pre_connect(self, ConnectParamsImpl params) except -1:
        """
        Called before the connection is established to perform common tasks.
        """
        params._check_credentials()
        self._connection_id = base64.b64encode(secrets.token_bytes(16)).decode()

    cdef int _return_statement(self, Statement statement) except -1:
        """
        Return the statement to the statement cache, if applicable.
        """
        self._statement_cache.return_statement(statement)

    def cancel(self):
        self._protocol._break_external()

    def create_msg_props_impl(self):
        cdef ThinMsgPropsImpl impl
        impl = ThinMsgPropsImpl()
        impl._conn_impl = self
        return impl

    def get_call_timeout(self):
        return self._call_timeout

    def get_current_schema(self):
        return self._current_schema

    def get_db_domain(self):
        if self._db_domain:
            return self._db_domain

    def get_db_name(self):
        return self._db_name

    def get_session_id(self):
        return self._session_id

    def get_serial_num(self):
        return self._serial_num

    def get_edition(self):
        return self._edition

    def get_external_name(self):
        return self._external_name

    def get_instance_name(self):
        return self._instance_name

    def get_internal_name(self):
        return self._internal_name

    def get_is_healthy(self):
        return self._protocol._transport is not None \
                and self._protocol._read_buf._pending_error_num == 0

    def get_ltxid(self):
        return self._ltxid or b''

    def get_max_identifier_length(self):
        return self._max_identifier_length

    def get_max_open_cursors(self):
        return self._max_open_cursors

    def get_sdu(self):
        return self._protocol._caps.sdu

    def get_service_name(self):
        return self._service_name

    def get_stmt_cache_size(self):
        return self._statement_cache._max_size

    def get_transaction_in_progress(self):
        return self._protocol._txn_in_progress

    def get_type(self, object conn, str name):
        cdef ThinDbObjectTypeCache cache = \
                get_dbobject_type_cache(self._dbobject_type_cache_num)
        return cache.get_type(conn, name)

    def ping(self):
        cdef Message message
        message = self._create_message(PingMessage)
        self._protocol._process_single_message(message)

    def rollback(self):
        cdef Message message
        message = self._create_message(RollbackMessage)
        self._protocol._process_single_message(message)

    def set_action(self, str value):
        self._action = value
        self._action_modified = True

    def set_client_identifier(self, str value):
        self._client_identifier = value
        self._client_identifier_modified = True

    def set_client_info(self, str value):
        self._client_info = value
        self._client_info_modified = True

    def set_current_schema(self, value):
        self._current_schema = value
        self._current_schema_modified = True

    def set_dbop(self, str value):
        self._dbop = value
        self._dbop_modified = True

    def set_external_name(self, value):
        self._external_name = value

    def set_internal_name(self, value):
        self._internal_name = value

    def set_module(self, str value):
        self._module = value
        self._module_modified = True
        # setting the module by itself results in an error so always force the
        # action to be set as well (which eliminates this error)
        self._action_modified = True

    def set_stmt_cache_size(self, uint32_t value):
        self._statement_cache.resize(value)


cdef class ThinConnImpl(BaseThinConnImpl):

    def __init__(self, str dsn, ConnectParamsImpl params):
        BaseThinConnImpl.__init__(self, dsn, params)
        self._protocol = Protocol()

    cdef int _connect_with_address(self, Address address,
                                   Description description,
                                   ConnectParamsImpl params,
                                   str connect_string,
                                   bint raise_exception) except -1:
        """
        Internal method used for connecting with the given description and
        address.
        """
        cdef Protocol protocol = <Protocol> self._protocol
        try:
            protocol._connect_phase_one(self, params, description,
                                        address, connect_string)
        except (exceptions.DatabaseError, socket.gaierror, OSError) as e:
            if raise_exception:
                errors._raise_err(errors.ERR_CONNECTION_FAILED, cause=e,
                                  connection_id=description.connection_id)
            return 0
        except Exception as e:
            errors._raise_err(errors.ERR_CONNECTION_FAILED, cause=e,
                              connection_id=description.connection_id)
        self._post_connect_phase_one(description, params)
        protocol._connect_phase_two(self, description, params)

    cdef int _connect_with_description(self, Description description,
                                       ConnectParamsImpl params,
                                       bint final_desc) except -1:
        """
        Internal method used for connecting with the given description. Retry
        connecting to the socket if an attempt fails and retry_count is
        specified in the connect string.
        """
        cdef:
            uint32_t i, j, k, num_attempts, num_lists, num_addresses
            AddressList address_list
            bint raise_exc = False
            str connect_string
            Address address
        num_lists = len(description.active_children)
        num_attempts = description.retry_count + 1
        connect_string = _get_connect_data(description, self._connection_id,
                                           params)
        if connect_string is None:
            errors._raise_err(errors.ERR_FEATURE_NOT_SUPPORTED,
                              feature="bequeath", driver_type="thick")
        for i in range(num_attempts):
            for j, address_list in enumerate(description.active_children):
                num_addresses = len(address_list.active_children)
                for k, address in enumerate(address_list.active_children):
                    if final_desc:
                        raise_exc = i == num_attempts - 1 \
                                and j == num_lists - 1 \
                                and k == num_addresses - 1
                    self._connect_with_address(address, description, params,
                                               connect_string, raise_exc)
                    if not self._protocol._in_connect:
                        return 0
            time.sleep(description.retry_delay)

    cdef int _connect_with_params(self, ConnectParamsImpl params) except -1:
        """
        Internal method used for connecting with the given parameters.
        """
        cdef:
            DescriptionList description_list = params.description_list
            ssize_t i, num_descriptions
            Description description
            bint final_desc
        description_list.set_active_children()
        num_descriptions = len(description_list.active_children)
        for i, description in enumerate(description_list.active_children):
            final_desc = (i == num_descriptions - 1)
            self._connect_with_description(description, params, final_desc)
            if not self._protocol._in_connect:
                break

    cdef BaseCursorImpl _create_cursor_impl(self):
        """
        Internal method for creating an empty cursor implementation object.
        """
        return ThinCursorImpl.__new__(ThinCursorImpl, self)

    def change_password(self, str old_password, str new_password):
        cdef:
            Protocol protocol = <Protocol> self._protocol
            Message message
        message = self._create_change_password_message(old_password,
                                                       new_password)
        protocol._process_single_message(message)

    def close(self, bint in_del=False):
        cdef Protocol protocol = <Protocol> self._protocol
        try:
            protocol._close(self)
        except (ssl.SSLError, exceptions.DatabaseError):
            pass

    def commit(self):
        cdef:
            Protocol protocol = <Protocol> self._protocol
            Message message
        message = self._create_message(CommitMessage)
        protocol._process_single_message(message)

    def connect(self, ConnectParamsImpl params):
        # specify that binding a string to a LOB value is possible in thin
        # mode without the use of asyncio (will be removed in a future release)
        self._allow_bind_str_to_lob = True

        try:
            self._pre_connect(params)
            self._connect_with_params(params)
            self._post_connect_phase_two(params)
        except:
            self._force_close()
            raise

    def create_queue_impl(self):
        return ThinQueueImpl.__new__(ThinQueueImpl)

    def create_temp_lob_impl(self, DbType dbtype):
        cdef ThinLobImpl lob_impl = self._create_lob_impl(dbtype)
        lob_impl.create_temp()
        return lob_impl

    def get_type(self, object conn, str name):
        cdef ThinDbObjectTypeCache cache = \
                get_dbobject_type_cache(self._dbobject_type_cache_num)
        return cache.get_type(conn, name)

    def ping(self):
        cdef:
            Protocol protocol = <Protocol> self._protocol
            Message message
        message = self._create_message(PingMessage)
        protocol._process_single_message(message)

    def rollback(self):
        cdef:
            Protocol protocol = <Protocol> self._protocol
            Message message
        message = self._create_message(RollbackMessage)
        protocol._process_single_message(message)

    def set_call_timeout(self, uint32_t value):
        self._protocol._transport.set_timeout(value / 1000)
        self._call_timeout = value

    def tpc_begin(self, xid, uint32_t flags, uint32_t timeout):
        cdef:
            Protocol protocol = <Protocol> self._protocol
            TransactionSwitchMessage message
        message = self._create_message(TransactionSwitchMessage)
        message.operation = TNS_TPC_TXN_START
        message.xid = xid
        message.flags = flags
        message.timeout = timeout
        protocol._process_single_message(message)
        self._transaction_context = message.context

    def tpc_commit(self, xid, bint one_phase):
        cdef:
            Protocol protocol = <Protocol> self._protocol
            TransactionChangeStateMessage message
        message = self._create_tpc_commit_message(xid, one_phase)
        protocol._process_single_message(message)
        self._check_tpc_commit_state(message.state, one_phase)

    def tpc_end(self, xid, uint32_t flags):
        cdef:
            Protocol protocol = <Protocol> self._protocol
            TransactionSwitchMessage message
        message = self._create_message(TransactionSwitchMessage)
        message.operation = TNS_TPC_TXN_DETACH
        message.xid = xid
        message.context = self._transaction_context
        message.flags = flags
        protocol._process_single_message(message)
        self._transaction_context = None

    def tpc_prepare(self, xid):
        cdef:
            Protocol protocol = <Protocol> self._protocol
            TransactionChangeStateMessage message
        message = self._create_message(TransactionChangeStateMessage)
        message.operation = TNS_TPC_TXN_PREPARE
        message.xid = xid
        message.context = self._transaction_context
        protocol._process_single_message(message)
        if message.state == TNS_TPC_TXN_STATE_REQUIRES_COMMIT:
            return True
        elif message.state == TNS_TPC_TXN_STATE_READ_ONLY:
            return False
        errors._raise_err(errors.ERR_UNKNOWN_TRANSACTION_STATE,
                          state=message.state)

    def tpc_rollback(self, xid):
        cdef:
            Protocol protocol = <Protocol> self._protocol
            TransactionChangeStateMessage message
        message = self._create_tpc_rollback_message(xid)
        protocol._process_single_message(message)
        if message.state != TNS_TPC_TXN_STATE_ABORTED:
            errors._raise_err(errors.ERR_UNKNOWN_TRANSACTION_STATE,
                              state=message.state)


cdef class AsyncThinConnImpl(BaseThinConnImpl):

    def __init__(self, str dsn, ConnectParamsImpl params):
        BaseThinConnImpl.__init__(self, dsn, params)
        self._protocol = AsyncProtocol()

    cdef BaseCursorImpl _create_cursor_impl(self):
        """
        Internal method for creating an empty cursor implementation object.
        """
        return AsyncThinCursorImpl.__new__(AsyncThinCursorImpl, self)

    async def _complete_pipeline_op(self, Message message):
        """
        Completes a particular pipeline operation.
        """
        cdef:
            BaseAsyncProtocol protocol = <BaseAsyncProtocol> self._protocol
            PipelineOpResultImpl result_impl = message.pipeline_result_impl
            MessageWithData fetch_message, message_with_data
            PipelineOpImpl op_impl = result_impl.operation
            uint8_t op_type = op_impl.op_type
            AsyncThinCursorImpl cursor_impl

        # all operations other than commit make use of a cursor
        if op_type == PIPELINE_OP_TYPE_COMMIT:
            return 0

        # keep warning, if applicable
        message_with_data = <MessageWithData> message
        result_impl.warning = message_with_data.warning

        # resend the message if that is required (for operations that fetch
        # LOBS, for example)
        cursor_impl = message_with_data.cursor_impl
        if message.resend:
            await protocol._process_message(message)
            if op_type in (
                PIPELINE_OP_TYPE_FETCH_ONE,
                PIPELINE_OP_TYPE_FETCH_MANY,
                PIPELINE_OP_TYPE_FETCH_ALL,
            ):
                while cursor_impl._buffer_rowcount > 0:
                    result_impl.rows.append(cursor_impl._create_row())
        result_impl.fetch_metadata = cursor_impl.fetch_metadata

        # for fetchall(), perform as many round trips as are required to
        # complete the fetch
        if op_type == PIPELINE_OP_TYPE_FETCH_ALL:
            fetch_message = cursor_impl._create_message(
                FetchMessage, message_with_data.cursor
            )
            while cursor_impl._more_rows_to_fetch:
                await protocol._process_single_message(fetch_message)
                while cursor_impl._buffer_rowcount > 0:
                    result_impl.rows.append(cursor_impl._create_row())
                if op_type != PIPELINE_OP_TYPE_FETCH_ALL:
                    break

        # for PL/SQL blocks that required a single execute, perform any
        # remaining executes now
        if op_type == PIPELINE_OP_TYPE_EXECUTE_MANY \
                and message_with_data.num_execs < op_impl.num_execs:
            while op_impl.num_execs > 0:
                op_impl.num_execs -= 1
                message_with_data.offset += 1
                if not cursor_impl._statement.requires_single_execute():
                    break
                await protocol._process_message(message)
            if op_impl.num_execs > 0:
                message_with_data.num_execs = op_impl.num_execs
                await protocol._process_message(message)

        # populate the metadata for any partial types observed during the
        # execution of the pipeline
        if message_with_data.type_cache is not None:
            conn = message_with_data.cursor.connection
            await message_with_data.type_cache.populate_partial_types(conn)

    async def _complete_pipeline_ops(
        self, list messages, bint continue_on_error
    ):
        """
        Completes any pipeline operations that have not actually completed.
        This could be due to the fact that LOBs were fetched or a fetch all
        operation has more rows to fetch.
        """
        cdef:
            PipelineOpResultImpl result_impl
            Message message
        for message in messages:
            result_impl = message.pipeline_result_impl
            if result_impl.error is not None:
                continue
            try:
                await self._complete_pipeline_op(message)
            except Exception as e:
                if not continue_on_error:
                    raise
                result_impl._capture_err(e)

    async def _connect_with_address(self, Address address,
                                    Description description,
                                    ConnectParamsImpl params,
                                    str connect_string,
                                    bint raise_exception):
        """
        Internal method used for connecting with the given description and
        address.
        """
        cdef:
            BaseAsyncProtocol protocol = <BaseAsyncProtocol> self._protocol
        try:
            await protocol._connect_phase_one(self, params, description,
                                              address, connect_string)
        except (exceptions.DatabaseError, socket.gaierror,
                ConnectionRefusedError) as e:
            if raise_exception:
                errors._raise_err(errors.ERR_CONNECTION_FAILED, cause=e,
                                  connection_id=description.connection_id)
            return 0
        except Exception as e:
            errors._raise_err(errors.ERR_CONNECTION_FAILED, cause=e,
                              connection_id=description.connection_id)
        self._post_connect_phase_one(description, params)
        await self._protocol._connect_phase_two(self, description, params)

    async def _connect_with_description(self, Description description,
                                        ConnectParamsImpl params,
                                        bint final_desc):
        """
        Internal method used for connecting with the given description. Retry
        connecting to the socket if an attempt fails and retry_count is
        specified in the connect string.
        """
        cdef:
            uint32_t i, j, k, num_attempts, num_lists, num_addresses
            AddressList address_list
            bint raise_exc = False
            str connect_string
            Address address
        num_lists = len(description.active_children)
        num_attempts = description.retry_count + 1
        connect_string = _get_connect_data(description, self._connection_id, params)
        for i in range(num_attempts):
            for j, address_list in enumerate(description.active_children):
                num_addresses = len(address_list.active_children)
                for k, address in enumerate(address_list.active_children):
                    if final_desc:
                        raise_exc = i == num_attempts - 1 \
                                and j == num_lists - 1 \
                                and k == num_addresses - 1
                    await self._connect_with_address(address, description,
                                                     params, connect_string,
                                                     raise_exc)
                    if not self._protocol._in_connect:
                        return 0
            await asyncio.sleep(description.retry_delay)

    async def _connect_with_params(self, ConnectParamsImpl params):
        """
        Internal method used for connecting with the given parameters.
        """
        cdef:
            DescriptionList description_list = params.description_list
            ssize_t i, num_descriptions
            Description description
            bint final_desc
        description_list.set_active_children()
        num_descriptions = len(description_list.active_children)
        for i, description in enumerate(description_list.active_children):
            final_desc = (i == num_descriptions - 1)
            await self._connect_with_description(description, params,
                                                 final_desc)
            if not self._protocol._in_connect:
                break

    cdef Message _create_message_for_pipeline_op(
        self, object conn, PipelineOpImpl op_impl
    ):
        """
        Creates a single message for a pipeline operation.
        """
        cdef:
            AsyncThinCursorImpl cursor_impl
            MessageWithData message
            uint32_t num_execs = 1
            object cursor
        if op_impl.op_type == PIPELINE_OP_TYPE_COMMIT:
            return self._create_message(CommitMessage)
        cursor = conn.cursor()
        cursor_impl = <AsyncThinCursorImpl> cursor._impl
        if op_impl.op_type == PIPELINE_OP_TYPE_CALL_FUNC:
            execute_args = cursor._call_get_execute_args(
                op_impl.name,
                op_impl.parameters,
                op_impl.keyword_parameters,
                cursor.var(op_impl.return_type)
            )
            cursor._prepare_for_execute(*execute_args)
        elif op_impl.op_type == PIPELINE_OP_TYPE_CALL_PROC:
            execute_args = cursor._call_get_execute_args(
                op_impl.name,
                op_impl.parameters,
                op_impl.keyword_parameters
            )
            cursor._prepare_for_execute(*execute_args)
        elif op_impl.op_type == PIPELINE_OP_TYPE_EXECUTE:
            cursor._prepare_for_execute(op_impl.statement, op_impl.parameters)
        elif op_impl.op_type == PIPELINE_OP_TYPE_EXECUTE_MANY:
            num_execs = cursor_impl._prepare_for_executemany(
                cursor, op_impl.statement, op_impl.parameters
            )
            op_impl.num_execs = num_execs
            if cursor_impl._statement.requires_single_execute():
                num_execs = 1
        elif op_impl.op_type == PIPELINE_OP_TYPE_FETCH_ONE:
            cursor._prepare_for_execute(op_impl.statement, op_impl.parameters)
            cursor_impl.prefetchrows = 1
            cursor_impl.arraysize = 1
            cursor_impl.rowfactory = op_impl.rowfactory
        elif op_impl.op_type == PIPELINE_OP_TYPE_FETCH_MANY:
            cursor._prepare_for_execute(op_impl.statement, op_impl.parameters)
            cursor_impl.prefetchrows = op_impl.num_rows
            cursor_impl.arraysize = op_impl.num_rows
            cursor_impl.rowfactory = op_impl.rowfactory
        elif op_impl.op_type == PIPELINE_OP_TYPE_FETCH_ALL:
            cursor._prepare_for_execute(op_impl.statement, op_impl.parameters)
            cursor_impl.prefetchrows = op_impl.arraysize
            cursor_impl.arraysize = op_impl.arraysize
            cursor_impl.rowfactory = op_impl.rowfactory
        else:
            errors._raise_err(errors.ERR_UNSUPPORTED_PIPELINE_OPERATION,
                              op_type=op_impl.op_type)
        cursor_impl._preprocess_execute(conn)
        message = cursor_impl._create_message(ExecuteMessage, cursor)
        message.num_execs = num_execs
        return message

    cdef list _create_messages_for_pipeline(
        self, object conn, list results, bint continue_on_error
    ):
        """
        Creates a list of messages for the pipeline and returns them after they
        have been submitted to the database for processing.
        """
        cdef:
            PipelineOpResultImpl result_impl
            PipelineOpImpl op_impl
            uint64_t token_num
            Message message
            object result
            list messages
        messages = []
        token_num = 1
        for result in results:
            result_impl = result._impl
            op_impl = result_impl.operation
            try:
                message = self._create_message_for_pipeline_op(conn, op_impl)
            except Exception as e:
                if not continue_on_error:
                    raise
                result_impl._capture_err(e)
                continue
            message.pipeline_result_impl = result_impl
            message.token_num = token_num
            token_num += 1
            messages.append(message)
        return messages

    cdef int _populate_pipeline_op_result(self, Message message) except -1:
        """
        Populates the pipeline operation result object.
        """
        cdef:
            MessageWithData message_with_data
            AsyncThinCursorImpl cursor_impl
            PipelineOpResultImpl result_impl
            PipelineOpImpl op_impl
            BindVar bind_var
        result_impl = message.pipeline_result_impl
        op_impl = result_impl.operation
        if op_impl.op_type == PIPELINE_OP_TYPE_COMMIT:
            return 0
        message_with_data = <MessageWithData> message
        cursor_impl = <AsyncThinCursorImpl> message_with_data.cursor_impl
        if op_impl.op_type == PIPELINE_OP_TYPE_CALL_FUNC:
            bind_var = <BindVar> cursor_impl.bind_vars[0]
            result_impl.return_value = bind_var.var_impl.get_value(0)
        elif op_impl.op_type in (
            PIPELINE_OP_TYPE_FETCH_ONE,
            PIPELINE_OP_TYPE_FETCH_MANY,
            PIPELINE_OP_TYPE_FETCH_ALL,
        ):
            result_impl.rows = []
            while cursor_impl._buffer_rowcount > 0:
                result_impl.rows.append(cursor_impl._create_row())

    cdef int _populate_pipeline_op_results(
        self, list messages, bint continue_on_error
    ) except -1:
        """
        Populates the pipeline operation result objects associated with the
        messages that were processed on the database.
        """
        cdef:
            PipelineOpResultImpl result_impl
            Message message
        for message in messages:
            result_impl = message.pipeline_result_impl
            if result_impl.error is not None:
                continue
            try:
                self._populate_pipeline_op_result(message)
            except Exception as e:
                if not continue_on_error:
                    raise
                result_impl._capture_err(e)

    async def _run_pipeline_op_without_pipelining(
        self, object conn, PipelineOpResultImpl result_impl
    ):
        """
        Runs a pipeline operation without the use of pipelining.
        """
        cdef:
            PipelineOpImpl op_impl = result_impl.operation
            object cursor
        if op_impl.op_type == PIPELINE_OP_TYPE_COMMIT:
            await conn.commit()
            return
        cursor = conn.cursor()
        if op_impl.op_type == PIPELINE_OP_TYPE_CALL_FUNC:
            result_impl.return_value = await cursor.callfunc(
                op_impl.name,
                op_impl.return_type,
                op_impl.parameters,
                op_impl.keyword_parameters,
            )
        elif op_impl.op_type == PIPELINE_OP_TYPE_CALL_PROC:
            await cursor.callproc(
                op_impl.name, op_impl.parameters, op_impl.keyword_parameters
            )
        elif op_impl.op_type == PIPELINE_OP_TYPE_EXECUTE:
            await cursor.execute(op_impl.statement, op_impl.parameters)
        elif op_impl.op_type == PIPELINE_OP_TYPE_EXECUTE_MANY:
            await cursor.executemany(op_impl.statement, op_impl.parameters)
        elif op_impl.op_type == PIPELINE_OP_TYPE_FETCH_ALL:
            await cursor.execute(op_impl.statement, op_impl.parameters)
            cursor.rowfactory = op_impl.rowfactory
            result_impl.rows = await cursor.fetchall()
        elif op_impl.op_type == PIPELINE_OP_TYPE_FETCH_MANY:
            await cursor.execute(op_impl.statement, op_impl.parameters)
            cursor.rowfactory = op_impl.rowfactory
            result_impl.rows = await cursor.fetchmany(op_impl.num_rows)
        elif op_impl.op_type == PIPELINE_OP_TYPE_FETCH_ONE:
            await cursor.execute(op_impl.statement, op_impl.parameters)
            cursor.rowfactory = op_impl.rowfactory
            result_impl.rows = await cursor.fetchmany(1)
        else:
            errors._raise_err(errors.ERR_UNSUPPORTED_PIPELINE_OPERATION,
                              op_type=op_impl.op_type)
        result_impl.warning = cursor.warning
        result_impl.fetch_metadata = cursor._impl.fetch_metadata

    cdef int _send_messages_for_pipeline(
        self, list messages, bint continue_on_error
    ) except -1:
        """
        Sends the messages for the pipeline to the database for processing.
        """
        cdef:
            BaseAsyncProtocol protocol = <BaseAsyncProtocol> self._protocol
            Message message
        for message in messages:
            try:
                message.send(protocol._write_buf)
            except Exception as e:
                if not continue_on_error:
                    raise
                message.pipeline_result_impl._capture_err(e)

    async def change_password(self, str old_password, str new_password):
        cdef:
            BaseAsyncProtocol protocol = <BaseAsyncProtocol> self._protocol
            Message message
        message = self._create_change_password_message(old_password,
                                                       new_password)
        await protocol._process_single_message(message)

    async def close(self, bint in_del=False):
        """
        Sends the messages needed to disconnect from the database.
        """
        cdef BaseAsyncProtocol protocol = <BaseAsyncProtocol> self._protocol
        try:
            await protocol._close(self)
        except (ssl.SSLError, exceptions.DatabaseError):
            pass

    async def commit(self):
        """
        Sends the message to commit any pending transaction.
        """
        cdef:
            BaseAsyncProtocol protocol = <BaseAsyncProtocol> self._protocol
            Message message
        message = self._create_message(CommitMessage)
        await protocol._process_single_message(message)

    async def connect(self, ConnectParamsImpl params):
        """
        Sends the messages needed to connect to the database.
        """
        cdef BaseAsyncProtocol protocol = <BaseAsyncProtocol> self._protocol
        protocol._read_buf._loop = asyncio.get_running_loop()
        try:
            self._pre_connect(params)
            await self._connect_with_params(params)
            self._post_connect_phase_two(params)
        except:
            self._force_close()
            raise

    def create_queue_impl(self):
        """
        Create and return the implementation object to use for AQ queuing.
        """
        return AsyncThinQueueImpl.__new__(AsyncThinQueueImpl)

    async def create_temp_lob_impl(self, DbType dbtype):
        cdef AsyncThinLobImpl lob_impl = self._create_lob_impl(dbtype)
        await lob_impl.create_temp()
        return lob_impl

    async def get_type(self, object conn, str name):
        cdef AsyncThinDbObjectTypeCache cache = \
                get_dbobject_type_cache(self._dbobject_type_cache_num)
        return await cache.get_type(conn, name)

    async def ping(self):
        cdef:
            BaseAsyncProtocol protocol = <BaseAsyncProtocol> self._protocol
            Message message
        message = self._create_message(PingMessage)
        await protocol._process_single_message(message)

    async def rollback(self):
        """
        Sends the message to roll back any pending transaction.
        """
        cdef:
            BaseAsyncProtocol protocol = <BaseAsyncProtocol> self._protocol
            Message message
        message = self._create_message(RollbackMessage)
        await protocol._process_single_message(message)

    async def run_pipeline_with_pipelining(
        self, object conn, list results, bint continue_on_error
    ):
        """
        Run the pipeline with pipelining when the database supports it.
        """
        cdef:
            BaseAsyncProtocol protocol = <BaseAsyncProtocol> self._protocol
            list messages
        messages = self._create_messages_for_pipeline(
            conn, results, continue_on_error
        )
        if messages:
            protocol._read_buf.reset_packets()
            if continue_on_error:
                self.pipeline_mode = TNS_PIPELINE_MODE_CONTINUE_ON_ERROR
            else:
                self.pipeline_mode = TNS_PIPELINE_MODE_ABORT_ON_ERROR
            self._send_messages_for_pipeline(messages, continue_on_error)
            await protocol.end_pipeline(self, messages, continue_on_error)
            self._populate_pipeline_op_results(messages, continue_on_error)
            await self._complete_pipeline_ops(messages, continue_on_error)

    async def run_pipeline_without_pipelining(
        self, object conn, list results, bint continue_on_error
    ):
        """
        Run the pipeline without pipelining when the database doesn't support
        pipelining. Call timeouts are disabled for consistency with when
        run with pipelining.
        """
        cdef:
            uint32_t call_timeout = self._call_timeout
            PipelineOpResultImpl result_impl
            object result
        try:
            for result in results:
                result_impl = result._impl
                try:
                    await self._run_pipeline_op_without_pipelining(
                        conn, result_impl
                    )
                except Exception as e:
                    if not continue_on_error:
                        raise
                    result_impl._capture_err(e)
        finally:
            self._call_timeout = call_timeout

    def set_call_timeout(self, uint32_t value):
        self._call_timeout = value

    def supports_pipelining(self):
        """
        Returns whether the connection supports pipelining. Currently this is
        only supported with asyncio and Oracle Database 23ai and later.
        """
        return self._protocol._caps.supports_pipelining

    async def tpc_begin(self, xid, uint32_t flags, uint32_t timeout):
        cdef:
            BaseAsyncProtocol protocol = <BaseAsyncProtocol> self._protocol
            TransactionSwitchMessage message
        message = self._create_message(TransactionSwitchMessage)
        message.operation = TNS_TPC_TXN_START
        message.xid = xid
        message.flags = flags
        message.timeout = timeout
        await protocol._process_single_message(message)
        self._transaction_context = message.context

    async def tpc_commit(self, xid, bint one_phase):
        cdef:
            BaseAsyncProtocol protocol = <BaseAsyncProtocol> self._protocol
            TransactionChangeStateMessage message
        message = self._create_tpc_commit_message(xid, one_phase)
        await protocol._process_single_message(message)
        self._check_tpc_commit_state(message.state, one_phase)

    async def tpc_end(self, xid, uint32_t flags):
        cdef:
            BaseAsyncProtocol protocol = <BaseAsyncProtocol> self._protocol
            TransactionSwitchMessage message
        message = self._create_message(TransactionSwitchMessage)
        message.operation = TNS_TPC_TXN_DETACH
        message.xid = xid
        message.context = self._transaction_context
        message.flags = flags
        await protocol._process_single_message(message)
        self._transaction_context = None

    async def tpc_prepare(self, xid):
        cdef:
            BaseAsyncProtocol protocol = <BaseAsyncProtocol> self._protocol
            TransactionChangeStateMessage message
        message = self._create_message(TransactionChangeStateMessage)
        message.operation = TNS_TPC_TXN_PREPARE
        message.xid = xid
        message.context = self._transaction_context
        await protocol._process_single_message(message)
        if message.state == TNS_TPC_TXN_STATE_REQUIRES_COMMIT:
            return True
        elif message.state == TNS_TPC_TXN_STATE_READ_ONLY:
            return False
        errors._raise_err(errors.ERR_UNKNOWN_TRANSACTION_STATE,
                          state=message.state)

    async def tpc_rollback(self, xid):
        cdef:
            BaseAsyncProtocol protocol = <BaseAsyncProtocol> self._protocol
            TransactionChangeStateMessage message
        message = self._create_tpc_rollback_message(xid)
        await protocol._process_single_message(message)
        if message.state != TNS_TPC_TXN_STATE_ABORTED:
            errors._raise_err(errors.ERR_UNKNOWN_TRANSACTION_STATE,
                              state=message.state)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\crypto.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2021, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# crypto.pyx
#
# Cython file defining the cryptographic methods used by the thin client
# (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

try:
    from cryptography import x509
    from cryptography.hazmat.primitives import hashes, serialization
    from cryptography.hazmat.primitives.ciphers import algorithms, modes, Cipher
    from cryptography.hazmat.primitives.asymmetric import padding
    from cryptography.hazmat.primitives.kdf import pbkdf2
except Exception as e:
    CRYPTOGRAPHY_IMPORT_ERROR = e


DN_REGEX = '(?:^|,\s?)(?:(?P<name>[A-Z]+)=(?P<val>"(?:[^"]|"")+"|[^,]+))+'
PEM_WALLET_FILE_NAME = "ewallet.pem"

def _name_matches(name_to_check, cert_name):
    """
    Returns a boolean indicating if the name to check matches with the
    certificate name. The certificate name may contain a wildcard (*)
    character.
    """

    # check for a full match (case insensitive)
    cert_name = cert_name.lower()
    name_to_check = name_to_check.lower()
    if name_to_check == cert_name:
        return True

    # ensure that more than one label exists in both the name to check and the
    # certificate name
    check_pos = name_to_check.find(".")
    cert_pos = cert_name.find(".")
    if check_pos <= 0 or cert_pos <= 0:
        return False

    # ensure that the right hand labels all match
    if name_to_check[check_pos:] != cert_name[cert_pos:]:
        return False

    # match wildcards, if applicable
    cert_label = cert_name[:cert_pos]
    check_label = name_to_check[:check_pos]
    if cert_label == "*":
        return True
    elif cert_label.startswith("*"):
        return check_label.endswith(cert_label[1:])
    elif cert_label.endswith("*"):
        return check_label.startswith(cert_label[:-1])
    wildcard_pos = cert_name.find("*")
    if wildcard_pos < 0:
        return False
    return check_label.startswith(cert_label[:wildcard_pos]) \
            and check_label.endswith(cert_label[wildcard_pos + 1:])


def check_server_dn(sock, expected_dn, expected_name):
    """
    Validates the server distinguished name (if one is specified) or the
    simple name (if a distinguished name is not present).
    """
    cert_data = sock.getpeercert(binary_form=True)
    cert = x509.load_der_x509_certificate(cert_data)
    if expected_dn is not None:
        server_dn = cert.subject.rfc4514_string()
        expected_dn_dict = dict(re.findall(DN_REGEX, expected_dn))
        server_dn_dict = dict(re.findall(DN_REGEX, server_dn))
        if server_dn_dict != expected_dn_dict:
            errors._raise_err(errors.ERR_INVALID_SERVER_CERT_DN,
                              expected_dn=expected_dn)
    else:
        try:
            ext = cert.extensions.get_extension_for_oid(
                x509.oid.ExtensionOID.SUBJECT_ALTERNATIVE_NAME
            )
            for name in ext.value.get_values_for_type(x509.DNSName):
                if _name_matches(expected_name, name):
                    return
        except x509.ExtensionNotFound:
            pass
        for name in cert.subject.get_attributes_for_oid(
            x509.oid.NameOID.COMMON_NAME
        ):
            if _name_matches(expected_name, name.value):
                return
        errors._raise_err(errors.ERR_INVALID_SERVER_NAME,
                          expected_name=expected_name)


def decrypt_cbc(key, encrypted_text):
    """
    Decrypt the given text using the given key.
    """
    iv = bytes(16)
    algo = algorithms.AES(key)
    cipher = Cipher(algo, modes.CBC(iv))
    decryptor = cipher.decryptor()
    return decryptor.update(encrypted_text)


def encrypt_cbc(key, plain_text, zeros=False):
    """
    Encrypt the given text using the given key. If the zeros flag is set, use
    zero padding if required. Otherwise, use number padding.
    """
    block_size = 16
    iv = bytes(block_size)
    algo = algorithms.AES(key)
    cipher = Cipher(algo, modes.CBC(iv))
    encryptor = cipher.encryptor()
    n = block_size - len(plain_text) % block_size
    if n:
        if zeros:
            plain_text += bytes(n)
        else:
            plain_text += (bytes([n]) * n)
    return encryptor.update(plain_text) + encryptor.finalize()


def get_derived_key(key, salt, length, iterations):
    """
    Return a derived key using PBKDF2.
    """
    kdf = pbkdf2.PBKDF2HMAC(algorithm=hashes.SHA512(), salt=salt,
                            length=length, iterations=iterations)
    return kdf.derive(key)


def get_signature(private_key_str, text):
    """
    Returns a signed version of the given text (used for IAM token
    authentication) in base64 encoding.
    """
    private_key = serialization.load_pem_private_key(private_key_str.encode(),
                                                     password=None)
    sig = private_key.sign(text.encode(), padding.PKCS1v15(), hashes.SHA256())
    return base64.b64encode(sig).decode()


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\cursor.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# cursor.pyx
#
# Cython file defining the thin Cursor implementation class (embedded in
# thin_impl.pyx).
#------------------------------------------------------------------------------

cdef class BaseThinCursorImpl(BaseCursorImpl):

    cdef:
        BaseThinConnImpl _conn_impl
        Statement _statement
        list _batcherrors
        list _dmlrowcounts
        list _implicit_resultsets
        uint64_t _buffer_min_row
        uint64_t _buffer_max_row
        uint32_t _num_columns
        uint32_t _last_row_index
        Rowid _lastrowid

    def __cinit__(self, conn_impl):
        self._conn_impl = conn_impl

    cdef int _close(self, bint in_del) except -1:
        if self._statement is not None:
            self._conn_impl._return_statement(self._statement)
            self._statement = None

    cdef MessageWithData _create_message(self, type typ, object cursor):
        """
        Creates a message object that is used to send a request to the database
        and receive back its response.
        """
        cdef MessageWithData message
        message = typ.__new__(typ, cursor, self)
        message._initialize(self._conn_impl)
        message.cursor = cursor
        message.cursor_impl = self
        return message

    cdef ExecuteMessage _create_execute_message(self, object cursor):
        """
        Creates and returns the message used to execute a statement once.
        """
        cdef ExecuteMessage message
        message = self._create_message(ExecuteMessage, cursor)
        message.num_execs = 1
        if self.scrollable:
            message.fetch_orientation = TNS_FETCH_ORIENTATION_CURRENT
            message.fetch_pos = 1
        return message

    cdef ExecuteMessage _create_scroll_message(self, object cursor,
                                               object mode, int32_t offset):
        """
        Creates a message object that is used to send a scroll request to the
        database and receive back its response.
        """
        cdef:
            uint64_t desired_row = 0
            uint32_t orientation = 0
            ExecuteMessage message

        # check mode and calculate desired row
        if mode == "relative":
            if <int64_t> (self.rowcount + offset) < 1:
                errors._raise_err(errors.ERR_SCROLL_OUT_OF_RESULT_SET)
            orientation = TNS_FETCH_ORIENTATION_RELATIVE
            desired_row = self.rowcount + offset
        elif mode == "absolute":
            orientation = TNS_FETCH_ORIENTATION_ABSOLUTE
            desired_row = <uint64_t> offset
        elif mode == "first":
            orientation = TNS_FETCH_ORIENTATION_FIRST
            desired_row = 1
        elif mode == "last":
            orientation = TNS_FETCH_ORIENTATION_LAST
        else:
            errors._raise_err(errors.ERR_WRONG_SCROLL_MODE)

        # determine if the server needs to be contacted at all
        # for "last", the server is always contacted
        if orientation != TNS_FETCH_ORIENTATION_LAST \
                and desired_row >= self._buffer_min_row \
                and desired_row < self._buffer_max_row:
            self._buffer_index = \
                    <uint32_t> (desired_row - self._buffer_min_row)
            self._buffer_rowcount = self._buffer_max_row - desired_row
            self.rowcount = desired_row - 1
            return None

        # build message
        message = self._create_message(ExecuteMessage, cursor)
        message.scroll_operation = self._more_rows_to_fetch
        message.fetch_orientation = orientation
        message.fetch_pos = <uint32_t> desired_row
        return message

    cdef BaseVarImpl _create_var_impl(self, object conn):
        cdef ThinVarImpl var_impl
        var_impl = ThinVarImpl.__new__(ThinVarImpl)
        var_impl._conn_impl = self._conn_impl
        return var_impl

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef BaseVarImpl _create_fetch_var(self, object conn, object cursor,
                                       object type_handler,
                                       bint uses_metadata, ssize_t pos,
                                       OracleMetadata metadata):
        """
        Internal method that creates a fetch variable. A check is made after
        the variable is created to determine if a conversion is required and
        therefore a define must be performed.
        """
        cdef:
            ThinDbObjectTypeImpl typ_impl
            ThinVarImpl var_impl
        var_impl = <ThinVarImpl> BaseCursorImpl._create_fetch_var(
            self, conn, cursor, type_handler, uses_metadata, pos, metadata
        )
        if metadata.objtype is not None:
            typ_impl = metadata.objtype
            if typ_impl.is_xml_type:
                var_impl.outconverter = \
                        lambda v: v if isinstance(v, str) else v.read()

    cdef BaseConnImpl _get_conn_impl(self):
        """
        Internal method used to return the connection implementation associated
        with the cursor implementation.
        """
        return self._conn_impl

    cdef bint _is_plsql(self):
        return self._statement._is_plsql

    cdef int _prepare(self, str statement, str tag,
                      bint cache_statement) except -1:
        """
        Internal method for preparing a statement for execution.
        """
        BaseCursorImpl._prepare(self, statement, tag, cache_statement)
        if self._statement is not None:
            self._conn_impl._return_statement(self._statement)
            self._statement = None
        self._statement = self._conn_impl._get_statement(statement.strip(),
                                                         cache_statement)
        self.fetch_metadata = self._statement._fetch_metadata
        self.fetch_vars = self._statement._fetch_vars
        self.fetch_var_impls = self._statement._fetch_var_impls
        self._num_columns = self._statement._num_columns

    cdef int _preprocess_execute(self, object conn) except -1:
        cdef BindInfo bind_info
        if self.bind_vars is not None:
            self._perform_binds(conn, 0)
        for bind_info in self._statement._bind_info_list:
            if bind_info._bind_var_impl is None:
                errors._raise_err(errors.ERR_MISSING_BIND_VALUE,
                                  name=bind_info._bind_name)

    cdef int _post_process_scroll(self, ExecuteMessage message) except -1:
        """
        Called after a scroll operation has completed successfully. The row
        count and buffer row counts and indices are updated as required.
        """
        if self._buffer_rowcount == 0:
            if message.fetch_orientation not in (
                TNS_FETCH_ORIENTATION_FIRST,
                TNS_FETCH_ORIENTATION_LAST
            ):
                errors._raise_err(errors.ERR_SCROLL_OUT_OF_RESULT_SET)
            self.rowcount = 0
            self._more_rows_to_fetch = False
            self._buffer_index = 0
            self._buffer_min_row = 0
            self._buffer_max_row = 0
        else:
            self.rowcount = message.error_info.rowcount - self._buffer_rowcount
            self._buffer_min_row = self.rowcount + 1
            self._buffer_max_row = self._buffer_min_row + self._buffer_rowcount
            self._buffer_index = 0

    cdef int _set_fetch_array_size(self, uint32_t value):
        """
        Internal method for setting the fetch array size. This also ensures
        that any fetch variables have enough space to store the fetched rows
        that are returned.
        """
        cdef:
            ThinVarImpl var_impl
            uint32_t num_vals
        self._fetch_array_size = value
        if self.fetch_var_impls is not None:
            for var_impl in self.fetch_var_impls:
                if var_impl.num_elements >= self._fetch_array_size:
                    continue
                num_vals = (self._fetch_array_size - var_impl.num_elements)
                var_impl.num_elements = self._fetch_array_size
                var_impl._values.extend([None] * num_vals)

    def get_array_dml_row_counts(self):
        if self._dmlrowcounts is None:
            errors._raise_err(errors.ERR_ARRAY_DML_ROW_COUNTS_NOT_ENABLED)
        return self._dmlrowcounts

    def get_batch_errors(self):
        return self._batcherrors

    def get_bind_names(self):
        return list(self._statement._bind_info_dict.keys())

    def get_implicit_results(self, connection):
        if self._implicit_resultsets is None:
            errors._raise_err(errors.ERR_NO_STATEMENT_EXECUTED)
        return self._implicit_resultsets

    def get_lastrowid(self):
        if self.rowcount > 0:
            return _encode_rowid(&self._lastrowid)

    def is_query(self, connection):
        return self.fetch_vars is not None



cdef class ThinCursorImpl(BaseThinCursorImpl):

    cdef int _fetch_rows(self, object cursor) except -1:
        """
        Internal method used for fetching rows from the database.
        """
        cdef:
            Protocol protocol = <Protocol> self._conn_impl._protocol
            MessageWithData message
        if self._statement._sql is None:
            message = self._create_message(ExecuteMessage, cursor)
        else:
            message = self._create_message(FetchMessage, cursor)
        protocol._process_single_message(message)
        self._buffer_min_row = self.rowcount + 1
        self._buffer_max_row = self._buffer_min_row + self._buffer_rowcount

    def execute(self, cursor):
        cdef:
            Protocol protocol = <Protocol> self._conn_impl._protocol
            object conn = cursor.connection
            MessageWithData message
        self._preprocess_execute(conn)
        message = self._create_execute_message(cursor)
        protocol._process_single_message(message)
        self.warning = message.warning
        if self._statement._is_query:
            if message.type_cache is not None:
                message.type_cache.populate_partial_types(conn)

    def executemany(self, cursor, num_execs, batcherrors, arraydmlrowcounts):
        cdef:
            Protocol protocol = <Protocol> self._conn_impl._protocol
            MessageWithData messsage
            Statement stmt
            uint32_t i

        # set up message to send
        self._preprocess_execute(cursor.connection)
        message = self._create_message(ExecuteMessage, cursor)
        message.num_execs = num_execs
        message.batcherrors = batcherrors
        message.arraydmlrowcounts = arraydmlrowcounts
        stmt = self._statement

        # only DML statements may use the batch errors or array DML row counts
        # flags
        if not stmt._is_dml and (batcherrors or arraydmlrowcounts):
            errors._raise_err(errors.ERR_EXECUTE_MODE_ONLY_FOR_DML)

        # if a PL/SQL statement requires a full execute, perform only a single
        # iteration in order to allow the determination of input/output binds
        # to be completed; after that, an execution of the remaining iterations
        # can be performed (but only if the cursor remains intact)
        if stmt.requires_single_execute():
            message.num_execs = 1
            while num_execs > 0:
                num_execs -= 1
                protocol._process_single_message(message)
                message.offset += 1
                if stmt._cursor_id != 0:
                    break
        if num_execs > 0:
            message.num_execs = num_execs
            protocol._process_single_message(message)
        self.warning = message.warning

    def parse(self, cursor):
        cdef:
            Protocol protocol = <Protocol> self._conn_impl._protocol
            MessageWithData message
        message = self._create_message(ExecuteMessage, cursor)
        message.parse_only = True
        protocol._process_single_message(message)

    def scroll(self, object cursor, int32_t offset, object mode):
        cdef:
            Protocol protocol = <Protocol> self._conn_impl._protocol
            ExecuteMessage message
        message = self._create_scroll_message(cursor, mode, offset)
        if message is not None:
            protocol._process_single_message(message)
            self._post_process_scroll(message)


cdef class AsyncThinCursorImpl(BaseThinCursorImpl):

    def _build_json_converter_fn(self):
        """
        Internal method for building a JSON converter function with asyncio.
        """
        async def converter(value):
            if isinstance(value, PY_TYPE_ASYNC_LOB):
                value = await value.read()
            if isinstance(value, bytes):
                value = value.decode()
            if value:
                return json.loads(value)
        return converter

    async def _fetch_rows_async(self, object cursor):
        """
        Internal method used for fetching rows from the database.
        """
        cdef MessageWithData message
        if self._statement._sql is None:
            message = self._create_message(ExecuteMessage, cursor)
        else:
            message = self._create_message(FetchMessage, cursor)
        await self._conn_impl._protocol._process_single_message(message)
        self._buffer_min_row = self.rowcount + 1

    async def _preprocess_execute_async(self, object conn):
        """
        Performs the necessary steps required before actually executing the
        statement associated with the cursor.
        """
        cdef:
            ThinVarImpl var_impl
            BindInfo bind_info
            ssize_t idx
        self._preprocess_execute(conn)
        for bind_info in self._statement._bind_info_list:
            var_impl = bind_info._bind_var_impl
            if var_impl._coroutine_indexes is not None:
                for idx in var_impl._coroutine_indexes:
                    var_impl._values[idx] = await var_impl._values[idx]
                var_impl._coroutine_indexes = None

    async def execute(self, cursor):
        cdef:
            object conn = cursor.connection
            BaseAsyncProtocol protocol
            MessageWithData message
        protocol = <BaseAsyncProtocol> self._conn_impl._protocol
        await self._preprocess_execute_async(conn)
        message = self._create_execute_message(cursor)
        await protocol._process_single_message(message)
        self.warning = message.warning
        if self._statement._is_query:
            if message.type_cache is not None:
                await message.type_cache.populate_partial_types(conn)

    async def executemany(self, cursor, num_execs, batcherrors,
                          arraydmlrowcounts):
        cdef:
            BaseAsyncProtocol protocol
            MessageWithData messsage
            Statement stmt
            uint32_t i

        # set up message to send
        protocol = <BaseAsyncProtocol> self._conn_impl._protocol
        await self._preprocess_execute_async(cursor.connection)
        message = self._create_message(ExecuteMessage, cursor)
        message.num_execs = num_execs
        message.batcherrors = batcherrors
        message.arraydmlrowcounts = arraydmlrowcounts
        stmt = self._statement

        # only DML statements may use the batch errors or array DML row counts
        # flags
        if not stmt._is_dml and (batcherrors or arraydmlrowcounts):
            errors._raise_err(errors.ERR_EXECUTE_MODE_ONLY_FOR_DML)

        # if a PL/SQL statement requires a full execute, perform only a single
        # iteration in order to allow the determination of input/output binds
        # to be completed; after that, an execution of the remaining iterations
        # can be performed (but only if the cursor remains intact)
        if stmt.requires_single_execute():
            message.num_execs = 1
            while num_execs > 0:
                num_execs -= 1
                await protocol._process_single_message(message)
                message.offset += 1
                if stmt._cursor_id != 0:
                    break
        if num_execs > 0:
            message.num_execs = num_execs
            await protocol._process_single_message(message)
        self.warning = message.warning

    async def fetch_df_all(self, cursor):
        """
        Internal method used for fetching all data as OracleDataFrame
        """
        while self._more_rows_to_fetch:
            await self._fetch_rows_async(cursor)
        return self._finish_building_arrow_arrays()

    async def fetch_df_batches(self, cursor, int batch_size):
        """
        Internal method used for fetching next batch as OracleDataFrame.
        """
        # Return the prefetched batch
        yield self._finish_building_arrow_arrays()

        while self._more_rows_to_fetch:
            self._create_arrow_arrays()
            await self._fetch_rows_async(cursor)
            if self._buffer_rowcount > 0:
                yield self._finish_building_arrow_arrays()

    async def fetch_next_row(self, cursor):
        """
        Internal method used for fetching the next row from a cursor.
        """
        if self._buffer_rowcount == 0 and self._more_rows_to_fetch:
            await self._fetch_rows_async(cursor)
        if self._buffer_rowcount > 0:
            return self._create_row()

    async def parse(self, cursor):
        cdef:
            BaseAsyncProtocol protocol
            MessageWithData message
        protocol = <BaseAsyncProtocol> self._conn_impl._protocol
        message = self._create_message(ExecuteMessage, cursor)
        message.parse_only = True
        await protocol._process_single_message(message)

    async def scroll(self, object cursor, int32_t offset, object mode):
        cdef:
            BaseAsyncProtocol protocol
            MessageWithData message
        protocol = <BaseAsyncProtocol> self._conn_impl._protocol
        message = self._create_scroll_message(cursor, mode, offset)
        if message is not None:
            await protocol._process_single_message(message)
            self._post_process_scroll(message)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\dbobject.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2022, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# dbobject.pyx
#
# Cython file defining the thin DbObjectType, DbObjectAttr and DbObject
# implementation classes (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class DbObjectPickleBuffer(GrowableBuffer):

    cdef int _read_raw_bytes_and_length(self, const char_type **ptr,
                                        ssize_t *num_bytes) except -1:
        """
        Helper function that processes the length (if needed) and then acquires
        the specified number of bytes from the buffer.
        """
        cdef uint32_t extended_num_bytes
        if num_bytes[0] == TNS_LONG_LENGTH_INDICATOR:
            self.read_uint32be(&extended_num_bytes)
            num_bytes[0] = <ssize_t> extended_num_bytes
        ptr[0] = self._get_raw(num_bytes[0])

    cdef int _write_raw_bytes_and_length(self, const char_type *ptr,
                                         ssize_t num_bytes) except -1:
        """
        Helper function that writes the length in the format required before
        writing the bytes.
        """
        self.write_length(num_bytes)
        self.write_raw(ptr, <uint32_t> num_bytes)

    cdef int get_is_atomic_null(self, bint is_collection,
                                bint* is_null) except -1:
        """
        Reads the next byte and checks to see if the value is atomically null.
        If not, the byte is returned to the buffer for further processing.
        """
        cdef uint8_t value
        self.read_ub1(&value)
        if value == TNS_OBJ_ATOMIC_NULL \
                or (is_collection and value == TNS_NULL_LENGTH_INDICATOR):
            is_null[0] = True
        else:
            is_null[0] = False
            self._pos -= 1

    cdef int read_header(self, uint8_t* flags, uint8_t *version) except -1:
        """
        Reads the header of the pickled data.
        """
        cdef:
            uint32_t prefix_seg_length
            uint8_t tmp
        self.read_ub1(flags)
        self.read_ub1(version)
        self.skip_length()
        if flags[0] & TNS_OBJ_IS_DEGENERATE:
            errors._raise_not_supported("DbObject stored in a LOB")
        if flags[0] & TNS_OBJ_NO_PREFIX_SEG:
            return 0
        self.read_length(&prefix_seg_length)
        self.skip_raw_bytes(prefix_seg_length)

    cdef int read_length(self, uint32_t *length) except -1:
        """
        Read the length from the buffer. This will be a single byte, unless the
        value meets or exceeds TNS_LONG_LENGTH_INDICATOR. In that case, the
        value is stored as a 4-byte integer.
        """
        cdef uint8_t short_length
        self.read_ub1(&short_length)
        if short_length == TNS_LONG_LENGTH_INDICATOR:
            self.read_uint32be(length)
        else:
            length[0] = short_length

    cdef object read_xmltype(self, BaseThinConnImpl conn_impl):
        """
        Reads an XML type from the buffer. This is similar to reading a
        database object but with specialized processing.
        """
        cdef:
            uint8_t image_flags, image_version
            BaseThinLobImpl lob_impl
            const char_type *ptr
            ssize_t bytes_left
            uint32_t xml_flag
            type cls
        self.read_header(&image_flags, &image_version)
        self.skip_raw_bytes(1)              # XML version
        self.read_uint32be(&xml_flag)
        if xml_flag & TNS_XML_TYPE_FLAG_SKIP_NEXT_4:
            self.skip_raw_bytes(4)
        bytes_left = self.bytes_left()
        ptr = self.read_raw_bytes(bytes_left)
        if xml_flag & TNS_XML_TYPE_STRING:
            return ptr[:bytes_left].decode()
        elif xml_flag & TNS_XML_TYPE_LOB:
            lob_impl = conn_impl._create_lob_impl(DB_TYPE_CLOB,
                                                  ptr[:bytes_left])
            cls = PY_TYPE_ASYNC_LOB \
                if conn_impl._protocol._transport._is_async \
                else PY_TYPE_LOB
            return cls._from_impl(lob_impl)
        errors._raise_err(errors.ERR_UNEXPECTED_XML_TYPE, flag=xml_flag)

    cdef int skip_length(self) except -1:
        """
        Skips the length instead of reading it from the buffer.
        """
        cdef uint8_t short_length
        self.read_ub1(&short_length)
        if short_length == TNS_LONG_LENGTH_INDICATOR:
            self.skip_raw_bytes(4)

    cdef int write_header(self, ThinDbObjectImpl obj_impl) except -1:
        """
        Writes the header of the pickled data. Since the size is unknown at
        this point, zero is written initially and the actual size is written
        later.
        """
        cdef ThinDbObjectTypeImpl typ_impl = obj_impl.type
        self.write_uint8(obj_impl.image_flags)
        self.write_uint8(obj_impl.image_version)
        self.write_uint8(TNS_LONG_LENGTH_INDICATOR)
        self.write_uint32be(0)
        if typ_impl.is_collection:
            self.write_uint8(1)             # length of prefix segment
            self.write_uint8(1)             # prefix segment contents

    cdef int write_length(self, ssize_t length) except -1:
        """
        Writes the length to the buffer.
        """
        if length <= TNS_OBJ_MAX_SHORT_LENGTH:
            self.write_uint8(<uint8_t> length)
        else:
            self.write_uint8(TNS_LONG_LENGTH_INDICATOR)
            self.write_uint32be(<uint32_t> length)


@cython.final
cdef class TDSBuffer(Buffer):
    pass


cdef class ThinDbObjectImpl(BaseDbObjectImpl):
    cdef:
        uint8_t image_flags, image_version
        bytes toid, oid, packed_data
        uint32_t num_elements
        dict unpacked_assoc_array
        list unpacked_assoc_keys
        dict unpacked_attrs
        list unpacked_array
        uint16_t flags

    cdef inline int _ensure_assoc_keys(self) except -1:
        """
        Ensure that the keys for the associative array have been calculated.
        PL/SQL associative arrays keep their keys in sorted order so this must
        be calculated when indices are required.
        """
        if self.unpacked_assoc_keys is None:
            self.unpacked_assoc_keys = list(sorted(self.unpacked_assoc_array))

    cdef inline int _ensure_unpacked(self) except -1:
        """
        Ensure that the data has been unpacked.
        """
        if self.packed_data is not None:
            self._unpack_data()

    cdef bytes _get_packed_data(self):
        """
        Returns the packed data for the object. This will either be the value
        retrieved from the database or generated packed data (for new objects
        and those that have had their data unpacked already).
        """
        cdef:
            ThinDbObjectTypeImpl typ_impl = self.type
            DbObjectPickleBuffer buf
            ssize_t size
        if self.packed_data is not None:
            return self.packed_data
        buf = DbObjectPickleBuffer.__new__(DbObjectPickleBuffer)
        buf._initialize()
        buf.write_header(self)
        self._pack_data(buf)
        size = buf._pos
        buf.skip_to(3)
        buf.write_uint32be(size)
        return buf._data[:size]

    cdef int _pack_data(self, DbObjectPickleBuffer buf) except -1:
        """
        Packs the data from the object into the buffer.
        """
        cdef:
            ThinDbObjectTypeImpl typ_impl = self.type
            ThinDbObjectAttrImpl attr
            int32_t index
            object value
        if typ_impl.is_collection:
            buf.write_uint8(typ_impl.collection_flags)
            if typ_impl.collection_type == TNS_OBJ_PLSQL_INDEX_TABLE:
                self._ensure_assoc_keys()
                buf.write_length(len(self.unpacked_assoc_keys))
                for index in self.unpacked_assoc_keys:
                    buf.write_uint32be(<uint32_t> index)
                    self._pack_value(buf, typ_impl.element_metadata,
                                     self.unpacked_assoc_array[index])
            else:
                buf.write_length(len(self.unpacked_array))
                for value in self.unpacked_array:
                    self._pack_value(buf, typ_impl.element_metadata, value)
        else:
            for attr in typ_impl.attrs:
                self._pack_value(buf, attr, self.unpacked_attrs[attr.name])

    cdef int _pack_value(self, DbObjectPickleBuffer buf,
                         OracleMetadata metadata, object value) except -1:
        """
        Packs a value into the buffer. At this point it is assumed that the
        value matches the correct type.
        """
        cdef:
            uint8_t ora_type_num = metadata.dbtype._ora_type_num
            ThinDbObjectImpl obj_impl
            BaseThinLobImpl lob_impl
            bytes temp_bytes
        if value is None:
            if metadata.objtype is not None \
                    and not metadata.objtype.is_collection:
                buf.write_uint8(TNS_OBJ_ATOMIC_NULL)
            else:
                buf.write_uint8(TNS_NULL_LENGTH_INDICATOR)
        elif ora_type_num in (ORA_TYPE_NUM_CHAR, ORA_TYPE_NUM_VARCHAR):
            if metadata.dbtype._csfrm == CS_FORM_IMPLICIT:
                temp_bytes = (<str> value).encode()
            else:
                temp_bytes = (<str> value).encode(ENCODING_UTF16)
            buf.write_bytes_with_length(temp_bytes)
        elif ora_type_num == ORA_TYPE_NUM_NUMBER:
            temp_bytes = (<str> cpython.PyObject_Str(value)).encode()
            buf.write_oracle_number(temp_bytes)
        elif ora_type_num == ORA_TYPE_NUM_BINARY_INTEGER:
            buf.write_uint8(4)
            buf.write_uint32be(<uint32_t> value)
        elif ora_type_num == ORA_TYPE_NUM_RAW:
            buf.write_bytes_with_length(value)
        elif ora_type_num == ORA_TYPE_NUM_BINARY_DOUBLE:
            buf.write_binary_double(value)
        elif ora_type_num == ORA_TYPE_NUM_BINARY_FLOAT:
            buf.write_binary_float(value)
        elif ora_type_num == ORA_TYPE_NUM_BOOLEAN:
            buf.write_uint8(4)
            buf.write_uint32be(value)
        elif ora_type_num in (ORA_TYPE_NUM_DATE, ORA_TYPE_NUM_TIMESTAMP,
                              ORA_TYPE_NUM_TIMESTAMP_TZ,
                              ORA_TYPE_NUM_TIMESTAMP_LTZ):
            buf.write_oracle_date(value, metadata.dbtype._buffer_size_factor)
        elif ora_type_num in (ORA_TYPE_NUM_CLOB, ORA_TYPE_NUM_BLOB):
            lob_impl = <BaseThinLobImpl> value._impl
            buf.write_bytes_with_length(lob_impl._locator)
        elif ora_type_num == ORA_TYPE_NUM_OBJECT:
            obj_impl = value._impl
            if self.type.is_collection or obj_impl.type.is_collection:
                temp_bytes = obj_impl._get_packed_data()
                buf.write_bytes_with_length(temp_bytes)
            else:
                obj_impl._pack_data(buf)
        else:
            errors._raise_err(errors.ERR_DB_TYPE_NOT_SUPPORTED,
                              name=metadata.dbtype.name)

    cdef int _unpack_data(self) except -1:
        """
        Unpacks the packed data into a dictionary of Python values.
        """
        cdef DbObjectPickleBuffer buf
        buf = DbObjectPickleBuffer.__new__(DbObjectPickleBuffer)
        buf._populate_from_bytes(self.packed_data)
        buf.read_header(&self.image_flags, &self.image_version)
        self._unpack_data_from_buf(buf)
        self.packed_data = None

    cdef int _unpack_data_from_buf(self, DbObjectPickleBuffer buf) except -1:
        """
        Unpacks the data from the buffer into Python values.
        """
        cdef:
            dict unpacked_attrs = {}, unpacked_assoc_array = None
            ThinDbObjectTypeImpl typ_impl = self.type
            list unpacked_array = None
            ThinDbObjectAttrImpl attr
            uint32_t num_elements, i
            int32_t assoc_index
            object value
        if typ_impl.is_collection:
            if typ_impl.collection_type == TNS_OBJ_PLSQL_INDEX_TABLE:
                unpacked_assoc_array = {}
            else:
                unpacked_array = []
            buf.skip_raw_bytes(1)           # collection flags
            buf.read_length(&num_elements)
            for i in range(num_elements):
                if typ_impl.collection_type == TNS_OBJ_PLSQL_INDEX_TABLE:
                    buf.read_int32be(&assoc_index)
                value = self._unpack_value(buf, typ_impl.element_metadata)
                if typ_impl.collection_type == TNS_OBJ_PLSQL_INDEX_TABLE:
                    unpacked_assoc_array[assoc_index] = value
                else:
                    unpacked_array.append(value)
        else:
            unpacked_attrs = {}
            for attr in typ_impl.attrs:
                value = self._unpack_value(buf, attr)
                unpacked_attrs[attr.name] = value
        self.unpacked_attrs = unpacked_attrs
        self.unpacked_array = unpacked_array
        self.unpacked_assoc_array = unpacked_assoc_array

    cdef object _unpack_value(self, DbObjectPickleBuffer buf,
                              OracleMetadata metadata):
        """
        Unpacks a single value and returns it.
        """
        cdef:
            uint8_t ora_type_num = metadata.dbtype._ora_type_num
            uint8_t csfrm = metadata.dbtype._csfrm
            DbObjectPickleBuffer xml_buf
            bint is_null, is_collection
            BaseThinConnImpl conn_impl
            ThinDbObjectImpl obj_impl
            BaseThinLobImpl lob_impl
            OracleData data
            bytes locator
            type cls
        if ora_type_num in (ORA_TYPE_NUM_CLOB,
                              ORA_TYPE_NUM_BLOB,
                              ORA_TYPE_NUM_BFILE):
            conn_impl = self.type._conn_impl
            locator = buf.read_bytes()
            if locator is None:
                return None
            lob_impl = conn_impl._create_lob_impl(metadata.dbtype, locator)
            cls = PY_TYPE_ASYNC_LOB \
                    if conn_impl._protocol._transport._is_async \
                    else PY_TYPE_LOB
            return cls._from_impl(lob_impl)
        elif ora_type_num == ORA_TYPE_NUM_OBJECT:
            is_collection = \
                    metadata.objtype.is_collection or self.type.is_collection
            buf.get_is_atomic_null(is_collection, &is_null)
            if is_null:
                return None
            if metadata.objtype is None:
                xml_buf = DbObjectPickleBuffer.__new__(DbObjectPickleBuffer)
                xml_buf._populate_from_bytes(buf.read_bytes())
                return xml_buf.read_xmltype(self.type._conn_impl)
            obj_impl = ThinDbObjectImpl.__new__(ThinDbObjectImpl)
            obj_impl.type = metadata.objtype
            if is_collection:
                obj_impl.packed_data = buf.read_bytes()
            else:
                obj_impl._unpack_data_from_buf(buf)
            return PY_TYPE_DB_OBJECT._from_impl(obj_impl)
        buf.read_oracle_data(metadata, &data, from_dbobject=True)
        if metadata.dbtype._csfrm == CS_FORM_NCHAR:
            conn_impl = self.type._conn_impl
            conn_impl._protocol._caps._check_ncharset_id()
        return convert_oracle_data_to_python(metadata, metadata, &data,
                                             encoding_errors=NULL,
                                             from_dbobject=True)

    def append_checked(self, object value):
        """
        Internal method for appending a value to a collection object.
        """
        cdef:
            ThinDbObjectTypeImpl typ_impl
            int32_t new_index
        self._ensure_unpacked()
        if self.unpacked_array is not None:
            typ_impl = self.type
            if typ_impl.max_num_elements > 0 \
                    and len(self.unpacked_array) >= typ_impl.max_num_elements:
                errors._raise_err(errors.ERR_INVALID_COLL_INDEX_SET,
                                  index=len(self.unpacked_array),
                                  min_index=0,
                                  max_index=typ_impl.max_num_elements - 1)
            self.unpacked_array.append(value)
        else:
            self._ensure_assoc_keys()
            new_index = self.unpacked_assoc_keys[-1] + 1 \
                    if self.unpacked_assoc_keys else 0
            self.unpacked_assoc_array[new_index] = value
            self.unpacked_assoc_keys.append(new_index)

    def copy(self):
        """
        Internal method for creating a copy of an object.
        """
        cdef ThinDbObjectImpl copied_impl
        copied_impl = ThinDbObjectImpl.__new__(ThinDbObjectImpl)
        copied_impl.type = self.type
        copied_impl.flags = self.flags
        copied_impl.image_flags = self.image_flags
        copied_impl.image_version = self.image_version
        copied_impl.toid = self.toid
        copied_impl.packed_data = self.packed_data
        copied_impl.num_elements = self.num_elements
        if self.unpacked_attrs is not None:
            copied_impl.unpacked_attrs = self.unpacked_attrs.copy()
        if self.unpacked_array is not None:
            copied_impl.unpacked_array = list(self.unpacked_array)
        return copied_impl

    def delete_by_index(self, int32_t index):
        """
        Internal method for deleting an entry from a collection that is indexed
        by integers.
        """
        self._ensure_unpacked()
        if self.unpacked_array is not None:
            del self.unpacked_array[index]
        else:
            self.unpacked_assoc_keys = None
            del self.unpacked_assoc_array[index]

    def exists_by_index(self, int32_t index):
        """
        Internal method for determining if an entry exists in a collection that
        is indexed by integers.
        """
        self._ensure_unpacked()
        if self.unpacked_array is not None:
            return index >= 0 and index < len(self.unpacked_array)
        else:
            return index in self.unpacked_assoc_array

    def get_attr_value(self, ThinDbObjectAttrImpl attr):
        """
        Internal method for getting an attribute value.
        """
        self._ensure_unpacked()
        return self.unpacked_attrs[attr.name]

    def get_element_by_index(self, int32_t index):
        """
        Internal method for getting an entry from a collection that is indexed
        by integers.
        """
        self._ensure_unpacked()
        try:
            if self.unpacked_array is not None:
                return self.unpacked_array[index]
            else:
                return self.unpacked_assoc_array[index]
        except (KeyError, IndexError):
            errors._raise_err(errors.ERR_INVALID_COLL_INDEX_GET, index=index)

    def get_first_index(self):
        """
        Internal method for getting the first index from a collection that is
        indexed by integers.
        """
        self._ensure_unpacked()
        if self.unpacked_array:
            return 0
        elif self.unpacked_assoc_array:
            self._ensure_assoc_keys()
            return self.unpacked_assoc_keys[0]

    def get_last_index(self):
        """
        Internal method for getting the last index from a collection that is
        indexed by integers.
        """
        self._ensure_unpacked()
        if self.unpacked_array:
            return len(self.unpacked_array) - 1
        elif self.unpacked_assoc_array:
            self._ensure_assoc_keys()
            return self.unpacked_assoc_keys[-1]

    def get_next_index(self, int32_t index):
        """
        Internal method for getting the next index from a collection that is
        indexed by integers.
        """
        cdef int32_t i
        self._ensure_unpacked()
        if self.unpacked_array:
            if index + 1 < len(self.unpacked_array):
                return index + 1
        elif self.unpacked_assoc_array:
            self._ensure_assoc_keys()
            for i in self.unpacked_assoc_keys:
                if i > index:
                    return i

    def get_prev_index(self, int32_t index):
        """
        Internal method for getting the next index from a collection that is
        indexed by integers.
        """
        self._ensure_unpacked()
        if self.unpacked_array:
            if index > 0:
                return index - 1
        elif self.unpacked_assoc_array:
            self._ensure_assoc_keys()
            for i in reversed(self.unpacked_assoc_keys):
                if i < index:
                    return i

    def get_size(self):
        """
        Internal method for getting the size of a collection.
        """
        self._ensure_unpacked()
        if self.unpacked_array is not None:
            return len(self.unpacked_array)
        else:
            return len(self.unpacked_assoc_array)

    def set_attr_value_checked(self, ThinDbObjectAttrImpl attr, object value):
        """
        Internal method for setting an attribute value.
        """
        self._ensure_unpacked()
        self.unpacked_attrs[attr.name] = value

    def set_element_by_index_checked(self, int32_t index, object value):
        """
        Internal method for setting an entry in a collection that is indexed by
        integers.
        """
        self._ensure_unpacked()
        if self.unpacked_array is not None:
            try:
                self.unpacked_array[index] = value
            except IndexError:
                max_index = max(len(self.unpacked_array) - 1, 0)
                errors._raise_err(errors.ERR_INVALID_COLL_INDEX_SET,
                                  index=index, min_index=0,
                                  max_index=max_index)
        else:
            if index not in self.unpacked_assoc_array:
                self.unpacked_assoc_keys = None
            self.unpacked_assoc_array[index] = value

    def trim(self, int32_t num_to_trim):
        """
        Internal method for trimming a number of entries from a collection.
        """
        self._ensure_unpacked()
        if num_to_trim > 0:
            self.unpacked_array = self.unpacked_array[:-num_to_trim]


cdef class ThinDbObjectAttrImpl(BaseDbObjectAttrImpl):
    cdef:
        bytes oid


cdef class ThinDbObjectTypeImpl(BaseDbObjectTypeImpl):
    cdef:
        uint8_t collection_type, collection_flags, version
        uint32_t max_num_elements
        bint is_row_type
        bint is_xml_type
        bytes oid

    def create_new_object(self):
        """
        Internal method for creating a new object.
        """
        cdef ThinDbObjectImpl obj_impl
        obj_impl = ThinDbObjectImpl.__new__(ThinDbObjectImpl)
        obj_impl.type = self
        obj_impl.toid = b'\x00\x22' + \
                bytes([TNS_OBJ_NON_NULL_OID, TNS_OBJ_HAS_EXTENT_OID]) + \
                self.oid + TNS_EXTENT_OID
        obj_impl.flags = TNS_OBJ_TOP_LEVEL
        obj_impl.image_flags = TNS_OBJ_IS_VERSION_81
        obj_impl.image_version = TNS_OBJ_IMAGE_VERSION
        obj_impl.unpacked_attrs = {}
        if self.is_collection:
            obj_impl.image_flags |= TNS_OBJ_IS_COLLECTION
            if self.collection_type == TNS_OBJ_PLSQL_INDEX_TABLE:
                obj_impl.unpacked_assoc_array = {}
            else:
                obj_impl.unpacked_array = []
        else:
            obj_impl.image_flags |= TNS_OBJ_NO_PREFIX_SEG
            for attr in self.attrs:
                obj_impl.unpacked_attrs[attr.name] = None
        return obj_impl


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\dbobject_cache.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2022, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# dbobject_cache.pyx
#
# Cython file defining the DbObject cache implementation class (embedded in
# thin_impl.pyx).
#------------------------------------------------------------------------------

# SQL statements used within the DbObject type cache
cdef str DBO_CACHE_SQL_GET_METADATA_FOR_NAME = """
        declare
            t_Instantiable              varchar2(3);
            t_SuperTypeOwner            varchar2(128);
            t_SuperTypeName             varchar2(128);
            t_SubTypeRefCursor          sys_refcursor;
            t_Pos                       pls_integer;
        begin
            :ret_val := dbms_pickler.get_type_shape(:full_name, :oid,
                :version, :tds, t_Instantiable, t_SuperTypeOwner,
                t_SuperTypeName, :attrs_rc, t_SubTypeRefCursor);
            :package_name := null;
            if substr(:full_name, length(:full_name) - 7) = '%ROWTYPE' then
                t_Pos := instr(:full_name, '.');
                :schema := substr(:full_name, 1, t_Pos - 1);
                :name := substr(:full_name, t_Pos + 1);
            else
                begin
                    select owner, type_name
                    into :schema, :name
                    from all_types
                    where type_oid = :oid;
                exception
                when no_data_found then
                    begin
                        select owner, package_name, type_name
                        into :schema, :package_name, :name
                        from all_plsql_types
                        where type_oid = :oid;
                    exception
                    when no_data_found then
                        null;
                    end;
                end;
            end if;
        end;"""

cdef str DBO_CACHE_SQL_GET_COLUMNS = """
        select
            column_name,
            data_type,
            data_type_owner,
            case
                when data_type in
                        ('CHAR', 'NCHAR', 'VARCHAR2', 'NVARCHAR2', 'RAW')
                    then data_length
                else 0
            end,
            case
                when data_precision is null and data_scale is null
                    then 0
                when data_precision is null
                    then 38
                else data_precision
            end,
            case
                when data_precision is null and data_scale is null
                        and data_type = 'NUMBER'
                    then -127
                when data_scale is null
                    then 0
                else data_scale
            end
        from all_tab_cols
        where owner = :owner
          and table_name = substr(:name, 1, length(:name) - 8)
          and hidden_column != 'YES'
        order by column_id"""

cdef str DBO_CACHE_SQL_GET_ELEM_TYPE_WITH_PACKAGE = """
        select elem_type_name
        from all_plsql_coll_types
        where owner = :owner
          and package_name = :package_name
          and type_name = :name"""

cdef str DBO_CACHE_SQL_GET_ELEM_TYPE_NO_PACKAGE = """
        select elem_type_name
        from all_coll_types
        where owner = :owner
          and type_name = :name"""

cdef str DBO_CACHE_SQL_GET_ELEM_OBJTYPE_WITH_PACKAGE = """
        select
            elem_type_owner,
            elem_type_package,
            elem_type_name
        from all_plsql_coll_types
        where owner = :owner
          and package_name = :package_name
          and type_name = :name"""

cdef str DBO_CACHE_SQL_GET_ELEM_OBJTYPE_NO_PACKAGE = """
        select
            elem_type_owner,
            elem_type_name
        from all_coll_types
        where owner = :owner
          and type_name = :name"""

cdef class ThinDbObjectTypeSuperCache:
    cdef:
        dict caches
        object lock
        int cache_num

    def __init__(self):
        self.caches = {}
        self.cache_num = 0
        self.lock = threading.Lock()


cdef class BaseThinDbObjectTypeCache:

    cdef:
        object meta_cursor, columns_cursor, attrs_ref_cursor_var, version_var
        object return_value_var, full_name_var, oid_var, tds_var
        object schema_var, package_name_var, name_var
        BaseThinConnImpl conn_impl
        dict types_by_oid
        dict types_by_name
        list partial_types

    cdef int _clear_cursors(self) except -1:
        """
        Clears the cursors used for searching metadata. This is needed when
        returning a connection to the pool since user-level objects are
        retained.
        """
        if self.meta_cursor is not None:
            self.meta_cursor.close()
            self.meta_cursor = None
            self.return_value_var = None
            self.full_name_var = None
            self.oid_var = None
            self.tds_var = None
            self.attrs_ref_cursor_var = None
            self.version_var = None
            self.schema_var = None
            self.package_name_var = None
            self.name_var = None
        if self.columns_cursor is not None:
            self.columns_cursor.close()
            self.columns_cursor = None

    cdef str _get_full_name(self, ThinDbObjectTypeImpl typ_impl):
        """
        Gets the full name of the type which is used for searching the database
        for the type information.
        """
        cdef str name, suffix = "%ROWTYPE"
        if typ_impl.name.endswith(suffix):
            name = typ_impl.name[:-len(suffix)]
        else:
            name = typ_impl.name
            suffix = ""
        if typ_impl.package_name is None:
            return f'"{typ_impl.schema}"."{name}"{suffix}'
        return f'"{typ_impl.schema}".' + \
               f'"{typ_impl.package_name}".' + \
               f'"{name}"{suffix}'

    cdef int _initialize(self, BaseThinConnImpl conn_impl) except -1:
        self.types_by_oid = {}
        self.types_by_name = {}
        self.partial_types = []
        self.conn_impl = conn_impl

    cdef int _init_columns_cursor(self, object conn) except -1:
        """
        Initializes the cursor that fetches the columns for a table or view.
        The input values come from the meta cursor that has been initialized
        and executed earlier.
        """
        cursor = conn.cursor()
        cursor.setinputsizes(owner=self.schema_var, name=self.name_var)
        cursor.prepare(DBO_CACHE_SQL_GET_COLUMNS)
        self.columns_cursor = cursor

    cdef int _init_meta_cursor(self, object conn) except -1:
        """
        Initializes the cursor that fetches the type metadata.
        """
        cursor = conn.cursor()
        self.return_value_var = cursor.var(DB_TYPE_BINARY_INTEGER)
        self.tds_var = cursor.var(bytes)
        self.full_name_var = cursor.var(str)
        self.schema_var = cursor.var(str)
        self.package_name_var = cursor.var(str)
        self.name_var = cursor.var(str)
        self.oid_var = cursor.var(bytes)
        self.version_var = cursor.var(DB_TYPE_BINARY_INTEGER)
        self.attrs_ref_cursor_var = cursor.var(DB_TYPE_CURSOR)
        cursor.setinputsizes(ret_val=self.return_value_var,
                             tds=self.tds_var,
                             full_name=self.full_name_var,
                             oid=self.oid_var,
                             schema=self.schema_var,
                             package_name=self.package_name_var,
                             name=self.name_var,
                             version=self.version_var,
                             attrs_rc=self.attrs_ref_cursor_var)
        cursor.prepare(DBO_CACHE_SQL_GET_METADATA_FOR_NAME)
        self.meta_cursor = cursor

    cdef object _parse_tds(self, ThinDbObjectTypeImpl typ_impl, bytes tds):
        """
        Parses the TDS for the type. This is only needed for collection types,
        so if the TDS is determined to be for an object type, the remaining
        information is skipped.
        """
        cdef:
            ThinDbObjectAttrImpl attr_impl
            OracleMetadata metadata
            uint16_t num_attrs, i
            uint8_t attr_type
            TDSBuffer buf
            uint32_t pos

        # parse initial TDS bytes
        buf = TDSBuffer.__new__(TDSBuffer)
        buf._populate_from_bytes(tds)
        buf.skip_raw_bytes(4)               # end offset
        buf.skip_raw_bytes(2)               # version op code and version
        buf.skip_raw_bytes(2)               # unknown
        buf.read_uint16be(&num_attrs)       # number of attributes
        buf.skip_raw_bytes(1)               # TDS attributes?
        buf.skip_raw_bytes(1)               # start ADT op code
        buf.skip_raw_bytes(2)               # ADT number (always zero)
        buf.skip_raw_bytes(4)               # offset to index table

        # check to see if type refers to a collection (only one attribute is
        # present in that case)
        if num_attrs == 1:
            pos = buf._pos
            buf.read_ub1(&attr_type)
            if attr_type == TNS_OBJ_TDS_TYPE_COLL:
                typ_impl.is_collection = True
            else:
                buf.skip_to(pos)

        # handle collections
        if typ_impl.is_collection:
            buf.read_uint32be(&pos)
            buf.read_uint32be(&typ_impl.max_num_elements)
            buf.read_ub1(&typ_impl.collection_type)
            if typ_impl.collection_type == TNS_OBJ_PLSQL_INDEX_TABLE:
                typ_impl.collection_flags = TNS_OBJ_HAS_INDEXES
            buf.skip_to(pos)
            typ_impl.element_metadata = self._parse_tds_attr(buf)
            typ_impl.element_metadata._finalize_init()
            if typ_impl.element_metadata.dbtype is DB_TYPE_CLOB:
                return self._get_element_type_clob(typ_impl)
            elif typ_impl.element_metadata.dbtype is DB_TYPE_OBJECT:
                return self._get_element_type_obj(typ_impl)

        # handle objects with attributes
        else:
            for i, attr_impl in enumerate(typ_impl.attrs):
                metadata = self._parse_tds_attr(buf)
                if metadata.precision != 0 or metadata.scale != 0:
                    attr_impl.precision = metadata.precision
                    attr_impl.scale = metadata.scale
                attr_impl.max_size = metadata.max_size
                metadata._finalize_init()

    cdef OracleMetadata _parse_tds_attr(self, TDSBuffer buf):
        """
        Parses a TDS attribute from the buffer.
        """
        cdef:
            uint8_t attr_type, ora_type_num = 0, csfrm = 0
            int8_t temp_precision, temp_scale
            OracleMetadata metadata
            uint16_t temp16

        # skip until a type code that is of interest
        while True:
            buf.read_ub1(&attr_type)
            if attr_type == TNS_OBJ_TDS_TYPE_EMBED_ADT_INFO:
                buf.skip_raw_bytes(1)       # flags
            elif attr_type != TNS_OBJ_TDS_TYPE_SUBTYPE_MARKER:
                break

        # process the type code
        metadata = OracleMetadata.__new__(OracleMetadata)
        if attr_type == TNS_OBJ_TDS_TYPE_NUMBER:
            ora_type_num = ORA_TYPE_NUM_NUMBER
            buf.read_sb1(&temp_precision)
            buf.read_sb1(&temp_scale)
            if temp_precision != 0 or temp_scale != 0:
                metadata.precision = temp_precision
                metadata.scale = temp_scale
        elif attr_type == TNS_OBJ_TDS_TYPE_FLOAT:
            ora_type_num = ORA_TYPE_NUM_NUMBER
            buf.skip_raw_bytes(1)           # precision
        elif attr_type in (TNS_OBJ_TDS_TYPE_VARCHAR, TNS_OBJ_TDS_TYPE_CHAR):
            buf.read_uint16be(&temp16)      # maximum length
            metadata.max_size = temp16
            buf.read_ub1(&csfrm)
            csfrm = csfrm & 0x7f
            buf.skip_raw_bytes(2)           # character set
            if attr_type == TNS_OBJ_TDS_TYPE_VARCHAR:
                ora_type_num = ORA_TYPE_NUM_VARCHAR
            else:
                ora_type_num = ORA_TYPE_NUM_CHAR
        elif attr_type == TNS_OBJ_TDS_TYPE_RAW:
            ora_type_num = ORA_TYPE_NUM_RAW
            buf.read_uint16be(&temp16)      # maximum length
            metadata.max_size = temp16
        elif attr_type == TNS_OBJ_TDS_TYPE_BINARY_FLOAT:
            ora_type_num = ORA_TYPE_NUM_BINARY_FLOAT
        elif attr_type == TNS_OBJ_TDS_TYPE_BINARY_DOUBLE:
            ora_type_num = ORA_TYPE_NUM_BINARY_DOUBLE
        elif attr_type == TNS_OBJ_TDS_TYPE_DATE:
            ora_type_num = ORA_TYPE_NUM_DATE
        elif attr_type == TNS_OBJ_TDS_TYPE_TIMESTAMP:
            buf.skip_raw_bytes(1)           # precision
            ora_type_num = ORA_TYPE_NUM_TIMESTAMP
        elif attr_type == TNS_OBJ_TDS_TYPE_TIMESTAMP_LTZ:
            buf.skip_raw_bytes(1)           # precision
            ora_type_num = ORA_TYPE_NUM_TIMESTAMP_LTZ
        elif attr_type == TNS_OBJ_TDS_TYPE_TIMESTAMP_TZ:
            buf.skip_raw_bytes(1)           # precision
            ora_type_num = ORA_TYPE_NUM_TIMESTAMP_TZ
        elif attr_type == TNS_OBJ_TDS_TYPE_BOOLEAN:
            ora_type_num = ORA_TYPE_NUM_BOOLEAN
        elif attr_type == TNS_OBJ_TDS_TYPE_CLOB:
            ora_type_num = ORA_TYPE_NUM_CLOB
            csfrm = CS_FORM_IMPLICIT
        elif attr_type == TNS_OBJ_TDS_TYPE_BLOB:
            ora_type_num = ORA_TYPE_NUM_BLOB
        elif attr_type == TNS_OBJ_TDS_TYPE_OBJ:
            ora_type_num = ORA_TYPE_NUM_OBJECT
            buf.skip_raw_bytes(5)           # offset and code
        elif attr_type == TNS_OBJ_TDS_TYPE_START_EMBED_ADT:
            ora_type_num = ORA_TYPE_NUM_OBJECT
            while self._parse_tds_attr(buf):
                pass
        elif attr_type == TNS_OBJ_TDS_TYPE_END_EMBED_ADT:
            return None
        else:
            errors._raise_err(errors.ERR_TDS_TYPE_NOT_SUPPORTED, num=attr_type)
        metadata.dbtype = DbType._from_ora_type_and_csfrm(ora_type_num, csfrm)
        return metadata

    cdef int _create_attr(self, ThinDbObjectTypeImpl typ_impl, str name,
                          str type_name, str type_owner,
                          str type_package_name=None, bytes oid=None,
                          int8_t precision=0, int8_t scale=0,
                          uint32_t max_size=0) except -1:
        """
        Creates an attribute from the supplied information and adds it to the
        list of attributes for the type.
        """
        cdef:
            ThinDbObjectTypeImpl attr_typ_impl
            ThinDbObjectAttrImpl attr_impl
        attr_impl = ThinDbObjectAttrImpl.__new__(ThinDbObjectAttrImpl)
        attr_impl.name = name
        if type_owner is not None:
            attr_typ_impl = self.get_type_for_info(oid, type_owner,
                                                   type_package_name,
                                                   type_name)
            if attr_typ_impl.is_xml_type:
                attr_impl.dbtype = DB_TYPE_XMLTYPE
            else:
                attr_impl.dbtype = DB_TYPE_OBJECT
                attr_impl.objtype = attr_typ_impl
        else:
            if type_name in ("INTEGER", "SMALLINT"):
                attr_impl.dbtype = DB_TYPE_NUMBER
                attr_impl.precision = 38
                attr_impl.scale = 0
            elif type_name == "REAL":
                attr_impl.dbtype = DB_TYPE_NUMBER
                attr_impl.precision = 63
                attr_impl.scale = -127
            elif type_name in ("DOUBLE PRECISION", "FLOAT"):
                attr_impl.dbtype = DB_TYPE_NUMBER
                # the database sends type name "FLOAT" instead of type name
                # "REAL" when looking at table metadata but not when examining
                # database object attribute metadata so account for that here
                if precision != 0:
                    attr_impl.precision = precision
                else:
                    attr_impl.precision = 126
                attr_impl.scale = -127
            else:
                attr_impl.dbtype = DbType._from_ora_name(type_name)
                attr_impl.max_size = max_size
                if attr_impl.dbtype._ora_type_num == ORA_TYPE_NUM_NUMBER:
                    attr_impl.precision = precision
                    attr_impl.scale = scale
        attr_impl._finalize_init()
        typ_impl.attrs.append(attr_impl)
        typ_impl.attrs_by_name[name] = attr_impl

    cdef object _populate_type_info(self, str name, object attrs,
                                    ThinDbObjectTypeImpl typ_impl):
        """
        Populate the type information given the name of the type.
        """
        cdef:
            ssize_t start_pos, end_pos, name_length
            ThinDbObjectAttrImpl attr_impl
            str data_type
        typ_impl.version = self.version_var.getvalue()
        if typ_impl.oid is None:
            typ_impl.oid = self.oid_var.getvalue()
            self.types_by_oid[typ_impl.oid] = typ_impl
        if typ_impl.schema is None:
            typ_impl.schema = self.schema_var.getvalue()
            typ_impl.package_name = self.package_name_var.getvalue()
            typ_impl.name = self.name_var.getvalue()
            if typ_impl.name is None:
                errors._raise_err(errors.ERR_INVALID_OBJECT_TYPE_NAME,
                                  name=name)
            typ_impl.is_xml_type = \
                    (typ_impl.schema == "SYS" and typ_impl.name == "XMLTYPE")
        typ_impl.attrs = []
        typ_impl.attrs_by_name = {}
        if typ_impl.is_row_type:
            for name, data_type, data_type_owner, max_size, precision, \
                    scale in attrs:
                if data_type_owner is None:
                    start_pos = data_type.find("(")
                    if start_pos > 0:
                        end_pos = data_type.find(")")
                        if end_pos > start_pos:
                            data_type = data_type[:start_pos] + \
                                    data_type[end_pos + 1:]
                self._create_attr(typ_impl, name, data_type, data_type_owner,
                                  None, None, precision, scale, max_size)
        else:
            for cursor_version, attr_name, attr_num, attr_type_name, \
                    attr_type_owner, attr_type_package, attr_type_oid, \
                    attr_instantiable, attr_super_type_owner, \
                    attr_super_type_name in attrs:
                if attr_name is None:
                    continue
                self._create_attr(typ_impl, attr_name, attr_type_name,
                                  attr_type_owner, attr_type_package,
                                  attr_type_oid)
            return self._parse_tds(typ_impl, self.tds_var.getvalue())

    cdef ThinDbObjectTypeImpl get_type_for_info(self, bytes oid, str schema,
                                                str package_name, str name):
        """
        Returns a type for the specified fetch info, if one has already been
        cached. If not, a new type object is created and cached. It is also
        added to the partial_types list which will be fully populated once the
        current execute has completed.
        """
        cdef:
            ThinDbObjectTypeImpl typ_impl
            str full_name
        if package_name is not None:
            full_name = f"{schema}.{package_name}.{name}"
        else:
            full_name = f"{schema}.{name}"
        if oid is not None:
            typ_impl = self.types_by_oid.get(oid)
        else:
            typ_impl = self.types_by_name.get(full_name)
        if typ_impl is None:
            typ_impl = ThinDbObjectTypeImpl.__new__(ThinDbObjectTypeImpl)
            typ_impl._conn_impl = self.conn_impl
            typ_impl.oid = oid
            typ_impl.schema = schema
            typ_impl.package_name = package_name
            typ_impl.name = name
            typ_impl.is_xml_type = (schema == "SYS" and name == "XMLTYPE")
            if oid is not None:
                self.types_by_oid[oid] = typ_impl
            self.types_by_name[full_name] = typ_impl
            self.partial_types.append(typ_impl)
        return typ_impl


cdef class ThinDbObjectTypeCache(BaseThinDbObjectTypeCache):

    def _get_element_type_clob(self, ThinDbObjectTypeImpl typ_impl):
        """
        Determine if the element type refers to an NCLOB or CLOB value. This
        must be fetched from the data dictionary since it is not included in
        the TDS.
        """
        cursor = self.meta_cursor.connection.cursor()
        if typ_impl.package_name is not None:
            cursor.execute(DBO_CACHE_SQL_GET_ELEM_TYPE_WITH_PACKAGE,
                    owner=typ_impl.schema,
                    package_name=typ_impl.package_name,
                    name=typ_impl.name)
        else:
            cursor.execute(DBO_CACHE_SQL_GET_ELEM_TYPE_NO_PACKAGE,
                    owner=typ_impl.schema,
                    name=typ_impl.name)
        type_name, = cursor.fetchone()
        if type_name == "NCLOB":
            typ_impl.element_metadata.dbtype = DB_TYPE_NCLOB

    def _get_element_type_obj(self, ThinDbObjectTypeImpl typ_impl):
        """
        Determine the element type's object type. This is needed when
        processing collections with object as the element type since this
        information is not available in the TDS.
        """
        cdef:
            str schema, name, package_name = None
            object cursor
        cursor = self.meta_cursor.connection.cursor()
        if typ_impl.package_name is not None:
            cursor.execute(DBO_CACHE_SQL_GET_ELEM_OBJTYPE_WITH_PACKAGE,
                    owner=typ_impl.schema,
                    package_name=typ_impl.package_name,
                    name=typ_impl.name)
            schema, package_name, name = cursor.fetchone()
        else:
            cursor.execute(DBO_CACHE_SQL_GET_ELEM_OBJTYPE_NO_PACKAGE,
                    owner=typ_impl.schema,
                    name=typ_impl.name)
            schema, name = cursor.fetchone()
        typ_impl.element_metadata.objtype = \
                self.get_type_for_info(None, schema, package_name, name)

    cdef list _lookup_type(self, object conn, str name,
                           ThinDbObjectTypeImpl typ_impl):
        """
        Lookup the type given its name and return the list of attributes for
        further processing. The metadata cursor execution will populate the
        variables.
        """
        if self.meta_cursor is None:
            self._init_meta_cursor(conn)
        self.full_name_var.setvalue(0, name)
        self.meta_cursor.execute(None)
        if self.return_value_var.getvalue() != 0:
            errors._raise_err(errors.ERR_INVALID_OBJECT_TYPE_NAME, name=name)
        if name.endswith("%ROWTYPE"):
            typ_impl.is_row_type = True
            if self.columns_cursor is None:
                self._init_columns_cursor(conn)
            self.columns_cursor.execute(None)
            return self.columns_cursor.fetchall()
        else:
            attrs_rc = self.attrs_ref_cursor_var.getvalue()
            return attrs_rc.fetchall()

    cdef ThinDbObjectTypeImpl get_type(self, object conn, str name):
        """
        Returns the database object type given its name. The cache is first
        searched and if it is not found, the database is searched and the
        result stored in the cache.
        """
        cdef:
            ThinDbObjectTypeImpl typ_impl
            bint is_rowtype
        typ_impl = self.types_by_name.get(name)
        if typ_impl is None:
            typ_impl = ThinDbObjectTypeImpl.__new__(ThinDbObjectTypeImpl)
            typ_impl._conn_impl = self.conn_impl
            attrs = self._lookup_type(conn, name, typ_impl)
            self._populate_type_info(name, attrs, typ_impl)
            self.types_by_oid[typ_impl.oid] = typ_impl
            self.types_by_name[name] = typ_impl
            self.populate_partial_types(conn)
        return typ_impl

    def populate_partial_types(self, object conn):
        """
        Populate any partial types that were discovered earlier. Since
        populating an object type might result in additional object types being
        discovered, object types are popped from the partial types list until
        the list is empty.
        """
        cdef:
            ThinDbObjectTypeImpl typ_impl
            str full_name
            list attrs
        while self.partial_types:
            typ_impl = self.partial_types.pop()
            full_name = self._get_full_name(typ_impl)
            attrs = self._lookup_type(conn, full_name, typ_impl)
            self._populate_type_info(full_name, attrs, typ_impl)


cdef class AsyncThinDbObjectTypeCache(BaseThinDbObjectTypeCache):

    async def _get_element_type_clob(self, ThinDbObjectTypeImpl typ_impl):
        """
        Determine if the element type refers to an NCLOB or CLOB value. This
        must be fetched from the data dictionary since it is not included in
        the TDS.
        """
        cursor = self.meta_cursor.connection.cursor()
        if typ_impl.package_name is not None:
            await cursor.execute(DBO_CACHE_SQL_GET_ELEM_TYPE_WITH_PACKAGE,
                    owner=typ_impl.schema,
                    package_name=typ_impl.package_name,
                    name=typ_impl.name)
        else:
            await cursor.execute(DBO_CACHE_SQL_GET_ELEM_TYPE_NO_PACKAGE,
                    owner=typ_impl.schema,
                    name=typ_impl.name)
        type_name, = await cursor.fetchone()
        if type_name == "NCLOB":
            typ_impl.element_metadata.dbtype = DB_TYPE_NCLOB

    async def _get_element_type_obj(self, ThinDbObjectTypeImpl typ_impl):
        """
        Determine the element type's object type. This is needed when
        processing collections with object as the element type since this
        information is not available in the TDS.
        """
        cdef:
            str schema, name, package_name = None
            object cursor
        cursor = self.meta_cursor.connection.cursor()
        if typ_impl.package_name is not None:
            await cursor.execute(DBO_CACHE_SQL_GET_ELEM_OBJTYPE_WITH_PACKAGE,
                    owner=typ_impl.schema,
                    package_name=typ_impl.package_name,
                    name=typ_impl.name)
            schema, package_name, name = await cursor.fetchone()
        else:
            await cursor.execute(DBO_CACHE_SQL_GET_ELEM_OBJTYPE_NO_PACKAGE,
                    owner=typ_impl.schema,
                    name=typ_impl.name)
            schema, name = await cursor.fetchone()
        typ_impl.element_metadata.objtype = \
                self.get_type_for_info(None, schema, package_name, name)

    async def _lookup_type(self, object conn, str name,
                           ThinDbObjectTypeImpl typ_impl):
        """
        Lookup the type given its name and return the list of attributes for
        further processing. The metadata cursor execution will populate the
        variables.
        """
        if self.meta_cursor is None:
            self._init_meta_cursor(conn)
        self.full_name_var.setvalue(0, name)
        await self.meta_cursor.execute(None)
        if self.return_value_var.getvalue() != 0:
            errors._raise_err(errors.ERR_INVALID_OBJECT_TYPE_NAME, name=name)
        if name.endswith("%ROWTYPE"):
            typ_impl.is_row_type = True
            if self.columns_cursor is None:
                self._init_columns_cursor(conn)
            await self.columns_cursor.execute(None)
            return await self.columns_cursor.fetchall()
        else:
            attrs_rc = self.attrs_ref_cursor_var.getvalue()
            return await attrs_rc.fetchall()

    async def get_type(self, object conn, str name):
        """
        Returns the database object type given its name. The cache is first
        searched and if it is not found, the database is searched and the
        result stored in the cache.
        """
        cdef ThinDbObjectTypeImpl typ_impl
        typ_impl = self.types_by_name.get(name)
        if typ_impl is None:
            typ_impl = ThinDbObjectTypeImpl.__new__(ThinDbObjectTypeImpl)
            typ_impl._conn_impl = self.conn_impl
            attrs = await self._lookup_type(conn, name, typ_impl)
            coroutine = self._populate_type_info(name, attrs, typ_impl)
            if coroutine is not None:
                await coroutine
            self.types_by_oid[typ_impl.oid] = typ_impl
            self.types_by_name[name] = typ_impl
            await self.populate_partial_types(conn)
        return typ_impl

    async def populate_partial_types(self, object conn):
        """
        Populate any partial types that were discovered earlier. Since
        populating an object type might result in additional object types being
        discovered, object types are popped from the partial types list until
        the list is empty.
        """
        cdef:
            ThinDbObjectTypeImpl typ_impl
            str full_name
            list attrs
        while self.partial_types:
            typ_impl = self.partial_types.pop()
            full_name = self._get_full_name(typ_impl)
            attrs = await self._lookup_type(conn, full_name, typ_impl)
            coroutine = self._populate_type_info(full_name, attrs, typ_impl)
            if coroutine is not None:
                await coroutine


# global cache of database object types
# since the database object types require a reference to the connection (in
# order to be able to manage LOBs), storing the cache on the connection would
# involve creating a circular reference
cdef ThinDbObjectTypeSuperCache DB_OBJECT_TYPE_SUPER_CACHE = \
        ThinDbObjectTypeSuperCache()


cdef int create_new_dbobject_type_cache(BaseThinConnImpl conn_impl) except -1:
    """
    Creates a new database object type cache and returns its identifier.
    """
    cdef:
        BaseThinDbObjectTypeCache cache
        bint is_async
        int cache_num
    with DB_OBJECT_TYPE_SUPER_CACHE.lock:
        DB_OBJECT_TYPE_SUPER_CACHE.cache_num += 1
        cache_num = DB_OBJECT_TYPE_SUPER_CACHE.cache_num
    is_async = conn_impl._protocol._transport._is_async
    cls = AsyncThinDbObjectTypeCache if is_async else ThinDbObjectTypeCache
    cache = cls.__new__(cls)
    cache._initialize(conn_impl)
    DB_OBJECT_TYPE_SUPER_CACHE.caches[cache_num] = cache
    return cache_num


cdef BaseThinDbObjectTypeCache get_dbobject_type_cache(int cache_num):
    """
    Returns the database object type cache given its identifier.
    """
    return DB_OBJECT_TYPE_SUPER_CACHE.caches[cache_num]


cdef int remove_dbobject_type_cache(int cache_num) except -1:
    """
    Removes the sub cache given its identifier.
    """
    del DB_OBJECT_TYPE_SUPER_CACHE.caches[cache_num]


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\lob.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# lob.pyx
#
# Cython file defining the thin Lob implementation class (embedded in
# thin_impl.pyx).
#------------------------------------------------------------------------------

cdef class BaseThinLobImpl(BaseLobImpl):

    cdef:
        BaseThinConnImpl _conn_impl
        bytes _locator
        bint _has_metadata
        uint64_t _size
        uint32_t _chunk_size

    cdef LobOpMessage _create_close_message(self):
        """
        Create the message needed to close a LOB.
        """
        cdef LobOpMessage message
        message = self._conn_impl._create_message(LobOpMessage)
        message.operation = TNS_LOB_OP_CLOSE
        message.source_lob_impl = self
        return message

    cdef LobOpMessage _create_create_temp_message(self):
        """
        Create the message needed to create a temp LOB.
        """
        cdef LobOpMessage message
        self._locator = bytes(40)
        message = self._conn_impl._create_message(LobOpMessage)
        message.operation = TNS_LOB_OP_CREATE_TEMP
        message.dest_length = TNS_DURATION_SESSION
        message.source_lob_impl = self
        message.source_offset = self.dbtype._csfrm
        message.dest_offset = self.dbtype._ora_type_num
        return message

    cdef LobOpMessage _create_get_chunk_size_message(self):
        """
        Create the message needed to return the chunk size for a LOB.
        """
        cdef LobOpMessage message
        message = self._conn_impl._create_message(LobOpMessage)
        message.operation = TNS_LOB_OP_GET_CHUNK_SIZE
        message.source_lob_impl = self
        message.send_amount = True
        return message

    cdef LobOpMessage _create_get_is_open_message(self):
        """
        Create the message needed to return if a LOB is open.
        """
        cdef LobOpMessage message
        message = self._conn_impl._create_message(LobOpMessage)
        message.operation = TNS_LOB_OP_IS_OPEN
        message.source_lob_impl = self
        return message

    cdef LobOpMessage _create_get_size_message(self):
        """
        Create the message needed to return the size of a LOB.
        """
        cdef LobOpMessage message
        message = self._conn_impl._create_message(LobOpMessage)
        message.operation = TNS_LOB_OP_GET_LENGTH
        message.source_lob_impl = self
        message.send_amount = True
        return message

    cdef LobOpMessage _create_open_message(self):
        """
        Create the message needed to open a LOB.
        """
        cdef LobOpMessage message
        message = self._conn_impl._create_message(LobOpMessage)
        message.operation = TNS_LOB_OP_OPEN
        message.source_lob_impl = self
        message.amount = TNS_LOB_OPEN_READ_WRITE
        message.send_amount = True
        return message

    cdef LobOpMessage _create_read_message(self, uint64_t offset,
                                           uint64_t amount):
        """
        Create the message needed to read data from a LOB.
        """
        cdef LobOpMessage message
        message = self._conn_impl._create_message(LobOpMessage)
        message.operation = TNS_LOB_OP_READ
        message.source_lob_impl = self
        message.source_offset = offset
        message.amount = amount
        message.send_amount = True
        return message

    cdef LobOpMessage _create_trim_message(self, uint64_t new_size):
        """
        Create the message needed to trim a LOB.
        """
        cdef LobOpMessage message
        message = self._conn_impl._create_message(LobOpMessage)
        message.operation = TNS_LOB_OP_TRIM
        message.source_lob_impl = self
        message.amount = new_size
        message.send_amount = True
        return message

    cdef LobOpMessage _create_write_message(self, object value,
                                            uint64_t offset):
        """
        Create the message needed to write data to a LOB.
        """
        cdef LobOpMessage message
        message = self._conn_impl._create_message(LobOpMessage)
        message.operation = TNS_LOB_OP_WRITE
        message.source_lob_impl = self
        message.source_offset = offset
        if self.dbtype._ora_type_num == ORA_TYPE_NUM_BLOB:
            if not isinstance(value, bytes):
                raise TypeError("only bytes can be written to BLOBs")
            message.data = value
        else:
            if not isinstance(value, str):
                raise TypeError(
                    "only strings can be written to CLOBs and NCLOBS"
                )
            message.data = (<str> value).encode(self._get_encoding())
        return message

    cdef LobOpMessage _create_file_exists_message(self):
        """
        Create a message needed to return if BFILE exists.
        """
        cdef LobOpMessage message
        message = self._conn_impl._create_message(LobOpMessage)
        message.operation = TNS_LOB_OP_FILE_EXISTS
        message.source_lob_impl = self
        return message

    cdef LobOpMessage _create_file_close_message(self):
        """
        Create a message needed to close a file
        """
        cdef LobOpMessage message
        message = self._conn_impl._create_message(LobOpMessage)
        message.operation = TNS_LOB_OP_FILE_CLOSE
        message.source_lob_impl = self
        return message

    cdef LobOpMessage _create_file_open_message(self):
        """
        Create a message needed to open a file
        """
        cdef LobOpMessage message
        message = self._conn_impl._create_message(LobOpMessage)
        message.operation = TNS_LOB_OP_FILE_OPEN
        message.source_lob_impl = self
        message.amount = TNS_LOB_OPEN_READ_ONLY
        message.send_amount = True
        return message

    cdef LobOpMessage _create_get_file_is_open_message(self):
        """
        Create a message needed to return if a file is open
        """
        cdef LobOpMessage message
        message = self._conn_impl._create_message(LobOpMessage)
        message.operation = TNS_LOB_OP_FILE_ISOPEN
        message.source_lob_impl = self
        return message

    cdef const char* _get_encoding(self):
        """
        Return the encoding used by the LOB.
        """
        if self.dbtype._csfrm == CS_FORM_NCHAR \
                or self._locator[TNS_LOB_LOC_OFFSET_FLAG_3] & \
                TNS_LOB_LOC_FLAGS_VAR_LENGTH_CHARSET:
            return ENCODING_UTF16
        return ENCODING_UTF8

    def free_lob(self):
        """
        Internal method for closing a temp LOB during the next piggyback.
        """
        cdef:
            uint8_t flags1 = self._locator[TNS_LOB_LOC_OFFSET_FLAG_1]
            uint8_t flags4 = self._locator[TNS_LOB_LOC_OFFSET_FLAG_4]
        if flags1 & TNS_LOB_LOC_FLAGS_ABSTRACT \
                or flags4 & TNS_LOB_LOC_FLAGS_TEMP:
            if self._conn_impl._temp_lobs_to_close is None:
                self._conn_impl._temp_lobs_to_close = []
            self._conn_impl._temp_lobs_to_close.append(self._locator)
            self._conn_impl._temp_lobs_total_size += len(self._locator)
            self._conn_impl = None

    def get_max_amount(self):
        """
        Internal method for returning the maximum amount that can be read.
        """
        return 2**32 - 1

    def get_file_name(self):
        """
        Internal method for returning a 2-tuple constaining the directory.
        """
        cdef:
            const char_type *ptr = self._locator
            uint16_t dir_name_offset, file_name_offset
            uint16_t dir_name_len, file_name_len
        dir_name_offset = TNS_LOB_LOC_FIXED_OFFSET + 2
        dir_name_len = decode_uint16be(&ptr[TNS_LOB_LOC_FIXED_OFFSET])
        file_name_offset = dir_name_offset + dir_name_len + 2
        file_name_len = decode_uint16be(&ptr[dir_name_offset + dir_name_len])
        return (
            ptr[dir_name_offset:dir_name_offset + dir_name_len].decode(),
            ptr[file_name_offset:file_name_offset + file_name_len].decode()
        )

    def set_file_name(self, str dir_alias, str name):
        """
        Internal method for setting the directory alias and file name
        associated with a BFILE LOB.
        """
        cdef char_type dir_length[2]
        cdef char_type name_length[2]
        encode_uint16be(dir_length, len(dir_alias))
        encode_uint16be(name_length, len(name))
        self._locator = self._locator[:TNS_LOB_LOC_FIXED_OFFSET] + \
                dir_length[:2] + dir_alias.encode() + name_length[:2] + \
                name.encode()


cdef class ThinLobImpl(BaseThinLobImpl):

    cdef inline int _process_message(self, LobOpMessage message) except -1:
        """
        Process the message.
        """
        cdef Protocol protocol = <Protocol> self._conn_impl._protocol
        protocol._process_single_message(message)

    def close(self):
        """
        Internal method for closing a LOB that was opened earlier.
        """
        if self.dbtype._ora_type_num == ORA_TYPE_NUM_BFILE:
            self._process_message(self._create_file_close_message())
        else:
            self._process_message(self._create_close_message())

    def create_temp(self):
        """
        Internal method for creating a temporary LOB.
        """
        self._process_message(self._create_create_temp_message())

    def file_exists(self):
        """
        Internal method for returning whether the file referenced by a BFILE
        exists.
        """
        cdef LobOpMessage message
        message = self._create_file_exists_message()
        self._process_message(message)
        return message.bool_flag

    def get_chunk_size(self):
        """
        Internal method for returning the chunk size of the LOB.
        """
        cdef LobOpMessage message
        if self._has_metadata:
            return self._chunk_size
        message = self._create_get_chunk_size_message()
        self._process_message(message)
        return message.amount

    def get_is_open(self):
        """
        Internal method for returning whether the LOB is open or not.
        """
        cdef LobOpMessage message
        if self.dbtype._ora_type_num == ORA_TYPE_NUM_BFILE:
            message = self._create_get_file_is_open_message()
        else:
            message = self._create_get_is_open_message()
        self._process_message(message)
        return message.bool_flag

    def get_size(self):
        """
        Internal method for returning the size of a LOB.
        """
        cdef LobOpMessage message
        if self._has_metadata:
            return self._size
        message = self._create_get_size_message()
        self._process_message(message)
        return message.amount

    def open(self):
        """
        Internal method for opening a LOB.
        """
        if self.dbtype._ora_type_num == ORA_TYPE_NUM_BFILE:
            self._process_message(self._create_file_open_message())
        else:
            self._process_message(self._create_open_message())

    def read(self, uint64_t offset, uint64_t amount):
        """
        Internal method for reading a portion (or all) of the data in the LOB.
        """
        cdef:
            bint should_close = False
            LobOpMessage message
        if self.dbtype._ora_type_num == ORA_TYPE_NUM_BFILE:
            if not self.get_is_open():
                should_close = True
                self.open()
        message = self._create_read_message(offset, amount)
        self._process_message(message)
        if should_close:
            self.close()
        if message.data is None:
            if self.dbtype._ora_type_num in (ORA_TYPE_NUM_BLOB,
                                             ORA_TYPE_NUM_BFILE):
                return b""
            return ""
        return message.data

    def trim(self, uint64_t new_size):
        """
        Internal method for trimming the data in the LOB to the new size.
        """
        self._process_message(self._create_trim_message(new_size))
        self._has_metadata = False

    def write(self, object value, uint64_t offset):
        """
        Internal method for writing data to the LOB object.
        """
        self._process_message(self._create_write_message(value, offset))
        self._has_metadata = False


cdef class AsyncThinLobImpl(BaseThinLobImpl):

    async def _process_message(self, LobOpMessage message):
        """
        Process the message.
        """
        cdef BaseAsyncProtocol protocol
        protocol = <BaseAsyncProtocol> self._conn_impl._protocol
        await protocol._process_single_message(message)

    async def close(self):
        """
        Internal method for closing a LOB that was opened earlier.
        """
        if self.dbtype._ora_type_num == ORA_TYPE_NUM_BFILE:
            await self._process_message(self._create_file_close_message())
        else:
            await self._process_message(self._create_close_message())

    async def create_temp(self):
        """
        Internal method for creating a temporary LOB.
        """
        await self._process_message(self._create_create_temp_message())

    async def get_chunk_size(self):
        """
        Internal method for returning the chunk size of the LOB.
        """
        cdef LobOpMessage message
        if self._has_metadata:
            return self._chunk_size
        message = self._create_get_chunk_size_message()
        await self._process_message(message)
        return message.amount

    async def file_exists(self):
        """
        Internal method returning a boolean indicating if file referenced by a
        BFILE exists.
        """
        cdef LobOpMessage message
        message = self._create_file_exists_message()
        await self._process_message(message)
        return message.bool_flag

    async def get_is_open(self):
        """
        Internal method for returning whether the LOB is open or not.
        """
        cdef LobOpMessage message
        if self.dbtype._ora_type_num == ORA_TYPE_NUM_BFILE:
            message = self._create_get_file_is_open_message()
        else:
            message = self._create_get_is_open_message()
        await self._process_message(message)
        return message.bool_flag

    async def get_size(self):
        """
        Internal method for returning the size of a LOB.
        """
        cdef LobOpMessage message
        if self._has_metadata:
            return self._size
        message = self._create_get_size_message()
        await self._process_message(message)
        return message.amount

    async def open(self):
        """
        Internal method for opening a LOB.
        """
        if self.dbtype._ora_type_num == ORA_TYPE_NUM_BFILE:
            await self._process_message(self._create_file_open_message())
        else:
            await self._process_message(self._create_open_message())

    async def read(self, uint64_t offset, uint64_t amount):
        """
        Internal method for reading a portion (or all) of the data in the LOB.
        """
        cdef:
            bint should_close = False
            LobOpMessage message
        if self.dbtype._ora_type_num == ORA_TYPE_NUM_BFILE:
            if not await self.get_is_open():
                should_close = True
                await self.open()
        message = self._create_read_message(offset, amount)
        await self._process_message(message)
        if should_close:
            await self.close()
        if message.data is None:
            if self.dbtype._ora_type_num in (ORA_TYPE_NUM_BLOB,
                                             ORA_TYPE_NUM_BFILE):
                return b""
            return ""
        return message.data

    async def trim(self, uint64_t new_size):
        """
        Internal method for trimming the data in the LOB to the new size
        """
        await self._process_message(self._create_trim_message(new_size))
        self._has_metadata = False

    async def write(self, object value, uint64_t offset):
        """
        Internal method for writing data to the LOB object.
        """
        await self._process_message(self._create_write_message(value, offset))
        self._has_metadata = False


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\aq_array.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# aq_array.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for enqueuing and dequeuing
# an array of AQ messages (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class AqArrayMessage(AqBaseMessage):
    cdef:
        list props_impls
        int operation
        uint32_t num_iters

    cdef int _initialize_hook(self) except -1:
        """
        Perform initialization
        """
        self.function_code = TNS_FUNC_ARRAY_AQ

    cdef int _process_return_parameters(self, ReadBuffer buf) except -1:
        """
        Process the return parameters of the AQ array enqueue/dequeue request.
        """
        cdef:
            uint32_t i, j, num_iters, temp32
            ThinMsgPropsImpl props_impl
            uint16_t temp16
            bytes msgid
        buf.read_ub4(&num_iters)
        for i in range(num_iters):
            props_impl = self.props_impls[i]
            buf.read_ub2(&temp16)
            if temp16 > 0:
                buf.skip_ub1()
                self._process_msg_props(buf, props_impl)
            self._process_recipients(buf)
            buf.read_ub2(&temp16)
            if temp16 > 0:
                props_impl.payload = self._process_payload(buf)
            msgid = buf.read_bytes_with_length()
            if self.operation == TNS_AQ_ARRAY_ENQ:
                for j, props_impl in enumerate(self.props_impls):
                    props_impl.msgid = msgid[j * 16:(j + 1) * 16]
            else:
                props_impl.msgid = msgid
            buf.read_ub2(&temp16)               # extensions len
            if temp16 > 0:
                errors._raise_err(errors.ERR_NOT_IMPLEMENTED)
            buf.skip_ub2()                      # output ack
        if self.operation == TNS_AQ_ARRAY_ENQ:
            buf.read_ub4(&self.num_iters)
        else:
            self.num_iters = num_iters

    cdef int _write_array_deq(self, WriteBuffer buf) except -1:
        """
        Writes to the buffer the fields specific to the array dqeueue of AQ
        messages.
        """
        cdef:
            bytes consumer_name_bytes = None
            bytes correlation_bytes = None
            bytes condition_bytes = None
            ThinMsgPropsImpl props_impl
            bytes queue_name_bytes
            uint16_t delivery_mode
            uint32_t flags = 0

        # setup
        queue_name_bytes = self.queue_impl.name.encode()
        delivery_mode = self.deq_options_impl.delivery_mode
        if delivery_mode == TNS_AQ_MSG_BUFFERED:
            flags |= TNS_KPD_AQ_BUFMSG
        elif delivery_mode == TNS_AQ_MSG_PERSISTENT_OR_BUFFERED:
            flags |= TNS_KPD_AQ_EITHER
        if self.deq_options_impl.consumer_name:
            consumer_name_bytes = self.deq_options_impl.consumer_name.encode()
        if self.deq_options_impl.condition:
            condition_bytes = self.deq_options_impl.condition.encode()
        if self.deq_options_impl.correlation:
            correlation_bytes = self.deq_options_impl.correlation.encode()

        # write message
        for props_impl in self.props_impls:
            buf.write_ub4(len(queue_name_bytes))
            buf.write_bytes_with_length(queue_name_bytes)
            self._write_msg_props(buf, props_impl)
            buf.write_ub4(0)                        # num recipients
            self._write_value_with_length(buf, consumer_name_bytes)
            buf.write_sb4(self.deq_options_impl.mode)
            buf.write_sb4(self.deq_options_impl.navigation)
            buf.write_sb4(self.deq_options_impl.visibility)
            buf.write_sb4(self.deq_options_impl.wait)
            self._write_value_with_length(buf, self.deq_options_impl.msgid)
            self._write_value_with_length(buf, correlation_bytes)
            self._write_value_with_length(buf, condition_bytes)
            buf.write_ub4(0)                        # extensions
            buf.write_ub4(0)                        # rel msg id
            buf.write_sb4(0)                        # seq deviation
            buf.write_ub4(16)                       # toid length
            buf.write_bytes_with_length(self.queue_impl.payload_toid)
            buf.write_ub2(TNS_AQ_MESSAGE_VERSION)
            buf.write_ub4(0)                        # payload length
            buf.write_ub4(0)                        # raw pay length
            buf.write_ub4(0)
            buf.write_ub4(flags)
            buf.write_ub4(0)                        # extensions len
            buf.write_ub4(0)                        # source seq len

    cdef int _write_array_enq(self, WriteBuffer buf) except -1:
        """
        Writing input parameters incase of array enqueue
        """
        cdef:
            ThinMsgPropsImpl props_impl
            bytes queue_name_bytes
            uint32_t flags = 0

        # setup
        queue_name_bytes = self.queue_impl.name.encode()
        if self.enq_options_impl.delivery_mode == TNS_AQ_MSG_BUFFERED:
            flags |= TNS_KPD_AQ_BUFMSG

        # write message
        buf.write_ub4(0)                            # rel msgid len
        buf.write_uint8(TNS_MSG_TYPE_ROW_HEADER)
        buf.write_ub4(len(queue_name_bytes))
        buf.write_bytes_with_length(queue_name_bytes)
        buf.write_bytes(self.queue_impl.payload_toid)
        buf.write_ub2(TNS_AQ_MESSAGE_VERSION)
        buf.write_ub4(flags)
        for props_impl in self.props_impls:
            buf.write_uint8(TNS_MSG_TYPE_ROW_DATA)
            buf.write_ub4(flags)                    # aqi flags
            self._write_msg_props(buf, props_impl)
            buf.write_ub4(0)                        # num recipients
            buf.write_sb4(self.enq_options_impl.visibility)
            buf.write_ub4(0)                        # relative msg id
            buf.write_sb4(0)                        # seq deviation
            if self.queue_impl.payload_type is None \
                    and not self.queue_impl.is_json:
                buf.write_ub4(len(props_impl.payload_obj))
            self._write_payload(buf, props_impl)
        buf.write_uint8(TNS_MSG_TYPE_STATUS)

    cdef int _write_message(self, WriteBuffer buf) except -1:
        """
        Write message to the network buffers.
        """
        self._write_function_code(buf)
        if self.operation == TNS_AQ_ARRAY_ENQ:
            buf.write_uint8(0)                      # input params
            buf.write_ub4(0)                        # length
        else:
            buf.write_uint8(1)
            buf.write_ub4(self.num_iters)
        buf.write_ub4(TNS_AQ_ARRAY_FLAGS_RETURN_MESSAGE_ID)
        if self.operation == TNS_AQ_ARRAY_ENQ:
            buf.write_uint8(1)                      # output params
            buf.write_uint8(0)                      # length
        else:
            buf.write_uint8(1)
            buf.write_uint8(1)
        buf.write_sb4(self.operation)
        if self.operation == TNS_AQ_ARRAY_ENQ:
            buf.write_uint8(1)                      # num iters (pointer)
        else:
            buf.write_uint8(0)
        if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_21_1:
            buf.write_ub4(0xffff)                   # shard id
        if self.operation == TNS_AQ_ARRAY_ENQ:
            buf.write_ub4(self.num_iters)
        if self.operation == TNS_AQ_ARRAY_ENQ:
            self._write_array_enq(buf)
        else:
            self._write_array_deq(buf)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\aq_base.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# aq_base.pyx
#
# Cython file defining the base class for messages that are sent to the
# database and the responses that are received by the client for enqueing and
# dequeuing AQ messages (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

cdef class AqBaseMessage(Message):
    cdef:
        BaseThinQueueImpl queue_impl
        ThinDeqOptionsImpl deq_options_impl
        ThinEnqOptionsImpl enq_options_impl
        bint no_msg_found

    cdef object _process_date(self, ReadBuffer buf):
        """
        Processes a date found in the buffer.
        """
        cdef:
            const char_type *ptr
            uint32_t num_bytes
            OracleData data
            ssize_t length
        buf.read_ub4(&num_bytes)
        if num_bytes > 0:
            buf.read_raw_bytes_and_length(&ptr, &length)
            decode_date(ptr, length, &data.buffer)
            return convert_date_to_python(&data.buffer)

    cdef int _process_error_info(self, ReadBuffer buf) except -1:
        """
        Process error information from the buffer. If the error that indicates
        that no messages were received is detected, the error is cleared and
        the flag set so that the dequeue can handle that case.
        """
        Message._process_error_info(self, buf)
        if self.error_info.num == TNS_ERR_NO_MESSAGES_FOUND:
            self.error_info.num = 0
            self.error_occurred = False
            self.no_msg_found = True

    cdef int _process_extensions(self, ReadBuffer buf,
                                 ThinMsgPropsImpl props_impl) except -1:
        """
        Processes extensions to the message property object returned by the
        database.
        """
        cdef:
            bytes text_value, binary_value, value
            uint32_t i, num_extensions
            uint16_t keyword
        buf.read_ub4(&num_extensions)
        if num_extensions > 0:
            buf.skip_ub1()
            for i in range(num_extensions):
                text_value = buf.read_bytes_with_length()
                binary_value = buf.read_bytes_with_length()
                value = text_value or binary_value
                buf.read_ub2(&keyword)
                if value is not None:
                    if keyword == TNS_AQ_EXT_KEYWORD_AGENT_NAME:
                        props_impl.sender_agent_name = value
                    elif keyword == TNS_AQ_EXT_KEYWORD_AGENT_ADDRESS:
                        props_impl.sender_agent_address = value
                    elif keyword == TNS_AQ_EXT_KEYWORD_AGENT_PROTOCOL:
                        props_impl.sender_agent_protocol = value
                    elif keyword == TNS_AQ_EXT_KEYWORD_ORIGINAL_MSGID:
                        props_impl.original_msg_id = value

    cdef bytes _process_msg_id(self, ReadBuffer buf):
        """
        Reads a message id from the buffer and returns it.
        """
        cdef const char_type *ptr
        ptr = buf.read_raw_bytes(TNS_AQ_MESSAGE_ID_LENGTH)
        return ptr[:TNS_AQ_MESSAGE_ID_LENGTH]

    cdef int _process_msg_props(self, ReadBuffer buf,
                                ThinMsgPropsImpl props_impl) except -1:
        """
        Processes a message property object returned by the database.
        """
        cdef uint32_t temp32
        buf.read_sb4(&props_impl.priority)
        buf.read_sb4(&props_impl.delay)
        buf.read_sb4(&props_impl.expiration)
        props_impl.correlation = buf.read_str_with_length()
        buf.read_sb4(&props_impl.num_attempts)
        props_impl.exceptionq = buf.read_str_with_length()
        buf.read_sb4(&props_impl.state)
        props_impl.enq_time = self._process_date(buf)
        props_impl.enq_txn_id = buf.read_bytes_with_length()
        self._process_extensions(buf, props_impl)
        buf.read_ub4(&temp32)                       # user properties
        if temp32 > 0:
            errors._raise_err(errors.ERR_NOT_IMPLEMENTED)
        buf.skip_ub4()                              # csn
        buf.skip_ub4()                              # dsn
        buf.skip_ub4()                              # flags
        if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_21_1:
            buf.skip_ub4()                          # shard number

    cdef object _process_payload(self, ReadBuffer buf):
        """
        Processes the payload for an enqueued message returned by the database.
        """
        cdef:
            ThinDbObjectImpl obj_impl
            uint32_t image_length
            bytes payload
        if self.queue_impl.payload_type is not None:
            obj_impl = buf.read_dbobject(self.queue_impl.payload_type)
            if obj_impl is None:
                obj_impl = self.queue_impl.payload_type.create_new_object()
            return PY_TYPE_DB_OBJECT._from_impl(obj_impl)
        else:
            buf.read_bytes_with_length()            # TOID
            buf.read_bytes_with_length()            # OID
            buf.read_bytes_with_length()            # snapshot
            buf.skip_ub2()                          # version no
            buf.read_ub4(&image_length)             # image length
            buf.skip_ub2()                          # flags
            if image_length > 0:
                payload = buf.read_bytes()[4:image_length]
                if self.queue_impl.is_json:
                    return self.conn_impl.decode_oson(payload)
                return payload
            elif not self.queue_impl.is_json:
                return b''

    cdef object _process_recipients(self, ReadBuffer buf):
        """
        Process recipients for a message. Currently this is unsupported.
        """
        cdef uint32_t temp32
        buf.read_ub4(&temp32)
        if temp32 > 0:
            errors._raise_err(errors.ERR_NOT_IMPLEMENTED)
        return []

    cdef int _write_msg_props(self, WriteBuffer buf,
                              ThinMsgPropsImpl props_impl) except -1:
        """
        Write a message property object to the buffer.
        """
        buf.write_ub4(props_impl.priority)
        buf.write_ub4(props_impl.delay)
        buf.write_sb4(props_impl.expiration)
        self._write_value_with_length(buf, props_impl.correlation)
        buf.write_ub4(0)                            # number of attempts
        self._write_value_with_length(buf, props_impl.exceptionq)
        buf.write_ub4(props_impl.state)
        buf.write_ub4(0)                            # enqueue time length
        self._write_value_with_length(buf, props_impl.enq_txn_id)
        buf.write_ub4(4)                            # number of extensions
        buf.write_uint8(0x0e)                       # unknown extra byte
        buf.write_extension_values(None, None, TNS_AQ_EXT_KEYWORD_AGENT_NAME)
        buf.write_extension_values(None, None,
                                   TNS_AQ_EXT_KEYWORD_AGENT_ADDRESS)
        buf.write_extension_values(None, b'\x00',
                                   TNS_AQ_EXT_KEYWORD_AGENT_PROTOCOL)
        buf.write_extension_values(None, None,
                                   TNS_AQ_EXT_KEYWORD_ORIGINAL_MSGID)
        buf.write_ub4(0)                            # user property
        buf.write_ub4(0)                            # cscn
        buf.write_ub4(0)                            # dscn
        buf.write_ub4(0)                            # flags
        if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_21_1:
            buf.write_ub4(0xffffffffl)              # shard id

    cdef int _write_payload(self, WriteBuffer buf,
                            ThinMsgPropsImpl props_impl) except -1:
        """
        Writes the payload of the message property object to the buffer.
        """
        if self.queue_impl.is_json:
            buf.write_oson(props_impl.payload_obj,
                           self.conn_impl._oson_max_fname_size, False)
        elif self.queue_impl.payload_type is not None:
            buf.write_dbobject(props_impl.payload_obj)
        else:
            buf.write_bytes(props_impl.payload_obj)

    cdef int _write_value_with_length(self, WriteBuffer buf,
                                      object value) except -1:
        """
        Write a string to the buffer, prefixed by a length.
        """
        cdef bytes value_bytes
        if value is None:
            buf.write_ub4(0)
        else:
            if isinstance(value, str):
                value_bytes = value.encode()
            else:
                value_bytes = value
            buf.write_ub4(len(value_bytes))
            buf.write_bytes_with_length(value_bytes)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\aq_deq.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# aq_deq.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for dequeuing an AQ message
# (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class AqDeqMessage(AqBaseMessage):
    cdef:
        ThinMsgPropsImpl props_impl

    cdef int _initialize_hook(self) except -1:
        """
        Perform initialization
        """
        self.function_code = TNS_FUNC_AQ_DEQ

    cdef int _process_return_parameters(self, ReadBuffer buf) except -1:
        """
        Process the return parameters of the AQ Dequeue request.
        """
        cdef:
            uint32_t num_bytes
            uint16_t keyword
            uint32_t imageLength
            ThinDbObjectImpl obj_impl
            ThinDbObjectTypeImpl type_impl
        buf.read_ub4(&num_bytes)
        if num_bytes > 0:
            self._process_msg_props(buf, self.props_impl)
            self.props_impl.recipients = self._process_recipients(buf)
            self.props_impl.payload = self._process_payload(buf)
            self.props_impl.msgid = self._process_msg_id(buf)

    cdef int _write_message(self, WriteBuffer buf) except -1:
        """
        Write message to the network buffers.
        """
        cdef:
             bytes queue_name_bytes
             bytes consumer_name_bytes
             bytes correlation_bytes
             bytes condition_bytes
             uint16_t delivery_mode
             int deq_flags
        self._write_function_code(buf)
        queue_name_bytes = self.queue_impl.name.encode()
        buf.write_uint8(1)                      # queue name (pointer)
        buf.write_ub4(len(queue_name_bytes))    # queue name length
        buf.write_uint8(1)                      # message properties
        buf.write_uint8(1)                      # msg props length
        buf.write_uint8(1)                      # recipient list
        buf.write_uint8(1)                      # recipient list length
        if self.deq_options_impl.consumer_name:
            consumer_name_bytes = self.deq_options_impl.consumer_name.encode()
            buf.write_uint8(1)                  # consumer name
            buf.write_ub4(len(consumer_name_bytes))
        else:
            consumer_name_bytes = None
            buf.write_uint8(0)                  # consumer name
            buf.write_ub4(0)                    # consumer name length
        buf.write_sb4(self.deq_options_impl.mode) # dequeue mode
        buf.write_sb4(self.deq_options_impl.navigation) # navigation
        buf.write_sb4(self.deq_options_impl.visibility) # visibility
        buf.write_sb4(self.deq_options_impl.wait) # wait
        if self.deq_options_impl.msgid:
            buf.write_uint8(1)                  # select mesg id
            buf.write_ub4(TNS_AQ_MESSAGE_ID_LENGTH) # mesg id len
        else:
            buf.write_uint8(0)                  # select mesg id
            buf.write_ub4(0)                    # select mesg id length
        if self.deq_options_impl.correlation:
            correlation_bytes = self.deq_options_impl.correlation.encode()
            buf.write_uint8(1)                  # correlation id
            buf.write_ub4(len(correlation_bytes)) # correlation id len
        else:
            correlation_bytes = None
            buf.write_uint8(0)                  # correlation id
            buf.write_ub4(0)                    # correlation id len
        buf.write_uint8(1)                      # toid of payload
        buf.write_ub4(16)                       # toid length
        buf.write_ub2(TNS_AQ_MESSAGE_VERSION)
        buf.write_uint8(1)                      # payload
        buf.write_uint8(1)                      # return msg id
        buf.write_ub4(TNS_AQ_MESSAGE_ID_LENGTH)
        deq_flags = 0
        delivery_mode = self.deq_options_impl.delivery_mode
        if (delivery_mode == TNS_AQ_MSG_BUFFERED):
            deq_flags |= TNS_KPD_AQ_BUFMSG
        elif (delivery_mode == TNS_AQ_MSG_PERSISTENT_OR_BUFFERED):
            deq_flags |= TNS_KPD_AQ_EITHER
        buf.write_ub4(deq_flags)                # dequeue flags
        if self.deq_options_impl.condition:
            condition_bytes = self.deq_options_impl.condition.encode()
            buf.write_uint8(1)                  # condition (pointer)
            buf.write_ub4(len(condition_bytes)) # condition length
        else:
            condition_bytes = None
            buf.write_uint8(0)                  # condition
            buf.write_ub4(0)                    # condition length
        buf.write_uint8(0)                      # extensions
        buf.write_ub4(0)                        # number of extensions
        if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_20_1:
            buf.write_uint8(0)                  # JSON payload
        if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_21_1:
            buf.write_ub4(-1)                   # shard id

        buf.write_bytes_with_length(queue_name_bytes)
        if consumer_name_bytes is not None:
            buf.write_bytes_with_length(consumer_name_bytes)
        if self.deq_options_impl.msgid:
            buf.write_bytes(self.deq_options_impl.msgid)
        if correlation_bytes is not None:
            buf.write_bytes_with_length(correlation_bytes)
        buf.write_bytes(self.queue_impl.payload_toid)
        if condition_bytes is not None:
            buf.write_bytes_with_length(condition_bytes)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\aq_enq.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# aq_enq.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for enqueuing an AQ message
# (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class AqEnqMessage(AqBaseMessage):
    cdef:
        ThinMsgPropsImpl props_impl

    cdef int _initialize_hook(self) except -1:
        """
        perform initialization
        """
        self.function_code = TNS_FUNC_AQ_ENQ

    cdef int _process_return_parameters(self, ReadBuffer buf) except -1:
        """
        Process the return parameters for the AQ enqueue request.
        """
        cdef const char_type *ptr = buf._get_raw(TNS_AQ_MESSAGE_ID_LENGTH)
        self.props_impl.msgid = ptr[:TNS_AQ_MESSAGE_ID_LENGTH]
        buf.skip_ub2()                          # extensions length

    cdef int _write_message(self, WriteBuffer buf) except -1:
        """
        Write message to the network buffers.
        """
        cdef:
            bytes queue_name_bytes
            bytes correlation_bytes
            bytes exceptionq_bytes
            int enq_flags

        self._write_function_code(buf)
        queue_name_bytes = self.queue_impl.name.encode()
        buf.write_uint8(1)                      # queue name (pointer)
        buf.write_ub4(len(queue_name_bytes))    # queue name length
        self._write_msg_props(buf, self.props_impl)
        buf.write_uint8(0)                      # recipients (pointer)
        buf.write_ub4(0)                        # number of key/value pairs
        buf.write_ub4(self.enq_options_impl.visibility)
        buf.write_uint8(0)                      # relative message id
        buf.write_ub4(0)                        # relative message length
        buf.write_ub4(0)                        # sequence deviation
        buf.write_uint8(1)                      # TOID of payload (pointer)
        buf.write_ub4(16)                       # TOID of payload length
        buf.write_ub2(TNS_AQ_MESSAGE_VERSION)
        if self.queue_impl.is_json:
            buf.write_uint8(0)                  # payload (pointer)
            buf.write_uint8(0)                  # RAW payload (pointer)
            buf.write_ub4(0)                    # RAW payload length
        elif self.queue_impl.payload_type is not None:
            buf.write_uint8(1)                  # payload (pointer)
            buf.write_uint8(0)                  # RAW payload (pointer)
            buf.write_ub4(0)                    # RAW payload (length)
        else:
            buf.write_uint8(0)                  # payload (pointer)
            buf.write_uint8(1)                  # RAW payload (pointer)
            buf.write_ub4(len(self.props_impl.payload_obj))
        buf.write_uint8(1)                      # return message id (pointer)
        buf.write_ub4(TNS_AQ_MESSAGE_ID_LENGTH) # return message id length
        enq_flags = 0
        if self.enq_options_impl.delivery_mode == TNS_AQ_MSG_BUFFERED:
            enq_flags |= TNS_KPD_AQ_BUFMSG
        buf.write_ub4(enq_flags)                # enqueue flags
        buf.write_uint8(0)                      # extensions 1 (pointer)
        buf.write_ub4(0)                        # number of extensions 1
        buf.write_uint8(0)                      # extensions 2 (pointer)
        buf.write_ub4(0)                        # number of extensions 2
        buf.write_uint8(0)                      # source sequence number
        buf.write_ub4(0)                        # source sequence length
        buf.write_uint8(0)                      # max sequence number
        buf.write_ub4(0)                        # max sequence length
        buf.write_uint8(0)                      # output ack length
        buf.write_uint8(0)                      # correlation (pointer)
        buf.write_ub4(0)                        # correlation length
        buf.write_uint8(0)                      # sender name (pointer)
        buf.write_ub4(0)                        # sender name length
        buf.write_uint8(0)                      # sender address (pointer)
        buf.write_ub4(0)                        # sender address length
        buf.write_uint8(0)                      # sender charset id (pointer)
        buf.write_uint8(0)                      # sender ncharset id (pointer)
        if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_20_1:
            if self.queue_impl.is_json:
                buf.write_uint8(1)              # JSON payload (pointer)
            else:
                buf.write_uint8(0)              # JSON payload (pointer)

        buf.write_bytes_with_length(queue_name_bytes)
        buf.write_bytes(self.queue_impl.payload_toid)
        self._write_payload(buf, self.props_impl)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\auth.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# auth.pyx
#
# Cython file defining the messages sent to the database and the responses that
# are received by the client for authentication (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class AuthMessage(Message):
    cdef:
        str encoded_password
        bytes password
        bytes newpassword
        str encoded_newpassword
        str encoded_jdwp_data
        str debug_jdwp
        str session_key
        str speedy_key
        str proxy_user
        str token
        str private_key
        str service_name
        uint8_t purity
        ssize_t user_bytes_len
        bytes user_bytes
        dict session_data
        uint32_t auth_mode
        uint32_t verifier_type
        bint change_password
        str program
        str terminal
        str machine
        str osuser
        str driver_name
        str edition
        list appcontext
        str connect_string

    cdef int _encrypt_passwords(self) except -1:
        """
        Encrypts the passwords using the session key.
        """

        # encrypt password
        salt = secrets.token_bytes(16)
        password_with_salt = salt + self.password
        encrypted_password = encrypt_cbc(self.conn_impl._combo_key,
                                         password_with_salt)
        self.encoded_password = encrypted_password.hex().upper()

        # encrypt new password
        if self.newpassword is not None:
            newpassword_with_salt = salt + self.newpassword
            encrypted_newpassword = encrypt_cbc(self.conn_impl._combo_key,
                                                newpassword_with_salt)
            self.encoded_newpassword = encrypted_newpassword.hex().upper()

    cdef int _generate_verifier(self) except -1:
        """
        Generate the multi-round verifier.
        """
        cdef:
            bytes jdwp_data
            bytearray b
            ssize_t i

        # create password hash
        verifier_data = bytes.fromhex(self.session_data['AUTH_VFR_DATA'])
        if self.verifier_type == TNS_VERIFIER_TYPE_12C:
            keylen = 32
            iterations = int(self.session_data['AUTH_PBKDF2_VGEN_COUNT'])
            salt = verifier_data + b'AUTH_PBKDF2_SPEEDY_KEY'
            password_key = get_derived_key(self.password, salt, 64,
                                           iterations)
            h = hashlib.new("sha512")
            h.update(password_key)
            h.update(verifier_data)
            password_hash = h.digest()[:32]
        else:
            keylen = 24
            h = hashlib.sha1(self.password)
            h.update(verifier_data)
            password_hash = h.digest() + bytes(4)

        # decrypt first half of session key
        encoded_server_key = bytes.fromhex(self.session_data['AUTH_SESSKEY'])
        session_key_part_a = decrypt_cbc(password_hash, encoded_server_key)

        # generate second half of session key
        session_key_part_b = secrets.token_bytes(len(session_key_part_a))
        encoded_client_key = encrypt_cbc(password_hash, session_key_part_b)

        # create session key and combo key
        if len(session_key_part_a) == 48:
            self.session_key = encoded_client_key.hex().upper()[:96]
            b = bytearray(24)
            for i in range(16, 40):
                b[i - 16] = session_key_part_a[i] ^ session_key_part_b[i]
            part1 = hashlib.md5(b[:16]).digest()
            part2 = hashlib.md5(b[16:]).digest()
            combo_key = (part1 + part2)[:keylen]
        else:
            self.session_key = encoded_client_key.hex().upper()[:64]
            salt = bytes.fromhex(self.session_data['AUTH_PBKDF2_CSK_SALT'])
            iterations = int(self.session_data['AUTH_PBKDF2_SDER_COUNT'])
            temp_key = session_key_part_b[:keylen] + session_key_part_a[:keylen]
            combo_key = get_derived_key(temp_key.hex().upper().encode(), salt,
                                        keylen, iterations)

        # retain session key for use by the change password API
        self.conn_impl._combo_key = combo_key

        # generate speedy key for 12c verifiers
        if self.verifier_type == TNS_VERIFIER_TYPE_12C:
            salt = secrets.token_bytes(16)
            speedy_key = encrypt_cbc(combo_key, salt + password_key)
            self.speedy_key = speedy_key[:80].hex().upper()

        # encrypts the passwords
        self._encrypt_passwords()

        # check if debug_jdwp is set. if set, encode the data using the
        # combo session key with zeros padding
        if self.debug_jdwp is not None:
            jdwp_data = self.debug_jdwp.encode()
            encrypted_jdwp_data = encrypt_cbc(combo_key, jdwp_data, zeros=True)
            # Add a "01" at the end of the hex encrypted data to indicate the
            # use of AES encryption
            self.encoded_jdwp_data = encrypted_jdwp_data.hex().upper() + "01"

    cdef str _get_alter_timezone_statement(self):
        """
        Returns the statement required to change the session time zone to match
        the time zone in use by the Python interpreter.
        """
        cdef:
            int tz_hour, tz_minute, timezone
            str sign, tz_repr
        tz_repr = os.environ.get("ORA_SDTZ")
        if tz_repr is None:
            timezone = time.localtime().tm_gmtoff
            tz_hour = timezone // 3600
            tz_minute = (timezone - (tz_hour * 3600)) // 60
            if tz_hour < 0:
                sign = "-"
                tz_hour = -tz_hour
            else:
                sign = "+"
            tz_repr = f"{sign}{tz_hour:02}:{tz_minute:02}"
        return f"ALTER SESSION SET TIME_ZONE='{tz_repr}'\x00"

    cdef tuple _get_version_tuple(self, ReadBuffer buf):
        """
        Return the 5-tuple for the database version. Note that the format
        changed with Oracle Database 18.
        """
        cdef uint32_t full_version_num
        full_version_num = int(self.session_data["AUTH_VERSION_NO"])
        if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_18_1_EXT_1:
            return ((full_version_num >> 24) & 0xFF,
                    (full_version_num >> 16) & 0xFF,
                    (full_version_num >> 12) & 0x0F,
                    (full_version_num >> 4) & 0xFF,
                    (full_version_num & 0x0F))
        else:
            return ((full_version_num >> 24) & 0xFF,
                    (full_version_num >> 20) & 0x0F,
                    (full_version_num >> 12) & 0x0F,
                    (full_version_num >> 8) & 0x0F,
                    (full_version_num & 0x0F))

    cdef int _initialize_hook(self) except -1:
        """
        Perform initialization.
        """
        self.function_code = TNS_FUNC_AUTH_PHASE_ONE
        self.session_data = {}
        if self.conn_impl.username is not None:
            self.user_bytes = self.conn_impl.username.encode()
            self.user_bytes_len = len(self.user_bytes)
        self.resend = True

    cdef int _process_return_parameters(self, ReadBuffer buf) except -1:
        cdef:
            uint16_t num_params, i
            str key, value
        buf.read_ub2(&num_params)
        for i in range(num_params):
            key = buf.read_str_with_length()
            value = buf.read_str_with_length()
            if value is None:
                value = ""
            if key == "AUTH_VFR_DATA":
                buf.read_ub4(&self.verifier_type)
            else:
                buf.skip_ub4()                  # skip flags
            self.session_data[key] = value
        if self.function_code == TNS_FUNC_AUTH_PHASE_ONE:
            self.function_code = TNS_FUNC_AUTH_PHASE_TWO
        elif not self.change_password:
            self.conn_impl._session_id = \
                    <uint32_t> int(self.session_data["AUTH_SESSION_ID"])
            self.conn_impl._serial_num = \
                    <uint16_t> int(self.session_data["AUTH_SERIAL_NUM"])
            self.conn_impl._db_domain = \
                    self.session_data.get("AUTH_SC_DB_DOMAIN")
            self.conn_impl._db_name = \
                    self.session_data.get("AUTH_SC_DBUNIQUE_NAME")
            self.conn_impl._max_open_cursors = \
                    int(self.session_data.get("AUTH_MAX_OPEN_CURSORS", 0))
            self.conn_impl._service_name = \
                    self.session_data.get("AUTH_SC_SERVICE_NAME")
            self.conn_impl._instance_name = \
                    self.session_data.get("AUTH_INSTANCENAME")
            self.conn_impl._max_identifier_length = \
                    int(self.session_data.get("AUTH_MAX_IDEN_LENGTH", 30))
            self.conn_impl.server_version = self._get_version_tuple(buf)
            self.conn_impl.supports_bool = \
                    buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_23_1
            self.conn_impl._edition = self.edition

    cdef int _set_params(self, ConnectParamsImpl params,
                         Description description) except -1:
        """
        Sets the parameters to use for the AuthMessage. The user and auth mode
        are retained in order to avoid duplicating this effort for both trips
        to the server.
        """
        self.password = params._get_password()
        self.newpassword = params._get_new_password()
        self.service_name = description.service_name
        self.proxy_user = params.proxy_user
        self.debug_jdwp = params.debug_jdwp
        self.program = params.program
        self.terminal = params.terminal
        self.machine = params.machine
        self.osuser = params.osuser
        self.driver_name = params.driver_name
        if self.driver_name is None:
            self.driver_name = f"{DRIVER_NAME} thn : {DRIVER_VERSION}"
        self.edition = params.edition
        self.appcontext = params.appcontext
        self.connect_string = params._get_connect_string()

        # if drcp is used, use purity = NEW as the default purity for
        # standalone connections and purity = SELF for connections that belong
        # to a pool
        if description.purity == PURITY_DEFAULT \
                and self.conn_impl._drcp_enabled:
            if self.conn_impl._pool is None:
                self.purity = PURITY_NEW
            else:
                self.purity = PURITY_SELF
        else:
            self.purity = description.purity

        # set token parameters; adjust processing so that only phase two is
        # sent
        if params._token is not None \
                or params.access_token_callback is not None:
            self.token = params._get_token()
            if params._private_key is not None:
                self.private_key = params._get_private_key()
            self.function_code = TNS_FUNC_AUTH_PHASE_TWO
            self.resend = False

        # set authentication mode
        if params._new_password is None:
            self.auth_mode = TNS_AUTH_MODE_LOGON
        if params.mode & AUTH_MODE_SYSDBA:
            self.auth_mode |= TNS_AUTH_MODE_SYSDBA
        if params.mode & AUTH_MODE_SYSOPER:
            self.auth_mode |= TNS_AUTH_MODE_SYSOPER
        if params.mode & AUTH_MODE_SYSASM:
            self.auth_mode |= TNS_AUTH_MODE_SYSASM
        if params.mode & AUTH_MODE_SYSBKP:
            self.auth_mode |= TNS_AUTH_MODE_SYSBKP
        if params.mode & AUTH_MODE_SYSDGD:
            self.auth_mode |= TNS_AUTH_MODE_SYSDGD
        if params.mode & AUTH_MODE_SYSKMT:
            self.auth_mode |= TNS_AUTH_MODE_SYSKMT
        if params.mode & AUTH_MODE_SYSRAC:
            self.auth_mode |= TNS_AUTH_MODE_SYSRAC
        if self.private_key is not None:
            self.auth_mode |= TNS_AUTH_MODE_IAM_TOKEN

    cdef int _write_key_value(self, WriteBuffer buf, str key, str value,
                              uint32_t flags=0) except -1:
        cdef:
            bytes key_bytes = key.encode()
            bytes value_bytes = value.encode()
            uint32_t key_len = <uint32_t> len(key_bytes)
            uint32_t value_len = <uint32_t> len(value_bytes)
        buf.write_ub4(key_len)
        buf.write_bytes_with_length(key_bytes)
        buf.write_ub4(value_len)
        if value_len > 0:
            buf.write_bytes_with_length(value_bytes)
        buf.write_ub4(flags)

    cdef int _write_message(self, WriteBuffer buf) except -1:
        cdef:
            uint8_t has_user = 1 if self.user_bytes_len > 0 else 0
            uint32_t num_pairs

        # perform final determination of data to write
        if self.function_code == TNS_FUNC_AUTH_PHASE_ONE:
            num_pairs = 5
        elif self.change_password:
            self._encrypt_passwords()
            num_pairs = 2
        else:
            num_pairs = 4

            # token authentication
            if self.token is not None:
                num_pairs += 1

            # normal user/password authentication
            else:
                num_pairs += 2
                self.auth_mode |= TNS_AUTH_MODE_WITH_PASSWORD
                if self.verifier_type == TNS_VERIFIER_TYPE_12C:
                    num_pairs += 1
                elif self.verifier_type not in (TNS_VERIFIER_TYPE_11G_1,
                                                TNS_VERIFIER_TYPE_11G_2):
                    errors._raise_err(errors.ERR_UNSUPPORTED_VERIFIER_TYPE,
                                      verifier_type=self.verifier_type)
                self._generate_verifier()

            # determine which other key/value pairs to write
            if self.newpassword is not None:
                num_pairs += 1
                self.auth_mode |= TNS_AUTH_MODE_CHANGE_PASSWORD
            if self.proxy_user is not None:
                num_pairs += 1
            if self.conn_impl._cclass is not None:
                num_pairs += 1
            if self.purity != 0:
                num_pairs += 1
            if self.private_key is not None:
                num_pairs += 2
            if self.encoded_jdwp_data is not None:
                num_pairs += 1
            if self.edition is not None:
                num_pairs += 1
            if self.appcontext is not None:
                num_pairs += len(self.appcontext) * 3
            if self.connect_string is not None:
                num_pairs += 1

        # write basic data to packet
        self._write_function_code(buf)
        buf.write_uint8(has_user)           # pointer (authusr)
        buf.write_ub4(self.user_bytes_len)
        buf.write_ub4(self.auth_mode)       # authentication mode
        buf.write_uint8(1)                  # pointer (authivl)
        buf.write_ub4(num_pairs)            # number of key/value pairs
        buf.write_uint8(1)                  # pointer (authovl)
        buf.write_uint8(1)                  # pointer (authovln)
        if has_user:
            buf.write_bytes_with_length(self.user_bytes)

        # write key/value pairs
        if self.function_code == TNS_FUNC_AUTH_PHASE_ONE:
            self._write_key_value(buf, "AUTH_TERMINAL", self.terminal)
            self._write_key_value(buf, "AUTH_PROGRAM_NM", self.program)
            self._write_key_value(buf, "AUTH_MACHINE", self.machine)
            self._write_key_value(buf, "AUTH_PID", _connect_constants.pid)
            self._write_key_value(buf, "AUTH_SID", self.osuser)
        else:
            if self.proxy_user is not None:
                self._write_key_value(buf, "PROXY_CLIENT_NAME",
                                      self.proxy_user)
            if self.token is not None:
                self._write_key_value(buf, "AUTH_TOKEN", self.token)
            elif not self.change_password:
                self._write_key_value(buf, "AUTH_SESSKEY", self.session_key, 1)
                if self.verifier_type == TNS_VERIFIER_TYPE_12C:
                    self._write_key_value(buf, "AUTH_PBKDF2_SPEEDY_KEY",
                                          self.speedy_key)
            if self.encoded_password is not None:
                self._write_key_value(buf, "AUTH_PASSWORD",
                                      self.encoded_password)
            if self.encoded_newpassword is not None:
                self._write_key_value(buf, "AUTH_NEWPASSWORD",
                                      self.encoded_newpassword)
            if not self.change_password:
                self._write_key_value(buf, "SESSION_CLIENT_CHARSET", "873")
                self._write_key_value(buf, "SESSION_CLIENT_DRIVER_NAME",
                                      self.driver_name)
                self._write_key_value(buf, "SESSION_CLIENT_VERSION",
                                    str(_connect_constants.full_version_num))
                self._write_key_value(buf, "AUTH_ALTER_SESSION",
                                      self._get_alter_timezone_statement(), 1)
            if self.conn_impl._cclass is not None:
                self._write_key_value(buf, "AUTH_KPPL_CONN_CLASS",
                                      self.conn_impl._cclass)
            if self.purity != 0:
                self._write_key_value(buf, "AUTH_KPPL_PURITY",
                                      str(self.purity), 1)
            if self.private_key is not None:
                date_format = "%a, %d %b %Y %H:%M:%S GMT"
                now = datetime.datetime.utcnow().strftime(date_format)
                host_info = "%s:%d" % buf._transport.get_host_info()
                header = f"date: {now}\n" + \
                         f"(request-target): {self.service_name}\n" + \
                         f"host: {host_info}"
                signature = get_signature(self.private_key, header)
                self._write_key_value(buf, "AUTH_HEADER", header)
                self._write_key_value(buf, "AUTH_SIGNATURE", signature)
            if self.encoded_jdwp_data is not None:
                self._write_key_value(buf, "AUTH_ORA_DEBUG_JDWP",
                                      self.encoded_jdwp_data)
            if self.edition is not None:
                self._write_key_value(buf, "AUTH_ORA_EDITION", self.edition)
            if self.appcontext is not None:
                # NOTE: these keys require a trailing null character as the
                # server expects it!
                for entry in self.appcontext:
                    self._write_key_value(buf, "AUTH_APPCTX_NSPACE\0", entry[0])
                    self._write_key_value(buf, "AUTH_APPCTX_ATTR\0", entry[1])
                    self._write_key_value(buf, "AUTH_APPCTX_VALUE\0", entry[2])
            if self.connect_string is not None:
                self._write_key_value(buf, "AUTH_CONNECT_STRING",
                                      self.connect_string)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\base.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# base.pyx
#
# Cython file defining the base classes used for messages sent to the database
# and the responses that are received by the client (embedded in
# thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.freelist(20)
cdef class _OracleErrorInfo:
    cdef:
        uint32_t num
        uint16_t cursor_id
        uint64_t pos
        uint64_t rowcount
        str message
        Rowid rowid
        list batcherrors


cdef class Message:
    cdef:
        BaseThinConnImpl conn_impl
        BaseThinDbObjectTypeCache type_cache
        PipelineOpResultImpl pipeline_result_impl
        _OracleErrorInfo error_info
        uint8_t message_type
        uint8_t function_code
        uint32_t call_status
        uint16_t end_to_end_seq_num
        uint64_t token_num
        bint end_of_response
        bint error_occurred
        bint flush_out_binds
        bint resend
        bint retry
        object warning

    cdef int _check_and_raise_exception(self) except -1:
        """
        Checks to see if an error has occurred. If one has, an error object is
        created and then the appropriate exception raised. Note that if a "dead
        connection" error is detected, the connection is forced closed
        immediately.
        """
        cdef bint is_recoverable = False
        if self.error_occurred:
            if self.error_info.num in (
                28,     # session has been terminated
                31,     # session marked for kill
                376,    # file %s cannot be read at this time
                603,    # ORACLE server session terminated
                1012,   # not logged on
                1033,   # ORACLE initialization or shutdown in progress
                1034,   # the Oracle instance is not available for use
                1089,   # immediate shutdown or close in progress
                1090,   # shutdown in progress
                1092,   # ORACLE instance terminated
                1115,   # IO error reading block from file %s (block # %s)
                2396,   # exceeded maximum idle time
                3113,   # end-of-file on communication channel
                3114,   # not connected to ORACLE
                3135,   # connection lost contact
                12153,  # TNS:not connected
                12514,  # Service %s is not registered with the listener
                12537,  # TNS:connection closed
                12547,  # TNS:lost contact
                12570,  # TNS:packet reader failure
                12571,  # TNS:packet writer failure
                12583,  # TNS:no reader
                12757,  # instance does not currently know of requested service
                16456,  # missing or invalid value
            ):
                is_recoverable = True
            error = errors._Error(self.error_info.message,
                                  code=self.error_info.num,
                                  offset=self.error_info.pos,
                                  isrecoverable=is_recoverable)
            if error.is_session_dead:
                self.conn_impl._protocol._force_close()
            raise error.exc_type(error)

    cdef int _initialize(self, BaseThinConnImpl conn_impl) except -1:
        """
        Initializes the message to contain the connection and a place to store
        error information. For DRCP, the status of the connection may change
        after the first round-trip to the database so this information needs to
        be preserved. Child classes may have their own initialization. In order
        to avoid overhead using the constructor, a special hook method is used
        instead.
        """
        conn_impl._protocol._read_buf._check_connected()
        self.conn_impl = conn_impl
        self.message_type = TNS_MSG_TYPE_FUNCTION
        self.error_info = _OracleErrorInfo.__new__(_OracleErrorInfo)
        self._initialize_hook()

    cdef int _initialize_hook(self) except -1:
        """
        A hook that is used by subclasses to perform any necessary
        initialization specific to that class.
        """
        pass

    cdef int _process_error_info(self, ReadBuffer buf) except -1:
        cdef:
            uint32_t num_bytes, i, offset, num_offsets
            _OracleErrorInfo info = self.error_info
            uint16_t temp16, num_errors, error_code
            uint8_t first_byte, flags
            int16_t error_pos
            str error_msg
        buf.read_ub4(&self.call_status)     # end of call status
        buf.skip_ub2()                      # end to end seq#
        buf.skip_ub4()                      # current row number
        buf.skip_ub2()                      # error number
        buf.skip_ub2()                      # array elem error
        buf.skip_ub2()                      # array elem error
        buf.read_ub2(&info.cursor_id)       # cursor id
        buf.read_sb2(&error_pos)            # error position
        buf.skip_ub1()                      # sql type (19c and earlier)
        buf.skip_ub1()                      # fatal?
        buf.skip_ub1()                      # flags
        buf.skip_ub1()                      # user cursor options
        buf.skip_ub1()                      # UPI parameter
        buf.read_ub1(&flags)
        if flags & 0x20:
            self.warning = errors._create_warning(errors.WRN_COMPILATION_ERROR)
        buf.read_rowid(&info.rowid)         # rowid
        buf.skip_ub4()                      # OS error
        buf.skip_ub1()                      # statement number
        buf.skip_ub1()                      # call number
        buf.skip_ub2()                      # padding
        buf.skip_ub4()                      # success iters
        buf.read_ub4(&num_bytes)            # oerrdd (logical rowid)
        if num_bytes > 0:
            buf.skip_raw_bytes_chunked()

        # batch error codes
        buf.read_ub2(&num_errors)           # batch error codes array
        if num_errors > 0:
            info.batcherrors = []
            buf.read_ub1(&first_byte)
            for i in range(num_errors):
                if first_byte == TNS_LONG_LENGTH_INDICATOR:
                    buf.skip_ub4()          # chunk length ignored
                buf.read_ub2(&error_code)
                info.batcherrors.append(errors._Error(code=error_code))
            if first_byte == TNS_LONG_LENGTH_INDICATOR:
                buf.skip_raw_bytes(1)       # ignore end marker

        # batch error offsets
        buf.read_ub4(&num_offsets)          # batch error row offset array
        if num_offsets > 0:
            if num_offsets > 65535:
                errors._raise_err(errors.ERR_TOO_MANY_BATCH_ERRORS)
            buf.read_ub1(&first_byte)
            for i in range(num_offsets):
                if first_byte == TNS_LONG_LENGTH_INDICATOR:
                    buf.skip_ub4()          # chunk length ignored
                buf.read_ub4(&offset)
                if i < num_errors:
                    info.batcherrors[i].offset = offset
            if first_byte == TNS_LONG_LENGTH_INDICATOR:
                buf.skip_raw_bytes(1)       # ignore end marker

        # batch error messages
        buf.read_ub2(&temp16)               # batch error messages array
        if temp16 > 0:
            buf.skip_raw_bytes(1)           # ignore packed size
            for i in range(temp16):
                buf.skip_ub2()              # skip chunk length
                info.batcherrors[i].message = \
                        buf.read_str(CS_FORM_IMPLICIT).rstrip()
                info.batcherrors[i]._make_adjustments()
                buf.skip_raw_bytes(2)       # ignore end marker

        buf.read_ub4(&info.num)             # error number (extended)
        buf.read_ub8(&info.rowcount)        # row number (extended)

        # fields added in Oracle Database 20c
        if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_20_1:
            buf.skip_ub4()                  # sql type
            buf.skip_ub4()                  # server checksum

        # error message
        if info.num != 0:
            self.error_occurred = True
            if error_pos > 0:
                info.pos = error_pos
            info.message = buf.read_str(CS_FORM_IMPLICIT).rstrip()

        # an error message marks the end of a response if no explicit end of
        # response is available
        if not buf._caps.supports_end_of_response:
            self.end_of_response = True

    cdef int _process_message(self, ReadBuffer buf,
                              uint8_t message_type) except -1:
        cdef uint64_t token_num
        if message_type == TNS_MSG_TYPE_ERROR:
            self._process_error_info(buf)
        elif message_type == TNS_MSG_TYPE_WARNING:
            self._process_warning_info(buf)
        elif message_type == TNS_MSG_TYPE_TOKEN:
            buf.read_ub8(&token_num)
            if token_num != self.token_num:
                errors._raise_err(errors.ERR_MISMATCHED_TOKEN,
                                  token_num=token_num,
                                  expected_token_num=self.token_num)
        elif message_type == TNS_MSG_TYPE_STATUS:
            buf.read_ub4(&self.call_status)
            buf.read_ub2(&self.end_to_end_seq_num)
            if not buf._caps.supports_end_of_response:
                self.end_of_response = True
        elif message_type == TNS_MSG_TYPE_PARAMETER:
            self._process_return_parameters(buf)
        elif message_type == TNS_MSG_TYPE_SERVER_SIDE_PIGGYBACK:
            self._process_server_side_piggyback(buf)
        elif message_type == TNS_MSG_TYPE_END_OF_RESPONSE:
            self.end_of_response = True
        else:
            errors._raise_err(errors.ERR_MESSAGE_TYPE_UNKNOWN,
                              message_type=message_type,
                              position=buf._pos - 1)

    cdef OracleMetadata _process_metadata(self, ReadBuffer buf):
        """
        Process metadata from the buffer and return it.
        """
        cdef:
            uint32_t uds_flags, num_annotations, i
            ThinDbObjectTypeImpl typ_impl
            str schema, name, key, value
            uint8_t ora_type_num, csfrm
            OracleMetadata metadata
            uint8_t nulls_allowed
            int cache_num
            bytes oid
        buf.read_ub1(&ora_type_num)
        metadata = OracleMetadata.__new__(OracleMetadata)
        buf.skip_ub1()                      # flags
        buf.read_sb1(&metadata.precision)
        buf.read_sb1(&metadata.scale)
        buf.read_ub4(&metadata.buffer_size)
        buf.skip_ub4()                      # max number of array elements
        buf.skip_ub8()                      # cont flags
        oid = buf.read_bytes_with_length()
        buf.skip_ub2()                      # version
        buf.skip_ub2()                      # character set id
        buf.read_ub1(&csfrm)                # character set form
        metadata.dbtype = DbType._from_ora_type_and_csfrm(ora_type_num, csfrm)
        buf.read_ub4(&metadata.max_size)
        if ora_type_num == ORA_TYPE_NUM_RAW:
            metadata.max_size = metadata.buffer_size
        if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_12_2:
            buf.skip_ub4()                  # oaccolid
        buf.read_ub1(&nulls_allowed)
        metadata.nulls_allowed = nulls_allowed
        buf.skip_ub1()                      # v7 length of name
        metadata.name = buf.read_str_with_length()
        schema = buf.read_str_with_length()
        name = buf.read_str_with_length()
        buf.skip_ub2()                      # column position
        buf.read_ub4(&uds_flags)
        metadata.is_json = uds_flags & TNS_UDS_FLAGS_IS_JSON
        metadata.is_oson = uds_flags & TNS_UDS_FLAGS_IS_OSON
        if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_23_1:
            metadata.domain_schema = buf.read_str_with_length()
            metadata.domain_name = buf.read_str_with_length()
        if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_23_1_EXT_3:
            buf.read_ub4(&num_annotations)
            if num_annotations > 0:
                buf.skip_ub1()
                metadata.annotations = {}
                buf.read_ub4(&num_annotations)
                buf.skip_ub1()
                for i in range(num_annotations):
                    key = buf.read_str_with_length()
                    value = buf.read_str_with_length()
                    if value is None:
                        value = ""
                    metadata.annotations[key] = value
                    buf.skip_ub4()          # flags
                buf.skip_ub4()              # flags
        if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_23_4:
            buf.read_ub4(&metadata.vector_dimensions)
            buf.read_ub1(&metadata.vector_format)
            buf.read_ub1(&metadata.vector_flags)
        if ora_type_num == ORA_TYPE_NUM_OBJECT:
            if self.type_cache is None:
                cache_num = self.conn_impl._dbobject_type_cache_num
                self.type_cache = get_dbobject_type_cache(cache_num)
            typ_impl = self.type_cache.get_type_for_info(oid, schema, None,
                                                         name)
            if typ_impl.is_xml_type:
                metadata.dbtype = DB_TYPE_XMLTYPE
            else:
                metadata.objtype = typ_impl
        return metadata

    cdef int _process_return_parameters(self, ReadBuffer buf) except -1:
        raise NotImplementedError()

    cdef int _process_server_side_piggyback(self, ReadBuffer buf) except -1:
        cdef:
            uint16_t num_elements, i, temp16
            uint32_t num_bytes, flags
            uint8_t opcode
        buf.read_ub1(&opcode)
        if opcode == TNS_SERVER_PIGGYBACK_LTXID:
            self.conn_impl._ltxid = buf.read_bytes_with_length()
        elif opcode == TNS_SERVER_PIGGYBACK_QUERY_CACHE_INVALIDATION \
                or opcode == TNS_SERVER_PIGGYBACK_TRACE_EVENT:
            pass
        elif opcode == TNS_SERVER_PIGGYBACK_OS_PID_MTS:
            buf.read_ub2(&temp16)
            buf.skip_raw_bytes_chunked()
        elif opcode == TNS_SERVER_PIGGYBACK_SYNC:
            buf.skip_ub2()                  # skip number of DTYs
            buf.skip_ub1()                  # skip length of DTYs
            buf.read_ub2(&num_elements)
            buf.skip_ub1()                  # skip length
            for i in range(num_elements):
                buf.read_ub2(&temp16)
                if temp16 > 0:              # skip key
                    buf.skip_raw_bytes_chunked()
                buf.read_ub2(&temp16)
                if temp16 > 0:              # skip value
                    buf.skip_raw_bytes_chunked()
                buf.skip_ub2()              # skip flags
            buf.skip_ub4()                  # skip overall flags
        elif opcode == TNS_SERVER_PIGGYBACK_EXT_SYNC:
            buf.skip_ub2()                  # skip number of DTYs
            buf.skip_ub1()                  # skip length of DTYs
        elif opcode == TNS_SERVER_PIGGYBACK_AC_REPLAY_CONTEXT:
            buf.skip_ub2()                  # skip number of DTYs
            buf.skip_ub1()                  # skip length of DTYs
            buf.skip_ub4()                  # skip flags
            buf.skip_ub4()                  # skip error code
            buf.skip_ub1()                  # skip queue
            buf.read_ub4(&num_bytes)        # skip replay context
            if num_bytes > 0:
                buf.skip_raw_bytes_chunked()
        elif opcode == TNS_SERVER_PIGGYBACK_SESS_RET:
            buf.skip_ub2()
            buf.skip_ub1()
            buf.read_ub2(&num_elements)
            if num_elements > 0:
                buf.skip_ub1()
                for i in range(num_elements):
                    buf.read_ub2(&temp16)
                    if temp16 > 0:          # skip key
                        buf.skip_raw_bytes_chunked()
                    buf.read_ub2(&temp16)
                    if temp16 > 0:          # skip value
                        buf.skip_raw_bytes_chunked()
                    buf.skip_ub2()          # skip flags
            buf.read_ub4(&flags)            # session flags
            if flags & TNS_SESSGET_SESSION_CHANGED:
                if self.conn_impl._drcp_establish_session:
                    self.conn_impl._statement_cache.clear_open_cursors()
            self.conn_impl._drcp_establish_session = False
            buf.read_ub4(&self.conn_impl._session_id)
            buf.read_ub2(&self.conn_impl._serial_num)
        elif opcode == TNS_SERVER_PIGGYBACK_SESS_SIGNATURE:
            buf.skip_ub2()                  # number of dtys
            buf.skip_ub1()                  # length of dty
            buf.skip_ub8()                  # signature flags
            buf.skip_ub8()                  # client signature
            buf.skip_ub8()                  # server signature
        else:
            errors._raise_err(errors.ERR_UNKNOWN_SERVER_PIGGYBACK,
                              opcode=opcode)

    cdef int _process_warning_info(self, ReadBuffer buf) except -1:
        cdef:
            uint16_t num_bytes, error_num
            str message
        buf.read_ub2(&error_num)            # error number
        buf.read_ub2(&num_bytes)            # length of error message
        buf.skip_ub2()                      # flags
        if error_num != 0 and num_bytes > 0:
            message = buf.read_str(CS_FORM_IMPLICIT).rstrip()
            self.warning = errors._Error(message, code=error_num,
                                         iswarning=True)

    cdef int _write_begin_pipeline_piggyback(self, WriteBuffer buf) except -1:
        """
        Writes the piggyback to the server that informs the server that a
        pipeline is beginning.
        """
        buf._data_flags |= TNS_DATA_FLAGS_BEGIN_PIPELINE
        self._write_piggyback_code(buf, TNS_FUNC_PIPELINE_BEGIN)
        buf.write_ub2(0)                    # error set ID
        buf.write_uint8(0)                  # error set mode
        buf.write_uint8(self.conn_impl.pipeline_mode)

    cdef int _write_close_cursors_piggyback(self, WriteBuffer buf) except -1:
        """
        Writes the piggyback that informs the server of the cursors that can be
        closed.
        """
        self._write_piggyback_code(buf, TNS_FUNC_CLOSE_CURSORS)
        buf.write_uint8(1)                  # pointer
        self.conn_impl._statement_cache.write_cursors_to_close(buf)

    cdef int _write_current_schema_piggyback(self, WriteBuffer buf) except -1:
        """
        Writes the piggyback that informs the server that a new current schema
        is desired.
        """
        cdef bytes schema_bytes
        self._write_piggyback_code(buf, TNS_FUNC_SET_SCHEMA)
        buf.write_uint8(1)                  # pointer
        schema_bytes = self.conn_impl._current_schema.encode()
        buf.write_ub4(len(schema_bytes))
        buf.write_bytes_with_length(schema_bytes)

    cdef int _write_close_temp_lobs_piggyback(self,
                                              WriteBuffer buf) except -1:
        """
        Writes the piggyback that informs the server of the temporary LOBs that
        can be closed.
        """
        cdef:
            list lobs_to_close = self.conn_impl._temp_lobs_to_close
            uint64_t total_size = 0
        self._write_piggyback_code(buf, TNS_FUNC_LOB_OP)
        op_code = TNS_LOB_OP_FREE_TEMP | TNS_LOB_OP_ARRAY

        # temp lob data
        buf.write_uint8(1)                  # pointer
        buf.write_ub4(self.conn_impl._temp_lobs_total_size)
        buf.write_uint8(0)                  # dest lob locator
        buf.write_ub4(0)
        buf.write_ub4(0)                    # source lob locator
        buf.write_ub4(0)
        buf.write_uint8(0)                  # source lob offset
        buf.write_uint8(0)                  # dest lob offset
        buf.write_uint8(0)                  # charset
        buf.write_ub4(op_code)
        buf.write_uint8(0)                  # scn
        buf.write_ub4(0)                    # losbscn
        buf.write_ub8(0)                    # lobscnl
        buf.write_ub8(0)
        buf.write_uint8(0)

        # array lob fields
        buf.write_uint8(0)
        buf.write_ub4(0)
        buf.write_uint8(0)
        buf.write_ub4(0)
        buf.write_uint8(0)
        buf.write_ub4(0)
        for i in range(len(lobs_to_close)):
            buf.write_bytes(lobs_to_close[i])

        # reset values
        self.conn_impl._temp_lobs_to_close = None
        self.conn_impl._temp_lobs_total_size = 0

    cdef int _write_end_to_end_piggyback(self, WriteBuffer buf) except -1:
        """
        Writes the piggyback that informs the server of end-to-end attributes
        that are being changed.
        """
        cdef:
            bytes action_bytes, client_identifier_bytes, client_info_bytes
            BaseThinConnImpl conn_impl = self.conn_impl
            bytes module_bytes, dbop_bytes
            uint32_t flags = 0

        # determine which flags to send
        if conn_impl._action_modified:
            flags |= TNS_END_TO_END_ACTION
        if conn_impl._client_identifier_modified:
            flags |= TNS_END_TO_END_CLIENT_IDENTIFIER
        if conn_impl._client_info_modified:
            flags |= TNS_END_TO_END_CLIENT_INFO
        if conn_impl._module_modified:
            flags |= TNS_END_TO_END_MODULE
        if conn_impl._dbop_modified:
            flags |= TNS_END_TO_END_DBOP

        # write initial packet data
        self._write_piggyback_code(buf, TNS_FUNC_SET_END_TO_END_ATTR)
        buf.write_uint8(0)                  # pointer (cidnam)
        buf.write_uint8(0)                  # pointer (cidser)
        buf.write_ub4(flags)

        # write client identifier header info
        if conn_impl._client_identifier_modified:
            buf.write_uint8(1)              # pointer (client identifier)
            if conn_impl._client_identifier is None:
                buf.write_ub4(0)
            else:
                client_identifier_bytes = conn_impl._client_identifier.encode()
                buf.write_ub4(len(client_identifier_bytes))
        else:
            buf.write_uint8(0)              # pointer (client identifier)
            buf.write_ub4(0)                # length of client identifier

        # write module header info
        if conn_impl._module_modified:
            buf.write_uint8(1)              # pointer (module)
            if conn_impl._module is None:
                buf.write_ub4(0)
            else:
                module_bytes = conn_impl._module.encode()
                buf.write_ub4(len(module_bytes))
        else:
            buf.write_uint8(0)              # pointer (module)
            buf.write_ub4(0)                # length of module

        # write action header info
        if conn_impl._action_modified:
            buf.write_uint8(1)              # pointer (action)
            if conn_impl._action is None:
                buf.write_ub4(0)
            else:
                action_bytes = conn_impl._action.encode()
                buf.write_ub4(len(action_bytes))
        else:
            buf.write_uint8(0)              # pointer (action)
            buf.write_ub4(0)                # length of action

        # write unsupported bits
        buf.write_uint8(0)                  # pointer (cideci)
        buf.write_ub4(0)                    # length (cideci)
        buf.write_uint8(0)                  # cidcct
        buf.write_ub4(0)                    # cidecs

        # write client info header info
        if conn_impl._client_info_modified:
            buf.write_uint8(1)              # pointer (client info)
            if conn_impl._client_info is None:
                buf.write_ub4(0)
            else:
                client_info_bytes = conn_impl._client_info.encode()
                buf.write_ub4(len(client_info_bytes))
        else:
            buf.write_uint8(0)              # pointer (client info)
            buf.write_ub4(0)                # length of client info

        # write more unsupported bits
        buf.write_uint8(0)                  # pointer (cidkstk)
        buf.write_ub4(0)                    # length (cidkstk)
        buf.write_uint8(0)                  # pointer (cidktgt)
        buf.write_ub4(0)                    # length (cidktgt)

        # write dbop header info
        if conn_impl._dbop_modified:
            buf.write_uint8(1)              # pointer (dbop)
            if conn_impl._dbop is None:
                buf.write_ub4(0)
            else:
                dbop_bytes = conn_impl._dbop.encode()
                buf.write_ub4(len(dbop_bytes))
        else:
            buf.write_uint8(0)              # pointer (dbop)
            buf.write_ub4(0)                # length of dbop

        # write strings
        if conn_impl._client_identifier_modified \
                and conn_impl._client_identifier is not None:
            buf.write_bytes_with_length(client_identifier_bytes)
        if conn_impl._module_modified and conn_impl._module is not None:
            buf.write_bytes_with_length(module_bytes)
        if conn_impl._action_modified and conn_impl._action is not None:
            buf.write_bytes_with_length(action_bytes)
        if conn_impl._client_info_modified \
                and conn_impl._client_info is not None:
            buf.write_bytes_with_length(client_info_bytes)
        if conn_impl._dbop_modified and conn_impl._dbop is not None:
            buf.write_bytes_with_length(dbop_bytes)

        # reset flags and values
        conn_impl._action_modified = False
        conn_impl._action = None
        conn_impl._client_identifier_modified = False
        conn_impl._client_identifier = None
        conn_impl._client_info_modified = False
        conn_impl._client_info = None
        conn_impl._dbop_modified = False
        conn_impl._dbop = None
        conn_impl._module_modified = False
        conn_impl._module = None

    cdef int _write_function_code(self, WriteBuffer buf) except -1:
        self._write_piggybacks(buf)
        buf.write_uint8(self.message_type)
        buf.write_uint8(self.function_code)
        buf.write_seq_num()
        if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_23_1_EXT_1:
            buf.write_ub8(self.token_num)

    cdef int _write_message(self, WriteBuffer buf) except -1:
        self._write_function_code(buf)

    cdef int _write_piggyback_code(self, WriteBuffer buf,
                                   uint8_t code) except -1:
        """
        Writes the header for piggybacks for the specified function code.
        """
        buf.write_uint8(TNS_MSG_TYPE_PIGGYBACK)
        buf.write_uint8(code)
        buf.write_seq_num()
        if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_23_1_EXT_1:
            buf.write_ub8(self.token_num)

    cdef int _write_piggybacks(self, WriteBuffer buf) except -1:
        """
        Writes all of the piggybacks to the server.
        """
        if self.conn_impl.pipeline_mode != 0:
            self._write_begin_pipeline_piggyback(buf)
            self.conn_impl.pipeline_mode = 0
        if self.conn_impl._current_schema_modified:
            self._write_current_schema_piggyback(buf)
        if self.conn_impl._statement_cache is not None \
                and self.conn_impl._statement_cache._num_cursors_to_close > 0 \
                and not self.conn_impl._drcp_establish_session:
            self._write_close_cursors_piggyback(buf)
        if self.conn_impl._action_modified \
                or self.conn_impl._client_identifier_modified \
                or self.conn_impl._client_info_modified \
                or self.conn_impl._dbop_modified \
                or self.conn_impl._module_modified:
            self._write_end_to_end_piggyback(buf)
        if self.conn_impl._temp_lobs_total_size > 0:
            self._write_close_temp_lobs_piggyback(buf)
        if self.conn_impl._session_state_desired != 0:
            self._write_session_state_piggyback(buf)

    cdef int _write_session_state_piggyback(self, WriteBuffer buf) except -1:
        """
        Write the session state piggyback. This is used to let the database
        know when the client is beginning and ending a request. The database
        uses this information to optimise its resources.
        """
        cdef uint8_t state = self.conn_impl._session_state_desired
        self._write_piggyback_code(buf, TNS_FUNC_SESSION_STATE)
        buf.write_ub8(state | TNS_SESSION_STATE_EXPLICIT_BOUNDARY)
        self.conn_impl._session_state_desired = 0

    cdef int postprocess(self) except -1:
        pass

    async def postprocess_async(self):
        pass

    cdef int preprocess(self) except -1:
        pass

    cdef int process(self, ReadBuffer buf) except -1:
        cdef uint8_t message_type
        self.end_of_response = False
        self.flush_out_binds = False
        while not self.end_of_response:
            buf.save_point()
            buf.read_ub1(&message_type)
            self._process_message(buf, message_type)

    cdef int send(self, WriteBuffer buf) except -1:
        buf.start_request(TNS_PACKET_TYPE_DATA)
        self._write_message(buf)
        if self.pipeline_result_impl is not None:
            buf._data_flags |= TNS_DATA_FLAGS_END_OF_REQUEST
        buf.end_request()


cdef class MessageWithData(Message):
    cdef:
        BaseThinCursorImpl cursor_impl
        array.array bit_vector_buf
        const char_type *bit_vector
        bint arraydmlrowcounts
        uint32_t row_index
        uint32_t num_execs
        uint16_t num_columns_sent
        list dmlrowcounts
        bint batcherrors
        list out_var_impls
        bint in_fetch
        bint parse_only
        object cursor
        uint32_t offset

    cdef int _adjust_metadata(self, ThinVarImpl prev_var_impl,
                              OracleMetadata metadata) except -1:
        """
        When a query is re-executed but the data type of a column has changed
        the server returns the type information of the new type. However, if
        the data type returned now is a CLOB or BLOB and the data type
        previously returned was CHAR/VARCHAR/RAW (or the equivalent long
        types), then the server returns the data as LONG (RAW), similarly to
        what happens when a define is done to return CLOB/BLOB as string/bytes.
        Detect these situations and adjust the fetch type appropriately.
        """
        cdef uint8_t type_num, prev_type_num, csfrm
        type_num = metadata.dbtype._ora_type_num
        prev_type_num = prev_var_impl._fetch_metadata.dbtype._ora_type_num
        if type_num == ORA_TYPE_NUM_CLOB \
                and prev_type_num in (ORA_TYPE_NUM_CHAR,
                                      ORA_TYPE_NUM_LONG,
                                      ORA_TYPE_NUM_VARCHAR):
            type_num = ORA_TYPE_NUM_LONG
            csfrm = prev_var_impl._fetch_metadata.dbtype._csfrm
            metadata.dbtype = DbType._from_ora_type_and_csfrm(type_num, csfrm)
        elif type_num == ORA_TYPE_NUM_BLOB \
                and prev_type_num in (ORA_TYPE_NUM_RAW, ORA_TYPE_NUM_LONG_RAW):
            type_num = ORA_TYPE_NUM_LONG_RAW
            metadata.dbtype = DbType._from_ora_type_and_csfrm(type_num, 0)

    cdef object _create_cursor_from_describe(self, ReadBuffer buf,
                                             object cursor=None):
        cdef BaseThinCursorImpl cursor_impl
        if cursor is None:
            cursor = self.cursor.connection.cursor()
        cursor_impl = cursor._impl
        cursor_impl._statement = self.conn_impl._get_statement()
        cursor_impl._more_rows_to_fetch = True
        cursor_impl._statement._is_query = True
        self._process_describe_info(buf, cursor, cursor_impl)
        return cursor

    cdef int _get_bit_vector(self, ReadBuffer buf,
                             ssize_t num_bytes) except -1:
        """
        Gets the bit vector from the buffer and stores it for later use by the
        row processing code. Since it is possible that the packet buffer may be
        overwritten by subsequent packet retrieval, the bit vector must be
        copied. An array is stored and a pointer to the underlying memory is
        used for performance reasons.
        """
        cdef const char_type *ptr = buf.read_raw_bytes(num_bytes)
        if self.bit_vector_buf is None:
            self.bit_vector_buf = array.array('B')
            array.resize(self.bit_vector_buf, num_bytes)
        self.bit_vector = <const char_type*> self.bit_vector_buf.data.as_chars
        memcpy(<void*> self.bit_vector, ptr, num_bytes)

    cdef bint _is_duplicate_data(self, uint32_t column_num):
        """
        Returns a boolean indicating if the given column contains data
        duplicated from the previous row. When duplicate data exists, the
        server sends a bit vector. Bits that are set indicate that data is sent
        with the row data; bits that are not set indicate that data should be
        duplicated from the previous row.
        """
        cdef int byte_num, bit_num
        if self.bit_vector == NULL:
            return False
        byte_num = column_num // 8
        bit_num = column_num % 8
        return self.bit_vector[byte_num] & (1 << bit_num) == 0

    cdef int _write_bind_params(self, WriteBuffer buf, list params) except -1:
        cdef:
            bint has_data = False
            list bind_var_impls
            BindInfo bind_info
        bind_var_impls = []
        for bind_info in params:
            if not bind_info._is_return_bind:
                has_data = True
            bind_var_impls.append(bind_info._bind_var_impl)
        self._write_column_metadata(buf, bind_var_impls)

        # write parameter values unless statement contains only returning binds
        if has_data:
            for i in range(self.num_execs):
                buf.write_uint8(TNS_MSG_TYPE_ROW_DATA)
                self._write_bind_params_row(buf, params, i)

    cdef int _preprocess_query(self) except -1:
        """
        Actions that takes place before query data is processed.
        """
        cdef:
            BaseThinCursorImpl cursor_impl = self.cursor_impl
            Statement statement = cursor_impl._statement
            object type_handler, conn
            ThinVarImpl var_impl
            ssize_t i, num_vals
            bint uses_metadata

        # set values to indicate the start of a new fetch operation
        self.in_fetch = True
        cursor_impl._more_rows_to_fetch = True
        cursor_impl._buffer_rowcount = cursor_impl._buffer_index = 0
        self.row_index = 0

        # if no fetch variables exist, nothing further to do at this point; the
        # processing that follows will take the metadata returned by the server
        # and use it to create new fetch variables
        if statement._fetch_var_impls is None:
            return 0

        # if the type handler set on the cursor or connection does not match
        # the one that was used during the last fetch, rebuild the fetch
        # variables in order to take the new type handler into account
        conn = self.cursor.connection
        type_handler = cursor_impl._get_output_type_handler(&uses_metadata)
        if type_handler is not statement._last_output_type_handler:
            for i, var_impl in enumerate(cursor_impl.fetch_var_impls):
                cursor_impl._create_fetch_var(conn, self.cursor, type_handler,
                                              uses_metadata, i,
                                              var_impl._fetch_metadata)
            statement._last_output_type_handler = type_handler

        # Create OracleArrowArray if fetching arrow is enabled
        if cursor_impl.fetching_arrow:
            cursor_impl._create_arrow_arrays()

        # the list of output variables is equivalent to the fetch variables
        self.out_var_impls = cursor_impl.fetch_var_impls

    cdef int _process_bit_vector(self, ReadBuffer buf) except -1:
        cdef ssize_t num_bytes
        buf.read_ub2(&self.num_columns_sent)
        num_bytes = self.cursor_impl._num_columns // 8
        if self.cursor_impl._num_columns % 8 > 0:
            num_bytes += 1
        self._get_bit_vector(buf, num_bytes)

    cdef object _process_column_data(self, ReadBuffer buf,
                                     ThinVarImpl var_impl, uint32_t pos):
        cdef:
            uint8_t num_bytes, ora_type_num, csfrm
            ThinDbObjectTypeImpl typ_impl
            BaseThinCursorImpl cursor_impl
            object column_value = None
            ThinDbObjectImpl obj_impl
            int32_t actual_num_bytes
            OracleMetadata metadata
            OracleData data
            Rowid rowid
        if self.in_fetch:
            metadata = var_impl._fetch_metadata
        else:
            metadata = var_impl.metadata
        ora_type_num = metadata.dbtype._ora_type_num
        csfrm =  metadata.dbtype._csfrm
        if var_impl.bypass_decode:
            ora_type_num = ORA_TYPE_NUM_RAW
        if metadata.buffer_size == 0 and self.in_fetch \
                and ora_type_num not in (ORA_TYPE_NUM_LONG,
                                         ORA_TYPE_NUM_LONG_RAW,
                                         ORA_TYPE_NUM_UROWID):
            column_value = None             # column is null by describe
        elif ora_type_num == ORA_TYPE_NUM_ROWID:
            if not self.in_fetch:
                column_value = buf.read_str(CS_FORM_IMPLICIT)
            else:
                buf.read_ub1(&num_bytes)
                if num_bytes == 0 or num_bytes == TNS_NULL_LENGTH_INDICATOR:
                    column_value = None
                else:
                    buf.read_rowid(&rowid)
                    column_value = _encode_rowid(&rowid)
        elif ora_type_num == ORA_TYPE_NUM_UROWID:
            if not self.in_fetch:
                column_value = buf.read_str(CS_FORM_IMPLICIT)
            else:
                column_value = buf.read_urowid()
        elif ora_type_num == ORA_TYPE_NUM_CURSOR:
            buf.skip_ub1()                  # length (fixed value)
            if not self.in_fetch:
                column_value = var_impl._values[pos]
            column_value = self._create_cursor_from_describe(buf, column_value)
            cursor_impl = column_value._impl
            buf.read_ub2(&cursor_impl._statement._cursor_id)
            if self.in_fetch:
                cursor_impl._statement._is_nested = True
        elif ora_type_num in (ORA_TYPE_NUM_CLOB,
                              ORA_TYPE_NUM_BLOB,
                              ORA_TYPE_NUM_BFILE):
            if self.cursor_impl._statement._is_plsql:
                column_value = var_impl._values[pos]
            column_value = buf.read_lob_with_length(self.conn_impl,
                                                    metadata.dbtype,
                                                    column_value)
        elif ora_type_num == ORA_TYPE_NUM_JSON:
            column_value = buf.read_oson()
        elif ora_type_num == ORA_TYPE_NUM_VECTOR:
            column_value = buf.read_vector()
        elif ora_type_num == ORA_TYPE_NUM_OBJECT:
            typ_impl = metadata.objtype
            if typ_impl is None:
                column_value = buf.read_xmltype(self.conn_impl)
            else:
                obj_impl = buf.read_dbobject(typ_impl)
                if obj_impl is not None:
                    if self.cursor_impl._statement._is_plsql:
                        column_value = var_impl._values[pos]
                    if column_value is not None:
                        column_value._impl = obj_impl
                    else:
                        column_value = PY_TYPE_DB_OBJECT._from_impl(obj_impl)
        else:
            buf.read_oracle_data(metadata, &data, from_dbobject=False)
            if metadata.dbtype._csfrm == CS_FORM_NCHAR:
                buf._caps._check_ncharset_id()
            if self.cursor_impl.fetching_arrow:
                convert_oracle_data_to_arrow(
                    metadata, var_impl.metadata, &data, var_impl._arrow_array
                )
            else:
                column_value = convert_oracle_data_to_python(
                    metadata, var_impl.metadata, &data,
                    var_impl._encoding_errors, from_dbobject=False
                )
        if not self.in_fetch:
            buf.read_sb4(&actual_num_bytes)
            if actual_num_bytes < 0 and ora_type_num == ORA_TYPE_NUM_BOOLEAN:
                column_value = None
            elif actual_num_bytes != 0 and column_value is not None:
                unit_type = "bytes" if isinstance(column_value, bytes) \
                            else "characters"
                errors._raise_err(errors.ERR_COLUMN_TRUNCATED,
                                  col_value_len=len(column_value),
                                  unit=unit_type, actual_len=actual_num_bytes)
        elif ora_type_num == ORA_TYPE_NUM_LONG \
                or ora_type_num == ORA_TYPE_NUM_LONG_RAW:
            buf.skip_sb4()                  # null indicator
            buf.skip_ub4()                  # return code
        return column_value

    cdef int _process_describe_info(self, ReadBuffer buf,
                                    object cursor,
                                    BaseThinCursorImpl cursor_impl) except -1:
        cdef:
            Statement stmt = cursor_impl._statement
            list prev_fetch_var_impls
            object type_handler, conn
            OracleMetadata metadata
            uint32_t num_bytes, i
            bint uses_metadata
            str message
        buf.skip_ub4()                      # max row size
        buf.read_ub4(&cursor_impl._num_columns)
        prev_fetch_var_impls = stmt._fetch_var_impls
        cursor_impl._init_fetch_vars(cursor_impl._num_columns)
        if cursor_impl._num_columns > 0:
            buf.skip_ub1()
        type_handler = cursor_impl._get_output_type_handler(&uses_metadata)
        conn = self.cursor.connection
        for i in range(cursor_impl._num_columns):
            metadata = self._process_metadata(buf)
            if prev_fetch_var_impls is not None \
                    and i < len(prev_fetch_var_impls):
                self._adjust_metadata(prev_fetch_var_impls[i], metadata)
            if metadata.dbtype._ora_type_num in (ORA_TYPE_NUM_BLOB,
                                                 ORA_TYPE_NUM_CLOB,
                                                 ORA_TYPE_NUM_JSON,
                                                 ORA_TYPE_NUM_VECTOR):
                stmt._requires_define = True
                stmt._no_prefetch = True
            cursor_impl._create_fetch_var(conn, self.cursor, type_handler,
                                          uses_metadata, i, metadata)
        buf.read_ub4(&num_bytes)
        if num_bytes > 0:
            buf.skip_raw_bytes_chunked()    # current date
        buf.skip_ub4()                      # dcbflag
        buf.skip_ub4()                      # dcbmdbz
        buf.skip_ub4()                      # dcbmnpr
        buf.skip_ub4()                      # dcbmxpr
        buf.read_ub4(&num_bytes)
        if num_bytes > 0:
            buf.skip_raw_bytes_chunked()    # dcbqcky
        stmt._fetch_metadata = cursor_impl.fetch_metadata
        stmt._fetch_vars = cursor_impl.fetch_vars
        stmt._fetch_var_impls = cursor_impl.fetch_var_impls
        stmt._num_columns = cursor_impl._num_columns
        stmt._last_output_type_handler = type_handler

    cdef int _process_error_info(self, ReadBuffer buf) except -1:
        cdef:
            BaseThinCursorImpl cursor_impl = self.cursor_impl
            BaseThinConnImpl conn_impl = self.conn_impl
            object exc_type
        Message._process_error_info(self, buf)
        if self.error_info.cursor_id != 0:
            cursor_impl._statement._cursor_id = self.error_info.cursor_id
        if not cursor_impl._statement._is_plsql and not self.in_fetch:
            cursor_impl.rowcount = self.error_info.rowcount
        elif self.in_fetch and self.row_index > 0:
            cursor_impl._statement._requires_define = False
        cursor_impl._lastrowid = self.error_info.rowid
        cursor_impl._batcherrors = self.error_info.batcherrors
        if self.batcherrors and cursor_impl._batcherrors is None:
            cursor_impl._batcherrors = []
        if self.error_info.num == TNS_ERR_NO_DATA_FOUND and self.in_fetch:
            self.error_info.num = 0
            cursor_impl._more_rows_to_fetch = False
            cursor_impl._last_row_index = 0
            cursor_impl._statement._requires_define = False
            self.error_occurred = False
        elif self.error_info.num == TNS_ERR_ARRAY_DML_ERRORS:
            self.error_info.num = 0
            self.error_occurred = False
        elif self.retry:
            self.retry = False
        elif cursor_impl._statement._is_query \
                and self.error_info.num in (TNS_ERR_VAR_NOT_IN_SELECT_LIST,
                                            TNS_ERR_INCONSISTENT_DATA_TYPES):
            self.retry = True
            conn_impl._statement_cache.clear_cursor(cursor_impl._statement)
        elif self.error_info.num != 0 and self.error_info.cursor_id != 0:
            if self.error_info.num not in errors.ERR_INTEGRITY_ERROR_CODES:
                conn_impl._statement_cache.clear_cursor(cursor_impl._statement)

    cdef int _process_implicit_result(self, ReadBuffer buf) except -1:
        cdef:
            BaseThinCursorImpl child_cursor_impl
            uint32_t i, num_results
            object child_cursor
            uint8_t num_bytes
        self.cursor_impl._implicit_resultsets = []
        buf.read_ub4(&num_results)
        for i in range(num_results):
            buf.read_ub1(&num_bytes)
            buf.skip_raw_bytes(num_bytes)
            child_cursor = self._create_cursor_from_describe(buf)
            child_cursor_impl = child_cursor._impl
            buf.read_ub2(&child_cursor_impl._statement._cursor_id)
            self.cursor_impl._implicit_resultsets.append(child_cursor)

    cdef int _process_io_vector(self, ReadBuffer buf) except -1:
        """
        An I/O vector is sent by the database in response to a PL/SQL execute.
        It indicates whether binds are IN only, IN/OUT or OUT only.
        """
        cdef:
            uint16_t i, num_bytes, temp16
            uint32_t temp32, num_binds
            BindInfo bind_info
        buf.skip_ub1()                      # flag
        buf.read_ub2(&temp16)               # num requests
        buf.read_ub4(&temp32)               # num iters
        num_binds = temp32 * 256 + temp16
        buf.skip_ub4()                      # num iters this time
        buf.skip_ub2()                      # uac buffer length
        buf.read_ub2(&num_bytes)            # bit vector for fast fetch
        if num_bytes > 0:
            buf.skip_raw_bytes(num_bytes)
        buf.read_ub2(&num_bytes)            # rowid
        if num_bytes > 0:
            buf.skip_raw_bytes(num_bytes)
        self.out_var_impls = []
        for i in range(num_binds):          # bind directions
            bind_info = self.cursor_impl._statement._bind_info_list[i]
            buf.read_ub1(&bind_info.bind_dir)
            if bind_info.bind_dir == TNS_BIND_DIR_INPUT:
                continue
            self.out_var_impls.append(bind_info._bind_var_impl)

    cdef int _process_message(self, ReadBuffer buf,
                              uint8_t message_type) except -1:
        if message_type == TNS_MSG_TYPE_ROW_HEADER:
            self._process_row_header(buf)
        elif message_type == TNS_MSG_TYPE_ROW_DATA:
            self._process_row_data(buf)
        elif message_type == TNS_MSG_TYPE_FLUSH_OUT_BINDS:
            self.flush_out_binds = True
            self.end_of_response = True
        elif message_type == TNS_MSG_TYPE_DESCRIBE_INFO:
            buf.skip_raw_bytes_chunked()
            self._process_describe_info(buf, self.cursor, self.cursor_impl)
            self.out_var_impls = self.cursor_impl.fetch_var_impls
        elif message_type == TNS_MSG_TYPE_ERROR:
            self._process_error_info(buf)
        elif message_type == TNS_MSG_TYPE_BIT_VECTOR:
            self._process_bit_vector(buf)
        elif message_type == TNS_MSG_TYPE_IO_VECTOR:
            self._process_io_vector(buf)
        elif message_type == TNS_MSG_TYPE_IMPLICIT_RESULTSET:
            self._process_implicit_result(buf)
        else:
            Message._process_message(self, buf, message_type)

    cdef int _process_return_parameters(self, ReadBuffer buf) except -1:
        cdef:
            uint16_t keyword_num, num_params, num_bytes
            uint32_t num_rows, i
            uint64_t rowcount
            bytes key_value
            list rowcounts
        buf.read_ub2(&num_params)           # al8o4l (ignored)
        for i in range(num_params):
            buf.skip_ub4()
        buf.read_ub2(&num_bytes)            # al8txl (ignored)
        if num_bytes > 0:
            buf.skip_raw_bytes(num_bytes)
        buf.read_ub2(&num_params)           # num key/value pairs
        for i in range(num_params):
            buf.read_ub2(&num_bytes)        # key
            if num_bytes > 0:
                key_value = buf.read_bytes()
            buf.read_ub2(&num_bytes)        # value
            if num_bytes > 0:
                buf.skip_raw_bytes_chunked()
            buf.read_ub2(&keyword_num)      # keyword num
            if keyword_num == TNS_KEYWORD_NUM_CURRENT_SCHEMA:
                self.conn_impl._current_schema = key_value.decode()
            elif keyword_num == TNS_KEYWORD_NUM_EDITION:
                self.conn_impl._edition = key_value.decode()
        buf.read_ub2(&num_bytes)            # registration
        if num_bytes > 0:
            buf.skip_raw_bytes(num_bytes)
        if self.arraydmlrowcounts:
            buf.read_ub4(&num_rows)
            rowcounts = self.cursor_impl._dmlrowcounts = []
            for i in range(num_rows):
                buf.read_ub8(&rowcount)
                rowcounts.append(rowcount)

    cdef int _process_row_data(self, ReadBuffer buf) except -1:
        cdef:
            uint32_t num_rows, pos
            ThinVarImpl var_impl
            ssize_t i, j
            object value
            list values
        for i, var_impl in enumerate(self.out_var_impls):
            if var_impl.is_array:
                buf.read_ub4(&var_impl.num_elements_in_array)
                for pos in range(var_impl.num_elements_in_array):
                    value = self._process_column_data(buf, var_impl, pos)
                    var_impl._values[pos] = value
            elif self.cursor_impl._statement._is_returning:
                buf.read_ub4(&num_rows)
                values = [None] * num_rows
                for j in range(num_rows):
                    values[j] = self._process_column_data(buf, var_impl, j)
                var_impl._values[self.row_index] = values
                var_impl._has_returned_data = True
            elif self.cursor_impl.fetching_arrow:
                if self._is_duplicate_data(i):
                    var_impl._arrow_array.append_last_value(
                        var_impl._last_arrow_array
                    )
                else:
                    self._process_column_data(buf, var_impl, self.row_index)
                var_impl._last_arrow_array = None
            elif self._is_duplicate_data(i):
                if self.row_index == 0 and var_impl.outconverter is not None:
                    value = var_impl._last_raw_value
                else:
                    value = var_impl._values[self.cursor_impl._last_row_index]
                var_impl._values[self.row_index] = value
            else:
                value = self._process_column_data(buf, var_impl,
                                                  self.row_index)
                var_impl._values[self.row_index] = value
        self.row_index += 1
        if self.in_fetch:
            self.cursor_impl._last_row_index = self.row_index - 1
            self.cursor_impl._buffer_rowcount = self.row_index
            self.bit_vector = NULL

    cdef int _process_row_header(self, ReadBuffer buf) except -1:
        cdef uint32_t num_bytes
        buf.skip_ub1()                      # flags
        buf.skip_ub2()                      # num requests
        buf.skip_ub4()                      # iteration number
        buf.skip_ub4()                      # num iters
        buf.skip_ub2()                      # buffer length
        buf.read_ub4(&num_bytes)
        if num_bytes > 0:
            buf.skip_ub1()                  # skip repeated length
            self._get_bit_vector(buf, num_bytes)
        buf.read_ub4(&num_bytes)
        if num_bytes > 0:
            buf.skip_raw_bytes_chunked()    # rxhrid

    cdef int _write_column_metadata(self, WriteBuffer buf,
                                    list bind_var_impls) except -1:
        cdef:
            uint32_t buffer_size, cont_flag, lob_prefetch_length
            ThinDbObjectTypeImpl typ_impl
            uint8_t ora_type_num, flag
            OracleMetadata metadata
            ThinVarImpl var_impl
        for var_impl in bind_var_impls:
            metadata = var_impl.metadata
            ora_type_num = metadata.dbtype._ora_type_num
            buffer_size = metadata.buffer_size
            if ora_type_num in (ORA_TYPE_NUM_ROWID, ORA_TYPE_NUM_UROWID):
                ora_type_num = ORA_TYPE_NUM_VARCHAR
                buffer_size = TNS_MAX_UROWID_LENGTH
            flag = TNS_BIND_USE_INDICATORS
            if var_impl.is_array:
                flag |= TNS_BIND_ARRAY
            cont_flag = 0
            lob_prefetch_length = 0
            if ora_type_num in (ORA_TYPE_NUM_BLOB,
                                ORA_TYPE_NUM_CLOB):
                cont_flag = TNS_LOB_PREFETCH_FLAG
            elif ora_type_num == ORA_TYPE_NUM_JSON:
                cont_flag = TNS_LOB_PREFETCH_FLAG
                buffer_size = lob_prefetch_length = TNS_JSON_MAX_LENGTH
            elif ora_type_num == ORA_TYPE_NUM_VECTOR:
                cont_flag = TNS_LOB_PREFETCH_FLAG
                buffer_size = lob_prefetch_length = TNS_VECTOR_MAX_LENGTH
            buf.write_uint8(ora_type_num)
            buf.write_uint8(flag)
            # precision and scale are always written as zero as the server
            # expects that and complains if any other value is sent!
            buf.write_uint8(0)
            buf.write_uint8(0)
            buf.write_ub4(buffer_size)
            if var_impl.is_array:
                buf.write_ub4(var_impl.num_elements)
            else:
                buf.write_ub4(0)            # max num elements
            buf.write_ub8(cont_flag)
            if metadata.objtype is not None:
                typ_impl = metadata.objtype
                buf.write_ub4(len(typ_impl.oid))
                buf.write_bytes_with_length(typ_impl.oid)
                buf.write_ub4(typ_impl.version)
            else:
                buf.write_ub4(0)            # OID
                buf.write_ub2(0)            # version
            if metadata.dbtype._csfrm != 0:
                buf.write_ub2(TNS_CHARSET_UTF8)
            else:
                buf.write_ub2(0)
            buf.write_uint8(metadata.dbtype._csfrm)
            buf.write_ub4(lob_prefetch_length)  # max chars (LOB prefetch)
            if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_12_2:
                buf.write_ub4(0)            # oaccolid

    cdef int _write_bind_params_column(self, WriteBuffer buf,
                                       OracleMetadata metadata,
                                       object value) except -1:
        cdef:
            uint8_t ora_type_num = metadata.dbtype._ora_type_num
            ThinDbObjectTypeImpl typ_impl
            BaseThinCursorImpl cursor_impl
            BaseThinLobImpl lob_impl
            uint32_t num_bytes
            bytes temp_bytes
        if value is None:
            if ora_type_num == ORA_TYPE_NUM_BOOLEAN:
                buf.write_uint8(TNS_ESCAPE_CHAR)
                buf.write_uint8(1)
            elif ora_type_num == ORA_TYPE_NUM_OBJECT:
                buf.write_ub4(0)                # TOID
                buf.write_ub4(0)                # OID
                buf.write_ub4(0)                # snapshot
                buf.write_ub2(0)                # version
                buf.write_ub4(0)                # packed data length
                buf.write_ub4(TNS_OBJ_TOP_LEVEL)    # flags
            else:
                buf.write_uint8(0)
        elif ora_type_num == ORA_TYPE_NUM_VARCHAR \
                or ora_type_num == ORA_TYPE_NUM_CHAR \
                or ora_type_num == ORA_TYPE_NUM_LONG:
            if metadata.dbtype._csfrm == CS_FORM_IMPLICIT:
                temp_bytes = (<str> value).encode()
            else:
                buf._caps._check_ncharset_id()
                temp_bytes = (<str> value).encode(ENCODING_UTF16)
            buf.write_bytes_with_length(temp_bytes)
        elif ora_type_num == ORA_TYPE_NUM_RAW \
                or ora_type_num == ORA_TYPE_NUM_LONG_RAW:
            buf.write_bytes_with_length(value)
        elif ora_type_num == ORA_TYPE_NUM_NUMBER \
                or ora_type_num == ORA_TYPE_NUM_BINARY_INTEGER:
            if isinstance(value, bool):
                temp_bytes = b'1' if value is True else b'0'
            else:
                temp_bytes = (<str> cpython.PyObject_Str(value)).encode()
            buf.write_oracle_number(temp_bytes)
        elif ora_type_num == ORA_TYPE_NUM_DATE \
                or ora_type_num == ORA_TYPE_NUM_TIMESTAMP \
                or ora_type_num == ORA_TYPE_NUM_TIMESTAMP_TZ \
                or ora_type_num == ORA_TYPE_NUM_TIMESTAMP_LTZ:
            buf.write_oracle_date(value, metadata.dbtype._buffer_size_factor)
        elif ora_type_num == ORA_TYPE_NUM_BINARY_DOUBLE:
            buf.write_binary_double(value)
        elif ora_type_num == ORA_TYPE_NUM_BINARY_FLOAT:
            buf.write_binary_float(value)
        elif ora_type_num == ORA_TYPE_NUM_CURSOR:
            cursor_impl = value._impl
            if cursor_impl is None:
                errors._raise_err(errors.ERR_CURSOR_NOT_OPEN)
            if cursor_impl._statement is None:
                cursor_impl._statement = self.conn_impl._get_statement()
            if cursor_impl._statement._cursor_id == 0:
                buf.write_uint8(1)
                buf.write_uint8(0)
            else:
                buf.write_ub4(1)
                buf.write_ub4(cursor_impl._statement._cursor_id)
            cursor_impl.statement = None
        elif ora_type_num == ORA_TYPE_NUM_BOOLEAN:
            buf.write_bool(value)
        elif ora_type_num == ORA_TYPE_NUM_INTERVAL_DS:
            buf.write_interval_ds(value)
        elif ora_type_num == ORA_TYPE_NUM_INTERVAL_YM:
            buf.write_interval_ym(value)
        elif ora_type_num in (
                ORA_TYPE_NUM_BLOB,
                ORA_TYPE_NUM_CLOB,
                ORA_TYPE_NUM_BFILE
            ):
            buf.write_lob_with_length(value._impl)
        elif ora_type_num in (ORA_TYPE_NUM_ROWID, ORA_TYPE_NUM_UROWID):
            temp_bytes = (<str> value).encode()
            buf.write_bytes_with_length(temp_bytes)
        elif ora_type_num == ORA_TYPE_NUM_OBJECT:
            buf.write_dbobject(value._impl)
        elif ora_type_num == ORA_TYPE_NUM_JSON:
            buf.write_oson(value, self.conn_impl._oson_max_fname_size)
        elif ora_type_num == ORA_TYPE_NUM_VECTOR:
            buf.write_vector(value)
        else:
            errors._raise_err(errors.ERR_DB_TYPE_NOT_SUPPORTED,
                              name=metadata.dbtype.name)

    cdef int _write_bind_params_row(self, WriteBuffer buf, list params,
                                    uint32_t pos) except -1:
        """
        Write a row of bind parameters. Note that non-LONG values are written
        first followed by any LONG values.
        """
        cdef:
            uint32_t i, num_elements, offset = self.offset
            bint found_long = False
            OracleMetadata metadata
            ThinVarImpl var_impl
            BindInfo bind_info
        for i, bind_info in enumerate(params):
            if bind_info._is_return_bind:
                continue
            var_impl = bind_info._bind_var_impl
            metadata = var_impl.metadata
            if var_impl.is_array:
                num_elements = var_impl.num_elements_in_array
                buf.write_ub4(num_elements)
                for value in var_impl._values[:num_elements]:
                    self._write_bind_params_column(buf, metadata, value)
            else:
                if not self.cursor_impl._statement._is_plsql \
                        and metadata.buffer_size > buf._caps.max_string_size:
                    found_long = True
                    continue
                self._write_bind_params_column(buf, metadata,
                                               var_impl._values[pos + offset])
        if found_long:
            for i, bind_info in enumerate(params):
                if bind_info._is_return_bind:
                    continue
                var_impl = bind_info._bind_var_impl
                metadata = var_impl.metadata
                if metadata.buffer_size <= buf._caps.max_string_size:
                    continue
                self._write_bind_params_column(buf, metadata,
                                               var_impl._values[pos + offset])

    cdef int postprocess(self) except -1:
        """
        Run any variable out converter functions on all non-null values that
        were returned in the current database response. This must be done
        independently since the out converter function may itself invoke a
        database round-trip.
        """
        cdef:
            uint32_t i, j, num_elements
            object value, element_value
            ThinVarImpl var_impl
        if self.out_var_impls is None:
            return 0
        for var_impl in self.out_var_impls:
            if var_impl is None or var_impl.outconverter is None:
                continue
            if not self.cursor_impl.fetching_arrow:
                var_impl._last_raw_value = \
                        var_impl._values[self.cursor_impl._last_row_index]
            if var_impl.is_array:
                num_elements = var_impl.num_elements_in_array
            else:
                num_elements = self.row_index
            for i in range(num_elements):
                value = var_impl._values[i]
                if value is None and not var_impl.convert_nulls:
                    continue
                if isinstance(value, list):
                    for j, element_value in enumerate(value):
                        if element_value is None:
                            continue
                        value[j] = var_impl.outconverter(element_value)
                else:
                    var_impl._values[i] = var_impl.outconverter(value)

    async def postprocess_async(self):
        """
        Run any variable out converter functions on all non-null values that
        were returned in the current database response. This must be done
        independently since the out converter function may itself invoke a
        database round-trip.
        """
        cdef:
            object value, element_value, fn
            uint32_t i, j, num_elements
            ThinVarImpl var_impl
        if self.out_var_impls is None:
            return 0
        for var_impl in self.out_var_impls:
            if var_impl is None or var_impl.outconverter is None:
                continue
            if not self.cursor_impl.fetching_arrow:
                var_impl._last_raw_value = \
                        var_impl._values[self.cursor_impl._last_row_index]
            if var_impl.is_array:
                num_elements = var_impl.num_elements_in_array
            else:
                num_elements = self.row_index
            fn = var_impl.outconverter
            for i in range(num_elements):
                value = var_impl._values[i]
                if value is None and not var_impl.convert_nulls:
                    continue
                if isinstance(value, list):
                    for j, element_value in enumerate(value):
                        if element_value is None:
                            continue
                        element_value = fn(element_value)
                        if inspect.isawaitable(element_value):
                            element_value = await element_value
                        value[j] = element_value
                else:
                    value = fn(value)
                    if inspect.isawaitable(value):
                        value = await value
                    var_impl._values[i] = value

    cdef int preprocess(self) except -1:
        cdef:
            Statement statement = self.cursor_impl._statement
            BindInfo bind_info
        if statement._is_returning and not self.parse_only:
            self.out_var_impls = []
            for bind_info in statement._bind_info_list:
                if not bind_info._is_return_bind:
                    continue
                self.out_var_impls.append(bind_info._bind_var_impl)
        elif statement._is_query:
            self._preprocess_query()


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\commit.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# commit.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for committing a transaction
# (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class CommitMessage(Message):

    cdef int _initialize_hook(self) except -1:
        """
        Perform initialization.
        """
        self.function_code = TNS_FUNC_COMMIT


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\connect.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# connect.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for the initial connection request
# (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class ConnectMessage(Message):
    cdef:
        bytes connect_string_bytes
        uint16_t connect_string_len, redirect_data_len
        bint read_redirect_data_len
        Description description
        uint8_t packet_flags
        str redirect_data
        str host
        int port

    cdef int process(self, ReadBuffer buf) except -1:
        cdef:
            uint16_t protocol_version, protocol_options
            const char_type *redirect_data
            uint32_t flags2 = 0
            uint8_t flags1
            bytes db_uuid
        if buf._current_packet.packet_type == TNS_PACKET_TYPE_REDIRECT:
            if not self.read_redirect_data_len:
                buf.read_uint16be(&self.redirect_data_len)
                self.read_redirect_data_len = True
            buf.wait_for_packets_sync()
            redirect_data = buf.read_raw_bytes(self.redirect_data_len)
            if self.redirect_data_len > 0:
                self.redirect_data = \
                        redirect_data[:self.redirect_data_len].decode()
            self.read_redirect_data_len = False
        elif buf._current_packet.packet_type == TNS_PACKET_TYPE_ACCEPT:
            buf.read_uint16be(&protocol_version)
            # check if the protocol version supported by the database is high
            # enough; if not, reject the connection immediately
            if protocol_version < TNS_VERSION_MIN_ACCEPTED:
                errors._raise_err(errors.ERR_SERVER_VERSION_NOT_SUPPORTED)
            buf.read_uint16be(&protocol_options)
            buf.skip_raw_bytes(10)
            buf.read_ub1(&flags1)
            if flags1 & TNS_NSI_NA_REQUIRED:
                feature = "Native Network Encryption and Data Integrity"
                errors._raise_not_supported(feature)
            buf.skip_raw_bytes(9)
            buf.read_uint32be(&buf._caps.sdu)
            if protocol_version >= TNS_VERSION_MIN_OOB_CHECK:
                buf.skip_raw_bytes(5)
                buf.read_uint32be(&flags2)
            buf._caps._adjust_for_protocol(protocol_version, protocol_options,
                                           flags2)
            buf._transport._full_packet_size = True
        elif buf._current_packet.packet_type == TNS_PACKET_TYPE_REFUSE:
            response = self.error_info.message
            error_code = "unknown"
            error_code_int = 0
            if response is not None:
                pos = response.find("(ERR=")
                if pos > 0:
                    end_pos = response.find(")", pos)
                    if end_pos > 0:
                        error_code = response[pos + 5:end_pos]
                        error_code_int = int(error_code)
            if error_code_int == 0:
                errors._raise_err(errors.ERR_UNEXPECTED_REFUSE)
            if error_code_int == TNS_ERR_INVALID_SERVICE_NAME:
                errors._raise_err(errors.ERR_INVALID_SERVICE_NAME,
                                  service_name=self.description.service_name,
                                  host=self.host, port=self.port)
            elif error_code_int == TNS_ERR_INVALID_SID:
                errors._raise_err(errors.ERR_INVALID_SID,
                                  sid=self.description.sid,
                                  host=self.host, port=self.port)
            errors._raise_err(errors.ERR_LISTENER_REFUSED_CONNECTION,
                              error_code=error_code)

    cdef int send(self, WriteBuffer buf) except -1:
        cdef:
            uint16_t service_options = TNS_GSO_DONT_CARE
            uint32_t connect_flags_1 = 0, connect_flags_2 = 0
            uint8_t nsi_flags = \
                    TNS_NSI_SUPPORT_SECURITY_RENEG | TNS_NSI_DISABLE_NA
        if buf._caps.supports_oob:
            service_options |= TNS_GSO_CAN_RECV_ATTENTION
            connect_flags_2 |= TNS_CHECK_OOB
        buf.start_request(TNS_PACKET_TYPE_CONNECT, self.packet_flags)
        buf.write_uint16be(TNS_VERSION_DESIRED)
        buf.write_uint16be(TNS_VERSION_MINIMUM)
        buf.write_uint16be(service_options)
        buf.write_uint16be(self.description.sdu)
        buf.write_uint16be(self.description.sdu)
        buf.write_uint16be(TNS_PROTOCOL_CHARACTERISTICS)
        buf.write_uint16be(0)               # line turnaround
        buf.write_uint16be(1)               # value of 1
        buf.write_uint16be(self.connect_string_len)
        buf.write_uint16be(74)              # offset to connect data
        buf.write_uint32be(0)               # max receivable data
        buf.write_uint8(nsi_flags)
        buf.write_uint8(nsi_flags)
        buf.write_uint64be(0)               # obsolete
        buf.write_uint64be(0)               # obsolete
        buf.write_uint64be(0)               # obsolete
        buf.write_uint32be(self.description.sdu)      # SDU (large)
        buf.write_uint32be(self.description.sdu)      # TDU (large)
        buf.write_uint32be(connect_flags_1)
        buf.write_uint32be(connect_flags_2)
        if self.connect_string_len > TNS_MAX_CONNECT_DATA:
            buf.end_request()
            buf.start_request(TNS_PACKET_TYPE_DATA)
        buf.write_bytes(self.connect_string_bytes)
        buf.end_request()


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\data_types.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2021, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# data_types.pyx
#
# Cython file defining the messages sent to the database and the responses that
# are received by the client for establishing data type formats (embedded in
# thin_impl.pyx).
#------------------------------------------------------------------------------

ctypedef struct DataType:
    uint16_t data_type
    uint16_t conv_data_type
    uint16_t representation


# data types not associated with actual data in the database
cdef enum:
    TNS_DATA_TYPE_FLOAT = 4
    TNS_DATA_TYPE_STR = 5
    TNS_DATA_TYPE_VNU = 6
    TNS_DATA_TYPE_PDN = 7
    TNS_DATA_TYPE_VCS = 9
    TNS_DATA_TYPE_TIDDEF = 10
    TNS_DATA_TYPE_VBI = 15
    TNS_DATA_TYPE_UB2 = 25
    TNS_DATA_TYPE_UB4 = 26
    TNS_DATA_TYPE_SB1 = 27
    TNS_DATA_TYPE_SB2 = 28
    TNS_DATA_TYPE_SB4 = 29
    TNS_DATA_TYPE_SWORD = 30
    TNS_DATA_TYPE_UWORD = 31
    TNS_DATA_TYPE_PTRB = 32
    TNS_DATA_TYPE_PTRW = 33
    TNS_DATA_TYPE_OER8 = 34 + 256
    TNS_DATA_TYPE_FUN = 35 + 256
    TNS_DATA_TYPE_AUA = 36 + 256
    TNS_DATA_TYPE_RXH7 = 37 + 256
    TNS_DATA_TYPE_NA6 = 38 + 256
    TNS_DATA_TYPE_OAC9 = 39
    TNS_DATA_TYPE_AMS = 40
    TNS_DATA_TYPE_BRN = 41
    TNS_DATA_TYPE_BRP = 42 + 256
    TNS_DATA_TYPE_BRV = 43 + 256
    TNS_DATA_TYPE_KVA = 44 + 256
    TNS_DATA_TYPE_CLS = 45 + 256
    TNS_DATA_TYPE_CUI = 46 + 256
    TNS_DATA_TYPE_DFN = 47 + 256
    TNS_DATA_TYPE_DQR = 48 + 256
    TNS_DATA_TYPE_DSC = 49 + 256
    TNS_DATA_TYPE_EXE = 50 + 256
    TNS_DATA_TYPE_FCH = 51 + 256
    TNS_DATA_TYPE_GBV = 52 + 256
    TNS_DATA_TYPE_GEM = 53 + 256
    TNS_DATA_TYPE_GIV = 54 + 256
    TNS_DATA_TYPE_OKG = 55 + 256
    TNS_DATA_TYPE_HMI = 56 + 256
    TNS_DATA_TYPE_INO = 57 + 256
    TNS_DATA_TYPE_LNF = 59 + 256
    TNS_DATA_TYPE_ONT = 60 + 256
    TNS_DATA_TYPE_OPE = 61 + 256
    TNS_DATA_TYPE_OSQ = 62 + 256
    TNS_DATA_TYPE_SFE = 63 + 256
    TNS_DATA_TYPE_SPF = 64 + 256
    TNS_DATA_TYPE_VSN = 65 + 256
    TNS_DATA_TYPE_UD7 = 66 + 256
    TNS_DATA_TYPE_DSA = 67 + 256
    TNS_DATA_TYPE_UIN = 68
    TNS_DATA_TYPE_PIN = 71 + 256
    TNS_DATA_TYPE_PFN = 72 + 256
    TNS_DATA_TYPE_PPT = 73 + 256
    TNS_DATA_TYPE_STO = 75 + 256
    TNS_DATA_TYPE_ARC = 77 + 256
    TNS_DATA_TYPE_MRS = 78 + 256
    TNS_DATA_TYPE_MRT = 79 + 256
    TNS_DATA_TYPE_MRG = 80 + 256
    TNS_DATA_TYPE_MRR = 81 + 256
    TNS_DATA_TYPE_MRC = 82 + 256
    TNS_DATA_TYPE_VER = 83 + 256
    TNS_DATA_TYPE_LON2 = 84 + 256
    TNS_DATA_TYPE_INO2 = 85 + 256
    TNS_DATA_TYPE_ALL = 86 + 256
    TNS_DATA_TYPE_UDB = 87 + 256
    TNS_DATA_TYPE_AQI = 88 + 256
    TNS_DATA_TYPE_ULB = 89 + 256
    TNS_DATA_TYPE_ULD = 90 + 256
    TNS_DATA_TYPE_SLS = 91
    TNS_DATA_TYPE_SID = 92 + 256
    TNS_DATA_TYPE_NA7 = 93 + 256
    TNS_DATA_TYPE_LVC = 94
    TNS_DATA_TYPE_LVB = 95
    TNS_DATA_TYPE_AVC = 97
    TNS_DATA_TYPE_AL7 = 98 + 256
    TNS_DATA_TYPE_K2RPC = 99 + 256
    TNS_DATA_TYPE_RDD = 104
    TNS_DATA_TYPE_XDP = 103 + 256
    TNS_DATA_TYPE_OSL = 106
    TNS_DATA_TYPE_OKO8 = 107 + 256
    TNS_DATA_TYPE_EXT_NAMED = 108
    TNS_DATA_TYPE_EXT_REF = 110
    TNS_DATA_TYPE_INT_REF = 111
    TNS_DATA_TYPE_CFILE = 115
    TNS_DATA_TYPE_RSET = 116
    TNS_DATA_TYPE_CWD = 117
    TNS_DATA_TYPE_OAC122 = 120
    TNS_DATA_TYPE_UD12 = 124 + 256
    TNS_DATA_TYPE_AL8 = 125 + 256
    TNS_DATA_TYPE_LFOP = 126 + 256
    TNS_DATA_TYPE_FCRT = 127 + 256
    TNS_DATA_TYPE_DNY = 128 + 256
    TNS_DATA_TYPE_OPR = 129 + 256
    TNS_DATA_TYPE_PLS = 130 + 256
    TNS_DATA_TYPE_XID = 131 + 256
    TNS_DATA_TYPE_TXN = 132 + 256
    TNS_DATA_TYPE_DCB = 133 + 256
    TNS_DATA_TYPE_CCA = 134 + 256
    TNS_DATA_TYPE_WRN = 135 + 256
    TNS_DATA_TYPE_TLH = 137 + 256
    TNS_DATA_TYPE_TOH = 138 + 256
    TNS_DATA_TYPE_FOI = 139 + 256
    TNS_DATA_TYPE_SID2 = 140 + 256
    TNS_DATA_TYPE_TCH = 141 + 256
    TNS_DATA_TYPE_PII = 142 + 256
    TNS_DATA_TYPE_PFI = 143 + 256
    TNS_DATA_TYPE_PPU = 144 + 256
    TNS_DATA_TYPE_PTE = 145 + 256
    TNS_DATA_TYPE_CLV = 146
    TNS_DATA_TYPE_RXH8 = 148 + 256
    TNS_DATA_TYPE_N12 = 149 + 256
    TNS_DATA_TYPE_AUTH = 150 + 256
    TNS_DATA_TYPE_KVAL = 151 + 256
    TNS_DATA_TYPE_DTR = 152
    TNS_DATA_TYPE_DUN = 153
    TNS_DATA_TYPE_DOP = 154
    TNS_DATA_TYPE_VST = 155
    TNS_DATA_TYPE_ODT = 156
    TNS_DATA_TYPE_FGI = 157 + 256
    TNS_DATA_TYPE_DSY = 158 + 256
    TNS_DATA_TYPE_DSYR8 = 159 + 256
    TNS_DATA_TYPE_DSYH8 = 160 + 256
    TNS_DATA_TYPE_DSYL = 161 + 256
    TNS_DATA_TYPE_DSYT8 = 162 + 256
    TNS_DATA_TYPE_DSYV8 = 163 + 256
    TNS_DATA_TYPE_DSYP = 164 + 256
    TNS_DATA_TYPE_DSYF = 165 + 256
    TNS_DATA_TYPE_DSYK = 166 + 256
    TNS_DATA_TYPE_DSYY = 167 + 256
    TNS_DATA_TYPE_DSYQ = 168 + 256
    TNS_DATA_TYPE_DSYC = 169 + 256
    TNS_DATA_TYPE_DSYA = 170 + 256
    TNS_DATA_TYPE_OT8 = 171 + 256
    TNS_DATA_TYPE_DOL = 172
    TNS_DATA_TYPE_DSYTY = 173 + 256
    TNS_DATA_TYPE_AQE = 174 + 256
    TNS_DATA_TYPE_KV = 175 + 256
    TNS_DATA_TYPE_AQD = 176 + 256
    TNS_DATA_TYPE_AQ8 = 177 + 256
    TNS_DATA_TYPE_TIME = 178
    TNS_DATA_TYPE_TIME_TZ = 179
    TNS_DATA_TYPE_EDATE = 184
    TNS_DATA_TYPE_ETIME = 185
    TNS_DATA_TYPE_ETTZ = 186
    TNS_DATA_TYPE_ESTAMP = 187
    TNS_DATA_TYPE_ESTZ = 188
    TNS_DATA_TYPE_EIYM = 189
    TNS_DATA_TYPE_EIDS = 190
    TNS_DATA_TYPE_RFS = 193 + 256
    TNS_DATA_TYPE_RXH10 = 194 + 256
    TNS_DATA_TYPE_DCLOB = 195
    TNS_DATA_TYPE_DBLOB = 196
    TNS_DATA_TYPE_DBFILE = 197
    TNS_DATA_TYPE_DJSON = 198
    TNS_DATA_TYPE_KPN = 198 + 256
    TNS_DATA_TYPE_KPDNR = 199 + 256
    TNS_DATA_TYPE_DSYD = 200 + 256
    TNS_DATA_TYPE_DSYS = 201 + 256
    TNS_DATA_TYPE_DSYR = 202 + 256
    TNS_DATA_TYPE_DSYH = 203 + 256
    TNS_DATA_TYPE_DSYT = 204 + 256
    TNS_DATA_TYPE_DSYV = 205 + 256
    TNS_DATA_TYPE_AQM = 206 + 256
    TNS_DATA_TYPE_OER11 = 207 + 256
    TNS_DATA_TYPE_AQL = 210 + 256
    TNS_DATA_TYPE_OTC = 211 + 256
    TNS_DATA_TYPE_KFNO = 212 + 256
    TNS_DATA_TYPE_KFNP = 213 + 256
    TNS_DATA_TYPE_KGT8 = 214 + 256
    TNS_DATA_TYPE_RASB4 = 215 + 256
    TNS_DATA_TYPE_RAUB2 = 216 + 256
    TNS_DATA_TYPE_RAUB1 = 217 + 256
    TNS_DATA_TYPE_RATXT = 218 + 256
    TNS_DATA_TYPE_RSSB4 = 219 + 256
    TNS_DATA_TYPE_RSUB2 = 220 + 256
    TNS_DATA_TYPE_RSUB1 = 221 + 256
    TNS_DATA_TYPE_RSTXT = 222 + 256
    TNS_DATA_TYPE_RIDL = 223 + 256
    TNS_DATA_TYPE_GLRDD = 224 + 256
    TNS_DATA_TYPE_GLRDG = 225 + 256
    TNS_DATA_TYPE_GLRDC = 226 + 256
    TNS_DATA_TYPE_OKO = 227 + 256
    TNS_DATA_TYPE_DPP = 228 + 256
    TNS_DATA_TYPE_DPLS = 229 + 256
    TNS_DATA_TYPE_DPMOP = 230 + 256
    TNS_DATA_TYPE_ESITZ = 232
    TNS_DATA_TYPE_UB8 = 233
    TNS_DATA_TYPE_STAT = 234 + 256
    TNS_DATA_TYPE_RFX = 235 + 256
    TNS_DATA_TYPE_FAL = 236 + 256
    TNS_DATA_TYPE_CKV = 237 + 256
    TNS_DATA_TYPE_DRCX = 238 + 256
    TNS_DATA_TYPE_KGH = 239 + 256
    TNS_DATA_TYPE_AQO = 240 + 256
    TNS_DATA_TYPE_PNTY = 241
    TNS_DATA_TYPE_OKGT = 242 + 256
    TNS_DATA_TYPE_KPFC = 243 + 256
    TNS_DATA_TYPE_FE2 = 244 + 256
    TNS_DATA_TYPE_SPFP = 245 + 256
    TNS_DATA_TYPE_DPULS = 246 + 256
    TNS_DATA_TYPE_AQA = 253 + 256
    TNS_DATA_TYPE_KPBF = 254 + 256
    TNS_DATA_TYPE_TSM = 513
    TNS_DATA_TYPE_MSS = 514
    TNS_DATA_TYPE_KPC = 516
    TNS_DATA_TYPE_CRS = 517
    TNS_DATA_TYPE_KKS = 518
    TNS_DATA_TYPE_KSP = 519
    TNS_DATA_TYPE_KSPTOP = 520
    TNS_DATA_TYPE_KSPVAL = 521
    TNS_DATA_TYPE_PSS = 522
    TNS_DATA_TYPE_NLS = 523
    TNS_DATA_TYPE_ALS = 524
    TNS_DATA_TYPE_KSDEVTVAL = 525
    TNS_DATA_TYPE_KSDEVTTOP = 526
    TNS_DATA_TYPE_KPSPP = 527
    TNS_DATA_TYPE_KOL = 528
    TNS_DATA_TYPE_LST = 529
    TNS_DATA_TYPE_ACX = 530
    TNS_DATA_TYPE_SCS = 531
    TNS_DATA_TYPE_RXH = 532
    TNS_DATA_TYPE_KPDNS = 533
    TNS_DATA_TYPE_KPDCN = 534
    TNS_DATA_TYPE_KPNNS = 535
    TNS_DATA_TYPE_KPNCN = 536
    TNS_DATA_TYPE_KPS = 537
    TNS_DATA_TYPE_APINF = 538
    TNS_DATA_TYPE_TEN = 539
    TNS_DATA_TYPE_XSSCS = 540
    TNS_DATA_TYPE_XSSSO = 541
    TNS_DATA_TYPE_XSSAO = 542
    TNS_DATA_TYPE_KSRPC = 543
    TNS_DATA_TYPE_KVL = 560
    TNS_DATA_TYPE_SESSGET = 563
    TNS_DATA_TYPE_SESSREL = 564
    TNS_DATA_TYPE_XSSDEF = 565
    TNS_DATA_TYPE_PDQCINV = 572
    TNS_DATA_TYPE_PDQIDC = 573
    TNS_DATA_TYPE_KPDQCSTA = 574
    TNS_DATA_TYPE_KPRS = 575
    TNS_DATA_TYPE_KPDQIDC = 576
    TNS_DATA_TYPE_RTSTRM = 578
    TNS_DATA_TYPE_SESSRET = 579
    TNS_DATA_TYPE_SCN6 = 580
    TNS_DATA_TYPE_KECPA = 581
    TNS_DATA_TYPE_KECPP = 582
    TNS_DATA_TYPE_SXA = 583
    TNS_DATA_TYPE_KVARR = 584
    TNS_DATA_TYPE_KPNGN = 585
    TNS_DATA_TYPE_XSNSOP = 590
    TNS_DATA_TYPE_XSATTR = 591
    TNS_DATA_TYPE_XSNS = 592
    TNS_DATA_TYPE_TXT = 593
    TNS_DATA_TYPE_XSSESSNS = 594
    TNS_DATA_TYPE_XSATTOP = 595
    TNS_DATA_TYPE_XSCREOP = 596
    TNS_DATA_TYPE_XSDETOP = 597
    TNS_DATA_TYPE_XSDESOP = 598
    TNS_DATA_TYPE_XSSETSP = 599
    TNS_DATA_TYPE_XSSIDP = 600
    TNS_DATA_TYPE_XSPRIN = 601
    TNS_DATA_TYPE_XSKVL = 602
    TNS_DATA_TYPE_XSSSDEF2 = 603
    TNS_DATA_TYPE_XSNSOP2 = 604
    TNS_DATA_TYPE_XSNS2 = 605
    TNS_DATA_TYPE_IMPLRES = 611
    TNS_DATA_TYPE_OER19 = 612
    TNS_DATA_TYPE_UB1ARRAY = 613
    TNS_DATA_TYPE_SESSSTATE = 614
    TNS_DATA_TYPE_AC_REPLAY = 615
    TNS_DATA_TYPE_AC_CONT = 616
    TNS_DATA_TYPE_KPDNREQ = 622
    TNS_DATA_TYPE_KPDNRNF = 623
    TNS_DATA_TYPE_KPNGNC = 624
    TNS_DATA_TYPE_KPNRI = 625
    TNS_DATA_TYPE_AQENQ = 626
    TNS_DATA_TYPE_AQDEQ = 627
    TNS_DATA_TYPE_AQJMS = 628
    TNS_DATA_TYPE_KPDNRPAY = 629
    TNS_DATA_TYPE_KPDNRACK = 630
    TNS_DATA_TYPE_KPDNRMP = 631
    TNS_DATA_TYPE_KPDNRDQ = 632
    TNS_DATA_TYPE_CHUNKINFO = 636
    TNS_DATA_TYPE_SCN = 637
    TNS_DATA_TYPE_SCN8 = 638
    TNS_DATA_TYPE_UD21 = 639
    TNS_DATA_TYPE_TNP = 640
    TNS_DATA_TYPE_OAC = 646
    TNS_DATA_TYPE_SESSSIGN = 647
    TNS_DATA_TYPE_OER = 652
    TNS_DATA_TYPE_PLEND = 660
    TNS_DATA_TYPE_PLBGN = 661
    TNS_DATA_TYPE_UDS = 663
    TNS_DATA_TYPE_PLOP = 665


# data type representations
cdef enum:
    TNS_TYPE_REP_NATIVE = 0
    TNS_TYPE_REP_UNIVERSAL = 1
    TNS_TYPE_REP_ORACLE = 10


cdef DataType[320] DATA_TYPES = [
    [ORA_TYPE_NUM_VARCHAR, ORA_TYPE_NUM_VARCHAR, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_NUMBER, ORA_TYPE_NUM_NUMBER, TNS_TYPE_REP_ORACLE],
    [ORA_TYPE_NUM_LONG, ORA_TYPE_NUM_LONG, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_DATE, ORA_TYPE_NUM_DATE, TNS_TYPE_REP_ORACLE],
    [ORA_TYPE_NUM_RAW, ORA_TYPE_NUM_RAW, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_LONG_RAW, ORA_TYPE_NUM_LONG_RAW, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_UB2, TNS_DATA_TYPE_UB2, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_UB4, TNS_DATA_TYPE_UB4, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SB1, TNS_DATA_TYPE_SB1, TNS_TYPE_REP_ORACLE],
    [TNS_DATA_TYPE_SB2, TNS_DATA_TYPE_SB2, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SB4, TNS_DATA_TYPE_SB4, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SWORD, TNS_DATA_TYPE_SWORD, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_UWORD, TNS_DATA_TYPE_UWORD, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PTRB, TNS_DATA_TYPE_PTRB, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PTRW, TNS_DATA_TYPE_PTRW, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_TIDDEF, TNS_DATA_TYPE_TIDDEF, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_ROWID, ORA_TYPE_NUM_ROWID, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AMS, TNS_DATA_TYPE_AMS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_BRN, TNS_DATA_TYPE_BRN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_CWD, TNS_DATA_TYPE_CWD, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OAC122, TNS_DATA_TYPE_OAC122, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OER8, TNS_DATA_TYPE_OER8, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_FUN, TNS_DATA_TYPE_FUN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AUA, TNS_DATA_TYPE_AUA, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RXH7, TNS_DATA_TYPE_RXH7, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_NA6, TNS_DATA_TYPE_NA6, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_BRP, TNS_DATA_TYPE_BRP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_BRV, TNS_DATA_TYPE_BRV, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KVA, TNS_DATA_TYPE_KVA, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_CLS, TNS_DATA_TYPE_CLS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_CUI, TNS_DATA_TYPE_CUI, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DFN, TNS_DATA_TYPE_DFN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DQR, TNS_DATA_TYPE_DQR, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSC, TNS_DATA_TYPE_DSC, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_EXE, TNS_DATA_TYPE_EXE, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_FCH, TNS_DATA_TYPE_FCH, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_GBV, TNS_DATA_TYPE_GBV, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_GEM, TNS_DATA_TYPE_GEM, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_GIV, TNS_DATA_TYPE_GIV, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OKG, TNS_DATA_TYPE_OKG, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_HMI, TNS_DATA_TYPE_HMI, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_INO, TNS_DATA_TYPE_INO, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_LNF, TNS_DATA_TYPE_LNF, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_ONT, TNS_DATA_TYPE_ONT, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OPE, TNS_DATA_TYPE_OPE, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OSQ, TNS_DATA_TYPE_OSQ, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SFE, TNS_DATA_TYPE_SFE, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SPF, TNS_DATA_TYPE_SPF, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_VSN, TNS_DATA_TYPE_VSN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_UD7, TNS_DATA_TYPE_UD7, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSA, TNS_DATA_TYPE_DSA, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PIN, TNS_DATA_TYPE_PIN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PFN, TNS_DATA_TYPE_PFN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PPT, TNS_DATA_TYPE_PPT, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_STO, TNS_DATA_TYPE_STO, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_ARC, TNS_DATA_TYPE_ARC, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_MRS, TNS_DATA_TYPE_MRS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_MRT, TNS_DATA_TYPE_MRT, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_MRG, TNS_DATA_TYPE_MRG, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_MRR, TNS_DATA_TYPE_MRR, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_MRC, TNS_DATA_TYPE_MRC, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_VER, TNS_DATA_TYPE_VER, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_LON2, TNS_DATA_TYPE_LON2, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_INO2, TNS_DATA_TYPE_INO2, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_ALL, TNS_DATA_TYPE_ALL, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_UDB, TNS_DATA_TYPE_UDB, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AQI, TNS_DATA_TYPE_AQI, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_ULB, TNS_DATA_TYPE_ULB, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_ULD, TNS_DATA_TYPE_ULD, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SID, TNS_DATA_TYPE_SID, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_NA7, TNS_DATA_TYPE_NA7, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AL7, TNS_DATA_TYPE_AL7, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_K2RPC, TNS_DATA_TYPE_K2RPC, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XDP, TNS_DATA_TYPE_XDP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OKO8, TNS_DATA_TYPE_OKO8, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_UD12, TNS_DATA_TYPE_UD12, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AL8, TNS_DATA_TYPE_AL8, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_LFOP, TNS_DATA_TYPE_LFOP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_FCRT, TNS_DATA_TYPE_FCRT, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DNY, TNS_DATA_TYPE_DNY, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OPR, TNS_DATA_TYPE_OPR, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PLS, TNS_DATA_TYPE_PLS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XID, TNS_DATA_TYPE_XID, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_TXN, TNS_DATA_TYPE_TXN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DCB, TNS_DATA_TYPE_DCB, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_CCA, TNS_DATA_TYPE_CCA, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_WRN, TNS_DATA_TYPE_WRN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_TLH, TNS_DATA_TYPE_TLH, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_TOH, TNS_DATA_TYPE_TOH, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_FOI, TNS_DATA_TYPE_FOI, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SID2, TNS_DATA_TYPE_SID2, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_TCH, TNS_DATA_TYPE_TCH, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PII, TNS_DATA_TYPE_PII, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PFI, TNS_DATA_TYPE_PFI, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PPU, TNS_DATA_TYPE_PPU, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PTE, TNS_DATA_TYPE_PTE, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RXH8, TNS_DATA_TYPE_RXH8, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_N12, TNS_DATA_TYPE_N12, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AUTH, TNS_DATA_TYPE_AUTH, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KVAL, TNS_DATA_TYPE_KVAL, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_FGI, TNS_DATA_TYPE_FGI, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSY, TNS_DATA_TYPE_DSY, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYR8, TNS_DATA_TYPE_DSYR8, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYH8, TNS_DATA_TYPE_DSYH8, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYL, TNS_DATA_TYPE_DSYL, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYT8, TNS_DATA_TYPE_DSYT8, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYV8, TNS_DATA_TYPE_DSYV8, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYP, TNS_DATA_TYPE_DSYP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYF, TNS_DATA_TYPE_DSYF, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYK, TNS_DATA_TYPE_DSYK, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYY, TNS_DATA_TYPE_DSYY, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYQ, TNS_DATA_TYPE_DSYQ, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYC, TNS_DATA_TYPE_DSYC, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYA, TNS_DATA_TYPE_DSYA, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OT8, TNS_DATA_TYPE_OT8, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYTY, TNS_DATA_TYPE_DSYTY, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AQE, TNS_DATA_TYPE_AQE, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KV, TNS_DATA_TYPE_KV, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AQD, TNS_DATA_TYPE_AQD, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AQ8, TNS_DATA_TYPE_AQ8, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RFS, TNS_DATA_TYPE_RFS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RXH10, TNS_DATA_TYPE_RXH10, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPN, TNS_DATA_TYPE_KPN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPDNR, TNS_DATA_TYPE_KPDNR, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYD, TNS_DATA_TYPE_DSYD, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYS, TNS_DATA_TYPE_DSYS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYR, TNS_DATA_TYPE_DSYR, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYH, TNS_DATA_TYPE_DSYH, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYT, TNS_DATA_TYPE_DSYT, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DSYV, TNS_DATA_TYPE_DSYV, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AQM, TNS_DATA_TYPE_AQM, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OER11, TNS_DATA_TYPE_OER11, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AQL, TNS_DATA_TYPE_AQL, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OTC, TNS_DATA_TYPE_OTC, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KFNO, TNS_DATA_TYPE_KFNO, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KFNP, TNS_DATA_TYPE_KFNP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KGT8, TNS_DATA_TYPE_KGT8, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RASB4, TNS_DATA_TYPE_RASB4, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RAUB2, TNS_DATA_TYPE_RAUB2, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RAUB1, TNS_DATA_TYPE_RAUB1, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RATXT, TNS_DATA_TYPE_RATXT, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RSSB4, TNS_DATA_TYPE_RSSB4, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RSUB2, TNS_DATA_TYPE_RSUB2, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RSUB1, TNS_DATA_TYPE_RSUB1, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RSTXT, TNS_DATA_TYPE_RSTXT, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RIDL, TNS_DATA_TYPE_RIDL, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_GLRDD, TNS_DATA_TYPE_GLRDD, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_GLRDG, TNS_DATA_TYPE_GLRDG, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_GLRDC, TNS_DATA_TYPE_GLRDC, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OKO, TNS_DATA_TYPE_OKO, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DPP, TNS_DATA_TYPE_DPP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DPLS, TNS_DATA_TYPE_DPLS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DPMOP, TNS_DATA_TYPE_DPMOP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_STAT, TNS_DATA_TYPE_STAT, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RFX, TNS_DATA_TYPE_RFX, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_FAL, TNS_DATA_TYPE_FAL, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_CKV, TNS_DATA_TYPE_CKV, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DRCX, TNS_DATA_TYPE_DRCX, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KGH, TNS_DATA_TYPE_KGH, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AQO, TNS_DATA_TYPE_AQO, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OKGT, TNS_DATA_TYPE_OKGT, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPFC, TNS_DATA_TYPE_KPFC, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_FE2, TNS_DATA_TYPE_FE2, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SPFP, TNS_DATA_TYPE_SPFP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DPULS, TNS_DATA_TYPE_DPULS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AQA, TNS_DATA_TYPE_AQA, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPBF, TNS_DATA_TYPE_KPBF, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_TSM, TNS_DATA_TYPE_TSM, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_MSS, TNS_DATA_TYPE_MSS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPC, TNS_DATA_TYPE_KPC, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_CRS, TNS_DATA_TYPE_CRS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KKS, TNS_DATA_TYPE_KKS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KSP, TNS_DATA_TYPE_KSP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KSPTOP, TNS_DATA_TYPE_KSPTOP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KSPVAL, TNS_DATA_TYPE_KSPVAL, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PSS, TNS_DATA_TYPE_PSS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_NLS, TNS_DATA_TYPE_NLS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_ALS, TNS_DATA_TYPE_ALS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KSDEVTVAL, TNS_DATA_TYPE_KSDEVTVAL, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KSDEVTTOP, TNS_DATA_TYPE_KSDEVTTOP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPSPP, TNS_DATA_TYPE_KPSPP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KOL, TNS_DATA_TYPE_KOL, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_LST, TNS_DATA_TYPE_LST, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_ACX, TNS_DATA_TYPE_ACX, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SCS, TNS_DATA_TYPE_SCS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RXH, TNS_DATA_TYPE_RXH, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPDNS, TNS_DATA_TYPE_KPDNS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPDCN, TNS_DATA_TYPE_KPDCN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPNNS, TNS_DATA_TYPE_KPNNS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPNCN, TNS_DATA_TYPE_KPNCN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPS, TNS_DATA_TYPE_KPS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_APINF, TNS_DATA_TYPE_APINF, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_TEN, TNS_DATA_TYPE_TEN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSSCS, TNS_DATA_TYPE_XSSCS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSSSO, TNS_DATA_TYPE_XSSSO, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSSAO, TNS_DATA_TYPE_XSSAO, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KSRPC, TNS_DATA_TYPE_KSRPC, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KVL, TNS_DATA_TYPE_KVL, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSSDEF, TNS_DATA_TYPE_XSSDEF, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PDQCINV, TNS_DATA_TYPE_PDQCINV, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PDQIDC, TNS_DATA_TYPE_PDQIDC, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPDQCSTA, TNS_DATA_TYPE_KPDQCSTA, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPRS, TNS_DATA_TYPE_KPRS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPDQIDC, TNS_DATA_TYPE_KPDQIDC, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RTSTRM, TNS_DATA_TYPE_RTSTRM, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SESSGET, TNS_DATA_TYPE_SESSGET, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SESSREL, TNS_DATA_TYPE_SESSREL, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SESSRET, TNS_DATA_TYPE_SESSRET, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SCN6, TNS_DATA_TYPE_SCN6, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KECPA, TNS_DATA_TYPE_KECPA, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KECPP, TNS_DATA_TYPE_KECPP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SXA, TNS_DATA_TYPE_SXA, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KVARR, TNS_DATA_TYPE_KVARR, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPNGN, TNS_DATA_TYPE_KPNGN, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_BINARY_INTEGER, ORA_TYPE_NUM_NUMBER, TNS_TYPE_REP_ORACLE],
    [TNS_DATA_TYPE_FLOAT, ORA_TYPE_NUM_NUMBER, TNS_TYPE_REP_ORACLE],
    [TNS_DATA_TYPE_STR, ORA_TYPE_NUM_VARCHAR, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_VNU, ORA_TYPE_NUM_NUMBER, TNS_TYPE_REP_ORACLE],
    [TNS_DATA_TYPE_PDN, ORA_TYPE_NUM_NUMBER, TNS_TYPE_REP_ORACLE],
    [TNS_DATA_TYPE_VCS, ORA_TYPE_NUM_VARCHAR, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_VBI, ORA_TYPE_NUM_VARCHAR, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OAC9, TNS_DATA_TYPE_OAC9, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_UIN, ORA_TYPE_NUM_NUMBER, TNS_TYPE_REP_ORACLE],
    [TNS_DATA_TYPE_SLS, ORA_TYPE_NUM_NUMBER, TNS_TYPE_REP_ORACLE],
    [TNS_DATA_TYPE_LVC, ORA_TYPE_NUM_VARCHAR, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_LVB, ORA_TYPE_NUM_RAW, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_CHAR, ORA_TYPE_NUM_CHAR, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AVC, ORA_TYPE_NUM_CHAR, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_BINARY_FLOAT, ORA_TYPE_NUM_BINARY_FLOAT,
            TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_BINARY_DOUBLE, ORA_TYPE_NUM_BINARY_DOUBLE,
            TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_CURSOR, ORA_TYPE_NUM_CURSOR, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RDD, ORA_TYPE_NUM_ROWID, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OSL, TNS_DATA_TYPE_OSL, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_EXT_NAMED, ORA_TYPE_NUM_OBJECT, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_OBJECT, ORA_TYPE_NUM_OBJECT, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_EXT_REF, TNS_DATA_TYPE_INT_REF, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_INT_REF, TNS_DATA_TYPE_INT_REF, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_CLOB, ORA_TYPE_NUM_CLOB, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_BLOB, ORA_TYPE_NUM_BLOB, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_BFILE, ORA_TYPE_NUM_BFILE, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_CFILE, TNS_DATA_TYPE_CFILE, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_RSET, ORA_TYPE_NUM_CURSOR, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_JSON, ORA_TYPE_NUM_JSON, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DJSON, TNS_DATA_TYPE_DJSON, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_CLV, TNS_DATA_TYPE_CLV, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DTR, ORA_TYPE_NUM_NUMBER, TNS_TYPE_REP_ORACLE],
    [TNS_DATA_TYPE_DUN, ORA_TYPE_NUM_NUMBER, TNS_TYPE_REP_ORACLE],
    [TNS_DATA_TYPE_DOP, ORA_TYPE_NUM_NUMBER, TNS_TYPE_REP_ORACLE],
    [TNS_DATA_TYPE_VST, ORA_TYPE_NUM_VARCHAR, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_ODT, ORA_TYPE_NUM_DATE, TNS_TYPE_REP_ORACLE],
    [TNS_DATA_TYPE_DOL, ORA_TYPE_NUM_NUMBER, TNS_TYPE_REP_ORACLE],
    [TNS_DATA_TYPE_TIME, TNS_DATA_TYPE_TIME, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_TIME_TZ, TNS_DATA_TYPE_TIME_TZ, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_TIMESTAMP, ORA_TYPE_NUM_TIMESTAMP, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_TIMESTAMP_TZ, ORA_TYPE_NUM_TIMESTAMP_TZ,
            TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_INTERVAL_YM, ORA_TYPE_NUM_INTERVAL_YM,
            TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_INTERVAL_DS, ORA_TYPE_NUM_INTERVAL_DS,
            TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_EDATE, ORA_TYPE_NUM_DATE, TNS_TYPE_REP_ORACLE],
    [TNS_DATA_TYPE_ETIME, TNS_DATA_TYPE_ETIME, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_ETTZ, TNS_DATA_TYPE_ETTZ, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_ESTAMP, TNS_DATA_TYPE_ESTAMP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_ESTZ, TNS_DATA_TYPE_ESTZ, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_EIYM, TNS_DATA_TYPE_EIYM, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_EIDS, TNS_DATA_TYPE_EIDS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DCLOB, ORA_TYPE_NUM_CLOB, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DBLOB, ORA_TYPE_NUM_BLOB, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_DBFILE, ORA_TYPE_NUM_BFILE, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_UROWID, ORA_TYPE_NUM_UROWID, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_TIMESTAMP_LTZ, ORA_TYPE_NUM_TIMESTAMP_LTZ,
            TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_ESITZ, ORA_TYPE_NUM_TIMESTAMP_LTZ, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_UB8, TNS_DATA_TYPE_UB8, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PNTY, ORA_TYPE_NUM_OBJECT, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_BOOLEAN, ORA_TYPE_NUM_BOOLEAN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSNSOP, TNS_DATA_TYPE_XSNSOP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSATTR, TNS_DATA_TYPE_XSATTR, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSNS, TNS_DATA_TYPE_XSNS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_UB1ARRAY, TNS_DATA_TYPE_UB1ARRAY, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SESSSTATE, TNS_DATA_TYPE_SESSSTATE, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AC_REPLAY, TNS_DATA_TYPE_AC_REPLAY, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AC_CONT, TNS_DATA_TYPE_AC_CONT, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_IMPLRES, TNS_DATA_TYPE_IMPLRES, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OER19, TNS_DATA_TYPE_OER19, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_TXT, TNS_DATA_TYPE_TXT, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSSESSNS, TNS_DATA_TYPE_XSSESSNS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSATTOP, TNS_DATA_TYPE_XSATTOP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSCREOP, TNS_DATA_TYPE_XSCREOP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSDETOP, TNS_DATA_TYPE_XSDETOP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSDESOP, TNS_DATA_TYPE_XSDESOP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSSETSP, TNS_DATA_TYPE_XSSETSP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSSIDP, TNS_DATA_TYPE_XSSIDP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSPRIN, TNS_DATA_TYPE_XSPRIN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSKVL, TNS_DATA_TYPE_XSKVL, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSSSDEF2, TNS_DATA_TYPE_XSSSDEF2, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSNSOP2, TNS_DATA_TYPE_XSNSOP2, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_XSNS2, TNS_DATA_TYPE_XSNS2, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPDNREQ, TNS_DATA_TYPE_KPDNREQ, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPDNRNF, TNS_DATA_TYPE_KPDNRNF, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPNGNC, TNS_DATA_TYPE_KPNGNC, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPNRI, TNS_DATA_TYPE_KPNRI, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AQENQ, TNS_DATA_TYPE_AQENQ, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AQDEQ, TNS_DATA_TYPE_AQDEQ, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_AQJMS, TNS_DATA_TYPE_AQJMS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPDNRPAY, TNS_DATA_TYPE_KPDNRPAY, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPDNRACK, TNS_DATA_TYPE_KPDNRACK, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPDNRMP, TNS_DATA_TYPE_KPDNRMP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_KPDNRDQ, TNS_DATA_TYPE_KPDNRDQ, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SCN, TNS_DATA_TYPE_SCN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SCN8, TNS_DATA_TYPE_SCN8, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_CHUNKINFO, TNS_DATA_TYPE_CHUNKINFO, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_UD21, TNS_DATA_TYPE_UD21, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_UDS, TNS_DATA_TYPE_UDS, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_TNP, TNS_DATA_TYPE_TNP, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OER, TNS_DATA_TYPE_OER, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_OAC, TNS_DATA_TYPE_OAC, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_SESSSIGN, TNS_DATA_TYPE_SESSSIGN, TNS_TYPE_REP_UNIVERSAL],
    [ORA_TYPE_NUM_VECTOR, ORA_TYPE_NUM_VECTOR, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PLEND, TNS_DATA_TYPE_PLEND, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PLBGN, TNS_DATA_TYPE_PLBGN, TNS_TYPE_REP_UNIVERSAL],
    [TNS_DATA_TYPE_PLOP, TNS_DATA_TYPE_PLOP, TNS_TYPE_REP_UNIVERSAL],
    [0, 0, 0]
]


@cython.final
cdef class DataTypesMessage(Message):

    cdef int _process_message(self, ReadBuffer buf,
                              uint8_t message_type) except -1:
        cdef uint16_t data_type, conv_data_type
        while True:
            buf.read_uint16be(&data_type)
            if data_type == 0:
                break
            buf.read_uint16be(&conv_data_type)
            if conv_data_type != 0:
                buf.skip_raw_bytes(4)
        if not buf._caps.supports_end_of_response:
            self.end_of_response = True

    cdef int _write_message(self, WriteBuffer buf) except -1:
        cdef:
            DataType* data_type
            int i

        # write character set and capabilities
        buf.write_uint8(TNS_MSG_TYPE_DATA_TYPES)
        buf.write_uint16le(TNS_CHARSET_UTF8)
        buf.write_uint16le(TNS_CHARSET_UTF8)
        buf.write_uint8(TNS_ENCODING_MULTI_BYTE | TNS_ENCODING_CONV_LENGTH)
        buf.write_bytes_with_length(bytes(buf._caps.compile_caps))
        buf.write_bytes_with_length(bytes(buf._caps.runtime_caps))

        # write data types
        i = 0
        while True:
            data_type = &DATA_TYPES[i]
            if data_type.data_type == 0:
                break
            i += 1
            buf.write_uint16be(data_type.data_type)
            buf.write_uint16be(data_type.conv_data_type)
            buf.write_uint16be(data_type.representation)
            buf.write_uint16be(0)
        buf.write_uint16be(0)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\end_pipeline.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# end_pipeline.pyx
#
# Cython file defining the messages sent to the database and the responses that
# are received by the client for ending a pipeline (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class EndPipelineMessage(Message):

    cdef int _initialize_hook(self) except -1:
        """
        Perform initialization.
        """
        self.function_code = TNS_FUNC_PIPELINE_END

    cdef int _write_message(self, WriteBuffer buf) except -1:
        """
        Write the message to the buffer.
        """
        self._write_function_code(buf)
        buf.write_ub4(0)                    # ID (unused)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\execute.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# execute.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for executing a SQL statement
# (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class ExecuteMessage(MessageWithData):
    cdef:
        uint32_t fetch_orientation
        uint32_t fetch_pos
        bint scroll_operation

    cdef int _write_execute_message(self, WriteBuffer buf) except -1:
        """
        Write the message for a full execute.
        """
        cdef:
            uint32_t options, exec_flags = 0, num_params = 0, num_iters = 1
            Statement stmt = self.cursor_impl._statement
            BaseThinCursorImpl cursor_impl = self.cursor_impl
            list params = stmt._bind_info_list

        # determine the options to use for the execute
        options = 0
        if not stmt._requires_define and not self.parse_only \
                and params is not None:
            num_params = <uint32_t> len(params)
        if stmt._requires_define:
            options |= TNS_EXEC_OPTION_DEFINE
        elif not self.parse_only and stmt._sql is not None:
            exec_flags |= TNS_EXEC_FLAGS_IMPLICIT_RESULTSET
            if not self.scroll_operation:
                options |= TNS_EXEC_OPTION_EXECUTE
        if cursor_impl.scrollable:
            exec_flags |= TNS_EXEC_FLAGS_SCROLLABLE
        if stmt._cursor_id == 0 or stmt._is_ddl:
            options |= TNS_EXEC_OPTION_PARSE
        if stmt._is_query:
            if self.parse_only:
                options |= TNS_EXEC_OPTION_DESCRIBE
            else:
                if stmt._cursor_id == 0 or stmt._requires_define:
                    num_iters = self.cursor_impl.prefetchrows
                else:
                    num_iters = self.cursor_impl.arraysize
                self.cursor_impl._set_fetch_array_size(num_iters)
                if num_iters > 0 and not stmt._no_prefetch:
                    options |= TNS_EXEC_OPTION_FETCH
        if not stmt._is_plsql and not self.parse_only:
            options |= TNS_EXEC_OPTION_NOT_PLSQL
        elif stmt._is_plsql and num_params > 0:
            options |= TNS_EXEC_OPTION_PLSQL_BIND
        if num_params > 0:
            options |= TNS_EXEC_OPTION_BIND
        if self.batcherrors:
            options |= TNS_EXEC_OPTION_BATCH_ERRORS
        if self.arraydmlrowcounts:
            exec_flags |= TNS_EXEC_FLAGS_DML_ROWCOUNTS
        if self.conn_impl.autocommit and not self.parse_only:
            options |= TNS_EXEC_OPTION_COMMIT

        # write body of message
        self._write_function_code(buf)
        buf.write_ub4(options)              # execute options
        buf.write_ub4(stmt._cursor_id)      # cursor id
        if stmt._cursor_id == 0 or stmt._is_ddl:
            buf.write_uint8(1)              # pointer (cursor id)
            buf.write_ub4(stmt._sql_length)
        else:
            buf.write_uint8(0)              # pointer (cursor id)
            buf.write_ub4(0)
        buf.write_uint8(1)                  # pointer (vector)
        buf.write_ub4(13)                   # al8i4 array length
        buf.write_uint8(0)                  # pointer (al8o4)
        buf.write_uint8(0)                  # pointer (al8o4l)
        buf.write_ub4(0)                    # prefetch buffer size
        buf.write_ub4(num_iters)            # prefetch number of rows
        buf.write_ub4(TNS_MAX_LONG_LENGTH)  # maximum long size
        if num_params == 0:
            buf.write_uint8(0)              # pointer (binds)
            buf.write_ub4(0)                # number of binds
        else:
            buf.write_uint8(1)              # pointer (binds)
            buf.write_ub4(num_params)       # number of binds
        buf.write_uint8(0)                  # pointer (al8app)
        buf.write_uint8(0)                  # pointer (al8txn)
        buf.write_uint8(0)                  # pointer (al8txl)
        buf.write_uint8(0)                  # pointer (al8kv)
        buf.write_uint8(0)                  # pointer (al8kvl)
        if stmt._requires_define:
            buf.write_uint8(1)              # pointer (al8doac)
            buf.write_ub4(len(self.cursor_impl.fetch_vars))
                                            # number of defines
        else:
            buf.write_uint8(0)
            buf.write_ub4(0)
        buf.write_ub4(0)                    # registration id
        buf.write_uint8(0)                  # pointer (al8objlist)
        buf.write_uint8(1)                  # pointer (al8objlen)
        buf.write_uint8(0)                  # pointer (al8blv)
        buf.write_ub4(0)                    # al8blvl
        buf.write_uint8(0)                  # pointer (al8dnam)
        buf.write_ub4(0)                    # al8dnaml
        buf.write_ub4(0)                    # al8regid_msb
        if self.arraydmlrowcounts:
            buf.write_uint8(1)              # pointer (al8pidmlrc)
            buf.write_ub4(self.num_execs)   # al8pidmlrcbl
            buf.write_uint8(1)              # pointer (al8pidmlrcl)
        else:
            buf.write_uint8(0)              # pointer (al8pidmlrc)
            buf.write_ub4(0)                # al8pidmlrcbl
            buf.write_uint8(0)              # pointer (al8pidmlrcl)
        if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_12_2:
            buf.write_uint8(0)                  # pointer (al8sqlsig)
            buf.write_ub4(0)                    # SQL signature length
            buf.write_uint8(0)                  # pointer (SQL ID)
            buf.write_ub4(0)                    # allocated size of SQL ID
            buf.write_uint8(0)                  # pointer (length of SQL ID)
            if buf._caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_12_2_EXT1:
                buf.write_uint8(0)              # pointer (chunk ids)
                buf.write_ub4(0)                # number of chunk ids
        if stmt._cursor_id == 0 or stmt._is_ddl:
            if stmt._sql_bytes is None:
                errors._raise_err(errors.ERR_INVALID_REF_CURSOR)
            buf.write_bytes_with_length(stmt._sql_bytes)
            buf.write_ub4(1)                # al8i4[0] parse
        else:
            buf.write_ub4(0)                # al8i4[0] parse
        if stmt._is_query:
            if stmt._cursor_id == 0:
                buf.write_ub4(0)            # al8i4[1] execution count
            else:
                buf.write_ub4(num_iters)
        else:
            buf.write_ub4(self.num_execs)   # al8i4[1] execution count
        buf.write_ub4(0)                    # al8i4[2]
        buf.write_ub4(0)                    # al8i4[3]
        buf.write_ub4(0)                    # al8i4[4]
        buf.write_ub4(0)                    # al8i4[5] SCN (part 1)
        buf.write_ub4(0)                    # al8i4[6] SCN (part 2)
        buf.write_ub4(stmt._is_query)       # al8i4[7] is query
        buf.write_ub4(0)                    # al8i4[8]
        buf.write_ub4(exec_flags)           # al8i4[9] execute flags
        buf.write_ub4(self.fetch_orientation) # al8i4[10] fetch orientation
        buf.write_ub4(self.fetch_pos)       # al8i4[11] fetch pos
        buf.write_ub4(0)                    # al8i4[12]
        if stmt._requires_define:
            self._write_column_metadata(buf, self.cursor_impl.fetch_var_impls)
        elif num_params > 0:
            self._write_bind_params(buf, params)

    cdef int _write_reexecute_message(self, WriteBuffer buf) except -1:
        """
        Write the message for a re-execute.
        """
        cdef:
            uint32_t i, options_1 = 0, options_2 = 0, num_iters
            Statement stmt = self.cursor_impl._statement
            list params = stmt._bind_info_list
            BindInfo info

        if params:
            if not stmt._is_query and not stmt._is_returning:
                self.out_var_impls = [info._bind_var_impl \
                                      for info in params \
                                      if info.bind_dir != TNS_BIND_DIR_INPUT]
            params = [info for info in params \
                      if info.bind_dir != TNS_BIND_DIR_OUTPUT \
                      and not info._is_return_bind]
        if self.function_code == TNS_FUNC_REEXECUTE_AND_FETCH:
            options_1 |= TNS_EXEC_OPTION_EXECUTE
            num_iters = self.cursor_impl.prefetchrows
            self.cursor_impl._set_fetch_array_size(num_iters)
        else:
            if self.conn_impl.autocommit:
                options_2 |= TNS_EXEC_OPTION_COMMIT_REEXECUTE
            num_iters = self.num_execs

        self._write_function_code(buf)
        buf.write_ub4(stmt._cursor_id)
        buf.write_ub4(num_iters)
        buf.write_ub4(options_1)
        buf.write_ub4(options_2)
        if params:
            for i in range(self.num_execs):
                buf.write_uint8(TNS_MSG_TYPE_ROW_DATA)
                self._write_bind_params_row(buf, params, i)

    cdef int _write_message(self, WriteBuffer buf) except -1:
        """
        Write the execute message to the buffer. Two types of execute messages
        are possible: one for a full execute and the second, simpler message,
        for when an existing cursor is being re-executed. A full execute is
        required under the following circumstances:
            - the statement has never been executed
            - the statement refers to a REF cursor (no sql is defined)
            - prefetch is not possible (LOB columns fetched)
            - bind metadata has changed
            - parse is being performed
            - define is being performed
            - DDL is being executed
            - batch errors mode is enabled
        """
        cdef:
            Statement stmt = self.cursor_impl._statement
        if stmt._cursor_id == 0 or not stmt._executed \
                or stmt._sql is None \
                or stmt._no_prefetch \
                or stmt._binds_changed \
                or self.parse_only \
                or stmt._requires_define \
                or stmt._is_ddl \
                or self.batcherrors \
                or self.cursor_impl.scrollable:
            self.function_code = TNS_FUNC_EXECUTE
            self._write_execute_message(buf)
        elif stmt._is_query and self.cursor_impl.prefetchrows > 0:
            self.function_code = TNS_FUNC_REEXECUTE_AND_FETCH
            self._write_reexecute_message(buf)
        else:
            self.function_code = TNS_FUNC_REEXECUTE
            self._write_reexecute_message(buf)
        stmt._binds_changed = False

    cdef int process(self, ReadBuffer buf) except -1:
        """
        Runs after the database response has been processed. If the statement
        executed requires define and is not a REF cursor (which would already
        have performed the define during its execute), then mark the message as
        needing to be resent. If this is after the second time the message has
        been sent, mark the statement as no longer needing a define (since this
        only needs to happen once).
        """
        cdef Statement stmt = self.cursor_impl._statement
        MessageWithData.process(self, buf)
        if self.error_occurred and self.error_info.pos == 0 and stmt._is_plsql:
            self.error_info.pos = self.error_info.rowcount + self.offset
        if not self.parse_only:
            stmt._executed = True
        if stmt._requires_define and stmt._sql is not None:
            if self.resend:
                stmt._requires_define = False
            else:
                self.resend = True


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\fast_auth.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# fast_auth.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for performing fast authentication
# to the database (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class FastAuthMessage(Message):
    cdef:
        DataTypesMessage data_types_message
        ProtocolMessage protocol_message
        AuthMessage auth_message

    cdef int _process_message(self, ReadBuffer buf,
                              uint8_t message_type) except -1:
        """
        Processes the messages returned from the server response.
        """
        if message_type == TNS_MSG_TYPE_PROTOCOL:
            ProtocolMessage._process_message(self.protocol_message, buf,
                                             message_type)
        elif message_type == TNS_MSG_TYPE_DATA_TYPES:
            DataTypesMessage._process_message(self.data_types_message, buf,
                                              message_type)
        else:
            AuthMessage._process_message(self.auth_message, buf, message_type)
            self.end_of_response = self.auth_message.end_of_response

    cdef int _write_message(self, WriteBuffer buf) except -1:
        """
        Writes the message to the buffer. This includes not just this message
        but also the protocol, data types and auth messages. This reduces the
        number of round-trips to the database and thereby increases
        performance.
        """
        buf.write_uint8(TNS_MSG_TYPE_FAST_AUTH)
        buf.write_uint8(1)                  # fast auth version
        buf.write_uint8(TNS_SERVER_CONVERTS_CHARS)  # flag 1
        buf.write_uint8(0)                  # flag 2
        ProtocolMessage._write_message(self.protocol_message, buf)
        buf.write_uint16be(0)               # server charset (unused)
        buf.write_uint8(0)                  # server charset flag (unused)
        buf.write_uint16be(0)               # server ncharset (unused)
        buf._caps.ttc_field_version = TNS_CCAP_FIELD_VERSION_19_1_EXT_1
        buf.write_uint8(buf._caps.ttc_field_version)
        DataTypesMessage._write_message(self.data_types_message, buf)
        AuthMessage._write_message(self.auth_message, buf)
        buf._caps.ttc_field_version = TNS_CCAP_FIELD_VERSION_MAX


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\fetch.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# fetch.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for fetching data (embedded in
# thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class FetchMessage(MessageWithData):

    cdef int _initialize_hook(self) except -1:
        """
        Perform initialization.
        """
        self.function_code = TNS_FUNC_FETCH

    cdef int _write_message(self, WriteBuffer buf) except -1:
        self.cursor_impl._set_fetch_array_size(self.cursor_impl.arraysize)
        self._write_function_code(buf)
        if self.cursor_impl._statement._cursor_id == 0:
            errors._raise_err(errors.ERR_CURSOR_HAS_BEEN_CLOSED)
        buf.write_ub4(self.cursor_impl._statement._cursor_id)
        buf.write_ub4(self.cursor_impl._fetch_array_size)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\lob_op.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# lob_op.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for performing LOB operations
# (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class LobOpMessage(Message):
    cdef:
        uint32_t operation
        BaseThinLobImpl source_lob_impl
        uint64_t source_offset
        uint64_t dest_offset
        uint32_t dest_length
        int64_t amount
        bint send_amount
        bint bool_flag
        object data

    cdef int _initialize_hook(self) except -1:
        """
        Perform initialization.
        """
        self.function_code = TNS_FUNC_LOB_OP

    cdef int _process_message(self, ReadBuffer buf,
                              uint8_t message_type) except -1:
        cdef:
            const char* encoding
            const char_type *ptr
            ssize_t num_bytes
        if message_type == TNS_MSG_TYPE_LOB_DATA:
            buf.read_raw_bytes_and_length(&ptr, &num_bytes)
            if self.source_lob_impl.dbtype._ora_type_num in \
                    (ORA_TYPE_NUM_BLOB, ORA_TYPE_NUM_BFILE):
                self.data = ptr[:num_bytes]
            else:
                encoding = self.source_lob_impl._get_encoding()
                self.data = ptr[:num_bytes].decode(encoding)
        else:
            Message._process_message(self, buf, message_type)

    cdef int _process_return_parameters(self, ReadBuffer buf) except -1:
        cdef:
            cdef const char_type *ptr
            ssize_t num_bytes
            uint8_t temp8
        if self.source_lob_impl is not None:
            num_bytes = len(self.source_lob_impl._locator)
            ptr = buf.read_raw_bytes(num_bytes)
            self.source_lob_impl._locator = ptr[:num_bytes]
        if self.operation == TNS_LOB_OP_CREATE_TEMP:
            buf.skip_ub2()                  # skip character set
            buf.skip_ub1()                  # skip trailing flags
        elif self.send_amount:
            buf.read_sb8(&self.amount)
        if self.operation in (TNS_LOB_OP_IS_OPEN,
                              TNS_LOB_OP_FILE_EXISTS,
                              TNS_LOB_OP_FILE_ISOPEN):
            buf.read_ub1(&temp8)
            self.bool_flag = temp8 > 0

    cdef int _write_message(self, WriteBuffer buf) except -1:
        cdef int i
        self._write_function_code(buf)
        if self.source_lob_impl is None:
            buf.write_uint8(0)              # source pointer
            buf.write_ub4(0)                # source length
        else:
            buf.write_uint8(1)              # source pointer
            buf.write_ub4(len(self.source_lob_impl._locator))
        buf.write_uint8(0)                  # dest pointer
        buf.write_ub4(self.dest_length)
        buf.write_ub4(0)                    # short source offset
        buf.write_ub4(0)                    # short dest offset
        if self.operation == TNS_LOB_OP_CREATE_TEMP:
            buf.write_uint8(1)              # pointer (character set)
        else:
            buf.write_uint8(0)              # pointer (character set)
        buf.write_uint8(0)                  # pointer (short amount)
        if self.operation in (TNS_LOB_OP_CREATE_TEMP,
                              TNS_LOB_OP_IS_OPEN,
                              TNS_LOB_OP_FILE_EXISTS,
                              TNS_LOB_OP_FILE_ISOPEN):
            buf.write_uint8(1)              # pointer (NULL LOB)
        else:
            buf.write_uint8(0)              # pointer (NULL LOB)
        buf.write_ub4(self.operation)
        buf.write_uint8(0)                  # pointer (SCN array)
        buf.write_uint8(0)                  # SCN array length
        buf.write_ub8(self.source_offset)
        buf.write_ub8(self.dest_offset)
        if self.send_amount:
            buf.write_uint8(1)              # pointer (amount)
        else:
            buf.write_uint8(0)              # pointer (amount)
        for i in range(3):                  # array LOB (not used)
            buf.write_uint16be(0)
        if self.source_lob_impl is not None:
            buf.write_bytes(self.source_lob_impl._locator)
        if self.operation == TNS_LOB_OP_CREATE_TEMP:
            if self.source_lob_impl.dbtype._csfrm == CS_FORM_NCHAR:
                buf._caps._check_ncharset_id()
                buf.write_ub4(TNS_CHARSET_UTF16)
            else:
                buf.write_ub4(TNS_CHARSET_UTF8)
        if self.data is not None:
            buf.write_uint8(TNS_MSG_TYPE_LOB_DATA)
            buf.write_bytes_with_length(self.data)
        if self.send_amount:
            buf.write_ub8(self.amount)      # LOB amount


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\logoff.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# logoff.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for logging off from the database
# (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class LogoffMessage(Message):

    cdef int _initialize_hook(self) except -1:
        """
        Perform initialization.
        """
        self.function_code = TNS_FUNC_LOGOFF


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\ping.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# ping.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for pinging the database
# (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class PingMessage(Message):

    cdef int _initialize_hook(self) except -1:
        """
        Perform initialization.
        """
        self.function_code = TNS_FUNC_PING


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\protocol.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# protocol.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for establishing the protoocl to
# use during the connection (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class ProtocolMessage(Message):
    cdef:
        uint8_t server_version
        uint8_t server_flags
        bytes server_compile_caps
        bytes server_runtime_caps
        bytes server_banner

    cdef int _write_message(self, WriteBuffer buf) except -1:
        buf.write_uint8(TNS_MSG_TYPE_PROTOCOL)
        buf.write_uint8(6)                  # protocol version (8.1 and higher)
        buf.write_uint8(0)                  # "array" terminator
        buf.write_str(DRIVER_NAME)
        buf.write_uint8(0)                  # NULL terminator

    cdef int _process_message(self, ReadBuffer buf,
                              uint8_t message_type) except -1:
        if message_type == TNS_MSG_TYPE_PROTOCOL:
            self._process_protocol_info(buf)
            if not buf._caps.supports_end_of_response:
                self.end_of_response = True
        else:
            Message._process_message(self, buf, message_type)

    cdef int _process_protocol_info(self, ReadBuffer buf) except -1:
        """
        Processes the response to the protocol request.
        """
        cdef:
            uint16_t num_elem, fdo_length
            Capabilities caps = buf._caps
            const char_type *fdo
            bytearray temp_array
            ssize_t ix
        buf.read_ub1(&self.server_version)
        buf.skip_ub1()                      # skip zero byte
        self.server_banner = buf.read_null_terminated_bytes()
        buf.read_uint16le(&caps.charset_id)
        buf.read_ub1(&self.server_flags)
        buf.read_uint16le(&num_elem)
        if num_elem > 0:                    # skip elements
            buf.skip_raw_bytes(num_elem * 5)
        buf.read_uint16be(&fdo_length)
        fdo = buf.read_raw_bytes(fdo_length)
        ix = 6 + fdo[5] + fdo[6]
        caps.ncharset_id = (fdo[ix + 3] << 8) + fdo[ix + 4]
        self.server_compile_caps = buf.read_bytes()
        if self.server_compile_caps is not None:
            temp_array = bytearray(self.server_compile_caps)
            caps._adjust_for_server_compile_caps(temp_array)
            if caps.ttc_field_version >= TNS_CCAP_FIELD_VERSION_23_1:
                self.conn_impl._oson_max_fname_size = 65535
        self.server_runtime_caps = buf.read_bytes()
        if self.server_runtime_caps is not None:
            temp_array = bytearray(self.server_runtime_caps)
            caps._adjust_for_server_runtime_caps(temp_array)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\rollback.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# rollback.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for rolling back a transaction
# (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class RollbackMessage(Message):

    cdef int _initialize_hook(self) except -1:
        """
        Perform initialization.
        """
        self.function_code = TNS_FUNC_ROLLBACK


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\session_release.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# session_release.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for releasing a session (embedded
# in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class SessionReleaseMessage(Message):

    cdef:
        uint32_t release_mode

    cdef int _initialize_hook(self) except -1:
        """
        Perform initialization.
        """
        self.message_type = TNS_MSG_TYPE_ONEWAY_FN
        self.function_code = TNS_FUNC_SESSION_RELEASE

    cdef int _write_message(self, WriteBuffer buf) except -1:
        """
        Write the message for a DRCP session release.
        """
        self._write_function_code(buf)
        buf.write_uint8(0)                  # pointer (tag name)
        buf.write_uint8(0)                  # tag name length
        buf.write_ub4(self.release_mode)    # mode


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\tpc_change_state.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# tpc_change_state.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for changing the state of a two
# phase commit (TPC) transaction (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

@cython.final
cdef class TransactionChangeStateMessage(Message):
    """
    Used for two-phase commit (TPC) transaction change state: commit, rollback,
    forget, etc.
    """
    cdef:
        uint32_t operation, state, flags
        bytes context
        object xid

    cdef int _initialize_hook(self) except -1:
        """
        Perform initialization.
        """
        self.function_code = TNS_FUNC_TPC_TXN_CHANGE_STATE

    cdef int _process_return_parameters(self, ReadBuffer buf) except -1:
        """
        Process the parameters returned by the database.
        """
        buf.read_ub4(&self.state)

    cdef int _write_message(self, WriteBuffer buf) except -1:
        """
        Writes the message to the database.
        """
        cdef:
            bytes global_transaction_id, branch_qualifier, xid_bytes
            uint32_t format_id = 0

        # acquire data to send to the server
        if self.xid is not None:
            format_id = self.xid[0]
            global_transaction_id = self.xid[1] \
                    if isinstance(self.xid[1], bytes) \
                    else self.xid[1].encode()
            branch_qualifier = self.xid[2] \
                    if isinstance(self.xid[2], bytes) \
                    else self.xid[2].encode()
            xid_bytes = global_transaction_id + branch_qualifier
            xid_bytes += bytes(128 - len(xid_bytes))

        self._write_function_code(buf)
        buf.write_ub4(self.operation)
        if self.context is not None:
            buf.write_uint8(1)              # pointer (context)
            buf.write_ub4(len(self.context))
        else:
            buf.write_uint8(0)              # pointer (context)
            buf.write_ub4(0)                # context length
        if self.xid is not None:
            buf.write_ub4(format_id)
            buf.write_ub4(len(global_transaction_id))
            buf.write_ub4(len(branch_qualifier))
            buf.write_uint8(1)              # pointer (xid)
            buf.write_ub4(len(xid_bytes))
        else:
            buf.write_ub4(0)                # format id
            buf.write_ub4(0)                # global transaction id length
            buf.write_ub4(0)                # branch qualifier length
            buf.write_uint8(0)              # pointer (xid)
            buf.write_ub4(0)                # XID length
        buf.write_ub4(0)                    # timeout
        buf.write_ub4(self.state)
        buf.write_uint8(1)                  # pointer (out state)
        buf.write_ub4(self.flags)
        if self.context is not None:
            buf.write_bytes(self.context)
        if self.xid is not None:
            buf.write_bytes(xid_bytes)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\messages\tpc_switch.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# tpc_switch.pyx
#
# Cython file defining the messages that are sent to the database and the
# responses that are received by the client for switching two phase commit
# (TPC) transactions (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------


@cython.final
cdef class TransactionSwitchMessage(Message):
    """
    Used for two-phase commit (TPC) transaction start, attach and detach.
    """
    cdef:
        uint32_t operation, flags, timeout, application_value
        bytes context
        object xid

    cdef int _initialize_hook(self) except -1:
        """
        Perform initialization.
        """
        self.function_code = TNS_FUNC_TPC_TXN_SWITCH

    cdef int _process_return_parameters(self, ReadBuffer buf) except -1:
        """
        Process the parameters returned by the database.
        """
        cdef:
            const char_type* ptr
            uint16_t context_len
        buf.read_ub4(&self.application_value)
        buf.read_ub2(&context_len)
        ptr = buf.read_raw_bytes(context_len)
        self.context = ptr[:context_len]

    cdef int _write_message(self, WriteBuffer buf) except -1:
        """
        Writes the message to the database.
        """
        cdef:
            bytes global_transaction_id, branch_qualifier, xid_bytes
            bytes internal_name = None, external_name = None
            uint32_t format_id = 0

        # acquire data to send to the server
        if self.xid is not None:
            format_id = self.xid[0]
            global_transaction_id = self.xid[1] \
                    if isinstance(self.xid[1], bytes) \
                    else self.xid[1].encode()
            branch_qualifier = self.xid[2] \
                    if isinstance(self.xid[2], bytes) \
                    else self.xid[2].encode()
            xid_bytes = global_transaction_id + branch_qualifier
            xid_bytes += bytes(128 - len(xid_bytes))
        if self.conn_impl._internal_name is not None:
            internal_name = self.conn_impl._internal_name.encode()
        if self.conn_impl._external_name is not None:
            external_name = self.conn_impl._external_name.encode()

        # write message
        self._write_function_code(buf)
        buf.write_ub4(self.operation)
        if self.context is not None:
            buf.write_uint8(1)              # pointer (transaction context)
            buf.write_ub4(len(self.context))
        else:
            buf.write_uint8(0)              # pointer (transaction context)
            buf.write_ub4(0)                # transaction context length
        if self.xid is not None:
            buf.write_ub4(format_id)
            buf.write_ub4(len(global_transaction_id))
            buf.write_ub4(len(branch_qualifier))
            buf.write_uint8(1)              # pointer (XID)
            buf.write_ub4(len(xid_bytes))
        else:
            buf.write_ub4(0)                # format id
            buf.write_ub4(0)                # global transaction id length
            buf.write_ub4(0)                # branch qualifier length
            buf.write_uint8(0)              # pointer (XID)
            buf.write_ub4(0)                # XID length
        buf.write_ub4(self.flags)
        buf.write_ub4(self.timeout)
        buf.write_uint8(1)                  # pointer (application value)
        buf.write_uint8(1)                  # pointer (return context)
        buf.write_uint8(1)                  # pointer (return context length)
        if internal_name is not None:
            buf.write_uint8(1)              # pointer (internal name)
            buf.write_ub4(len(internal_name))
        else:
            buf.write_uint8(0)              # pointer (internal name)
            buf.write_ub4(0)                # length of internal name
        if external_name is not None:
            external_name = self.conn_impl._external_name.encode()
            buf.write_uint8(1)              # pointer (external name)
            buf.write_ub4(len(external_name))
        else:
            buf.write_uint8(0)              # pointer (external name)
            buf.write_ub4(0)                # length of external name
        if self.context is not None:
            buf.write_bytes(self.context)
        if self.xid is not None:
            buf.write_bytes(xid_bytes)
        buf.write_ub4(self.application_value)
        if internal_name is not None:
            buf.write_bytes(internal_name)
        if external_name is not None:
            buf.write_bytes(external_name)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\packet.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# buffer.pyx
#
# Cython file defining the low-level network buffer read and write classes and
# methods for reading and writing low-level data from those buffers (embedded
# in thin_impl.pyx).
#------------------------------------------------------------------------------

cdef enum:
    PACKET_HEADER_SIZE = 8
    CHUNKED_BYTES_CHUNK_SIZE = 65536

cdef struct BytesChunk:
    char_type *ptr
    uint32_t length
    uint32_t allocated_length

cdef struct Rowid:
    uint32_t rba
    uint16_t partition_id
    uint32_t block_num
    uint16_t slot_num

@cython.final
@cython.freelist(20)
cdef class Packet:

    cdef:
        uint32_t packet_size
        uint8_t packet_type
        uint8_t packet_flags
        bytes buf

    cdef inline bint has_end_of_response(self):
        """
        Returns a boolean indicating if the end of request byte is found at the
        end of the packet.
        """
        cdef:
            uint16_t flags
            char *ptr
        ptr = cpython.PyBytes_AS_STRING(self.buf)
        flags = decode_uint16be(<const char_type*> &ptr[PACKET_HEADER_SIZE])
        if flags & TNS_DATA_FLAGS_END_OF_RESPONSE:
            return True
        if self.packet_size == PACKET_HEADER_SIZE + 3 \
                and ptr[PACKET_HEADER_SIZE + 2] == TNS_MSG_TYPE_END_OF_RESPONSE:
            return True
        return False


@cython.final
cdef class ChunkedBytesBuffer:

    cdef:
        uint32_t _num_chunks
        uint32_t _allocated_chunks
        BytesChunk *_chunks

    def __dealloc__(self):
        cdef uint32_t i
        for i in range(self._allocated_chunks):
            if self._chunks[i].ptr is not NULL:
                cpython.PyMem_Free(self._chunks[i].ptr)
                self._chunks[i].ptr = NULL
        if self._chunks is not NULL:
            cpython.PyMem_Free(self._chunks)
            self._chunks = NULL

    cdef int _allocate_chunks(self) except -1:
        """
        Allocates a new set of chunks and copies data from the original set of
        chunks if needed.
        """
        cdef:
            BytesChunk *chunks
            uint32_t allocated_chunks
        allocated_chunks = self._allocated_chunks + 8
        chunks = <BytesChunk*> \
                cpython.PyMem_Malloc(sizeof(BytesChunk) * allocated_chunks)
        memset(chunks, 0, sizeof(BytesChunk) * allocated_chunks)
        if self._num_chunks > 0:
            memcpy(chunks, self._chunks, sizeof(BytesChunk) * self._num_chunks)
            cpython.PyMem_Free(self._chunks)
        self._chunks = chunks
        self._allocated_chunks = allocated_chunks

    cdef BytesChunk* _get_chunk(self, uint32_t num_bytes) except NULL:
        """
        Return the chunk that can be used to write the number of bytes
        requested.
        """
        cdef:
            uint32_t num_allocated_bytes
            BytesChunk *chunk
        if self._num_chunks > 0:
            chunk = &self._chunks[self._num_chunks - 1]
            if chunk.allocated_length >= chunk.length + num_bytes:
                return chunk
        if self._num_chunks >= self._allocated_chunks:
            self._allocate_chunks()
        self._num_chunks += 1
        chunk = &self._chunks[self._num_chunks - 1]
        chunk.length = 0
        if chunk.allocated_length < num_bytes:
            num_allocated_bytes = self._get_chunk_size(num_bytes)
            if chunk.ptr:
                cpython.PyMem_Free(chunk.ptr)
            chunk.ptr = <char_type*> cpython.PyMem_Malloc(num_allocated_bytes)
            chunk.allocated_length = num_allocated_bytes
        return chunk

    cdef inline uint32_t _get_chunk_size(self, uint32_t size):
        """
        Returns the size to allocate aligned on a 64K boundary.
        """
        return (size + CHUNKED_BYTES_CHUNK_SIZE - 1) & \
               ~(CHUNKED_BYTES_CHUNK_SIZE - 1)

    cdef char_type* end_chunked_read(self) except NULL:
        """
        Called when a chunked read has ended. Since a chunked read is never
        started until at least some bytes are being read, it is assumed that at
        least one chunk is in use. If one chunk is in use, those bytes are
        returned directly, but if more than one chunk is in use, the first
        chunk is resized to include all of the bytes in a contiguous section of
        memory first.
        """
        cdef:
            uint32_t i, num_allocated_bytes, total_num_bytes = 0, pos = 0
            char_type *ptr
        if self._num_chunks > 1:
            for i in range(self._num_chunks):
                total_num_bytes += self._chunks[i].length
            num_allocated_bytes = self._get_chunk_size(total_num_bytes)
            ptr = <char_type*> cpython.PyMem_Malloc(num_allocated_bytes)
            for i in range(self._num_chunks):
                memcpy(&ptr[pos], self._chunks[i].ptr, self._chunks[i].length)
                pos += self._chunks[i].length
                cpython.PyMem_Free(self._chunks[i].ptr)
                self._chunks[i].ptr = NULL
                self._chunks[i].allocated_length = 0
                self._chunks[i].length = 0
            self._num_chunks = 1
            self._chunks[0].ptr = ptr
            self._chunks[0].length = total_num_bytes
            self._chunks[0].allocated_length = num_allocated_bytes
        return self._chunks[0].ptr

    cdef char_type* get_chunk_ptr(self, uint32_t size_required) except NULL:
        """
        Called when memory is required for a chunked read.
        """
        cdef:
            BytesChunk *chunk
            char_type *ptr
        chunk = self._get_chunk(size_required)
        ptr = &chunk.ptr[chunk.length]
        chunk.length += size_required
        return ptr

    cdef inline void start_chunked_read(self):
        """
        Called when a chunked read is started and simply indicates that no
        chunks are in use. The memory is retained in order to reduce the
        overhead in freeing and reallocating memory for each chunked read.
        """
        self._num_chunks = 0


@cython.final
cdef class ReadBuffer(Buffer):

    cdef:
        ssize_t _saved_packet_pos, _next_packet_pos, _saved_pos
        ChunkedBytesBuffer _chunked_bytes_buf
        const char_type _split_data[255]
        uint32_t _pending_error_num
        Packet _current_packet
        Transport _transport
        list _saved_packets
        Capabilities _caps
        bint _check_request_boundary
        bint _in_pipeline
        object _waiter
        object _loop

    def __cinit__(self, Transport transport, Capabilities caps):
        self._transport = transport
        self._caps = caps
        self._chunked_bytes_buf = ChunkedBytesBuffer()

    cdef int _check_connected(self):
        """
        Checks to see if the transport is connected and throws the appropriate
        exception if not.
        """
        if self._pending_error_num not in (
            0, TNS_ERR_SESSION_SHUTDOWN, TNS_ERR_INBAND_MESSAGE
        ):
            if self._transport is not None:
                self._transport.disconnect()
                self._transport = None
            if self._pending_error_num == TNS_ERR_EXCEEDED_IDLE_TIME:
                errors._raise_err(errors.ERR_EXCEEDED_IDLE_TIME)
            else:
                errors._raise_err(errors.ERR_UNSUPPORTED_INBAND_NOTIFICATION,
                                  err_num=self._pending_error_num)
        elif self._transport is None:
            errors._raise_err(errors.ERR_NOT_CONNECTED)

    cdef int _get_int_length_and_sign(self, uint8_t *length,
                                      bint *is_negative,
                                      uint8_t max_length) except -1:
        """
        Returns the length of an integer sent on the wire. A check is also made
        to ensure the integer does not exceed the maximum length. If the
        is_negative pointer is NULL, negative integers will result in an
        exception being raised.
        """
        cdef const char_type *ptr = self._get_raw(1)
        if ptr[0] & 0x80:
            if is_negative == NULL:
                errors._raise_err(errors.ERR_UNEXPECTED_NEGATIVE_INTEGER)
            is_negative[0] = True
            length[0] = ptr[0] & 0x7f
        else:
            if is_negative != NULL:
                is_negative[0] = False
            length[0] = ptr[0]
        if length[0] > max_length:
            errors._raise_err(errors.ERR_INTEGER_TOO_LARGE, length=length[0],
                              max_length=max_length)

    cdef const char_type* _get_raw(self, ssize_t num_bytes,
                                   bint in_chunked_read=False) except NULL:
        """
        Returns a pointer to a buffer containing the requested number of bytes.
        This may be split across multiple packets in which case a chunked bytes
        buffer is used.
        """
        cdef:
            ssize_t num_bytes_left, num_bytes_split, max_split_data
            const char_type *source_ptr
            char_type *dest_ptr

        # if no bytes are left in the buffer, a new packet needs to be fetched
        # before anything else can take place
        if self._pos == self._size:
            self.wait_for_packets_sync(check_marker=True)

        # if there is enough room in the buffer to satisfy the number of bytes
        # requested, return a pointer to the current location and advance the
        # offset the required number of bytes
        source_ptr = &self._data[self._pos]
        num_bytes_left = self._size - self._pos
        if num_bytes <= num_bytes_left:
            if in_chunked_read:
                dest_ptr = self._chunked_bytes_buf.get_chunk_ptr(num_bytes)
                memcpy(dest_ptr, source_ptr, num_bytes)
            self._pos += num_bytes
            return source_ptr

        # the requested bytes are split across multiple packets; if a chunked
        # read is in progress, a chunk is acquired that will accommodate the
        # remainder of the bytes in the current packet; otherwise, the split
        # buffer will be used instead (after first checking to see if there is
        # sufficient room available within it)
        if in_chunked_read:
            dest_ptr = self._chunked_bytes_buf.get_chunk_ptr(num_bytes_left)
        else:
            max_split_data = sizeof(self._split_data)
            if max_split_data < num_bytes:
                errors._raise_err(errors.ERR_BUFFER_LENGTH_INSUFFICIENT,
                                  actual_buffer_len=max_split_data,
                                  required_buffer_len=num_bytes)
            dest_ptr = <char_type*> self._split_data
        memcpy(dest_ptr, source_ptr, num_bytes_left)

        # acquire packets until the requested number of bytes is satisfied
        num_bytes -= num_bytes_left
        while num_bytes > 0:

            # advance to next packet
            self.wait_for_packets_sync(check_marker=True)

            # copy data into the chunked buffer or split buffer, as appropriate
            source_ptr = &self._data[self._pos]
            num_bytes_split = min(num_bytes, self._size - self._pos)
            if in_chunked_read:
                dest_ptr = \
                        self._chunked_bytes_buf.get_chunk_ptr(num_bytes_split)
            else:
                dest_ptr = <char_type*> &self._split_data[num_bytes_left]
            memcpy(dest_ptr, source_ptr, num_bytes_split)
            self._pos += num_bytes_split
            num_bytes -= num_bytes_split

        # return the split buffer unconditionally; if performing a chunked read
        # the return value is ignored anyway
        return self._split_data

    cdef int _process_control_packet(self, Packet packet) except -1:
        """
        Processes a control packet.
        """
        cdef:
            uint16_t control_type
            Buffer buf
        buf = Buffer.__new__(Buffer)
        buf._populate_from_bytes(packet.buf)
        buf.skip_raw_bytes(8)               # skip packet header
        buf.read_uint16be(&control_type)
        if control_type == TNS_CONTROL_TYPE_RESET_OOB:
            self._caps.supports_oob = False
        elif control_type == TNS_CONTROL_TYPE_INBAND_NOTIFICATION:
            buf.skip_raw_bytes(4)           # skip first integer
            buf.read_uint32be(&self._pending_error_num)

    cdef int _process_packet(self, Packet packet,
                             bint *notify_waiter,
                             bint check_connected) except -1:
        """
        Processes a packet. If the packet is a control packet it is processed
        immediately and discarded; if the packet is a marker packet and a
        pipeline is being processed, the packet is discarded; otherwise, it is
        added to the list of saved packets for this response. If the protocol
        supports sending the end of request notification we wait for that
        message type to be returned at the end of the packet.
        """
        if packet.packet_type == TNS_PACKET_TYPE_CONTROL:
            self._process_control_packet(packet)
            notify_waiter[0] = False
            if check_connected:
                self._check_connected()
        elif self._in_pipeline \
                and packet.packet_type == TNS_PACKET_TYPE_MARKER:
            notify_waiter[0] = False
        else:
            self._saved_packets.append(packet)
            notify_waiter[0] = \
                    packet.packet_type != TNS_PACKET_TYPE_DATA \
                    or not self._check_request_boundary \
                    or packet.has_end_of_response()

    cdef int _read_raw_bytes_and_length(self, const char_type **ptr,
                                        ssize_t *num_bytes) except -1:
        """
        Helper function that processes the length. If the length is defined as
        TNS_LONG_LENGTH_INDICATOR, a chunked read is performed.
        """
        cdef uint32_t temp_num_bytes
        if num_bytes[0] != TNS_LONG_LENGTH_INDICATOR:
            return Buffer._read_raw_bytes_and_length(self, ptr, num_bytes)
        self._chunked_bytes_buf.start_chunked_read()
        num_bytes[0] = 0
        while True:
            self.read_ub4(&temp_num_bytes)
            if temp_num_bytes == 0:
                break
            num_bytes[0] += temp_num_bytes
            self._get_raw(temp_num_bytes, in_chunked_read=True)
        ptr[0] = self._chunked_bytes_buf.end_chunked_read()

    cdef int _start_packet(self) except -1:
        """
        Starts a packet. This prepares the current packet for processing.
        """
        cdef uint16_t data_flags
        self._current_packet = self._saved_packets[self._next_packet_pos]
        self._next_packet_pos += 1
        self._populate_from_bytes(self._current_packet.buf)
        self._pos = PACKET_HEADER_SIZE
        if self._current_packet.packet_type == TNS_PACKET_TYPE_DATA:
            self.read_uint16be(&data_flags)
            if data_flags == TNS_DATA_FLAGS_EOF:
                self._pending_error_num = TNS_ERR_SESSION_SHUTDOWN

    async def discard_pipeline_responses(self, ssize_t num_responses):
        """
        Discards the specified number of responses after the pipeline has
        encountered an exception.
        """
        while num_responses > 0:
            if not self.has_response():
                await self.wait_for_response_async()
            while True:
                self._start_packet()
                if self._current_packet.has_end_of_response():
                    break
            num_responses -= 1
        self.reset_packets()

    cdef int notify_packet_received(self) except -1:
        """
        Notify the registered waiter that a packet has been received. This is
        only used by the asyncio implementation.
        """
        if self._waiter is not None:
            self._waiter.set_result(None)
            self._waiter = None

    cdef ThinDbObjectImpl read_dbobject(self, BaseDbObjectTypeImpl typ_impl):
        """
        Read a database object from the buffer and return a DbObject object
        containing it.
        it.
        """
        cdef:
            bytes oid = None, toid = None
            ThinDbObjectImpl obj_impl
            uint32_t num_bytes
        self.read_ub4(&num_bytes)
        if num_bytes > 0:                   # type OID
            toid = self.read_bytes()
        self.read_ub4(&num_bytes)
        if num_bytes > 0:                   # OID
            oid = self.read_bytes()
        self.read_ub4(&num_bytes)
        if num_bytes > 0:                   # snapshot
            self.read_bytes()
        self.skip_ub2()                     # version
        self.read_ub4(&num_bytes)           # length of data
        self.skip_ub2()                     # flags
        if num_bytes > 0:
            obj_impl = ThinDbObjectImpl.__new__(ThinDbObjectImpl)
            obj_impl.type = typ_impl
            obj_impl.toid = toid
            obj_impl.oid = oid
            obj_impl.packed_data = self.read_bytes()
            return obj_impl

    cdef object read_oson(self):
        """
        Read an OSON value from the buffer and return the converted value. OSON
        is sent as a LOB value with all of the data prefetched. Since the LOB
        locator is not required it is simply discarded.
        it.
        """
        cdef:
            OsonDecoder decoder
            uint32_t num_bytes
            bytes data
        self.read_ub4(&num_bytes)
        if num_bytes > 0:
            self.skip_ub8()             # size (unused)
            self.skip_ub4()             # chunk size (unused)
            data = self.read_bytes()
            self.read_bytes()           # LOB locator (unused)
            decoder = OsonDecoder.__new__(OsonDecoder)
            return decoder.decode(data)

    cdef object read_lob_with_length(self, BaseThinConnImpl conn_impl,
                                     DbType dbtype, object lob):
        """
        Read a LOB locator from the buffer and return a LOB object containing
        it.
        """
        cdef:
            uint32_t chunk_size, num_bytes
            BaseThinLobImpl lob_impl
            uint64_t size
            bytes locator
            type cls
        self.read_ub4(&num_bytes)
        if num_bytes > 0:
            if dbtype._ora_type_num == ORA_TYPE_NUM_BFILE:
                size = chunk_size = 0
            else:
                self.read_ub8(&size)
                self.read_ub4(&chunk_size)
            locator = self.read_bytes()
            if lob is None:
                lob_impl = conn_impl._create_lob_impl(dbtype, locator)
                cls = PY_TYPE_ASYNC_LOB \
                        if conn_impl._protocol._transport._is_async \
                        else PY_TYPE_LOB
                lob = cls._from_impl(lob_impl)
            else:
                lob_impl = lob._impl
                lob_impl._locator = locator
            lob_impl._size = size
            lob_impl._chunk_size = chunk_size
            lob_impl._has_metadata = \
                    dbtype._ora_type_num != ORA_TYPE_NUM_BFILE
            return lob

    cdef const char_type* read_raw_bytes(self, ssize_t num_bytes) except NULL:
        """
        Read the specified number of bytes from the packet and return them.
        """
        self._chunked_bytes_buf.start_chunked_read()
        self._get_raw(num_bytes, in_chunked_read=True)
        return self._chunked_bytes_buf.end_chunked_read()

    cdef int read_rowid(self, Rowid *rowid) except -1:
        """
        Reads a rowid from the buffer and populates the rowid structure.
        """
        self.read_ub4(&rowid.rba)
        self.read_ub2(&rowid.partition_id)
        self.skip_ub1()
        self.read_ub4(&rowid.block_num)
        self.read_ub2(&rowid.slot_num)

    cdef object read_urowid(self):
        """
        Read a universal rowid from the buffer and return the Python object
        representing its value.
        """
        cdef:
            ssize_t output_len, input_len, remainder, pos
            int input_offset = 1, output_offset = 0
            const char_type *input_ptr
            bytearray output_value
            uint32_t num_bytes
            uint8_t length
            Rowid rowid

        # get data (first buffer contains the length, which can be ignored)
        self.read_raw_bytes_and_length(&input_ptr, &input_len)
        if input_ptr == NULL:
            return None
        self.read_raw_bytes_and_length(&input_ptr, &input_len)

        # handle physical rowid
        if input_ptr[0] == 1:
            rowid.rba = decode_uint32be(&input_ptr[1])
            rowid.partition_id = decode_uint16be(&input_ptr[5])
            rowid.block_num = decode_uint32be(&input_ptr[7])
            rowid.slot_num = decode_uint16be(&input_ptr[11])
            return _encode_rowid(&rowid)

        # handle logical rowid
        output_len = (input_len // 3) * 4
        remainder = input_len % 3
        if remainder == 1:
            output_len += 1
        elif remainder == 2:
            output_len += 3
        output_value = bytearray(output_len)
        input_len -= 1
        output_value[0] = 42            # '*'
        output_offset += 1
        while input_len > 0:

            # produce first byte of quadruple
            pos = input_ptr[input_offset] >> 2
            output_value[output_offset] = TNS_BASE64_ALPHABET_ARRAY[pos]
            output_offset += 1

            # produce second byte of quadruple, but if only one byte is left,
            # produce that one byte and exit
            pos = (input_ptr[input_offset] & 0x3) << 4
            if input_len == 1:
                output_value[output_offset] = TNS_BASE64_ALPHABET_ARRAY[pos]
                break
            input_offset += 1
            pos |= ((input_ptr[input_offset] & 0xf0) >> 4)
            output_value[output_offset] = TNS_BASE64_ALPHABET_ARRAY[pos]
            output_offset += 1

            # produce third byte of quadruple, but if only two bytes are left,
            # produce that one byte and exit
            pos = (input_ptr[input_offset] & 0xf) << 2
            if input_len == 2:
                output_value[output_offset] = TNS_BASE64_ALPHABET_ARRAY[pos]
                break
            input_offset += 1
            pos |= ((input_ptr[input_offset] & 0xc0) >> 6)
            output_value[output_offset] = TNS_BASE64_ALPHABET_ARRAY[pos]
            output_offset += 1

            # produce final byte of quadruple
            pos = input_ptr[input_offset] & 0x3f
            output_value[output_offset] = TNS_BASE64_ALPHABET_ARRAY[pos]
            output_offset += 1
            input_offset += 1
            input_len -= 3

        return bytes(output_value).decode()

    cdef object read_vector(self):
        """
        Read a VECTOR value from the buffer and return the converted value.
        VECTOR is sent as a LOB value with all of the data prefetched. Since
        the LOB locator is not required it is simply discarded.
        it.
        """
        cdef:
            VectorDecoder decoder
            uint32_t num_bytes
            bytes data
        self.read_ub4(&num_bytes)
        if num_bytes > 0:
            self.skip_ub8()             # size (unused)
            self.skip_ub4()             # chunk size (unused)
            data = self.read_bytes()
            self.read_bytes()           # LOB locator (unused)
            if data:
                decoder = VectorDecoder.__new__(VectorDecoder)
                return decoder.decode(data)

    cdef object read_xmltype(self, BaseThinConnImpl conn_impl):
        """
        Reads an XMLType value from the buffer and returns the string value.
        The XMLType object is a special DbObjectType and is handled separately
        since the structure is a bit different.
        """
        cdef:
            DbObjectPickleBuffer buf
            uint32_t num_bytes
        self.read_ub4(&num_bytes)
        if num_bytes > 0:                   # type OID
            self.read_bytes()
        self.read_ub4(&num_bytes)
        if num_bytes > 0:                   # OID
            self.read_bytes()
        self.read_ub4(&num_bytes)
        if num_bytes > 0:                   # snapshot
            self.read_bytes()
        self.skip_ub2()                     # version
        self.read_ub4(&num_bytes)           # length of data
        self.skip_ub2()                     # flags
        if num_bytes > 0:
            buf = DbObjectPickleBuffer.__new__(DbObjectPickleBuffer)
            buf._populate_from_bytes(self.read_bytes())
            return buf.read_xmltype(conn_impl)

    cdef int check_control_packet(self) except -1:
        """
        Checks for a control packet or final close packet from the server.
        """
        cdef:
            bint notify_waiter
            Packet packet
        packet = self._transport.read_packet()
        self._process_packet(packet, &notify_waiter, False)
        if notify_waiter:
            self._start_packet()

    cdef bint has_response(self):
        """
        Returns a boolean indicating if the list of saved packets contains all
        of the packets for a response from the database. This method can only
        be called if support for the end of response bit is present.
        """
        cdef:
            Packet packet
            ssize_t i, max_pos
        for i in range(self._next_packet_pos, len(self._saved_packets)):
            packet = <Packet> self._saved_packets[i]
            if packet.has_end_of_response():
                return True
        return False

    cdef int reset_packets(self) except -1:
        """
        Resets the list of saved packets and the saved position (called when a
        request has been sent to the database and a response is expected).
        """
        self._saved_packets = []
        self._next_packet_pos = 0
        self._saved_packet_pos = 0
        self._saved_pos = 0

    cdef int restore_point(self) except -1:
        """
        Restores the position in the packets to the last saved point. This is
        needed by asyncio where an ansychronous wait for more packets is
        required so the processing of the response must be restarted at a known
        position.
        """
        if self._saved_packet_pos != self._next_packet_pos - 1:
            self._current_packet = self._saved_packets[self._saved_packet_pos]
            self._populate_from_bytes(self._current_packet.buf)
            self._next_packet_pos = self._saved_packet_pos + 1
        self._pos = self._saved_pos

    cdef int save_point(self) except -1:
        """
        Saves the current position in the packets. This is needed by asyncio
        where an asynchronous wait for more packets is required so the
        processing of the response must be restarted at a known position.
        """
        self._saved_packet_pos = self._next_packet_pos - 1
        self._saved_pos = self._pos

    cdef int skip_raw_bytes_chunked(self) except -1:
        """
        Skip a number of bytes that may or may not be chunked in the buffer.
        The first byte gives the length. If the length is
        TNS_LONG_LENGTH_INDICATOR, however, chunks are read and discarded.
        """
        cdef:
            uint32_t temp_num_bytes
            uint8_t length
        self.read_ub1(&length)
        if length != TNS_LONG_LENGTH_INDICATOR:
            self.skip_raw_bytes(length)
        else:
            while True:
                self.read_ub4(&temp_num_bytes)
                if temp_num_bytes == 0:
                    break
                self.skip_raw_bytes(temp_num_bytes)

    async def wait_for_packets_async(self):
        """
        Wait for packets to arrive in response to the request that was sent to
        the database (using asyncio).
        """
        if self._next_packet_pos >= len(self._saved_packets):
            self._waiter = self._loop.create_future()
            await self._waiter
        self._start_packet()

    cdef int wait_for_packets_sync(self, bint check_marker=False) except -1:
        """
        Wait for packets to arrive in response to the request that was sent to
        the database (synchronously). If no packets are available and we are
        using asyncio, raise an exception so that processing can be restarted
        once packets have arrived. If the check_marker flag is set and a marker
        is detected, throw an exception so that the protocol can process it
        accordingly. This is required because the server can send a marker
        packet in the middle of the data packets that form the response to the
        client's request.
        """
        cdef:
            bint notify_waiter
            Packet packet
        if self._next_packet_pos >= len(self._saved_packets):
            if self._transport._is_async:
                raise OutOfPackets()
            while True:
                packet = self._transport.read_packet()
                self._process_packet(packet, &notify_waiter, True)
                if notify_waiter:
                    break
        self._start_packet()
        if check_marker \
                and self._current_packet.packet_type == TNS_PACKET_TYPE_MARKER:
            raise MarkerDetected()

    async def wait_for_response_async(self):
        """
        Wait for packets to arrive in response to the request that was sent to
        the database (using asyncio). This method will not return until the
        complete response has been received. This requires the "end of
        response" capability available in Oracle Database 23ai and higher. This
        method also assumes that the current list of saved packets does not
        contain a full response.
        """
        try:
            self._check_request_boundary = True
            self._waiter = self._loop.create_future()
            await self._waiter
        finally:
            self._check_request_boundary = False


@cython.final
cdef class WriteBuffer(Buffer):

    cdef:
        uint8_t _packet_type
        uint8_t _packet_flags
        uint16_t _data_flags
        Capabilities _caps
        Transport _transport
        uint8_t _seq_num
        bint _packet_sent

    def __cinit__(self, Transport transport, Capabilities caps):
        self._transport = transport
        self._caps = caps
        self._size_for_sdu()

    cdef int _send_packet(self, bint final_packet) except -1:
        """
        Write the packet header and then send the packet. Once sent, reset the
        pointers back to an empty packet.
        """
        cdef ssize_t size = self._pos
        self._pos = 0
        if self._caps.protocol_version >= TNS_VERSION_MIN_LARGE_SDU:
            self.write_uint32be(size)
        else:
            self.write_uint16be(size)
            self.write_uint16be(0)
        self.write_uint8(self._packet_type)
        self.write_uint8(self._packet_flags)
        self.write_uint16be(0)
        if self._packet_type == TNS_PACKET_TYPE_DATA:
            self.write_uint16be(self._data_flags)
        self._pos = size
        self._transport.write_packet(self)
        self._packet_sent = True
        self._pos = PACKET_HEADER_SIZE
        if not final_packet and self._packet_type == TNS_PACKET_TYPE_DATA:
            self._pos += sizeof(uint16_t)   # allow space for data flags

    cdef int _size_for_sdu(self) except -1:
        """
        Resizes the buffer based on the SDU size of the capabilities.
        """
        self._initialize(self._caps.sdu)

    cdef int _write_more_data(self, ssize_t num_bytes_available,
                              ssize_t num_bytes_wanted) except -1:
        """
        Called when the amount of buffer available is less than the amount of
        data requested. This sends the packet to the server and then resets the
        buffer for further writing.
        """
        self._send_packet(final_packet=False)

    cdef int end_request(self) except -1:
        """
        Indicates that the request from the client is completing and will send
        any packet remaining, if necessary.
        """
        if self._pos > PACKET_HEADER_SIZE:
            self._send_packet(final_packet=True)

    cdef inline ssize_t max_payload_bytes(self):
        """
        Return the maximum number of bytes that can be sent in a packet. This
        is the maximum size of the entire packet, less the bytes in the header
        and 2 bytes for the data flags.
        """
        return self._max_size - PACKET_HEADER_SIZE - 2

    cdef void start_request(self, uint8_t packet_type, uint8_t packet_flags=0,
                            uint16_t data_flags=0):
        """
        Indicates that a request from the client is starting. The packet type
        is retained just in case a request spans multiple packets. The packet
        header (8 bytes in length) is written when a packet is actually being
        sent and so is skipped at this point.
        """
        self._packet_sent = False
        self._packet_type = packet_type
        self._packet_flags = packet_flags
        self._pos = PACKET_HEADER_SIZE
        if packet_type == TNS_PACKET_TYPE_DATA:
            self._data_flags = data_flags
            self._pos += sizeof(uint16_t)

    cdef object write_dbobject(self, ThinDbObjectImpl obj_impl):
        """
        Writes a database object to the buffer.
        """
        cdef:
            ThinDbObjectTypeImpl typ_impl = obj_impl.type
            uint32_t num_bytes
            bytes packed_data
        self.write_ub4(len(obj_impl.toid))
        self.write_bytes_with_length(obj_impl.toid)
        if obj_impl.oid is None:
            self.write_ub4(0)
        else:
            self.write_ub4(len(obj_impl.oid))
            self.write_bytes_with_length(obj_impl.oid)
        self.write_ub4(0)                   # snapshot
        self.write_ub4(0)                   # version
        packed_data = obj_impl._get_packed_data()
        self.write_ub4(len(packed_data))
        self.write_ub4(obj_impl.flags)      # flags
        self.write_bytes_with_length(packed_data)

    cdef int write_extension_values(self, str txt_value, bytes bytes_value,
                                    uint16_t keyword) except -1:
        """
        Writes extension's text value, binary value and keyword entry to the
        buffer.
        """
        cdef bytes txt_value_bytes
        if txt_value is None:
            self.write_uint8(0)
        else:
            txt_value_bytes = txt_value.encode()
            self.write_ub4(len(txt_value_bytes))
            self.write_bytes_with_length(txt_value_bytes)
        if bytes_value is None:
            self.write_uint8(0)
        else:
            self.write_ub4(len(bytes_value))
            self.write_bytes_with_length(bytes_value)
        self.write_ub2(keyword)

    cdef int write_lob_with_length(self, BaseThinLobImpl lob_impl) except -1:
        """
        Writes a LOB locator to the buffer.
        """
        self.write_ub4(len(lob_impl._locator))
        self.write_bytes_with_length(lob_impl._locator)

    cdef int write_qlocator(self, uint64_t data_length,
                            bint write_length=True) except -1:
        """
        Writes a QLocator. QLocators are always 40 bytes in length.
        """
        self.write_ub4(40)                  # QLocator length
        if write_length:
            self.write_uint8(40)            # chunk length
        self.write_uint16be(38)             # QLocator length less 2 bytes
        self.write_uint16be(TNS_LOB_QLOCATOR_VERSION)
        self.write_uint8(TNS_LOB_LOC_FLAGS_VALUE_BASED | \
                         TNS_LOB_LOC_FLAGS_BLOB | \
                         TNS_LOB_LOC_FLAGS_ABSTRACT)
        self.write_uint8(TNS_LOB_LOC_FLAGS_INIT)
        self.write_uint16be(0)              # additional flags
        self.write_uint16be(1)              # byt1
        self.write_uint64be(data_length)
        self.write_uint16be(0)              # unused
        self.write_uint16be(0)              # csid
        self.write_uint16be(0)              # unused
        self.write_uint64be(0)              # unused
        self.write_uint64be(0)              # unused

    cdef object write_oson(self, value, ssize_t max_fname_size,
                           bint write_length=True):
        """
        Encodes the given value to OSON and then writes that to the buffer.
        it.
        """
        cdef OsonEncoder encoder = OsonEncoder.__new__(OsonEncoder)
        encoder.encode(value, max_fname_size)
        self.write_qlocator(encoder._pos, write_length)
        self._write_raw_bytes_and_length(encoder._data, encoder._pos)

    cdef int write_seq_num(self) except -1:
        self._seq_num += 1
        if self._seq_num == 0:
            self._seq_num = 1
        self.write_uint8(self._seq_num)

    cdef object write_vector(self, value):
        """
        Encodes the given value to VECTOR and then writes that to the buffer.
        """
        cdef VectorEncoder encoder = VectorEncoder.__new__(VectorEncoder)
        encoder.encode(value)
        self.write_qlocator(encoder._pos)
        self._write_raw_bytes_and_length(encoder._data, encoder._pos)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\pool.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# pool.pyx
#
# Cython file defining the pool implementation class (embedded in
# thin_impl.pyx).
#------------------------------------------------------------------------------

cdef class BaseThinPoolImpl(BasePoolImpl):

    cdef:
        list _free_new_conn_impls
        list _free_used_conn_impls
        list _busy_conn_impls
        list _conn_impls_to_drop
        list _requests
        uint32_t _getmode
        uint32_t _stmt_cache_size
        uint32_t _timeout
        uint32_t _max_lifetime_session
        uint32_t _auth_mode
        uint32_t _open_count
        uint32_t _num_to_create
        int _ping_interval
        uint32_t _ping_timeout
        object _wait_timeout
        object _bg_task
        object _bg_task_condition
        object _condition
        object _timeout_task
        object _ssl_session
        bint _force_get
        bint _open

    def __init__(self, str dsn, PoolParamsImpl params):
        _check_cryptography()
        params._check_credentials()
        self.connect_params = params
        self.username = params.user
        self.dsn = dsn
        self.min = params.min
        self.max = params.max
        self.increment = params.increment
        self.homogeneous = params.homogeneous
        self.set_getmode(params.getmode)
        self.set_wait_timeout(params.wait_timeout)
        self.set_timeout(params.timeout)
        self._stmt_cache_size = params.stmtcachesize
        self._max_lifetime_session = params.max_lifetime_session
        self._ping_interval = params.ping_interval
        self._ping_timeout = params.ping_timeout
        self._free_new_conn_impls = []
        self._free_used_conn_impls = []
        self._busy_conn_impls = []
        self._conn_impls_to_drop = []
        self._requests = []
        self._num_to_create = self.min
        self._auth_mode = AUTH_MODE_DEFAULT
        self._open = True

    cdef int _add_request(self, PooledConnRequest request) except -1:
        """
        Adds a request for the background task to process.
        """
        request.bg_processing = True
        request.completed = False
        self._requests.append(request)
        self._notify_bg_task()

    cdef int _check_timeout(self) except -1:
        """
        Checks whether a timeout is in effect and that the number of
        connections exceeds the minimum and if so, starts a timer to check
        if these connections have expired. Only one task is ever started.
        The timeout value is increased by a second to allow for small time
        discrepancies.
        """
        if self._open and self._timeout_task is None and self._timeout > 0 \
                and self._open_count > self.min:
            self._start_timeout_task()

    cdef int _close_helper(self, bint force) except -1:
        """
        Helper function that closes all of the connections in the pool.
        """
        cdef BaseThinConnImpl conn_impl

        # if force parameter is not True and busy connections exist in the
        # pool or there are outstanding requests, raise an exception
        if not force and (self.get_busy_count() > 0 or self._requests):
            errors._raise_err(errors.ERR_POOL_HAS_BUSY_CONNECTIONS)

        # close all connections in the pool; this is done by simply adding
        # to the list of connections that require closing and then notifying
        # the background task to perform the work
        self._open = False
        for lst in (self._free_used_conn_impls,
                    self._free_new_conn_impls,
                    self._busy_conn_impls):
            self._conn_impls_to_drop.extend(lst)
            for conn_impl in lst:
                conn_impl._pool = None
            lst.clear()
        self._notify_bg_task()

    cdef PooledConnRequest _create_request(self, ConnectParamsImpl params):
        """
        Returns a poooled connection request suitable for establishing a
        connection to the pool with the given parameters.
        """
        cdef:
            ConnectParamsImpl creation_params = self.connect_params
            str pool_cclass = creation_params._default_description.cclass
            PooledConnRequest request
        request = PooledConnRequest.__new__(PooledConnRequest)
        request.pool_impl = self
        request.params = params
        request.cclass = params._default_description.cclass
        request.wants_new = (params._default_description.purity == PURITY_NEW)
        request.cclass_matches = \
                (request.cclass is None or request.cclass == pool_cclass)
        request.waiting = True
        return request

    cdef int _drop_conn_impl(self, BaseThinConnImpl conn_impl) except -1:
        """
        Helper method which adds a connection to the list of connections to be
        closed and notifies the background task.
        """
        conn_impl._pool = None
        if conn_impl._protocol._transport is not None:
            self._conn_impls_to_drop.append(conn_impl)
            self._notify_bg_task()
        self._ensure_min_connections()

    cdef int _drop_conn_impls_helper(self, list conn_impls_to_drop) except -1:
        """
        Helper method which drops the requested list of connections. Exceptions
        that take place while attempting to close the connection are ignored.
        """
        cdef BaseThinConnImpl conn_impl
        for conn_impl in conn_impls_to_drop:
            try:
                conn_impl._force_close()
            except:
                pass

    cdef int _ensure_min_connections(self) except -1:
        """
        Ensure that the minimum number of connections in the pool is
        maintained.
        """
        if self._open_count < self.min:
            self._num_to_create = max(self._num_to_create,
                                      self.min - self._open_count)
            self._notify_bg_task()

    cdef PooledConnRequest _get_next_request(self):
        """
        Get the next request to process.
        """
        cdef PooledConnRequest request
        for request in self._requests:
            if not request.waiting \
                    or request.requires_ping \
                    or request.is_replacing \
                    or request.is_extra \
                    or self._open_count < self.max:
                request.in_progress = request.waiting
                return request
            break

    cdef BaseThinConnImpl _post_acquire(self, BaseThinConnImpl conn_impl):
        """
        Called after an acquire has succeeded. The connection is added to the
        list of busy connections and is marked as being in a request.
        """
        self._busy_conn_impls.append(conn_impl)
        if conn_impl._protocol._caps.supports_request_boundaries:
            conn_impl._session_state_desired = TNS_SESSION_STATE_REQUEST_BEGIN
            conn_impl._in_request = True
        return conn_impl

    cdef int _post_create_conn_impl(self,
                                    BaseThinConnImpl conn_impl) except -1:
        """
        Called after a connection has been created without an associated
        request.
        """
        cdef PooledConnRequest request
        if conn_impl is None:
            self._num_to_create = 0
        elif not self._open:
            conn_impl._force_close()
        else:
            self._open_count += 1
            if self._num_to_create > 0:
                self._num_to_create -= 1
            for request in self._requests:
                if request.in_progress or request.conn_impl is not None \
                        or not request.waiting:
                    continue
                if request.cclass is None \
                        or request.cclass == conn_impl._cclass:
                    request.conn_impl = conn_impl
                    request.completed = True
                    self._requests.remove(request)
                    self._condition.notify_all()
                    break
                elif not request.cclass_matches \
                        and self._open_count >= self.max:
                    request.conn_impl = conn_impl
                    request.is_replacing = True
                    break
            else:
                self._free_new_conn_impls.append(conn_impl)
            self._check_timeout()

    cdef int _post_process_request(self, PooledConnRequest request) except -1:
        """
        Called after the request has been processed. This removes the request
        from the list of requests and adds the connection to the appropriate
        list depending on whether the waiter is still waiting for the request
        to be satisfied!
        """
        request.in_progress = False
        request.bg_processing = False
        if request.conn_impl is not None:
            request.completed = True
            if not request.is_replacing and not request.requires_ping:
                self._open_count += 1
                if self._num_to_create > 0:
                    self._num_to_create -= 1
            if not request.waiting:
                request.reject()
        elif request.requires_ping:
            self._open_count -= 1
            if self._num_to_create == 0 and self._open_count < self.min:
                self._num_to_create = self.min - self._open_count
        self._requests.remove(request)
        self._condition.notify_all()

    cdef int _pre_connect(self, BaseThinConnImpl conn_impl,
                          ConnectParamsImpl params) except -1:
        """
        Called before the connection is connected. The connection class and
        pool attributes are updated and the TLS session is stored on the
        transport for reuse. The timestamps are also retained for later use.
        """
        if params is not None:
            conn_impl._cclass = params._default_description.cclass
        else:
            conn_impl._cclass = self.connect_params._default_description.cclass
        conn_impl._pool = self
        conn_impl._time_created = time.monotonic()
        conn_impl._time_returned = conn_impl._time_created

    def _process_timeout(self):
        """
        Processes the timeout after the timer task completes. Drops any free
        connections that have expired (while maintaining the minimum number of
        connections in the pool).
        """
        self._timeout_task = None
        self._timeout_helper(self._free_new_conn_impls)
        self._timeout_helper(self._free_used_conn_impls)
        self._check_timeout()

    cdef int _return_connection_helper(self,
                                       BaseThinConnImpl conn_impl) except -1:
        """
        Returns the connection to the pool. If the connection was closed for
        some reason it will be dropped; otherwise, it will be returned to the
        list of connections available for further use. If an "extra" connection
        was created (because the pool has a mode of "force" get or because a
        different connection class than that used by the pool was requested)
        then it will be added to the pool or will replace an unused new
        connection or will be discarded depending on the current pool size.
        """
        cdef:
            bint is_open = conn_impl._protocol._transport is not None
            BaseThinDbObjectTypeCache type_cache
            PooledConnRequest request
            double tstamp
            int cache_num
        self._busy_conn_impls.remove(conn_impl)
        if conn_impl._dbobject_type_cache_num > 0:
            cache_num = conn_impl._dbobject_type_cache_num
            type_cache = get_dbobject_type_cache(cache_num)
            type_cache._clear_cursors()
        if not is_open:
            self._open_count -= 1
            self._ensure_min_connections()
        if conn_impl._is_pool_extra:
            conn_impl._is_pool_extra = False
            if is_open and self._open_count >= self.max:
                if self._free_new_conn_impls and self._open_count == self.max:
                    self._drop_conn_impl(self._free_new_conn_impls.pop(0))
                else:
                    self._open_count -= 1
                    self._drop_conn_impl(conn_impl)
                    is_open = False
        if is_open:
            conn_impl.warning = None
            conn_impl._time_returned = time.monotonic()
            if self._max_lifetime_session != 0:
                tstamp = conn_impl._time_created + self._max_lifetime_session
                if conn_impl._time_returned > tstamp:
                    self._open_count -= 1
                    self._drop_conn_impl(conn_impl)
                    is_open = False
        if is_open:
            for request in self._requests:
                if request.in_progress or request.wants_new \
                        or request.conn_impl is not None \
                        or not request.waiting:
                    continue
                if request.cclass is None \
                        or request.conn_impl._cclass == self.cclass:
                    request.conn_impl = conn_impl
                    request.completed = True
                    self._requests.remove(request)
                    self._condition.notify_all()
                    return 0
            self._free_used_conn_impls.append(conn_impl)
        self._check_timeout()

    cdef int _shutdown(self) except -1:
        """
        Called when the main interpreter has completed and only shutdown code
        is being executed. All connections in the pool are marked as non-pooled
        and the pool itself terminated.
        """
        cdef BaseThinConnImpl conn_impl
        with self._condition:
            self._open = False
            for lst in (self._free_used_conn_impls,
                        self._free_new_conn_impls,
                        self._busy_conn_impls):
                for conn_impl in lst:
                    conn_impl._pool = None
                lst.clear()
            self._requests.clear()
            self._notify_bg_task()
        self._bg_task.join()

    cdef int _start_timeout_task(self) except -1:
        """
        Starts the task for checking timeouts (differs for sync and async).
        """
        pass

    cdef int _timeout_helper(self, list conn_impls_to_check) except -1:
        """
        Helper method which checks the list of connections to see if any
        connections have expired (while maintaining the minimum number of
        connections in the pool).
        """
        cdef BaseThinConnImpl conn_impl
        current_time = time.monotonic()
        while conn_impls_to_check and self._open_count > self.min:
            conn_impl = conn_impls_to_check[0]
            if current_time - conn_impl._time_returned < self._timeout:
                break
            conn_impls_to_check.pop(0)
            self._drop_conn_impl(conn_impl)
            self._open_count -= 1

    def get_busy_count(self):
        """
        Internal method for getting the number of busy connections in the pool.
        """
        return len(self._busy_conn_impls)

    def get_getmode(self):
        """
        Internal method for getting the method by which connections are
        acquired from the pool.
        """
        return self._getmode

    def get_max_lifetime_session(self):
        """
        Internal method for getting the maximum lifetime of each session.
        """
        return self._max_lifetime_session

    def get_open_count(self):
        """
        Internal method for getting the number of connections in the pool.
        """
        return self._open_count

    def get_ping_interval(self):
        """
        Internal method for getting the value of the pool-ping-interval.
        """
        return self._ping_interval

    def get_stmt_cache_size(self):
        """
        Internal method for getting the size of the statement cache.
        """
        return self._stmt_cache_size

    def get_timeout(self):
        """
        Internal method for getting the timeout for idle sessions.
        """
        return self._timeout

    def get_wait_timeout(self):
        """
        Internal method for getting the wait timeout for acquiring sessions.
        """
        if self._getmode == POOL_GETMODE_TIMEDWAIT:
            return self._wait_timeout
        return 0

    def set_getmode(self, uint32_t value):
        """
        Internal method for setting the method by which connections are
        acquired from the pool.
        """
        if self._getmode != value:
            self._getmode = value
            self._force_get = (self._getmode == POOL_GETMODE_FORCEGET)
            if self._getmode == POOL_GETMODE_TIMEDWAIT:
                self._wait_timeout = 0
            else:
                self._wait_timeout = None

    def set_max_lifetime_session(self, uint32_t value):
        """
        Internal method for setting the maximum lifetime of each session.
        """
        self._max_lifetime_session = value

    def set_ping_interval(self, int value):
        """
        Internal method for setting the value of the pool-ping-interval.
        """
        self._ping_interval = value

    def set_stmt_cache_size(self, uint32_t value):
        """
        Internal method for setting the size of the statement cache.
        """
        self._stmt_cache_size = value

    def set_timeout(self, uint32_t value):
        """
        Internal method for setting the timeout for idle sessions.
        """
        self._timeout = value

    def set_wait_timeout(self, uint32_t value):
        """
        Internal method for setting the wait timeout for acquiring sessions.
        """
        if self._getmode == POOL_GETMODE_TIMEDWAIT:
            self._wait_timeout = value / 1000
        else:
            self._wait_timeout = None


cdef class ThinPoolImpl(BaseThinPoolImpl):

    def __init__(self, str dsn, PoolParamsImpl params):
        super().__init__(dsn, params)
        self._condition = threading.Condition()
        self._bg_task_condition = threading.Condition()
        self._bg_task = threading.Thread(target=self._bg_task_func)
        self._bg_task.start()

    def _bg_task_func(self):
        """
        Method which runs in a dedicated thread and is used to create
        connections and close them when needed. When first started, it creates
        pool.min connections. After that, it creates pool.increment connections
        up to the value of pool.max when needed and destroys connections when
        needed. It also pings connections when requested to do so. The thread
        terminates automatically when the pool is closed.
        """
        cdef:
            PooledConnRequest request = None
            BaseThinConnImpl conn_impl
            list conn_impls_to_drop
            uint32_t num_to_create

        # add to the list of pools that require closing
        pool_closer.add_pool(self)

        # perform task until pool is closed
        while self._open or self._conn_impls_to_drop:

            # check to see if there a request to process
            if request is None and self._open:
                with self._condition:
                    request = self._get_next_request()
            if request is not None and self._open:
                self._process_request(request)
                with self._condition:
                    self._post_process_request(request)
                    request = self._get_next_request()
                    continue

            # check to see if there is a connection that needs to be built
            with self._condition:
                num_to_create = self._num_to_create
            if num_to_create > 0 and self._open:
                try:
                    conn_impl = self._create_conn_impl()
                except:
                    conn_impl = None
                with self._condition:
                    self._post_create_conn_impl(conn_impl)
                    continue

            # check to see if there are any connections to drop
            with self._condition:
                conn_impls_to_drop = self._conn_impls_to_drop
                self._conn_impls_to_drop = []
            if conn_impls_to_drop:
                self._drop_conn_impls_helper(conn_impls_to_drop)
                continue

            # otherwise, nothing to do yet, wait for notifications!
            with self._bg_task_condition:
                self._bg_task_condition.wait()

        # stop the timeout task, if one is active
        if self._timeout_task is not None:
            self._timeout_task.cancel()

        # remove from the list of pools that require closing
        pool_closer.remove_pool(self)

    cdef ThinConnImpl _create_conn_impl(self, ConnectParamsImpl params=None):
        """
        Create a single connection using the pool's information. This
        connection may be placed in the pool or may be returned directly (such
        as when the pool is full and POOL_GETMODE_FORCEGET is being used).
        """
        cdef ThinConnImpl conn_impl
        conn_impl = ThinConnImpl(self.dsn, self.connect_params)
        self._pre_connect(conn_impl, params)
        conn_impl.connect(self.connect_params)
        return conn_impl

    def _notify_bg_task(self):
        """
        Notify the background task that work needs to be done.
        """
        with self._bg_task_condition:
            self._bg_task_condition.notify()

    cdef int _process_request(self, PooledConnRequest request) except -1:
        """
        Processes a request.
        """
        cdef BaseThinConnImpl conn_impl
        try:
            if request.requires_ping:
                try:
                    request.conn_impl.set_call_timeout(self._ping_timeout)
                    request.conn_impl.ping()
                    request.conn_impl.set_call_timeout(0)
                except exceptions.Error:
                    request.conn_impl._force_close()
                    request.conn_impl = None
            else:
                conn_impl = self._create_conn_impl(request.params)
                if request.conn_impl is not None:
                    request.conn_impl._force_close()
                request.conn_impl = conn_impl
                request.conn_impl._is_pool_extra = request.is_extra
        except Exception as e:
            request.exception = e

    cdef int _return_connection(self, BaseThinConnImpl conn_impl) except -1:
        """
        Returns the connection to the pool.
        """
        with self._condition:
            self._return_connection_helper(conn_impl)

    cdef int _start_timeout_task(self) except -1:
        """
        Starts the task for checking timeouts. The timeout value is increased
        by a second to allow for small time discrepancies.
        """
        def handler():
            with self._condition:
                self._process_timeout()
        self._timeout_task = threading.Timer(self._timeout + 1, handler)
        self._timeout_task.start()

    def acquire(self, ConnectParamsImpl params):
        """
        Internal method for acquiring a connection from the pool.
        """
        cdef PooledConnRequest request

        # if pool is closed, raise an exception
        if not self._open:
            errors._raise_err(errors.ERR_POOL_NOT_OPEN)

        # session tagging has not been implemented yet
        if params.tag is not None:
            raise NotImplementedError("Tagging has not been implemented yet")

        # wait until an acceptable connection is found
        request = self._create_request(params)
        with self._condition:
            try:
                self._condition.wait_for(request.fulfill, self._wait_timeout)
            except:
                if not request.bg_processing:
                    request.reject()
                raise
            finally:
                request.waiting = False
            if not request.completed:
                errors._raise_err(errors.ERR_POOL_NO_CONNECTION_AVAILABLE)
            return self._post_acquire(request.conn_impl)

    def close(self, bint force):
        """
        Internal method for closing the pool. Note that the thread to destroy
        pools gracefully may have already run, so if the close has already
        happened, nothing more needs to be done!
        """
        if self._open:
            with self._condition:
                self._close_helper(force)
            self._bg_task.join()

    def drop(self, ThinConnImpl conn_impl):
        """
        Internal method for dropping a connection from the pool.
        """
        with self._condition:
            self._open_count -= 1
            self._busy_conn_impls.remove(conn_impl)
            self._drop_conn_impl(conn_impl)
            self._condition.notify()


cdef class AsyncThinPoolImpl(BaseThinPoolImpl):

    cdef:
        object _bg_notify_task

    def __init__(self, str dsn, PoolParamsImpl params):
        super().__init__(dsn, params)
        self._condition = asyncio.Condition()
        self._bg_task_condition = asyncio.Condition()
        self._bg_task = asyncio.create_task(self._bg_task_func())

    async def _acquire_helper(self, PooledConnRequest request):
        """
        Helper function for acquiring a connection from the pool.
        """
        async with self._condition:
            try:
                await self._condition.wait_for(request.fulfill)
            except:
                if not request.bg_processing:
                    request.reject()
                raise
            finally:
                request.waiting = False

    async def _bg_task_func(self):
        """
        Method which runs in a dedicated task and is used to create connections
        and close them when needed. When first started, it creates pool.min
        connections. After that, it creates pool.increment connections up to
        the value of pool.max when needed and destroys connections when needed.
        The task terminates automatically when the pool is closed.
        """
        cdef:
            PooledConnRequest request = None
            BaseThinConnImpl conn_impl
            list conn_impls_to_drop
            uint32_t num_to_create

        # perform task until pool is closed
        while self._open or self._conn_impls_to_drop:

            # check to see if there a request to process
            if request is None and self._open:
                async with self._condition:
                    request = self._get_next_request()
            if request is not None and self._open:
                await self._process_request(request)
                async with self._condition:
                    self._post_process_request(request)
                    request = self._get_next_request()
                    continue

            # check to see if there is a connection that needs to be built
            async with self._condition:
                num_to_create = self._num_to_create
            if num_to_create > 0 and self._open:
                try:
                    conn_impl = await self._create_conn_impl()
                except:
                    conn_impl = None
                async with self._condition:
                    self._post_create_conn_impl(conn_impl)
                    continue

            # check to see if there are any connections to drop
            async with self._condition:
                conn_impls_to_drop = self._conn_impls_to_drop
                self._conn_impls_to_drop = []
            if conn_impls_to_drop:
                self._drop_conn_impls_helper(conn_impls_to_drop)
                continue

            # otherwise, nothing to do yet, wait for notifications!
            async with self._bg_task_condition:
                await self._bg_task_condition.wait()

        # stop the timeout task, if one is active
        if self._timeout_task is not None:
            self._timeout_task.cancel()

    async def _create_conn_impl(self, ConnectParamsImpl params=None):
        """
        Create a single connection using the pool's information. This
        connection may be placed in the pool or may be returned directly (such
        as when the pool is full and POOL_GETMODE_FORCEGET is being used).
        """
        cdef AsyncThinConnImpl conn_impl
        conn_impl = AsyncThinConnImpl(self.dsn, self.connect_params)
        self._pre_connect(conn_impl, params)
        await conn_impl.connect(self.connect_params)
        return conn_impl

    def _notify_bg_task(self):
        """
        Notify the background task that work needs to be done.
        """
        if self._bg_notify_task is None or self._bg_notify_task.done():
            async def helper():
                async with self._bg_task_condition:
                    self._bg_task_condition.notify()
            self._bg_notify_task = asyncio.create_task(helper())

    async def _process_request(self, PooledConnRequest request):
        """
        Processes a request.
        """
        cdef BaseThinConnImpl conn_impl
        try:
            if request.requires_ping:
                try:
                    request.conn_impl.set_call_timeout(self._ping_timeout)
                    await request.conn_impl.ping()
                    request.conn_impl.set_call_timeout(0)
                except exceptions.Error:
                    request.conn_impl._force_close()
                    request.conn_impl = None
            else:
                conn_impl = await self._create_conn_impl(request.params)
                if request.conn_impl is not None:
                    request.conn_impl._force_close()
                request.conn_impl = conn_impl
                request.conn_impl._is_pool_extra = request.is_extra
        except Exception as e:
            request.exception = e

    async def _return_connection(self, BaseThinConnImpl conn_impl):
        """
        Returns the connection to the pool.
        """
        async with self._condition:
            self._return_connection_helper(conn_impl)

    cdef int _start_timeout_task(self) except -1:
        """
        Starts the task for checking timeouts. The timeout value is increased
        by a second to allow for small time discrepancies.
        """
        async def process_timeout():
            await asyncio.sleep(self._timeout + 1)
            async with self._condition:
                self._process_timeout()
        self._timeout_task = asyncio.create_task(process_timeout())

    async def acquire(self, ConnectParamsImpl params):
        """
        Internal method for acquiring a connection from the pool.
        """
        cdef PooledConnRequest request

        # if pool is closed, raise an exception
        if not self._open:
            errors._raise_err(errors.ERR_POOL_NOT_OPEN)

        # session tagging has not been implemented yet
        if params.tag is not None:
            raise NotImplementedError("Tagging has not been implemented yet")

        # use the helper function to allow for a timeout since asyncio
        # condition variables do not have that capability directly
        request = self._create_request(params)
        try:
            await asyncio.wait_for(
                self._acquire_helper(request), self._wait_timeout
            )
        except asyncio.TimeoutError:
            errors._raise_err(errors.ERR_POOL_NO_CONNECTION_AVAILABLE)
        return self._post_acquire(request.conn_impl)

    async def close(self, bint force):
        """
        Internal method for closing the pool.
        """
        async with self._condition:
            self._close_helper(force)
        await self._bg_task

    async def drop(self, AsyncThinConnImpl conn_impl):
        """
        Internal method for dropping a connection from the pool.
        """
        async with self._condition:
            self._open_count -= 1
            self._busy_conn_impls.remove(conn_impl)
            self._drop_conn_impl(conn_impl)
            self._condition.notify()


@cython.freelist(20)
cdef class PooledConnRequest:
    cdef:
        BaseThinPoolImpl pool_impl
        BaseThinConnImpl conn_impl
        ConnectParamsImpl params
        str cclass
        object exception
        bint cclass_matches
        bint requires_ping
        bint wants_new
        bint bg_processing
        bint is_extra
        bint is_replacing
        bint in_progress
        bint completed
        bint waiting

    cdef int _check_connection(self, BaseThinConnImpl conn_impl) except -1:
        """
        Checks the connection to see if it can be used. First, if any control
        packets are sent that indicate that the connection should be closed,
        the connection is indeed closed. After that, a flag is updated to the
        caller indicating that a ping is required according to the pool
        configuration.
        """
        cdef:
            ReadBuffer buf = conn_impl._protocol._read_buf
            double elapsed_time, min_create_time
            bint has_data_ready
        if not buf._transport._is_async:
            while buf._pending_error_num == 0:
                buf._transport.has_data_ready(&has_data_ready)
                if not has_data_ready:
                    break
                buf.check_control_packet()
        if buf._pending_error_num != 0:
            self.pool_impl._open_count -= 1
            self.pool_impl._drop_conn_impl(conn_impl)
            return 0
        elif self.pool_impl._max_lifetime_session > 0:
            min_create_time = \
                    time.monotonic() - self.pool_impl._max_lifetime_session
            if conn_impl._time_created < min_create_time:
                self.pool_impl._open_count -= 1
                self.pool_impl._drop_conn_impl(conn_impl)
                return 0
        self.conn_impl = conn_impl
        if self.pool_impl._ping_interval == 0:
            self.requires_ping = True
        elif self.pool_impl._ping_interval > 0:
            elapsed_time = time.monotonic() - conn_impl._time_returned
            if elapsed_time > self.pool_impl._ping_interval:
                self.requires_ping = True
        if self.requires_ping:
            self.pool_impl._add_request(self)
        else:
            self.completed = True

    def fulfill(self):
        """
        Fulfills the connection request. If a connection is available and does
        not require a ping to validate it, it is returned immediately. If a
        connection needs to be created or requires a ping to validate it, the
        background function is notified.
        """
        cdef:
            BaseThinPoolImpl pool = self.pool_impl
            BaseThinConnImpl conn_impl
            ssize_t ix
            object exc

        # if an exception was raised in the background thread, raise it now
        if self.exception is not None:
            raise self.exception

        # if the request is completed, waiting can end
        elif self.completed:
            return True

        # if the background task is still working on this request, go back to
        # waiting
        elif self.bg_processing:
            return False

        # check for an available used connection (only permitted if a new
        # connection is not required); in addition, ensure that the connection
        # class matches
        if not self.wants_new and pool._free_used_conn_impls:
            ix = len(pool._free_used_conn_impls) - 1
            for conn_impl in reversed(pool._free_used_conn_impls):
                if self.cclass is None or conn_impl._cclass == self.cclass:
                    pool._free_used_conn_impls.pop(ix)
                    self._check_connection(conn_impl)
                    if self.completed or self.requires_ping:
                        return self.completed
                ix -= 1

        # check for an available new connection (only permitted if the
        # connection class matches)
        if self.cclass_matches:
            while pool._free_new_conn_impls:
                conn_impl = pool._free_new_conn_impls.pop()
                self._check_connection(conn_impl)
                if self.completed or self.requires_ping:
                    return self.completed

        # no matching connections are available; if the pool is full, see if
        # any connections are available and if so, ask the background task to
        # create a new one to replace the non-matching one
        self.requires_ping = False
        if pool._open_count + pool._num_to_create >= pool.max:
            if pool._free_new_conn_impls:
                self.is_replacing = True
                conn_impl = pool._free_new_conn_impls.pop()
                pool._conn_impls_to_drop.append(conn_impl)
                pool._add_request(self)
                return False
            elif pool._free_used_conn_impls:
                self.is_replacing = True
                conn_impl = pool._free_used_conn_impls.pop()
                pool._conn_impls_to_drop.append(conn_impl)
                pool._add_request(self)
                return False
            elif pool._force_get:
                self.is_extra = True
                pool._add_request(self)
                return False
            elif pool._getmode == POOL_GETMODE_NOWAIT:
                errors._raise_err(errors.ERR_POOL_NO_CONNECTION_AVAILABLE)

        # the pool has room to grow; ask the background task to create a
        # specific connection if the connection class does not match;
        # otherwise, ask the pool to grow (if it is not already growing)
        elif self.cclass_matches:
            if pool._num_to_create == 0:
                pool._num_to_create = min(pool.increment,
                                          pool.max - pool._open_count)

        # wait for the pool to grow or a connection to be returned to the pool
        pool._add_request(self)
        return False

    cdef int reject(self) except -1:
        """
        Called when a request has been rejected for any reason (such as when a
        wait timeout has been exceeded). Any connection that is associated with
        the request is returned to the pool or destroyed, depending on the
        request.
        """
        cdef:
            BaseThinPoolImpl pool_impl = self.pool_impl
            BaseThinConnImpl conn_impl = self.conn_impl
        if conn_impl is not None:
            self.conn_impl = None
            if conn_impl._is_pool_extra:
                conn_impl._is_pool_extra = False
                pool_impl._conn_impls_to_drop.append(conn_impl)
            elif conn_impl.invoke_session_callback:
                pool_impl._free_new_conn_impls.append(conn_impl)
            else:
                pool_impl._free_used_conn_impls.append(conn_impl)


cdef class PoolCloser:
    cdef:
        bint closing
        object lock
        set pools

    def __init__(self):
        self.lock = threading.Lock()
        self.closing = False

    cdef int add_pool(self, ThinPoolImpl pool_impl) except -1:
        """
        Adds a pool to the list of pools to close. If this is the first pool
        being added, a thread is started to ensure that all remaining open
        pools are closed gracefully at shutdown of the interpreter.
        """
        with self.lock:
            if self.pools is None:
                self.pools = set()
                threading.Thread(target=self.close_pools_gracefully).start()
            self.pools.add(pool_impl)

    def close_pools_gracefully(self):
        """
        Closes all remaining open pools gracefully. Since pools start a
        background thread, the interpreter will not shut down until these
        background threads have completed, nor will registered atexit functions
        run. Marking the background threads as daemon threads allows the
        interpreter to kill them but then pools are not closed gracefully. This
        method of starting a thread to wait until the main thread finishes
        handles all of these situations.
        """
        cdef ThinPoolImpl pool_impl
        threading.main_thread().join()      # wait for main thread to finish
        self.closing = True
        for pool_impl in self.pools:
            pool_impl._shutdown()

    cdef int remove_pool(self, ThinPoolImpl pool_impl) except -1:
        """
        Removes a pool from the list of pools to close.
        """
        with self.lock:
            if not self.closing:
                self.pools.remove(pool_impl)


cdef PoolCloser pool_closer = PoolCloser()


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\protocol.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# protocol.pyx
#
# Cython file defining the protocol used by the client when communicating with
# the database (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

cdef class BaseProtocol:

    cdef:
        uint8_t _seq_num
        Transport _transport
        Capabilities _caps
        ReadBuffer _read_buf
        WriteBuffer _write_buf
        bint _in_connect
        bint _txn_in_progress
        bint _break_in_progress
        object _request_lock

    def __init__(self):
        self._caps = Capabilities()
        # mark protocol to indicate that connect is in progress; this prevents
        # the normal break/reset mechanism from firing, which is unnecessary
        # since the connection is going to be immediately closed anyway!
        self._in_connect = True
        self._transport = Transport.__new__(Transport)
        self._transport._max_packet_size = self._caps.sdu
        self._read_buf = ReadBuffer(self._transport, self._caps)
        self._write_buf = WriteBuffer(self._transport, self._caps)

    cdef int _break_external(self) except -1:
        """
        Method for sending a break to the server from an external request. A
        separate write buffer is used in order to avoid a potential conflict
        with any in progress writes.
        """
        cdef WriteBuffer buf
        if not self._break_in_progress:
            self._break_in_progress = True
            if self._caps.supports_oob:
                self._transport.send_oob_break()
            else:
                buf = WriteBuffer(self._transport, self._caps)
                self._send_marker(buf, TNS_MARKER_TYPE_INTERRUPT)

    cdef int _final_close(self, WriteBuffer buf) except -1:
        """
        Send the final close packet to the server and close the socket.
        """
        buf.start_request(TNS_PACKET_TYPE_DATA, 0, TNS_DATA_FLAGS_EOF)
        buf.end_request()
        self._force_close()

    cdef int _force_close(self) except -1:
        """
        Forces the connection closed. This is used when an unrecoverable error
        has taken place.
        """
        cdef Transport transport = self._transport
        if transport is not None:
            self._transport = None
            self._read_buf._transport = None
            self._write_buf._transport = None
            transport.disconnect()

    cdef int _post_connect(self, BaseThinConnImpl conn_impl,
                           AuthMessage auth_message) except -1:
        """"
        Performs activities after the connection has completed. The protocol
        must be marked to indicate that the connect is no longer in progress,
        which allows the normal break/reset mechanism to fire. The session must
        also be marked as not needing to be closed since for listener redirects
        the packet may indicate EOF for the initial connection that is
        established.
        """
        conn_impl.warning = auth_message.warning
        self._read_buf._pending_error_num = 0
        self._in_connect = False

    cdef int _release_drcp_session(self, BaseThinConnImpl conn_impl,
                                   uint32_t release_mode) except -1:
        """
        Release the session back to DRCP. Standalone sessions are marked for
        deauthentication.
        """
        cdef SessionReleaseMessage message
        message = conn_impl._create_message(SessionReleaseMessage)
        message.release_mode = release_mode
        message.send(self._write_buf)

    cdef int _send_marker(self, WriteBuffer buf, uint8_t marker_type):
        """
        Sends a marker of the specified type to the server.
        Internal method for sending a break to the server.
        """
        buf.start_request(TNS_PACKET_TYPE_MARKER)
        buf.write_uint8(1)
        buf.write_uint8(0)
        buf.write_uint8(marker_type)
        buf.end_request()

    cdef int _process_call_status(self, BaseThinConnImpl conn_impl,
                                  uint32_t call_status) except -1:
        """
        Processes the call status flags returned by the server.
        """
        self._txn_in_progress = call_status & TNS_EOCS_FLAGS_TXN_IN_PROGRESS
        if call_status & TNS_EOCS_FLAGS_SESS_RELEASE:
            conn_impl._statement_cache.clear_open_cursors()


cdef class Protocol(BaseProtocol):

    def __init__(self):
        BaseProtocol.__init__(self)
        self._request_lock = threading.Lock()

    cdef int _close(self, ThinConnImpl conn_impl) except -1:
        """
        Closes the connection. If a transaction is in progress it will be
        rolled back. DRCP sessions will be released. For standalone
        connections, the session will be logged off. For pooled connections,
        the connection will be returned to the pool for subsequent use.
        """
        cdef:
            uint32_t release_mode = DRCP_DEAUTHENTICATE \
                    if conn_impl._pool is None else 0
            ThinPoolImpl pool_impl
            Message message

        with self._request_lock:

            # if a read failed on the socket earlier, clear the socket
            if self._read_buf._transport is None \
                    or self._read_buf._transport._transport is None:
                self._transport = None

            # if the session was marked as needing to be closed, force it
            # closed immediately (unless it was already closed)
            if self._read_buf._pending_error_num != 0 \
                    and self._transport is not None:
                self._force_close()

            # rollback any open transaction and release the DRCP session, if
            # applicable; end the request, if one was started (and that
            # information made it to the database)
            if self._transport is not None:
                if conn_impl._in_request \
                        and conn_impl._session_state_desired != 0:
                    conn_impl._in_request = False
                if self._txn_in_progress or conn_impl._in_request:
                    if conn_impl._in_request:
                        conn_impl._session_state_desired = \
                                TNS_SESSION_STATE_REQUEST_END
                        conn_impl._in_request = False
                    if conn_impl._transaction_context is not None:
                        message = conn_impl._create_tpc_rollback_message()
                    else:
                        message = conn_impl._create_message(RollbackMessage)
                    self._process_message(message)
                    conn_impl._transaction_context = None
                if conn_impl._drcp_enabled:
                    self._release_drcp_session(conn_impl, release_mode)
                    conn_impl._drcp_establish_session = True

            # if the connection is part of a pool, return it to the pool
            if conn_impl._pool is not None:
                pool_impl = <ThinPoolImpl> conn_impl._pool
                return pool_impl._return_connection(conn_impl)

            # otherwise, destroy the database object type cache, send the
            # logoff message and final close packet
            if conn_impl._dbobject_type_cache_num > 0:
                remove_dbobject_type_cache(conn_impl._dbobject_type_cache_num)
                conn_impl._dbobject_type_cache_num = 0
            if self._transport is not None:
                if not conn_impl._drcp_enabled:
                    message = conn_impl._create_message(LogoffMessage)
                    self._process_message(message)
                self._final_close(self._write_buf)

    cdef int _connect_phase_one(self, ThinConnImpl conn_impl,
                                ConnectParamsImpl params,
                                Description description,
                                Address address,
                                str connect_string) except -1:
        """
        Method for performing the required steps for establishing a connection
        within the scope of a retry. If the listener refuses the connection, a
        retry will be performed, if retry_count is set.
        """
        cdef:
            ConnectMessage connect_message = None
            uint8_t packet_type, packet_flags = 0
            object ssl_context, connect_info
            ConnectParamsImpl temp_params
            str host, redirect_data
            Address temp_address
            int port, pos

        # store whether OOB processing is possible or not
        self._caps.supports_oob = not params.disable_oob \
                and sys.platform != "win32"

        # establish initial TCP connection and get initial connect string
        host = address.ip_address
        port = address.port
        self._connect_tcp(params, description, address, host, port,
                          connect_string)

        # send connect message and process response; this may request the
        # message to be resent multiple times; if a redirect packet is
        # detected, a new TCP connection is established first
        while True:

            # create connection message, if needed
            if connect_message is None:
                connect_message = conn_impl._create_message(ConnectMessage)
                connect_message.host = host
                connect_message.port = port
                connect_message.description = description
                connect_message.connect_string_bytes = connect_string.encode()
                connect_message.connect_string_len = \
                        <uint16_t> len(connect_message.connect_string_bytes)
                connect_message.packet_flags = packet_flags

            # process connection message
            self._process_message(connect_message)
            packet_type = self._read_buf._current_packet.packet_type
            if connect_message.redirect_data is not None:
                redirect_data = connect_message.redirect_data
                pos = redirect_data.find('\x00')
                if pos < 0:
                    errors._raise_err(errors.ERR_INVALID_REDIRECT_DATA,
                                      data=redirect_data)
                temp_params = ConnectParamsImpl()
                temp_params._parse_connect_string(redirect_data[:pos])
                temp_address = temp_params._get_addresses()[0]
                host = temp_address.host
                port = temp_address.port
                connect_string = redirect_data[pos + 1:]
                self._connect_tcp(params, description, address, host, port,
                                  connect_string)
                connect_message = None
                packet_flags = TNS_PACKET_FLAG_REDIRECT
            elif packet_type == TNS_PACKET_TYPE_ACCEPT:
                self._transport._max_packet_size = self._caps.sdu
                self._write_buf._size_for_sdu()
                break

            # for TCPS connections, if the packet flags indicate that TLS
            # renegotiation is required, this is performed now
            if address.protocol == "tcps":
                packet_flags = self._read_buf._current_packet.packet_flags
                if packet_flags & TNS_PACKET_FLAG_TLS_RENEG:
                    self._transport.renegotiate_tls(address, description)

    cdef int _connect_phase_two(self, ThinConnImpl conn_impl,
                                Description description,
                                ConnectParamsImpl params) except -1:
        """"
        Method for perfoming the required steps for establishing a connection
        oustide the scope of a retry. If any of the steps in this method fail,
        an exception will be raised.
        """
        cdef:
            DataTypesMessage data_types_message
            FastAuthMessage fast_auth_message
            ProtocolMessage protocol_message
            bint supports_end_of_response
            AuthMessage auth_message

        # if we can use OOB, send an urgent message now followed by a reset
        # marker to see if the server understands it
        if self._caps.supports_oob and self._caps.supports_oob_check:
            self._transport.send_oob_break()
            self._send_marker(self._write_buf, TNS_MARKER_TYPE_RESET)

        # create the messages that need to be sent to the server
        protocol_message = conn_impl._create_message(ProtocolMessage)
        data_types_message = conn_impl._create_message(DataTypesMessage)
        auth_message = conn_impl._create_message(AuthMessage)
        auth_message._set_params(params, description)

        # starting in 23ai, fast authentication is possible; see if the server
        # supports it
        if self._caps.supports_fast_auth:
            fast_auth_message = conn_impl._create_message(FastAuthMessage)
            fast_auth_message.protocol_message = protocol_message
            fast_auth_message.data_types_message = data_types_message
            fast_auth_message.auth_message = auth_message
            self._process_message(fast_auth_message)

        # otherwise, do the normal authentication; disable end of response for
        # the first two messages as the server does not send an end of response
        # for these messages
        else:
            supports_end_of_response = self._caps.supports_end_of_response
            self._caps.supports_end_of_response = False
            self._process_message(protocol_message)
            self._process_message(data_types_message)
            self._caps.supports_end_of_response = supports_end_of_response
            self._process_message(auth_message)

        # send authorization message a second time, if needed, to respond to
        # the challenge sent by the server
        if auth_message.resend:
            self._process_message(auth_message)

        # perform post connect activities
        self._post_connect(conn_impl, auth_message)

    cdef int _connect_tcp(self, ConnectParamsImpl params,
                          Description description, Address address, str host,
                          int port, str connect_string) except -1:
        """
        Creates a socket on which to communicate using the provided parameters.
        If a proxy is configured, a connection to the proxy is established and
        the target host and port is forwarded to the proxy.
        """
        cdef:
            bint use_proxy = (address.https_proxy is not None)
            double timeout = description.tcp_connect_timeout
            bint use_tcps = (address.protocol == "tcps")
            object connect_info, sock, data, reply, m

        # establish connection to appropriate host/port
        if use_proxy:
            if not use_tcps:
                errors._raise_err(errors.ERR_HTTPS_PROXY_REQUIRES_TCPS)
            connect_info = (address.https_proxy, address.https_proxy_port)
        else:
            connect_info = (host, port)
            if not use_tcps and (params._token is not None
                    or params.access_token_callback is not None):
                errors._raise_err(errors.ERR_ACCESS_TOKEN_REQUIRES_TCPS)
        if description.use_tcp_fast_open:
            sock = socket.socket(address.ip_family, socket.SOCK_STREAM)
            sock.sendto(connect_string.encode(), socket.MSG_FASTOPEN,
                        connect_info)
        else:
            sock = socket.create_connection(connect_info, timeout)

        # complete connection through proxy, if applicable
        if use_proxy:
            data = f"CONNECT {host}:{port} HTTP/1.0\r\n\r\n"
            sock.send(data.encode())
            reply = sock.recv(1024)
            m = re.search('HTTP/1.[01]\\s+(\\d+)\\s+', reply.decode())
            if m is None or m.groups()[0] != '200':
                errors._raise_err(errors.ERR_PROXY_FAILURE,
                                  response=reply.decode())

        # set socket on transport
        self._transport.set_from_socket(sock, params, description, address)

        # for TCPS connections, OOB processing is not supported and TLS
        # negotiation is required
        if use_tcps:
            self._caps.supports_oob = False
            self._transport.create_ssl_context(params, description, address)
            self._transport.negotiate_tls(sock, address, description)

    cdef int _process_message(self, Message message) except -1:
        cdef uint32_t timeout = message.conn_impl._call_timeout
        try:
            self._read_buf.reset_packets()
            message.send(self._write_buf)
            self._receive_packet(message, check_request_boundary=True)
            message.process(self._read_buf)
        except socket.timeout:
            try:
                self._break_external()
                self._receive_packet(message)
                self._break_in_progress = False
                errors._raise_err(errors.ERR_CALL_TIMEOUT_EXCEEDED,
                                  timeout=timeout)
            except socket.timeout:
                self._force_close()
                errors._raise_err(errors.ERR_CONNECTION_CLOSED,
                                  "socket timed out while recovering from " \
                                  "previous socket timeout")
            raise
        except MarkerDetected:
            self._reset()
            message.process(self._read_buf)
        except Exception as e:
            if not self._in_connect \
                    and self._write_buf._packet_sent \
                    and self._read_buf._transport is not None \
                    and self._read_buf._transport._transport is not None:
                self._send_marker(self._write_buf, TNS_MARKER_TYPE_BREAK)
                self._reset()
            raise
        if message.flush_out_binds:
            self._write_buf.start_request(TNS_PACKET_TYPE_DATA)
            self._write_buf.write_uint8(TNS_MSG_TYPE_FLUSH_OUT_BINDS)
            self._write_buf.end_request()
            self._receive_packet(message)
            message.process(self._read_buf)
        if self._break_in_progress:
            try:
                if self._caps.supports_oob:
                    self._send_marker(self._write_buf,
                                      TNS_MARKER_TYPE_INTERRUPT)
                self._receive_packet(message)
            except socket.timeout:
                errors._raise_err(errors.ERR_CONNECTION_CLOSED,
                                  "socket timed out while awaiting break " \
                                  "response from server")
            message.process(self._read_buf)
            self._break_in_progress = False
        self._process_call_status(message.conn_impl, message.call_status)
        if message.error_occurred:
            if message.retry:
                message.error_occurred = False
                return self._process_message(message)
            message._check_and_raise_exception()

    cdef int _process_single_message(self, Message message) except -1:
        """
        Process a single message within a request.
        """
        message.preprocess()
        with self._request_lock:
            self._process_message(message)
            if message.resend:
                self._process_message(message)
        message.postprocess()

    cdef int _receive_packet(self, Message message,
                             bint check_request_boundary=False) except -1:
        cdef:
            bint orig_check_request_boundary
            ReadBuffer buf = self._read_buf
            uint16_t refuse_message_len
            const char_type* ptr
        orig_check_request_boundary = buf._check_request_boundary
        buf._check_request_boundary = \
                check_request_boundary and self._caps.supports_end_of_response
        try:
            buf.wait_for_packets_sync()
        finally:
            buf._check_request_boundary = orig_check_request_boundary
        if buf._current_packet.packet_type == TNS_PACKET_TYPE_MARKER:
            self._reset()
        elif buf._current_packet.packet_type == TNS_PACKET_TYPE_REFUSE:
            self._write_buf._packet_sent = False
            buf.skip_raw_bytes(2)
            buf.read_uint16be(&refuse_message_len)
            if refuse_message_len == 0:
                message.error_info.message = None
            else:
                ptr = buf.read_raw_bytes(refuse_message_len)
                message.error_info.message = ptr[:refuse_message_len].decode()

    cdef int _reset(self) except -1:
        cdef uint8_t marker_type, packet_type

        # send reset marker
        self._send_marker(self._write_buf, TNS_MARKER_TYPE_RESET)

        # read and discard all packets until a reset marker is received
        while True:
            packet_type = self._read_buf._current_packet.packet_type
            if packet_type == TNS_PACKET_TYPE_MARKER:
                self._read_buf.skip_raw_bytes(2)
                self._read_buf.read_ub1(&marker_type)
                if marker_type == TNS_MARKER_TYPE_RESET:
                    break
            self._read_buf.wait_for_packets_sync()

        # read error packet; first skip as many marker packets as may be sent
        # by the server; if the server doesn't handle out-of-band breaks
        # properly, some quit immediately and others send multiple reset
        # markers (this addresses both situations without resulting in strange
        # errors)
        while packet_type == TNS_PACKET_TYPE_MARKER:
            self._read_buf.wait_for_packets_sync()
            packet_type = self._read_buf._current_packet.packet_type
        self._break_in_progress = False


cdef class BaseAsyncProtocol(BaseProtocol):

    def __init__(self):
        BaseProtocol.__init__(self)
        self._request_lock = asyncio.Lock()
        self._transport._is_async = True

    async def _close(self, AsyncThinConnImpl conn_impl):
        """
        Closes the connection. If a transaction is in progress it will be
        rolled back. DRCP sessions will be released. For standalone
        connections, the session will be logged off. For pooled connections,
        the connection will be returned to the pool for subsequent use.
        """
        cdef:
            uint32_t release_mode = DRCP_DEAUTHENTICATE \
                    if conn_impl._pool is None else 0
            AsyncThinPoolImpl pool_impl
            Message message

        async with self._request_lock:

            # if a read failed on the socket earlier, clear the socket
            if self._read_buf._transport is None:
                self._transport = None

            # if the session was marked as needing to be closed, force it
            # closed immediately (unless it was already closed)
            if self._read_buf._pending_error_num != 0 \
                    and self._transport is not None:
                self._force_close()

            # rollback any open transaction and release the DRCP session, if
            # applicable
            if self._transport is not None:
                if self._txn_in_progress:
                    message = conn_impl._create_message(RollbackMessage)
                    await self._process_message(message)
                if conn_impl._drcp_enabled:
                    self._release_drcp_session(conn_impl, release_mode)
                    conn_impl._drcp_establish_session = True

            # if the connection is part of a pool, return it to the pool
            if conn_impl._pool is not None:
                pool_impl = <AsyncThinPoolImpl> conn_impl._pool
                return await pool_impl._return_connection(conn_impl)

            # otherwise, destroy the database object type cache, send the
            # logoff message and final close packet
            if conn_impl._dbobject_type_cache_num > 0:
                remove_dbobject_type_cache(conn_impl._dbobject_type_cache_num)
                conn_impl._dbobject_type_cache_num = 0
            if self._transport is not None:
                if not conn_impl._drcp_enabled:
                    message = conn_impl._create_message(LogoffMessage)
                    await self._process_message(message)
                self._final_close(self._write_buf)

    async def _connect_phase_one(self,
                                 AsyncThinConnImpl conn_impl,
                                 ConnectParamsImpl params,
                                 Description description,
                                 Address address,
                                 str connect_string):
        """
        Method for performing the required steps for establishing a connection
        within the scope of a retry. If the listener refuses the connection, a
        retry will be performed, if retry_count is set.
        """
        cdef:
            ConnectMessage connect_message = None
            uint8_t packet_type, packet_flags = 0
            object ssl_context, connect_info
            ConnectParamsImpl temp_params
            str host, redirect_data
            object orig_transport
            Address temp_address
            int port, pos

        # asyncio doesn't support OOB processing
        self._caps.supports_oob = False

        # establish initial TCP connection and get initial connect string
        host = address.ip_address
        port = address.port
        orig_transport = await self._connect_tcp(params, description, address,
                                                 host, port)

        # send connect message and process response; this may request the
        # message to be resent multiple times; if a redirect packet is
        # detected, a new TCP connection is established first
        while True:

            # create connection message, if needed
            if connect_message is None:
                connect_message = conn_impl._create_message(ConnectMessage)
                connect_message.host = host
                connect_message.port = port
                connect_message.description = description
                connect_message.connect_string_bytes = connect_string.encode()
                connect_message.connect_string_len = \
                        <uint16_t> len(connect_message.connect_string_bytes)
                connect_message.packet_flags = packet_flags

            # process connection message
            await self._process_message(connect_message)
            packet_type = self._read_buf._current_packet.packet_type
            if connect_message.redirect_data is not None:
                redirect_data = connect_message.redirect_data
                pos = redirect_data.find('\x00')
                if pos < 0:
                    errors._raise_err(errors.ERR_INVALID_REDIRECT_DATA,
                                      data=redirect_data)
                temp_params = ConnectParamsImpl()
                temp_params._parse_connect_string(redirect_data[:pos])
                temp_address = temp_params._get_addresses()[0]
                host = temp_address.host
                port = temp_address.port
                connect_string = redirect_data[pos + 1:]
                orig_transport = await self._connect_tcp(params, description,
                                                         address, host, port)
                connect_message = None
                packet_flags = TNS_PACKET_FLAG_REDIRECT
            elif packet_type == TNS_PACKET_TYPE_ACCEPT:
                self._transport._max_packet_size = self._caps.sdu
                self._write_buf._size_for_sdu()
                break

            # for TCPS connections, OOB processing is not supported; if the
            # packet flags indicate that TLS renegotiation is required, this is
            # performed now
            if address.protocol == "tcps":
                self._caps.supports_oob = False
                packet_flags = self._read_buf._current_packet.packet_flags
                if packet_flags & TNS_PACKET_FLAG_TLS_RENEG:
                    self._transport._transport = orig_transport
                    await self._transport.negotiate_tls_async(self, address,
                                                              description)

    async def _connect_phase_two(self, AsyncThinConnImpl conn_impl,
                                 Description description,
                                 ConnectParamsImpl params):
        """"
        Method for perfoming the required steps for establishing a connection
        oustide the scope of a retry. If any of the steps in this method fail,
        an exception will be raised.
        """
        cdef:
            DataTypesMessage data_types_message
            FastAuthMessage fast_auth_message
            ProtocolMessage protocol_message
            bint supports_end_of_response
            AuthMessage auth_message

        # create the messages that need to be sent to the server
        protocol_message = conn_impl._create_message(ProtocolMessage)
        data_types_message = conn_impl._create_message(DataTypesMessage)
        auth_message = conn_impl._create_message(AuthMessage)
        auth_message._set_params(params, description)

        # starting in 23ai, fast authentication is possible; see if the server
        # supports it
        if self._caps.supports_fast_auth:
            fast_auth_message = conn_impl._create_message(FastAuthMessage)
            fast_auth_message.protocol_message = protocol_message
            fast_auth_message.data_types_message = data_types_message
            fast_auth_message.auth_message = auth_message
            await self._process_message(fast_auth_message)

        # otherwise, do the normal authentication; disable end of response for
        # the first two messages as the server does not send an end of response
        # for these messages
        else:
            supports_end_of_response = self._caps.supports_end_of_response
            self._caps.supports_end_of_response = False
            await self._process_message(protocol_message)
            await self._process_message(data_types_message)
            self._caps.supports_end_of_response = supports_end_of_response
            await self._process_message(auth_message)

        # send authorization message a second time, if needed, to respond to
        # the challenge sent by the server
        if auth_message.resend:
            await self._process_message(auth_message)

        # perform post connect activities
        self._post_connect(conn_impl, auth_message)


    async def _connect_tcp(self, ConnectParamsImpl params,
                           Description description, Address address, str host,
                           int port):
        """
        Creates a socket on which to communicate using the provided parameters.
        If a proxy is configured, a connection to the proxy is established and
        the target host and port is forwarded to the proxy.
        """
        cdef:
            bint use_proxy = (address.https_proxy is not None)
            double timeout = description.tcp_connect_timeout
            bint use_tcps = (address.protocol == "tcps")
            object connect_info, data, reply, m
            str connect_host
            int connect_port

        # establish connection to appropriate host/port
        if use_proxy:
            if not use_tcps:
                errors._raise_err(errors.ERR_HTTPS_PROXY_REQUIRES_TCPS)
            connect_host = address.https_proxy
            connect_port = address.https_proxy_port
        else:
            connect_host = host
            connect_port = port
            if not use_tcps and (params._token is not None
                    or params.access_token_callback is not None):
                errors._raise_err(errors.ERR_ACCESS_TOKEN_REQUIRES_TCPS)
        transport, protocol = await self._read_buf._loop.create_connection(
            lambda: self,
            connect_host,
            connect_port
        )

        # complete connection through proxy, if applicable
        if use_proxy:
            data = f"CONNECT {host}:{port} HTTP/1.0\r\n\r\n"
            transport.write(data.encode())
            reply = transport.read(1024)
            m = re.search('HTTP/1.[01]\\s+(\\d+)\\s+', reply.decode())
            if m is None or m.groups()[0] != '200':
                errors._raise_err(errors.ERR_PROXY_FAILURE,
                                  response=reply.decode())

        # set socket on transport
        self._transport.set_from_socket(transport, params, description,
                                        address)

        # negotiate TLS, if applicable
        if use_tcps:
            self._transport.create_ssl_context(params, description, address)
            return await self._transport.negotiate_tls_async(self, address,
                                                             description)

    async def _process_message(self, Message message):
        """
        Sends a message to the server and processes its response.
        """
        cdef:
            uint32_t timeout = message.conn_impl._call_timeout
            object timeout_obj = (timeout / 1000) or None
        try:
            coroutine = self._process_message_helper(message)
            await asyncio.wait_for(coroutine, timeout_obj)
        except asyncio.TimeoutError:
            try:
                coroutine = self._process_timeout_helper(message, timeout)
                await asyncio.wait_for(coroutine, timeout_obj)
            except asyncio.TimeoutError:
                self._force_close()
                errors._raise_err(errors.ERR_CONNECTION_CLOSED,
                                  "socket timed out while recovering from " \
                                  "previous socket timeout")
            raise
        except MarkerDetected:
            await self._reset()
            message.process(self._read_buf)
        except:
            if not self._in_connect \
                    and self._write_buf._packet_sent \
                    and self._transport is not None:
                self._send_marker(self._write_buf, TNS_MARKER_TYPE_BREAK)
                await self._reset()
            raise
        if message.flush_out_binds:
            self._write_buf.start_request(TNS_PACKET_TYPE_DATA)
            self._write_buf.write_uint8(TNS_MSG_TYPE_FLUSH_OUT_BINDS)
            self._write_buf.end_request()
            await self._receive_packet(message)
            message.process(self._read_buf)
        if self._break_in_progress:
            try:
                coroutine = self._receive_packet(message)
                await asyncio.wait_for(coroutine, timeout_obj)
            except asyncio.TimeoutError:
                self._force_close()
                errors._raise_err(errors.ERR_CONNECTION_CLOSED,
                                  "socket timed out while awaiting break " \
                                  "response from server")
            message.process(self._read_buf)
            self._break_in_progress = False
        self._process_call_status(message.conn_impl, message.call_status)
        if message.error_occurred:
            if message.retry:
                message.error_occurred = False
                return await self._process_message(message)
            message._check_and_raise_exception()

    async def _process_message_helper(self, Message message):
        """
        Helper routine that is called to process a message within a timeout.
        """
        self._read_buf.reset_packets()
        message.send(self._write_buf)
        await self._receive_packet(message, check_request_boundary=True)
        while True:
            try:
                message.process(self._read_buf)
                break
            except OutOfPackets:
                await self._receive_packet(message)
                self._read_buf.restore_point()

    async def _process_single_message(self, Message message):
        """
        Process a single message within a request.
        """
        message.preprocess()
        async with self._request_lock:
            await self._process_message(message)
            if message.resend:
                await self._process_message(message)
        await message.postprocess_async()

    async def _process_timeout_helper(self, Message message, uint32_t timeout):
        """
        Helper routine that is called to process a timeout.
        """
        self._break_external()
        await self._receive_packet(message)
        self._break_in_progress = False
        errors._raise_err(errors.ERR_CALL_TIMEOUT_EXCEEDED, timeout=timeout)

    async def _receive_packet(self, Message message,
                              bint check_request_boundary=False,
                              bint in_pipeline=False):
        cdef:
            ReadBuffer buf = self._read_buf
            uint16_t refuse_message_len
            const char_type* ptr
        buf._check_request_boundary = \
                check_request_boundary and self._caps.supports_end_of_response
        await buf.wait_for_packets_async()
        buf._check_request_boundary = False
        if buf._current_packet.packet_type == TNS_PACKET_TYPE_MARKER:
            if in_pipeline:
                # skip to next packet as the marker packet doesn't contain any
                # useful information
                buf.wait_for_packets_sync()
            else:
                await self._reset()
        elif buf._current_packet.packet_type == TNS_PACKET_TYPE_REFUSE:
            self._write_buf._packet_sent = False
            buf.skip_raw_bytes(2)
            buf.read_uint16be(&refuse_message_len)
            if refuse_message_len == 0:
                message.error_info.message = None
            else:
                ptr = buf.read_raw_bytes(refuse_message_len)
                message.error_info.message = ptr[:refuse_message_len].decode()

    async def _reset(self):
        cdef:
            uint8_t marker_type, packet_type

        # send reset marker
        self._send_marker(self._write_buf, TNS_MARKER_TYPE_RESET)

        # read and discard all packets until a reset marker is received
        while True:
            packet_type = self._read_buf._current_packet.packet_type
            if packet_type == TNS_PACKET_TYPE_MARKER:
                self._read_buf.skip_raw_bytes(2)
                self._read_buf.read_ub1(&marker_type)
                if marker_type == TNS_MARKER_TYPE_RESET:
                    break
            await self._read_buf.wait_for_packets_async()

        # read error packet; first skip as many marker packets as may be sent
        # by the server; if the server doesn't handle out-of-band breaks
        # properly, some quit immediately and others send multiple reset
        # markers (this addresses both situations without resulting in strange
        # errors)
        while packet_type == TNS_PACKET_TYPE_MARKER:
            await self._read_buf.wait_for_packets_async()
            packet_type = self._read_buf._current_packet.packet_type
        self._break_in_progress = False

    def connection_lost(self, exc):
        """
        Called when a connection has been lost. The presence of an exception
        indicates an abornmal loss of the connection. If in the process of
        establishing a connection, losing the connection is ignored since this
        can happen normally when a listener redirect is encountered.
        """
        if not self._in_connect:
            self._transport = None
            if self._read_buf._waiter is not None \
                    and not self._read_buf._waiter.done():
                error = errors._create_err(errors.ERR_CONNECTION_CLOSED)
                self._read_buf._waiter.set_exception(error.exc_type(error))

    def data_received(self, data):
        """
        Called when data has been received on the transport.
        """
        cdef:
            bint notify_waiter = False
            Packet packet
        packet = self._transport.extract_packet(data)
        while packet is not None:
            self._read_buf._process_packet(packet, &notify_waiter, False)
            if notify_waiter:
                self._read_buf.notify_packet_received()
            packet = self._transport.extract_packet()

    async def end_pipeline(self, BaseThinConnImpl conn_impl, list messages,
                           bint continue_on_error):
        """
        Called when all messages for the pipeline have been sent to the
        database. An end pipeline message is sent to the database and then
        the responses to all of the messages are processed.
        """
        cdef:
            ssize_t num_responses_to_discard
            ReadBuffer buf = self._read_buf
            Message message, end_message
        end_message = conn_impl._create_message(EndPipelineMessage)
        end_message.send(self._write_buf)
        buf._check_request_boundary = True
        buf._in_pipeline = True
        try:
            num_responses_to_discard = len(messages) + 1
            for message in messages:
                try:
                    if not buf.has_response():
                        await buf.wait_for_response_async()
                    buf._start_packet()
                    message.preprocess()
                    message.process(buf)
                    num_responses_to_discard -= 1
                    self._process_call_status(conn_impl, message.call_status)
                    message._check_and_raise_exception()
                except Exception as e:
                    if not continue_on_error:
                        raise
                    message.pipeline_result_impl._capture_err(e)
            await self._receive_packet(end_message,
                                       check_request_boundary=True)
            end_message.process(buf)
            num_responses_to_discard = 0
            end_message._check_and_raise_exception()
        except:
            await buf.discard_pipeline_responses(num_responses_to_discard)
            raise
        finally:
            buf._check_request_boundary = False
            buf._in_pipeline = False


class AsyncProtocol(BaseAsyncProtocol, asyncio.Protocol):
    pass


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\queue.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# queue.pyx
#
# Cython file defining the thin Queue implementation class (embedded in
# thin_impl.pyx).
#------------------------------------------------------------------------------

cdef class BaseThinQueueImpl(BaseQueueImpl):

    cdef:
        BaseThinConnImpl _conn_impl
        bytes payload_toid

    cdef AqArrayMessage _create_array_deq_message(self, uint32_t num_iters):
        """
        Create the message used for dequeuing multiple AQ messages
        """
        cdef:
            AqArrayMessage message
            uint32_t i
        message = self._conn_impl._create_message(AqArrayMessage)
        message.num_iters = num_iters
        message.props_impls = [ThinMsgPropsImpl() for i in range(num_iters)]
        message.queue_impl = self
        message.deq_options_impl = self.deq_options_impl
        message.operation = TNS_AQ_ARRAY_DEQ
        return message

    cdef AqArrayMessage _create_array_enq_message(self, list props_impls):
        """
        Create the message used for enqueuing multiple AQ messages
        """
        cdef AqArrayMessage message
        message = self._conn_impl._create_message(AqArrayMessage)
        message.queue_impl = self
        message.enq_options_impl = self.enq_options_impl
        message.props_impls = props_impls
        message.operation = TNS_AQ_ARRAY_ENQ
        message.num_iters = len(props_impls)
        return message

    cdef AqDeqMessage _create_deq_message(self):
        """
        Create the message for dequeuing a payload.
        """
        cdef:
            ThinMsgPropsImpl props_impl
            AqDeqMessage message
        props_impl = ThinMsgPropsImpl()
        message = self._conn_impl._create_message(AqDeqMessage)
        message.queue_impl = self
        message.deq_options_impl = self.deq_options_impl
        message.props_impl = props_impl
        return message

    cdef AqEnqMessage _create_enq_message(self, ThinMsgPropsImpl props_impl):
        """
        Create the message for enqueuing the provided payload.
        """
        cdef AqEnqMessage message
        message = self._conn_impl._create_message(AqEnqMessage)
        message.queue_impl = self
        message.enq_options_impl = self.enq_options_impl
        message.props_impl = props_impl
        return message

    def initialize(self, BaseThinConnImpl conn_impl, str name,
                   ThinDbObjectTypeImpl payload_type, bint is_json):
        """
        Internal method for initializing the queue.
        """
        self._conn_impl = conn_impl
        self.is_json = is_json
        self.deq_options_impl = ThinDeqOptionsImpl()
        self.enq_options_impl = ThinEnqOptionsImpl()
        self.payload_type = payload_type
        if self.is_json:
            self.payload_toid = bytes([0]*15+[0x47])
        elif self.payload_type is not None:
            self.payload_toid = payload_type.oid
        else:
            self.payload_toid = bytes([0]*15+[0x17])
        self.name = name


cdef class ThinQueueImpl(BaseThinQueueImpl):

    def deq_many(self, uint32_t max_num_messages):
        """
        Internal method for dequeuing multiple messages from a queue.
        """
        cdef:
            Protocol protocol = <Protocol> self._conn_impl._protocol
            AqArrayMessage message
        message = self._create_array_deq_message(max_num_messages)
        protocol._process_single_message(message)
        if message.no_msg_found:
            return []
        return message.props_impls[:message.num_iters]

    def deq_one(self):
        """
        Internal method for dequeuing a single message from a queue.
        """
        cdef:
            Protocol protocol = <Protocol> self._conn_impl._protocol
            AqDeqMessage message
        message = self._create_deq_message()
        protocol._process_single_message(message)
        if not message.no_msg_found:
            return message.props_impl

    def enq_many(self, list props_impls):
        """
        Internal method for enqueuing many messages into a queue.
        """
        cdef :
            Protocol protocol = <Protocol> self._conn_impl._protocol
            AqArrayMessage message
        message = self._create_array_enq_message(props_impls)
        protocol._process_single_message(message)

    def enq_one(self, ThinMsgPropsImpl props_impl):
        """
        Internal method for enqueuing a single message into a queue.
        """
        cdef:
            Protocol protocol = <Protocol> self._conn_impl._protocol
            AqEnqMessage message
        message = self._create_enq_message(props_impl)
        protocol._process_single_message(message)


cdef class AsyncThinQueueImpl(BaseThinQueueImpl):

    async def deq_many(self, uint32_t max_num_messages):
        """
        Internal method for dequeuing multiple messages from a queue.
        """
        cdef:
            BaseAsyncProtocol protocol
            AqArrayMessage message
        protocol = <BaseAsyncProtocol> self._conn_impl._protocol
        message = self._create_array_deq_message(max_num_messages)
        await protocol._process_single_message(message)
        if message.no_msg_found:
            return []
        return message.props_impls[:message.num_iters]

    async def deq_one(self):
        """
        Internal method for dequeuing a single message from a queue.
        """
        cdef:
            BaseAsyncProtocol protocol
            AqDeqMessage message
        protocol = <BaseAsyncProtocol> self._conn_impl._protocol
        message = self._create_deq_message()
        await protocol._process_single_message(message)
        if not message.no_msg_found:
            return message.props_impl

    async def enq_many(self, list props_impls):
        """
        Internal method for enqueuing many messages into a queue.
        """
        cdef :
            BaseAsyncProtocol protocol
            AqArrayMessage message
        protocol = <BaseAsyncProtocol> self._conn_impl._protocol
        message = self._create_array_enq_message(props_impls)
        await protocol._process_single_message(message)

    async def enq_one(self, ThinMsgPropsImpl props_impl):
        """
        Internal method for enqueuing a single message into a queue.
        """
        cdef:
            BaseAsyncProtocol protocol
            AqEnqMessage message
        protocol = <BaseAsyncProtocol> self._conn_impl._protocol
        message = self._create_enq_message(props_impl)
        await protocol._process_single_message(message)


cdef class ThinDeqOptionsImpl(BaseDeqOptionsImpl):
    cdef:
        str condition
        str consumer_name
        str correlation
        uint16_t delivery_mode
        uint32_t mode
        bytes msgid
        uint32_t navigation
        str transformation
        uint32_t visibility
        uint32_t wait

    def __init__(self):
        self.delivery_mode = TNS_AQ_MSG_PERSISTENT
        self.mode = TNS_AQ_DEQ_REMOVE
        self.navigation = TNS_AQ_DEQ_NEXT_MSG
        self.visibility = TNS_AQ_DEQ_ON_COMMIT
        self.wait = TNS_AQ_DEQ_WAIT_FOREVER

    def get_condition(self):
        """
        Internal method for getting the condition.
        """
        return self.condition

    def get_consumer_name(self):
        """
        Internal method for getting the consumer name.
        """
        return self.consumer_name

    def get_correlation(self):
        """
        Internal method for getting the correlation.
        """
        return self.correlation

    def get_message_id(self):
        """
        Internal method for getting the message id.
        """
        return self.msgid

    def get_mode(self):
        """
        Internal method for getting the mode.
        """
        return self.mode

    def get_navigation(self):
        """
        Internal method for getting the navigation.
        """
        return self.navigation

    def get_transformation(self):
        """
        Internal method for getting the transformation.
        """
        return self.transformation

    def get_visibility(self):
        """
        Internal method for getting the visibility.
        """
        return self.visibility

    def get_wait(self):
        """
        Internal method for getting the wait.
        """
        return self.wait

    def set_condition(self, str value):
        """
        Internal method for setting the condition.
        """
        self.condition = value

    def set_consumer_name(self, str value):
        """
        Internal method for setting the consumer name.
        """
        self.consumer_name =  value

    def set_correlation(self, str value):
        """
        Internal method for setting the correlation.
        """
        self.correlation = value

    def set_delivery_mode(self, uint16_t value):
        """
        Internal method for setting the delivery mode.
        """
        self.delivery_mode = value

    def set_mode(self, uint32_t value):
        """
        Internal method for setting the mode.
        """
        self.mode = value

    def set_message_id(self, bytes value):
        """
        Internal method for setting the message id.
        """
        self.msgid = value

    def set_navigation(self, uint32_t value):
        """
        Internal method for setting the navigation.
        """
        self.navigation = value

    def set_transformation(self, str value):
        """
        Internal method for setting the transformation.
        """
        self.transformation = value

    def set_visibility(self, uint32_t value):
        """
        Internal method for setting the visibility.
        """
        self.visibility = value

    def set_wait(self, uint32_t value):
        """
        Internal method for setting the wait.
        """
        self.wait = value


cdef class ThinEnqOptionsImpl(BaseEnqOptionsImpl):
    cdef:
        str transformation
        uint32_t visibility
        uint32_t delivery_mode

    def __init__(self):
        self.visibility = TNS_AQ_ENQ_ON_COMMIT
        self.delivery_mode = TNS_AQ_MSG_PERSISTENT

    def get_transformation(self):
        """
        Internal method for getting the transformation.
        """
        return self.transformation

    def get_visibility(self):
        """
        Internal method for getting the visibility.
        """
        return self.visibility

    def set_delivery_mode(self, uint16_t value):
        """
        Internal method for setting the delivery mode.
        """
        self.delivery_mode = value

    def set_transformation(self, str value):
        """
        Internal method for setting the transformation.
        """
        self.transformation = value

    def set_visibility(self, uint32_t value):
        """
        Internal method for setting the visibility.
        """
        self.visibility = value


cdef class ThinMsgPropsImpl(BaseMsgPropsImpl):

    cdef:
        int32_t delay
        str correlation
        str exceptionq
        int32_t expiration
        int32_t priority
        list recipients
        int32_t num_attempts
        uint32_t delivery_mode
        cydatetime.datetime enq_time
        bytes msgid
        int32_t state
        object payload_obj
        BaseThinConnImpl _conn_impl
        bytes enq_txn_id
        bytes sender_agent_name
        bytes sender_agent_address
        unsigned char sender_agent_protocol
        bytes original_msg_id

    def __init__(self):
        self.delay = TNS_AQ_MSG_NO_DELAY
        self.expiration = TNS_AQ_MSG_NO_EXPIRATION
        self.recipients = []
        self.sender_agent_protocol = 0

    def get_num_attempts(self):
        """
        Internal method for getting the number of attempts made.
        """
        return self.num_attempts

    def get_correlation(self):
        """
        Internal method for getting the correlation.
        """
        return self.correlation

    def get_delay(self):
        """
        Internal method for getting the delay.
        """
        return self.delay

    def get_delivery_mode(self):
        """
        Internal method for getting the delivery mode.
        """
        return self.delivery_mode

    def get_enq_time(self):
        """
        Internal method for getting the enqueue time.
        """
        return self.enq_time

    def get_exception_queue(self):
        """
        Internal method for getting the exception queue.
        """
        return self.exceptionq

    def get_expiration(self):
        """
        Internal method for getting the message expiration.
        """
        return self.expiration

    def get_message_id(self):
        """
        Internal method for getting the message id.
        """
        return self.msgid

    def get_priority(self):
        """
        Internal method for getting the priority.
        """
        return self.priority

    def get_state(self):
        """
        Internal method for getting the message state.
        """
        return self.state

    def set_correlation(self, str value):
        """
        Internal method for setting the correlation.
        """
        self.correlation = value

    def set_delay(self, int32_t value):
        """
        Internal method for setting the delay.
        """
        self.delay = value

    def set_exception_queue(self, str value):
        """
        Internal method for setting the exception queue.
        """
        self.exceptionq = value

    def set_expiration(self, int32_t value):
        """
        Internal method for setting the message expiration.
        """
        self.expiration = value

    def set_payload_bytes(self, bytes value):
        """
        Internal method for setting the payload from bytes.
        """
        self.payload_obj = value

    def set_payload_object(self, ThinDbObjectImpl value):
        """
        Internal method for setting the payload from an object.
        """
        if not isinstance(value, ThinDbObjectImpl):
            raise TypeError("Expected ThinDbObjectImpl instance.")
        self.payload_obj = value

    def set_payload_json(self, object json_val):
        """
        Internal method for setting the payload from a JSON object
        """
        self.payload_obj = json_val

    def set_priority(self, int32_t value):
        """
        Internal method for setting the priority.
        """
        self.priority = value

    def set_recipients(self, list value):
        """
        Internal method for setting the recipients list.
        """
        self.recipients = value


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\statement.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# statement.pyx
#
# Cython file defining the Statement and BindInfo classes used to hold
# information about statements that are executed and any bind parameters that
# may be bound to those statements (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

cdef class BindInfo:

    cdef:
        uint32_t num_elements
        bint _is_return_bind
        uint8_t ora_type_num
        uint32_t buffer_size
        int16_t precision
        uint8_t bind_dir
        uint32_t size
        str _bind_name
        bint is_array
        int16_t scale
        uint8_t csfrm
        ThinVarImpl _bind_var_impl

    def __cinit__(self, str name, bint is_return_bind):
        self._bind_name = name
        self._is_return_bind = is_return_bind

    cdef BindInfo copy(self):
        return BindInfo(self._bind_name, self._is_return_bind)


cdef class StatementParser(BaseParser):

    cdef:
        bint returning_keyword_found

    cdef int _parse_bind_name(self, Statement stmt) except -1:
        """
        Bind variables are identified as follows:
        - Quoted and non-quoted bind names are allowed.
        - Quoted bind names can contain any characters.
        - Non-quoted bind names must begin with an alphabetic character.
        - Non-quoted bind names can only contain alphanumeric characters, the
          underscore, the dollar sign and the pound sign.
        - Non-quoted bind names cannot be Oracle Database Reserved Names (this
          is left to the server to detct and return an appropriate error).
        """
        cdef:
            bint quoted_name = False, in_bind = False, digits_only = False
            ssize_t start_pos = 0
            str bind_name
            Py_UCS4 ch
        self.temp_pos = self.pos + 1
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if not in_bind:
                if cpython.Py_UNICODE_ISSPACE(ch):
                    self.temp_pos += 1
                    continue
                elif ch == '"':
                    quoted_name = True
                elif cpython.Py_UNICODE_ISDIGIT(ch):
                    digits_only = True
                elif not cpython.Py_UNICODE_ISALPHA(ch):
                    break
                in_bind = True
                start_pos = self.temp_pos
            elif digits_only and not cpython.Py_UNICODE_ISDIGIT(ch):
                self.pos = self.temp_pos - 1
                break
            elif quoted_name and ch == '"':
                self.pos = self.temp_pos
                break
            elif not digits_only and not quoted_name \
                    and not cpython.Py_UNICODE_ISALNUM(ch) \
                    and ch not in ('_', '$', '#'):
                self.pos = self.temp_pos - 1
                break
            self.temp_pos += 1
        if in_bind:
            if quoted_name:
                bind_name = stmt._sql[start_pos + 1:self.temp_pos]
            elif digits_only:
                bind_name = stmt._sql[start_pos:self.temp_pos]
            else:
                bind_name = stmt._sql[start_pos:self.temp_pos].upper()
            stmt._add_bind(bind_name)

    cdef int _parse_multiple_line_comment(self) except -1:
        """
        Multiple line comments consist of the characters /* followed by all
        characters up until */. This method is called when the first slash is
        detected and checks for the subsequent asterisk. If found, the comment
        is traversed and the current position is updated; otherwise, the
        current position is left untouched.
        """
        cdef:
            bint in_comment = False, exiting_comment = False
            Py_UCS4 ch
        self.temp_pos = self.pos + 1
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if not in_comment:
                if ch != '*':
                    break
                in_comment = True
            elif ch == '*':
                exiting_comment = True
            elif exiting_comment:
                if ch == '/':
                    self.pos = self.temp_pos
                    break
                exiting_comment = False
            self.temp_pos += 1

    cdef int _parse_qstring(self) except -1:
        """
        Parses a q-string which consists of the characters "q" and a single
        quote followed by a start separator, any text that does not contain the
        end seprator and the end separator and ending quote. The following are
        examples that demonstrate this:
            - q'[...]'
            - q'{...}'
            - q'<...>'
            - q'(...)'
            - q'?...?' (where ? is any character)
        """
        cdef:
            bint exiting_qstring = False, in_qstring = False
            Py_UCS4 ch, sep = 0
        self.temp_pos += 1
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if not in_qstring:
                if ch == '[':
                    sep = ']'
                elif ch == '{':
                    sep = '}'
                elif ch == '<':
                    sep = '>'
                elif ch == '(':
                    sep = ')'
                else:
                    sep = ch
                in_qstring = True
            elif not exiting_qstring and ch == sep:
                exiting_qstring = True
            elif exiting_qstring:
                if ch == "'":
                    self.pos = self.temp_pos
                    return 0
                elif ch != sep:
                    exiting_qstring = False
            self.temp_pos += 1
        errors._raise_err(errors.ERR_MISSING_ENDING_SINGLE_QUOTE)

    cdef int _parse_single_line_comment(self) except -1:
        """
        Single line comments consist of two dashes and all characters up to the
        next line break (or the end of the data). This method is called when
        the first dash is detected and checks for the subsequent dash. If
        found, the single line comment is traversed and the current position is
        updated; otherwise, the current position is left untouched.
        """
        cdef:
            bint in_comment = False
            Py_UCS4 ch
        self.temp_pos = self.pos + 1
        while self.temp_pos < self.num_chars:
            ch = self.get_current_char()
            if not in_comment:
                if ch != '-':
                    return 0
                in_comment = True
            elif cpython.Py_UNICODE_ISLINEBREAK(ch):
                break
            self.temp_pos += 1
        self.pos = self.temp_pos

    cdef int parse(self, Statement stmt) except -1:
        """
        Parses the SQL stored in the statement in order to determine the
        keyword that identifies the type of SQL being executed as well as a
        list of bind variable names. A check is also made for DML returning
        statements since the bind variables following the "INTO" keyword are
        treated differently from other bind variables.
        """
        cdef:
            bint initial_keyword_found = False, last_was_string = False
            Py_UCS4 ch, last_ch = 0, alpha_start_ch = 0
            ssize_t alpha_start_pos = 0, alpha_len
            bint last_was_alpha = False, is_alpha
            str keyword

        # initialization
        self.initialize(stmt._sql)

        # scan all characters in the string
        while self.pos < self.num_chars:
            self.temp_pos = self.pos
            ch = self.get_current_char()

            # look for certain keywords (initial keyword and the ones for
            # detecting DML returning statements
            is_alpha = cpython.Py_UNICODE_ISALPHA(ch)
            if is_alpha and not last_was_alpha:
                alpha_start_pos = self.pos
                alpha_start_ch = ch
            elif not is_alpha and last_was_alpha:
                alpha_len = self.pos - alpha_start_pos
                if not initial_keyword_found:
                    keyword = stmt._sql[alpha_start_pos:self.pos].upper()
                    stmt._determine_statement_type(keyword)
                    if stmt._is_ddl:
                        break
                    initial_keyword_found = True
                elif stmt._is_dml and not self.returning_keyword_found \
                        and alpha_len == 9 and alpha_start_ch in ('r', 'R'):
                    keyword = stmt._sql[alpha_start_pos:self.pos].upper()
                    if keyword == "RETURNING":
                        self.returning_keyword_found = True
                elif self.returning_keyword_found and alpha_len == 4 \
                        and alpha_start_ch in ('i', 'I'):
                    keyword = stmt._sql[alpha_start_pos:self.pos].upper()
                    if keyword == "INTO":
                        stmt._is_returning = True

            # need to keep track of whether the last token parsed was a string
            # (excluding whitespace) as if the last token parsed was a string
            # a following colon is not a bind variable but a part of the JSON
            # constant syntax
            if ch == "'":
                last_was_string = True
                if last_ch in ('q', 'Q'):
                    self._parse_qstring()
                else:
                    self.temp_pos += 1
                    self.parse_quoted_string(ch)
                    self.pos -= 1
            elif not cpython.Py_UNICODE_ISSPACE(ch):
                if ch == '-':
                    self._parse_single_line_comment()
                elif ch == '/':
                    self._parse_multiple_line_comment()
                elif ch == '"':
                    self.temp_pos += 1
                    self.parse_quoted_string(ch)
                    self.pos -= 1
                elif ch == ':' and not last_was_string:
                    self._parse_bind_name(stmt)
                last_was_string = False

            # advance to next character and track previous character
            self.pos += 1
            last_was_alpha = is_alpha
            last_ch = ch


cdef class Statement:

    cdef:
        str _sql
        bytes _sql_bytes
        uint32_t _sql_length
        uint16_t _cursor_id
        bint _is_query
        bint _is_plsql
        bint _is_dml
        bint _is_ddl
        bint _is_returning
        list _bind_info_list
        list _fetch_metadata
        list _fetch_vars
        list _fetch_var_impls
        object _bind_info_dict
        object _last_output_type_handler
        uint32_t _num_columns
        bint _executed
        bint _binds_changed
        bint _no_prefetch
        bint _requires_define
        bint _return_to_cache
        bint _is_nested
        bint _in_use

    cdef Statement copy(self):
        cdef:
            Statement copied_statement = Statement.__new__(Statement)
            object bind_info_dict
            BindInfo bind_info
        copied_statement._sql = self._sql
        copied_statement._sql_bytes = self._sql_bytes
        copied_statement._sql_length = self._sql_length
        copied_statement._is_query = self._is_query
        copied_statement._is_plsql = self._is_plsql
        copied_statement._is_dml = self._is_dml
        copied_statement._is_ddl = self._is_ddl
        copied_statement._is_returning = self._is_returning
        copied_statement._bind_info_list = \
                [bind_info.copy() for bind_info in self._bind_info_list]
        copied_statement._bind_info_dict = collections.OrderedDict()
        bind_info_dict = copied_statement._bind_info_dict
        for bind_info in copied_statement._bind_info_list:
            if bind_info._bind_name in bind_info_dict:
                bind_info_dict[bind_info._bind_name].append(bind_info)
            else:
                bind_info_dict[bind_info._bind_name] = [bind_info]
        copied_statement._return_to_cache = False
        return copied_statement

    cdef int _add_bind(self, str name) except -1:
        """
        Add bind information to the statement by examining the passed SQL for
        bind variable names.
        """
        cdef BindInfo info, orig_info
        if not self._is_plsql or name not in self._bind_info_dict:
            info = BindInfo(name, self._is_returning)
            self._bind_info_list.append(info)
            if info._bind_name in self._bind_info_dict:
                if self._is_returning:
                    orig_info = self._bind_info_dict[info._bind_name][-1]
                    if not orig_info._is_return_bind:
                        errors._raise_err(errors.ERR_DML_RETURNING_DUP_BINDS,
                                          name=info._bind_name)
                self._bind_info_dict[info._bind_name].append(info)
            else:
                self._bind_info_dict[info._bind_name] = [info]

    cdef _determine_statement_type(self, str sql_keyword):
        """
        Determine the type of the SQL statement by examining the first keyword
        found in the statement.
        """
        if sql_keyword in ("DECLARE", "BEGIN", "CALL"):
            self._is_plsql = True
        elif sql_keyword in ("SELECT", "WITH"):
            self._is_query = True
        elif sql_keyword in ("INSERT", "UPDATE", "DELETE", "MERGE"):
            self._is_dml = True
        elif sql_keyword in ("CREATE", "ALTER", "DROP", "GRANT", "REVOKE",
                             "ANALYZE", "AUDIT", "COMMENT", "TRUNCATE"):
            self._is_ddl = True

    cdef int _prepare(self, str sql) except -1:
        """
        Prepare the SQL for execution by determining the list of bind names
        that are found within it. The length of the SQL text is also calculated
        at this time.
        """
        cdef StatementParser parser = StatementParser.__new__(StatementParser)

        # retain normalized SQL (as string and bytes) as well as the length
        self._sql = sql
        self._sql_bytes = self._sql.encode()
        self._sql_length = <uint32_t> len(self._sql_bytes)

        # parse SQL and populate bind variable list (bind by position) and dict
        # (bind by name)
        self._bind_info_dict = collections.OrderedDict()
        self._bind_info_list = []
        parser.parse(self)

    cdef int _set_var(self, BindInfo bind_info, ThinVarImpl var_impl,
                      ThinCursorImpl cursor_impl) except -1:
        """
        Set the variable on the bind information and copy across metadata that
        will be used for binding. If the bind metadata has changed, mark the
        statement as requiring a full execute. In addition, binding a REF
        cursor also requires a full execute.
        """
        cdef:
            OracleMetadata metadata = var_impl.metadata
            object value
        if metadata.dbtype._ora_type_num == ORA_TYPE_NUM_CURSOR:
            for value in var_impl._values:
                if value is not None and value._impl is cursor_impl:
                    errors._raise_err(errors.ERR_SELF_BIND_NOT_SUPPORTED)
            self._binds_changed = True
        if metadata.dbtype._ora_type_num != bind_info.ora_type_num \
                or metadata.max_size != bind_info.size \
                or metadata.buffer_size != bind_info.buffer_size \
                or metadata.precision != bind_info.precision \
                or metadata.scale != bind_info.scale \
                or var_impl.is_array != bind_info.is_array \
                or var_impl.num_elements != bind_info.num_elements \
                or metadata.dbtype._csfrm != bind_info.csfrm:
            bind_info.ora_type_num = metadata.dbtype._ora_type_num
            bind_info.csfrm = metadata.dbtype._csfrm
            bind_info.is_array = var_impl.is_array
            bind_info.num_elements = var_impl.num_elements
            bind_info.size = metadata.max_size
            bind_info.buffer_size = metadata.buffer_size
            bind_info.precision = metadata.precision
            bind_info.scale = metadata.scale
            self._binds_changed = True
        bind_info._bind_var_impl = var_impl

    cdef int clear_all_state(self) except -1:
        """
        Clears all state associated with the cursor.
        """
        self._fetch_vars = None
        self._fetch_metadata = None
        self._fetch_var_impls = None
        self._executed = False
        self._binds_changed = False
        self._requires_define = False
        self._no_prefetch = False
        self._cursor_id = 0

    cdef bint requires_single_execute(self):
        """
        Returns a boolean indicating if the statement requires a single execute
        in order to be processed correctly by the server. If a PL/SQL block has
        not been executed before, the determination of input/output binds has
        not been completed and so a single execution is required in order to
        complete that determination.
        """
        return self._is_plsql and (self._cursor_id == 0 or self._binds_changed)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\statement_cache.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2024, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# statement_cache.pyx
#
# Cython file defining the StatementCache class used to manage cached
# statements (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

cdef class StatementCache:

    cdef:
        object _cached_statements
        object _lock
        uint32_t _max_size
        uint32_t _max_cursors
        array.array _cursors_to_close
        ssize_t _num_cursors_to_close
        set _open_cursors

    cdef int _add_cursor_to_close(self, Statement stmt) except -1:
        """
        Add the statement's cursor to the list of cursors that need to be
        closed.
        """
        if stmt._cursor_id != 0 and not stmt._is_nested:
            self._cursors_to_close[self._num_cursors_to_close] = \
                    stmt._cursor_id
            self._num_cursors_to_close += 1
        self._open_cursors.remove(stmt)

    cdef int _adjust_cache(self) except -1:
        """
        Adjust the cache so that no more than the maximum number of statements
        are cached.
        """
        cdef Statement stmt
        while len(self._cached_statements) > self._max_size:
            stmt = <Statement> self._cached_statements.popitem(last=False)[1]
            if stmt._in_use:
                stmt._return_to_cache = False
            else:
                self._add_cursor_to_close(stmt)

    cdef int clear_cursor(self, Statement stmt) except -1:
        """
        Clears the particular cursor but retains it in the list of open
        cursors. This is for cases where the cursor id needs to be cleared but
        the cursor itself is still going to be used.
        """
        self._cursors_to_close[self._num_cursors_to_close] = stmt._cursor_id
        self._num_cursors_to_close += 1
        stmt._cursor_id = 0
        stmt._fetch_var_impls = None
        stmt._executed = False

    cdef int clear_open_cursors(self) except -1:
        """
        Clears the list of open cursors and removes the list of cursors that
        need to be closed. This is required when a DRCP session change has
        taken place as the cursor ID values are invalidated.
        """
        cdef:
            set new_open_cursors = set()
            Statement stmt
        with self._lock:
            for stmt in self._open_cursors:
                stmt.clear_all_state()
                if stmt._in_use or stmt._return_to_cache:
                    new_open_cursors.add(stmt)
            self._open_cursors = new_open_cursors
            self._num_cursors_to_close = 0

    cdef Statement get_statement(self, str sql, bint cache_statement,
                                 bint force_new):
        """
        Get a statement from the statement cache, or prepare a new statement
        for use. If a statement is already in use or the statement is not
        supposed to be cached, a copy will be made (and not returned to the
        cache).
        """
        cdef Statement stmt = None
        with self._lock:
            if sql is not None:
                stmt = self._cached_statements.get(sql)
            if stmt is None:
                stmt = Statement.__new__(Statement)
                if sql is not None:
                    stmt._prepare(sql)
                if cache_statement and not stmt._is_ddl and self._max_size > 0:
                    stmt._return_to_cache = True
                    self._cached_statements[sql] = stmt
                    self._adjust_cache()
                self._open_cursors.add(stmt)
            elif force_new or stmt._in_use:
                if not cache_statement:
                    self._add_cursor_to_close(stmt)
                    del self._cached_statements[sql]
                stmt = stmt.copy()
                self._open_cursors.add(stmt)
            elif not cache_statement:
                del self._cached_statements[sql]
                stmt._return_to_cache = False
            else:
                self._cached_statements.move_to_end(sql)
        stmt._in_use = True
        return stmt

    cdef int initialize(self, uint32_t max_size,
                         uint32_t max_cursors) except -1:
        """
        Initialize the statement cache.
        """
        if max_cursors == 0:
            self._max_size = 0
            self._max_cursors = 1
        else:
            self._max_size = max_size
            self._max_cursors = max_cursors
        self._cached_statements = collections.OrderedDict()
        self._lock = threading.Lock()
        self._open_cursors = set()
        self._cursors_to_close = array.array('I')
        array.resize(self._cursors_to_close, self._max_cursors)
        self._num_cursors_to_close = 0

    cdef int resize(self, uint32_t new_size) except -1:
        """
        Resizes the statement cache to the new value.
        """
        with self._lock:
            self._max_size = new_size
            self._adjust_cache()

    cdef int return_statement(self, Statement stmt) except -1:
        """
        Return the statement to the statement cache, if applicable. If the
        statement must not be returned to the statement cache, add the cursor
        id to the list of cursor ids to close on the next round trip to the
        database. Clear all bind variables and fetch variables in order to
        ensure that unnecessary references are not retained.
        """
        cdef:
            ThinVarImpl var_impl
            BindInfo bind_info
        if stmt._bind_info_list is not None:
            for bind_info in stmt._bind_info_list:
                bind_info._bind_var_impl = None
        if stmt._fetch_var_impls is not None:
            for var_impl in stmt._fetch_var_impls:
                var_impl._values = [None] * var_impl.num_elements
        with self._lock:
            if stmt._return_to_cache:
                stmt._in_use = False
            else:
                self._add_cursor_to_close(stmt)

    cdef int write_cursors_to_close(self, WriteBuffer buf) except -1:
        """
        Write the list of cursors to close to the buffer.
        """
        cdef:
            unsigned int *cursor_ids
            ssize_t i
        with self._lock:
            buf.write_ub4(self._num_cursors_to_close)
            cursor_ids = self._cursors_to_close.data.as_uints
            for i in range(self._num_cursors_to_close):
                buf.write_ub4(cursor_ids[i])
            self._num_cursors_to_close = 0


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\transport.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2023, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# transport.pyx
#
# Cython file defining the transport class used by the client for sending and
# receiving packets (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

cdef bint DEBUG_PACKETS = ("PYO_DEBUG_PACKETS" in os.environ)

cdef class Transport:

    cdef:
        object _transport
        object _ssl_context
        str _ssl_sni_data
        uint32_t _transport_num
        ssize_t _max_packet_size
        uint32_t _op_num
        bytes _partial_buf
        bint _full_packet_size
        bint _is_async

    cdef str _calc_sni_data(self, Description description):
        """
        Calculates the string used for the special SNI handling that allows one
        of the TLS negotiations to be bypassed.
        """
        cdef str server_type_part = ""
        if description.server_type is not None:
            server_type_part = f".T1.{description.server_type[:1]}"
        return (
            f"S{len(description.service_name)}.{description.service_name}"
            f"{server_type_part}"
            f".V3.{TNS_VERSION_DESIRED}"
        )

    cdef str _get_debugging_header(self, str operation):
        """
        Returns the header line used for debugging packets.
        """
        cdef str header
        self._op_num += 1
        current_date = datetime.datetime.now().isoformat(
            sep=" ",
            timespec="milliseconds"
        )
        return (
            f"{current_date} "
            f"{operation} [op {self._op_num}] on socket {self._transport_num}"
        )

    cdef int _print_output(self, str text) except -1:
        """
        Prints and flushes the text to stdout to ensure that multiple
        threads don't lose output due to buffering.
        """
        print(text + "\n", flush=True)

    cdef int _print_packet(self, str operation, object data) except -1:
        """
        Print the packet content in a format suitable for debugging.
        """
        offset = 0
        hex_data = memoryview(data).hex().upper()
        output_lines = [self._get_debugging_header(operation)]
        while hex_data:
            line_hex_data = hex_data[:16]
            hex_data = hex_data[16:]
            hex_dump_values = []
            printable_values = []
            for i in range(0, len(line_hex_data), 2):
                hex_byte = line_hex_data[i:i + 2]
                hex_dump_values.append(hex_byte)
                byte_val = ord(bytes.fromhex(hex_byte))
                char_byte = chr(byte_val)
                if char_byte.isprintable() and byte_val < 128 \
                        and char_byte != " ":
                    printable_values.append(char_byte)
                else:
                    printable_values.append(".")
            while len(hex_dump_values) < 8:
                hex_dump_values.append("  ")
                printable_values.append(" ")
            output_lines.append(
                f'{offset:04} : {" ".join(hex_dump_values)} '
                f'|{"".join(printable_values)}|'
            )
            offset += 8
        self._print_output("\n".join(output_lines))

    cdef int disconnect(self) except -1:
        """
        Disconnects the transport.
        """
        if self._transport is not None:
            if DEBUG_PACKETS:
                self._print_output(
                    self._get_debugging_header("Disconnecting transport")
                )
            self._transport.close()
            self._transport = None

    cdef int create_ssl_context(self, ConnectParamsImpl params,
                                Description description,
                                Address address) except -1:
        """
        Creates the SSL context used for establishing TLS communications
        between the database and the client.
        """

        # start with a default SSL context, unless a custom one is supplied
        self._ssl_context = params.ssl_context
        if self._ssl_context is None:
            self._ssl_context = ssl.create_default_context()

        # set the minimum and maximum versions of the TLS protocol
        if description.ssl_version is not None:
            self._ssl_context.minimum_version = description.ssl_version
            self._ssl_context.maximum_version = description.ssl_version

        # if the platform is macOS, check if the certifi package is installed;
        # if certifi is not installed, load the certificates from the macOS
        # keychain in PEM format
        if sys.platform == "darwin" and certifi is None:
            global macos_certs
            if macos_certs is None:
                certs = subprocess.run(["security", "find-certificate",
                                        "-a", "-p"],
                                        stdout=subprocess.PIPE).stdout
                macos_certs = certs.decode("utf-8")
            self._ssl_context.load_verify_locations(cadata=macos_certs)

        # if a wallet is specified, either mTLS is being used or a set of
        # certificates is being loaded to validate the server
        if description.wallet_location is not None:
            pem_file_name = os.path.join(description.wallet_location,
                                         PEM_WALLET_FILE_NAME)
            if not os.path.exists(pem_file_name):
                errors._raise_err(errors.ERR_WALLET_FILE_MISSING,
                                  name=pem_file_name)
            self._ssl_context.load_verify_locations(pem_file_name)
            wallet_password = params._get_wallet_password()
            try:
                self._ssl_context.load_cert_chain(pem_file_name,
                                                  password=wallet_password)
            except ssl.SSLError:
                pass

        # the SSL host name is not checked but the SSL server DN matching
        # algorithm is run instead after the TLS connection has been
        # established
        self._ssl_context.check_hostname = False

        # calculate the SNI data to send to the server, if applicable
        if description.use_sni:
            self._ssl_sni_data = self._calc_sni_data(description)
        else:
            self._ssl_sni_data = None

    cdef Packet extract_packet(self, bytes data=None):
        """
        Extracts a packet from the data, if possible (after first appending it
        to the partial buffer, if applicable). Any extra data not needed by the
        packet is stored in the partial buffer for a later call to this
        function.
        """
        cdef:
            ssize_t size, packet_size
            Packet packet
            char_type *ptr

        # update the partial buffer with the new data
        if data is not None:
            if self._partial_buf is None:
                self._partial_buf = data
            else:
                self._partial_buf += data
        size = 0 if self._partial_buf is None else len(self._partial_buf)

        # if enough bytes for the packet header, extract the packet size
        if size >= PACKET_HEADER_SIZE:

            # extract the packet size
            ptr = <char_type*> self._partial_buf
            if self._full_packet_size:
                packet_size = decode_uint32be(ptr)
            else:
                packet_size = decode_uint16be(ptr)

            # if enough bytes are available for the packet, return it
            if size >= packet_size:
                packet = Packet.__new__(Packet)
                packet.packet_size = packet_size
                packet.packet_type = ptr[4]
                packet.packet_flags = ptr[5]

                # store the packet buffer and adjust the partial buffer, as
                # needed
                if size == packet_size:
                    packet.buf = self._partial_buf
                    self._partial_buf = None
                else:
                    packet.buf = self._partial_buf[:packet_size]
                    self._partial_buf = self._partial_buf[packet_size:]

                # display packet, if requested
                if DEBUG_PACKETS:
                    self._print_packet("Receiving packet", packet.buf)
                return packet

    cdef tuple get_host_info(self):
        """
        Return a 2-tuple supplying the host and port to which the transport is
        connected.
        """
        cdef object sock
        if self._is_async:
            sock = self._transport.get_extra_info('socket')
        else:
            sock = self._transport
        return sock.getpeername()[:2]

    cdef int has_data_ready(self, bint *data_ready) except -1:
        """
        Returns true if data is ready to be read on the transport.
        """
        socket_list = [self._transport]
        read_socks, _, _ = select.select(socket_list, [], [], 0)
        data_ready[0] = bool(read_socks)

    cdef int negotiate_tls(self, object sock, Address address,
                           Description description) except -1:
        """
        Negotiate TLS on the socket.
        """
        if DEBUG_PACKETS:
            self._print_output(self._get_debugging_header("Negotiate TLS"))
        self._transport = self._ssl_context.wrap_socket(
            sock, server_hostname=self._ssl_sni_data
        )
        if description.ssl_server_dn_match:
            check_server_dn(self._transport, description.ssl_server_cert_dn,
                            address.host)

    cdef int renegotiate_tls(self, Address address,
                             Description description) except -1:
        """
        Renegotiate TLS on the socket.
        """
        orig_sock = self._transport
        sock = socket.socket(family=orig_sock.family, type=orig_sock.type,
                             proto=orig_sock.proto, fileno=orig_sock.detach())
        self.negotiate_tls(sock, address, description)

    async def negotiate_tls_async(self, BaseAsyncProtocol protocol,
                                  Address address, Description description):
        """
        Negotiate TLS on the socket asynchronously.
        """
        if DEBUG_PACKETS:
            self._print_output(self._get_debugging_header("Negotiate TLS"))
        orig_transport = self._transport
        loop = protocol._read_buf._loop
        self._transport = await loop.start_tls(
            self._transport, protocol,
            self._ssl_context,
            server_hostname=self._ssl_sni_data
        )
        if description.ssl_server_dn_match:
            sock = self._transport.get_extra_info("ssl_object")
            check_server_dn(sock, description.ssl_server_cert_dn, address.host)
        return orig_transport

    cdef int send_oob_break(self) except -1:
        """
        Sends an out-of-band break on the transport.
        """
        if DEBUG_PACKETS:
            self._print_output(
                self._get_debugging_header("Sending out of band break")
            )
        self._transport.send(b"!", socket.MSG_OOB)

    cdef int set_from_socket(self, object transport,
                             ConnectParamsImpl params,
                             Description description,
                             Address address) except -1:
        """
        Sets the transport from a socket.
        """
        cdef object sock
        if self._is_async:
            sock = transport.get_extra_info('socket')
        else:
            sock = transport
        if description.expire_time > 0:
            sock.setsockopt(socket.SOL_SOCKET, socket.SO_KEEPALIVE, 1)
            if hasattr(socket, "TCP_KEEPIDLE") \
                    and hasattr(socket, "TCP_KEEPINTVL") \
                    and hasattr(socket, "TCP_KEEPCNT"):
                sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPIDLE,
                                description.expire_time * 60)
                sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPINTVL, 6)
                sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_KEEPCNT, 10)
        sock.setsockopt(socket.IPPROTO_TCP, socket.TCP_NODELAY, 1)
        if sock.gettimeout() != 0:
            sock.settimeout(None)
        self._transport = transport
        self._transport_num = sock.fileno()

    cdef Packet read_packet(self):
        """
        Reads a packet from the transport.
        """
        cdef:
            Packet packet
            bytes data
        packet = self.extract_packet()
        while packet is None:
            try:
                data = self._transport.recv(self._max_packet_size)
            except ConnectionResetError as e:
                errors._raise_err(errors.ERR_CONNECTION_CLOSED, str(e),
                                  cause=e)
            if len(data) == 0:
                self.disconnect()
                errors._raise_err(errors.ERR_CONNECTION_CLOSED)
            packet = self.extract_packet(data)
        return packet

    cdef int set_timeout(self, double value) except -1:
        """
        Sets the timeout on the transport.
        """
        self._transport.settimeout(value or None)

    cdef int write_packet(self, WriteBuffer buf) except -1:
        """
        Writes a packet on the transport.
        """
        data = bytes(buf._data_view[:buf._pos])
        if DEBUG_PACKETS:
            self._print_packet("Sending packet", data)
        try:
            if self._is_async:
                self._transport.write(data)
            else:
                self._transport.send(data)
        except OSError as e:
            self.disconnect()
            errors._raise_err(errors.ERR_CONNECTION_CLOSED, cause=e)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\utils.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# utils.pyx
#
# Cython file defining utility classes and methods (embedded in thin_impl.pyx).
#------------------------------------------------------------------------------

class OutOfPackets(Exception):
    pass

class MarkerDetected(Exception):
    pass

class ConnectConstants:

    def __init__(self):
        self.pid = str(os.getpid())
        pattern = r"(?P<major_num>\d+)\.(?P<minor_num>\d+)\.(?P<patch_num>\d+)"
        match_dict = re.match(pattern, DRIVER_VERSION)
        major_num = int(match_dict["major_num"])
        minor_num = int(match_dict["minor_num"])
        patch_num = int(match_dict["patch_num"])
        self.full_version_num = \
                major_num << 24 | minor_num << 20 | patch_num << 12


cdef int _convert_base64(char_type *buf, long value, int size, int offset):
    """
    Converts every 6 bits into a character, from left to right. This is
    similar to ordinary base64 encoding with a few differences and written
    here for performance.
    """
    cdef int i
    for i in range(size):
        buf[offset + size - i - 1] = TNS_BASE64_ALPHABET_ARRAY[value & 0x3f]
        value = value >> 6
    return offset + size


cdef object _encode_rowid(Rowid *rowid):
    """
    Converts the rowid structure into an encoded string, if the rowid structure
    contains valid data; otherwise, it returns None.
    """
    cdef:
        char_type buf[TNS_MAX_ROWID_LENGTH]
        int offset = 0
    if rowid.rba != 0 or rowid.partition_id != 0 or rowid.block_num != 0 \
            or rowid.slot_num != 0:
        offset = _convert_base64(buf, rowid.rba, 6, offset)
        offset = _convert_base64(buf, rowid.partition_id, 3, offset)
        offset = _convert_base64(buf, rowid.block_num, 6, offset)
        offset = _convert_base64(buf, rowid.slot_num, 3, offset)
        return buf[:TNS_MAX_ROWID_LENGTH].decode()


cdef str _get_connect_data(Description description, str connection_id, ConnectParamsImpl params):
    """
    Return the connect data required by the listener in order to connect.
    """
    cid = f"(PROGRAM={params.program})" + \
          f"(HOST={params.machine})" + \
          f"(USER={params.osuser})"
    if description.connection_id_prefix:
        description.connection_id = description.connection_id_prefix + \
                connection_id
    else:
        description.connection_id = connection_id
    return description.build_connect_string(cid)


cdef int _check_cryptography() except -1:
    """
    Checks to see that the cryptography package was imported successfully.
    """
    if CRYPTOGRAPHY_IMPORT_ERROR is not None:
        errors._raise_err(errors.ERR_NO_CRYPTOGRAPHY_PACKAGE,
                          str(CRYPTOGRAPHY_IMPORT_ERROR))


def init_thin_impl(package):
    """
    Initializes globals after the package has been completely initialized. This
    is to avoid circular imports and eliminate the need for global lookups.
    """
    global _connect_constants, errors, exceptions
    _connect_constants = ConnectConstants()
    errors = package.errors
    exceptions = package.exceptions


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\impl\thin\var.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# var.pyx
#
# Cython file defining the variable implementation class (embedded in
# thin_impl.pyx).
#------------------------------------------------------------------------------

cdef class ThinVarImpl(BaseVarImpl):
    cdef:
        object _last_raw_value
        OracleArrowArray _last_arrow_array
        list _coroutine_indexes

    cdef int _bind(self, object conn, BaseCursorImpl cursor_impl,
                   uint32_t num_execs, object name, uint32_t pos) except -1:
        cdef:
            ThinCursorImpl thin_cursor_impl = <ThinCursorImpl> cursor_impl
            Statement stmt = thin_cursor_impl._statement
            object bind_info_dict = stmt._bind_info_dict
            list bind_info_list = stmt._bind_info_list
            OracleMetadata metadata = self.metadata
            ssize_t idx, num_binds, num_vars
            BindInfo bind_info
            str normalized_name
            bint is_async
            object value

        # for PL/SQL blocks, if the size of a string or bytes object exceeds
        # 32,767 bytes it must be converted to a BLOB/CLOB; an out converter
        # needs to be established as well to return the string in the way that
        # the user expects to get it
        if stmt._is_plsql and metadata.max_size > 32767:
            if metadata.dbtype._ora_type_num == ORA_TYPE_NUM_RAW \
                    or metadata.dbtype._ora_type_num == ORA_TYPE_NUM_LONG_RAW:
                metadata.dbtype = DB_TYPE_BLOB
            elif metadata.dbtype._csfrm == CS_FORM_NCHAR:
                metadata.dbtype = DB_TYPE_NCLOB
            else:
                metadata.dbtype = DB_TYPE_CLOB
            orig_converter = self.outconverter
            def converter(v):
                v = v.read()
                if orig_converter is not None:
                    v = orig_converter(v)
                return v
            self.outconverter = converter

        # for variables containing LOBs, create temporary LOBs, if needed
        is_async = thin_cursor_impl._conn_impl._protocol._transport._is_async
        if metadata.dbtype._ora_type_num == ORA_TYPE_NUM_CLOB \
                or metadata.dbtype._ora_type_num == ORA_TYPE_NUM_BLOB:
            for idx, value in enumerate(self._values):
                if value is not None \
                        and not isinstance(value, (PY_TYPE_LOB,
                                                   PY_TYPE_ASYNC_LOB)):
                    self._values[idx] = conn.createlob(metadata.dbtype, value)
                    if is_async:
                        if self._coroutine_indexes is None:
                            self._coroutine_indexes = []
                        self._coroutine_indexes.append(idx)

        # bind by name
        if name is not None:
            if name.startswith('"') and name.endswith('"'):
                normalized_name = name[1:-1]
            else:
                normalized_name = name.upper()
            if normalized_name.startswith(":"):
                normalized_name = normalized_name[1:]
            if normalized_name not in bind_info_dict:
                errors._raise_err(errors.ERR_INVALID_BIND_NAME, name=name)
            for bind_info in bind_info_dict[normalized_name]:
                stmt._set_var(bind_info, self, thin_cursor_impl)

        # bind by position
        else:
            num_binds = len(bind_info_list)
            num_vars = len(cursor_impl.bind_vars)
            if num_binds != num_vars:
                errors._raise_err(errors.ERR_WRONG_NUMBER_OF_POSITIONAL_BINDS,
                                  expected_num=num_binds, actual_num=num_vars)
            bind_info = bind_info_list[pos - 1]
            stmt._set_var(bind_info, self, thin_cursor_impl)

    cdef int _finalize_init(self) except -1:
        """
        Internal method that finalizes initialization of the variable.
        """
        BaseVarImpl._finalize_init(self)
        self._values = [None] * self.num_elements

    cdef OracleArrowArray _finish_building_arrow_array(self):
        """
        Finish building the Arrow array associated with the variable and then
        return that array (after clearing it in the variable so that a new
        array will be built if more rows are fetched). In thin mode, the
        duplicate row handling requires the last array to be retained, so do
        that here.
        """
        self._last_arrow_array = BaseVarImpl._finish_building_arrow_array(self)
        return self._last_arrow_array

    cdef list _get_array_value(self):
        """
        Internal method to return the value of the array.
        """
        return self._values[:self.num_elements_in_array]

    cdef object _get_scalar_value(self, uint32_t pos):
        """
        Internal method to return the value of the variable at the given
        position.
        """
        return self._values[pos]

    @cython.boundscheck(False)
    @cython.wraparound(False)
    cdef int _set_scalar_value(self, uint32_t pos, object value) except -1:
        """
        Set the value of the variable at the given position. At this point it
        is assumed that all checks have been performed!
        """
        self._values[pos] = value


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\interchange\buffer.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# buffer.py
#
# Implements the Buffer class as documented in DataFrame API
# -----------------------------------------------------------------------------

from typing import Tuple

from .protocol import (
    Buffer,
    DlpackDeviceType,
)


class OracleColumnBuffer(Buffer):
    """
    OracleColumnBuffer represents a contiguous memory buffer in the DataFrame
    Interchange Protocol. It provides access to raw binary data that backs
    various components of the data frame such as column values, validity masks
    and offsets for variable-length data types.
    """

    def __init__(self, buffer_type, size_in_bytes, address) -> None:
        self.buffer_type = buffer_type
        self.size_in_bytes = size_in_bytes
        self.address = address

    def __dlpack__(self):
        """
        Represent this structure as a DLPack interface.
        """
        raise NotImplementedError("__dlpack__")

    def __dlpack_device__(self) -> Tuple[DlpackDeviceType, None]:
        """
        Device type and device ID for where the data
        in the buffer resides
        """
        return (DlpackDeviceType.CPU, None)

    def __repr__(self) -> str:
        device = self.__dlpack_device__()[0].name
        return (
            f"OracleColumnBuffer(bufsize={self.bufsize}, "
            f"ptr={self.ptr}, type={self.buffer_type}, device={device!r})"
        )

    @property
    def bufsize(self) -> int:
        """
        Returns the total size of buffer in bytes.
        """
        return self.size_in_bytes

    @property
    def ptr(self) -> int:
        """
        Returns the memory address of the buffer.
        """
        return self.address


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\interchange\column.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# column.py
#
# Implements the Column class as documented in DataFrame API
# -----------------------------------------------------------------------------

from typing import Any, Dict, Iterable, Optional, Tuple

from .buffer import OracleColumnBuffer
from .protocol import (
    CategoricalDescription,
    Column,
    Dtype,
    ColumnBuffers,
    ColumnNullType,
    DtypeKind,
)

from .nanoarrow_bridge import (
    NANOARROW_TIME_UNIT_SECOND,
    NANOARROW_TIME_UNIT_MILLI,
    NANOARROW_TIME_UNIT_MICRO,
    NANOARROW_TIME_UNIT_NANO,
    NANOARROW_TYPE_BINARY,
    NANOARROW_TYPE_DOUBLE,
    NANOARROW_TYPE_FLOAT,
    NANOARROW_TYPE_INT64,
    NANOARROW_TYPE_LARGE_BINARY,
    NANOARROW_TYPE_LARGE_STRING,
    NANOARROW_TYPE_STRING,
    NANOARROW_TYPE_TIMESTAMP,
    NANOARROW_TYPE_DECIMAL128,
)


class OracleColumn(Column):
    """
    OracleColumn represents a column in the DataFrame Interchange Protocol. It
    provides a standardized way to expose a column's data, metadata and chunks,
    allowing interoperability between data frame libraries.
    """

    def __init__(self, ora_arrow_array: object):
        self.ora_arrow_array = ora_arrow_array
        self._buffer_info = ora_arrow_array.get_buffer_info()

    def __arrow_c_array__(self, requested_schema=None):
        return self.ora_arrow_array.__arrow_c_array__(
            requested_schema=requested_schema
        )

    def _data_buffer(self):
        buffer = self._buffer_info.get("data")
        if buffer is None:
            return None
        size_bytes, address = buffer
        data_buffer = OracleColumnBuffer(
            size_in_bytes=size_bytes, address=address, buffer_type="data"
        )
        return data_buffer, self.dtype

    def _offsets_buffer(self):
        buffer = self._buffer_info.get("offsets")
        if buffer is None:
            return None
        size_bytes, address = buffer
        offsets_buffer = OracleColumnBuffer(
            size_in_bytes=size_bytes, address=address, buffer_type="offsets"
        )
        if self.ora_arrow_array.arrow_type in (
            NANOARROW_TYPE_LARGE_STRING,
            NANOARROW_TYPE_LARGE_BINARY,
        ):
            dtype = (DtypeKind.INT, 64, "l", "=")
        else:
            dtype = (DtypeKind.INT, 32, "i", "=")
        return offsets_buffer, dtype

    def _validity_buffer(self):
        buffer = self._buffer_info.get("validity")
        if buffer is None:
            return None
        size_bytes, address = buffer
        validity_buffer = OracleColumnBuffer(
            size_in_bytes=size_bytes, address=address, buffer_type="validity"
        )
        dtype = (DtypeKind.BOOL, 1, "b", "=")
        return validity_buffer, dtype

    def describe_categorical(self) -> CategoricalDescription:
        """
        Returns a description of a categorical data type.
        """
        raise NotImplementedError()

    @property
    def describe_null(self) -> Tuple[ColumnNullType, Optional[int]]:
        """
        Returns a description of the null representation used by the column.
        """
        if self.null_count == 0:
            return ColumnNullType.NON_NULLABLE, None
        else:
            return ColumnNullType.USE_BITMASK, 0

    @property
    def dtype(self) -> Dtype:
        """
        Returns the data type of the column. The returned dtype provides
        information on the storage format and the type of data in the column.
        """
        if self.ora_arrow_array.arrow_type == NANOARROW_TYPE_INT64:
            return (DtypeKind.INT, 64, "l", "=")
        elif self.ora_arrow_array.arrow_type == NANOARROW_TYPE_DOUBLE:
            return (DtypeKind.FLOAT, 64, "g", "=")
        elif self.ora_arrow_array.arrow_type == NANOARROW_TYPE_FLOAT:
            return (DtypeKind.FLOAT, 64, "g", "=")
        elif self.ora_arrow_array.arrow_type == NANOARROW_TYPE_STRING:
            return (DtypeKind.STRING, 8, "u", "=")
        elif self.ora_arrow_array.arrow_type == NANOARROW_TYPE_TIMESTAMP:
            if self.ora_arrow_array.time_unit == NANOARROW_TIME_UNIT_MICRO:
                return (DtypeKind.DATETIME, 64, "tsu:", "=")
            elif self.ora_arrow_array.time_unit == NANOARROW_TIME_UNIT_SECOND:
                return (DtypeKind.DATETIME, 64, "tss:", "=")
            elif self.ora_arrow_array.time_unit == NANOARROW_TIME_UNIT_MILLI:
                return (DtypeKind.DATETIME, 64, "tsm:", "=")
            elif self.ora_arrow_array.time_unit == NANOARROW_TIME_UNIT_NANO:
                return (DtypeKind.DATETIME, 64, "tsn:", "=")
        elif self.ora_arrow_array.arrow_type == NANOARROW_TYPE_DECIMAL128:
            array = self.ora_arrow_array
            return (
                DtypeKind.DECIMAL,
                128,
                f"d:{array.precision}.{array.scale}",
                "=",
            )
        elif self.ora_arrow_array.arrow_type == NANOARROW_TYPE_BINARY:
            return (DtypeKind.STRING, 8, "z", "=")
        elif self.ora_arrow_array.arrow_type == NANOARROW_TYPE_LARGE_BINARY:
            return (DtypeKind.STRING, 8, "Z", "=")
        elif self.ora_arrow_array.arrow_type == NANOARROW_TYPE_LARGE_STRING:
            return (DtypeKind.STRING, 8, "U", "=")

    def get_buffers(self) -> ColumnBuffers:
        """
        Returns a dictionary specifying the memory buffers backing the column.
        This currently consists of:
        - "data": the main buffer storing column values
        - "validity": a buffer containing null/missing values
        - "offsets": a buffer for variable-length types like string
        """
        return {
            "data": self._data_buffer(),
            "validity": self._validity_buffer(),
            "offsets": self._offsets_buffer(),
        }

    def get_chunks(self, n_chunks: Optional[int] = None) -> Iterable[Column]:
        """
        Return an iterator containing the column chunks. Currently this only
        returns itself.
        """
        yield self

    @property
    def metadata(self) -> Dict[str, Any]:
        """
        Returns metadata about the column.
        """
        return {
            "name": self.ora_arrow_array.name,
            "size": self.size(),
            "num_chunks": self.num_chunks(),
        }

    @property
    def null_count(self) -> int:
        """
        Returns the number of null elements.
        """
        return self.ora_arrow_array.null_count

    def num_chunks(self) -> int:
        """
        Returns the number of chunks used by the column. This method currently
        always returns the value 1, implying that the column uses contiguous
        memory.
        """
        return 1

    @property
    def offset(self) -> int:
        """
        Returns the offset of the first element.
        """
        return self.ora_arrow_array.offset

    def size(self) -> int:
        """
        Returns the number of elements in the column.
        """
        return len(self.ora_arrow_array)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\interchange\dataframe.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# dataframe.py
#
# Implement DataFrame class as documented in the standard
# https://data-apis.org/dataframe-protocol/latest/API.html
# -----------------------------------------------------------------------------

from typing import Any, Dict, Iterable, List, Optional, Sequence

from .column import OracleColumn

from .protocol import DataFrame


class OracleDataFrame(DataFrame):
    """
    OracleDataFrame is an implementation of the DataFrame Interchange Protocol.
    It provides an interface for exchanging tabular data between different data
    frame libraries (e.g. pandas, pyarrow, polars).
    """

    def __init__(
        self,
        oracle_arrow_arrays: List,
        allow_copy: bool = True,
    ):
        self._cols = []
        self._cols_map = {}
        self._rows = None
        self._arrays = oracle_arrow_arrays
        for ora_arrow_array in oracle_arrow_arrays:
            column = OracleColumn(ora_arrow_array=ora_arrow_array)
            self._rows = column.size()
            self._cols.append(column)
            self._cols_map[ora_arrow_array.name] = column
        self.allow_copy = allow_copy

    def __dataframe__(
        self,
        nan_as_null: bool = False,  # noqa: FBT001
        allow_copy: bool = True,  # noqa: FBT001
    ) -> DataFrame:
        """
        Returns a data frame adhering to the DataFrame Interchange protocol.
        """
        return self

    def get_chunks(
        self, n_chunks: Optional[int] = None
    ) -> Iterable[DataFrame]:
        """
        Returns an iterator for each of the chunks in the data frame. Since
        there is currently only one chunk, this simply returns itself.
        """
        yield self

    def column_arrays(self) -> List:
        """
        Returns a list of the Arrow arrays corresponding to each column in the
        data frame.
        """
        return self._arrays

    def column_names(self) -> List[str]:
        """
        Returns a list of the names of the columns in the data frame.
        """
        return list(self._cols_map.keys())

    def get_column(self, i: int) -> OracleColumn:
        """
        Returns a column from the data frame given its zero-based index. If the
        index is out of range, an IndexError exception is raised.
        """
        if i < 0 or i >= self.num_columns():
            raise IndexError(
                f"Column index {i} is out of bounds for "
                f"DataFrame with {self.num_columns()} columns"
            )
        return self._cols[i]

    def get_column_by_name(self, name: str) -> OracleColumn:
        """
        Returns a column from the data frame given the name of the column. If
        the column name is not found, a KeyError exception is raised.
        """
        if name not in self._cols_map:
            raise KeyError(f"Column {name} not found in DataFrame")
        return self._cols_map[name]

    def get_columns(self) -> List[OracleColumn]:
        """
        Returns a list of all of the columns in the data frame.
        """
        return self._cols

    @property
    def metadata(self) -> Dict[str, Any]:
        """
        Returns metadata for the data frame. Currently this returns
        information about the number of columns (num_columns), number of rows
        (num_rows) and number of chunks (num_chunks).
        """
        return {
            "num_columns": self.num_columns(),
            "num_rows": self.num_rows(),
            "num_chunks": self.num_chunks(),
        }

    def num_chunks(self) -> int:
        """
        Returns the number of chunks (contiguous memory blocks) in the data
        frame. Currently this always returns 1.
        """
        return 1

    def num_columns(self) -> int:
        """
        Returns the number of columns in the data frame.
        """
        return len(self._cols)

    def num_rows(self) -> int:
        """
        Returns the number of rows in the data frame.
        """
        return self._rows

    def select_columns(self, indices: Sequence[int]) -> "DataFrame":
        """
        Create a new DataFrame by selecting a subset of columns by index.
        """
        raise NotImplementedError()

    def select_columns_by_name(self, names: Sequence[str]) -> "DataFrame":
        """
        Create a new DataFrame by selecting a subset of columns by name.
        """
        raise NotImplementedError()


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\interchange\nanoarrow_bridge.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------
#------------------------------------------------------------------------------
# nanoarrow_bridge.pyx
#
# Cython wrapper around the Arrow C Data interface
#------------------------------------------------------------------------------

cimport cpython

from libc.stdint cimport uintptr_t
from libc.string cimport memcpy, strlen, strchr
from cpython.pycapsule cimport PyCapsule_New

from .. import errors

cdef extern from "nanoarrow/nanoarrow.c":

    ctypedef int ArrowErrorCode

    cdef union ArrowBufferViewData:
        const void* data

    cdef struct ArrowBufferView:
        ArrowBufferViewData data
        int64_t size_bytes

    cdef struct ArrowArrayView:
        ArrowBufferView *buffer_views

    cdef struct ArrowBuffer:
        uint8_t *data
        int64_t size_bytes

    cdef struct ArrowDecimal:
        pass

    cdef struct ArrowError:
        pass

    cdef struct ArrowStringView:
        const char* data
        int64_t size_bytes

    cdef ArrowErrorCode NANOARROW_OK

    void ArrowArrayRelease(ArrowArray *array)
    void ArrowSchemaRelease(ArrowSchema *schema)

    ArrowErrorCode ArrowArrayInitFromType(ArrowArray* array,
                                          ArrowType storage_type)
    ArrowErrorCode ArrowArrayAppendBytes(ArrowArray* array,
                                         ArrowBufferView value)
    ArrowErrorCode ArrowArrayAppendDouble(ArrowArray* array, double value)
    ArrowErrorCode ArrowArrayAppendNull(ArrowArray* array, int64_t n)
    ArrowErrorCode ArrowArrayAppendInt(ArrowArray* array, int64_t value)
    ArrowErrorCode ArrowArrayAppendDecimal(ArrowArray* array,
                                           const ArrowDecimal* value)
    ArrowBuffer* ArrowArrayBuffer(ArrowArray* array, int64_t i)
    ArrowErrorCode ArrowArrayFinishBuildingDefault(ArrowArray* array,
                                                   ArrowError* error)
    ArrowErrorCode ArrowArrayReserve(ArrowArray* array,
                                     int64_t additional_size_elements)
    ArrowErrorCode ArrowArrayStartAppending(ArrowArray* array)
    ArrowErrorCode ArrowArrayViewInitFromSchema(ArrowArrayView* array_view,
                                                const ArrowSchema* schema,
                                                ArrowError* error)
    ArrowErrorCode ArrowArrayViewSetArray(ArrowArrayView* array_view,
                                          const ArrowArray* array,
                                          ArrowError* error)
    int8_t ArrowBitGet(const uint8_t* bits, int64_t i)
    void ArrowSchemaInit(ArrowSchema* schema)
    ArrowErrorCode ArrowSchemaInitFromType(ArrowSchema* schema, ArrowType type)
    ArrowErrorCode ArrowSchemaSetTypeDateTime(ArrowSchema* schema,
                                              ArrowType arrow_type,
                                              ArrowTimeUnit time_unit,
                                              const char* timezone)
    ArrowErrorCode ArrowSchemaSetTypeDecimal(ArrowSchema* schema,
                                             ArrowType type,
                                             int32_t decimal_precision,
                                             int32_t decimal_scale)
    ArrowErrorCode ArrowSchemaSetName(ArrowSchema* schema, const char* name)
    int64_t ArrowSchemaToString(const ArrowSchema* schema, char* out,
                                int64_t n, char recursive)
    void ArrowDecimalInit(ArrowDecimal* decimal, int32_t bitwidth,
                          int32_t precision, int32_t scale)
    void ArrowDecimalSetBytes(ArrowDecimal *decimal, const uint8_t* value)
    ArrowErrorCode ArrowDecimalSetDigits(ArrowDecimal* decimal,
                                         ArrowStringView value)


cdef int _check_nanoarrow(int code) except -1:
    """
    Checks the return code of the nanoarrow function and raises an exception if
    it is not NANOARROW_OK.
    """
    if code != NANOARROW_OK:
        errors._raise_err(errors.ERR_ARROW_C_API_ERROR, code=code)


cdef void array_deleter(ArrowArray *array) noexcept:
    """
    Called when an external library calls the release for an Arrow array. This
    method simply marks the release as completed but doesn't actually do it, so
    that the handling of duplicate rows can still make use of the array, even
    if the external library no longer requires it!
    """
    array.release = NULL


cdef void pycapsule_array_deleter(object array_capsule) noexcept:
    cdef ArrowArray* array = <ArrowArray*> cpython.PyCapsule_GetPointer(
        array_capsule, "arrow_array"
    )
    if array.release != NULL:
        ArrowArrayRelease(array)


cdef void pycapsule_schema_deleter(object schema_capsule) noexcept:
    cdef ArrowSchema* schema = <ArrowSchema*> cpython.PyCapsule_GetPointer(
        schema_capsule, "arrow_schema"
    )
    if schema.release != NULL:
        ArrowSchemaRelease(schema)


cdef class OracleArrowArray:

    def __cinit__(self, ArrowType arrow_type, str name, int8_t precision,
                  int8_t scale, ArrowTimeUnit time_unit):
        cdef ArrowType storage_type = arrow_type
        self.arrow_type = arrow_type
        self.time_unit = time_unit
        self.name = name
        self.arrow_array = \
                <ArrowArray*> cpython.PyMem_Malloc(sizeof(ArrowArray))
        if arrow_type == NANOARROW_TYPE_TIMESTAMP:
            storage_type = NANOARROW_TYPE_INT64
        if time_unit == NANOARROW_TIME_UNIT_MILLI:
            self.factor = 1e3
        elif time_unit == NANOARROW_TIME_UNIT_MICRO:
            self.factor = 1e6
        elif time_unit == NANOARROW_TIME_UNIT_NANO:
            self.factor = 1e9
        else:
            self.factor = 1

        _check_nanoarrow(ArrowArrayInitFromType(self.arrow_array,
                                                storage_type))
        self.arrow_schema = \
                <ArrowSchema*> cpython.PyMem_Malloc(sizeof(ArrowSchema))
        _check_nanoarrow(ArrowArrayStartAppending(self.arrow_array))
        if arrow_type == NANOARROW_TYPE_DECIMAL128:
            self.precision = precision
            self.scale = scale
            ArrowSchemaInit(self.arrow_schema)
            _check_nanoarrow(ArrowSchemaSetTypeDecimal(self.arrow_schema,
                                                       arrow_type,
                                                       precision, scale))
        else:
            _check_nanoarrow(ArrowSchemaInitFromType(self.arrow_schema,
                                                     storage_type))
            if arrow_type == NANOARROW_TYPE_TIMESTAMP:
                _check_nanoarrow(ArrowSchemaSetTypeDateTime(self.arrow_schema,
                                                            arrow_type,
                                                            time_unit, NULL))
        _check_nanoarrow(ArrowSchemaSetName(self.arrow_schema, name.encode()))

    def __dealloc__(self):
        if self.arrow_array != NULL:
            if self.arrow_array.release == NULL:
                self.arrow_array.release = self.actual_array_release
            if self.arrow_array.release != NULL:
                ArrowArrayRelease(self.arrow_array)
            cpython.PyMem_Free(self.arrow_array)
        if self.arrow_schema != NULL:
            if self.arrow_schema.release != NULL:
                ArrowSchemaRelease(self.arrow_schema)
            cpython.PyMem_Free(self.arrow_schema)

    def __len__(self):
        return self.arrow_array.length

    def __repr__(self):
        return (
            f"OracleArrowArray(name={self.name}, "
            f"len={self.arrow_array.length}, "
            f"type={self._schema_to_string()})"
        )

    def __str__(self):
        return self.__repr__()

    cdef str _schema_to_string(self):
        """
        Converts the schema to a string representation.
        """
        cdef char buffer[81]
        ArrowSchemaToString(self.arrow_schema, buffer, sizeof(buffer), 0)
        return buffer.decode()

    cdef int append_bytes(self, void* ptr, int64_t num_bytes) except -1:
        """
        Append a value of type bytes to the array.
        """
        cdef ArrowBufferView data
        data.data.data = ptr
        data.size_bytes = num_bytes
        _check_nanoarrow(ArrowArrayAppendBytes(self.arrow_array, data))

    cdef int append_decimal(self, void* ptr, int64_t num_bytes) except -1:
        """
        Append a value of type ArrowDecimal to the array

        Arrow decimals are fixed-point decimal numbers encoded as a
        scaled integer. decimal128(7, 3) can exactly represent the numbers
        1234.567 and -1234.567 encoded internally as the 128-bit integers
        1234567 and -1234567, respectively.
        """
        cdef:
            ArrowStringView decimal_view
            ArrowDecimal decimal
        decimal_view.data = <char*> ptr
        decimal_view.size_bytes = num_bytes
        ArrowDecimalInit(&decimal, 128, self.precision, self.scale)
        _check_nanoarrow(ArrowDecimalSetDigits(&decimal, decimal_view))
        _check_nanoarrow(ArrowArrayAppendDecimal(self.arrow_array, &decimal))

    cdef int append_double(self, double value) except -1:
        """
        Append a value of type double to the array.
        """
        _check_nanoarrow(ArrowArrayAppendDouble(self.arrow_array, value))

    cdef int append_float(self, float value) except -1:
        """
        Append a value of type float to the array.
        """
        self.append_double(value)

    cdef int append_int64(self, int64_t value) except -1:
        """
        Append a value of type int64_t to the array.
        """
        _check_nanoarrow(ArrowArrayAppendInt(self.arrow_array, value))

    cdef int append_last_value(self, OracleArrowArray array) except -1:
        """
        Appends the last value of the given array to this array.
        """
        cdef:
            int32_t start_offset, end_offset
            ArrowBuffer *offsets_buffer
            ArrowBuffer *data_buffer
            ArrowDecimal decimal
            int64_t *as_int64
            int32_t *as_int32
            double *as_double
            float *as_float
            int8_t as_bool
            int64_t index
            uint8_t *ptr
            void* temp
        if array is None:
            array = self
        index = array.arrow_array.length - 1
        if array.arrow_type in (NANOARROW_TYPE_INT64, NANOARROW_TYPE_TIMESTAMP):
            data_buffer = ArrowArrayBuffer(array.arrow_array, 1)
            as_int64 = <int64_t*> data_buffer.data
            self.append_int64(as_int64[index])
        elif array.arrow_type == NANOARROW_TYPE_DOUBLE:
            data_buffer = ArrowArrayBuffer(array.arrow_array, 1)
            as_double = <double*> data_buffer.data
            self.append_double(as_double[index])
        elif array.arrow_type == NANOARROW_TYPE_FLOAT:
            data_buffer = ArrowArrayBuffer(array.arrow_array, 1)
            as_float = <float*> data_buffer.data
            self.append_double(as_float[index])
        elif array.arrow_type == NANOARROW_TYPE_BOOL:
            data_buffer = ArrowArrayBuffer(array.arrow_array, 1)
            as_bool = ArrowBitGet(data_buffer.data, index)
            self.append_int64(as_bool)
        elif array.arrow_type == NANOARROW_TYPE_DECIMAL128:
            data_buffer = ArrowArrayBuffer(array.arrow_array, 1)
            ArrowDecimalInit(&decimal, 128, self.precision, self.scale)
            ptr = data_buffer.data + index * 16
            ArrowDecimalSetBytes(&decimal, ptr)
            _check_nanoarrow(ArrowArrayAppendDecimal(self.arrow_array,
                                                     &decimal))
        elif array.arrow_type in (
                NANOARROW_TYPE_BINARY,
                NANOARROW_TYPE_STRING
        ):
            offsets_buffer = ArrowArrayBuffer(array.arrow_array, 1)
            data_buffer = ArrowArrayBuffer(array.arrow_array, 2)
            as_int32 = <int32_t*> offsets_buffer.data
            start_offset = as_int32[index]
            end_offset = as_int32[index + 1]
            temp = cpython.PyMem_Malloc(end_offset - start_offset)
            memcpy(temp, &data_buffer.data[start_offset],
                   end_offset - start_offset)
            try:
                self.append_bytes(temp, end_offset - start_offset)
            finally:
                cpython.PyMem_Free(temp)

        elif array.arrow_type in (
                NANOARROW_TYPE_LARGE_BINARY,
                NANOARROW_TYPE_LARGE_STRING
        ):
            offsets_buffer = ArrowArrayBuffer(array.arrow_array, 1)
            data_buffer = ArrowArrayBuffer(array.arrow_array, 2)
            as_int64 = <int64_t*> offsets_buffer.data
            start_offset = as_int64[index]
            end_offset = as_int64[index + 1]
            temp = cpython.PyMem_Malloc(end_offset - start_offset)
            memcpy(temp, &data_buffer.data[start_offset],
                   end_offset - start_offset)
            try:
                self.append_bytes(temp, end_offset - start_offset)
            finally:
                cpython.PyMem_Free(temp)

    cdef int append_null(self) except -1:
        """
        Append a null value to the array.
        """
        _check_nanoarrow(ArrowArrayAppendNull(self.arrow_array, 1))

    cdef int finish_building(self) except -1:
        """
        Finish building the array. No more data will be added to it.
        """
        _check_nanoarrow(ArrowArrayFinishBuildingDefault(self.arrow_array,
                                                         NULL))

    def get_buffer_info(self):
        """
        Get buffer information required by the dataframe interchange logic.
        """
        cdef:
            int64_t n_buffers = self.arrow_array.n_buffers
            ArrowBufferView *buffer
            ArrowArrayView view
        _check_nanoarrow(ArrowArrayViewInitFromSchema(&view, self.arrow_schema,
                                                      NULL))
        _check_nanoarrow(ArrowArrayViewSetArray(&view, self.arrow_array, NULL))

        # initialize all buffers to None to begin with
        buffers = {
            "validity": None,
            "offsets": None,
            "data": None
        }

        # validity buffer
        if n_buffers > 0 and self.arrow_array.null_count > 0:
            buffer = &view.buffer_views[0]
            buffers["validity"] = (
                buffer.size_bytes,
                <uintptr_t> buffer.data.data
            )

        # data / offset buffer
        if n_buffers == 2:
            buffer = &view.buffer_views[1]
            buffers["data"] = (
                buffer.size_bytes,
                <uintptr_t> buffer.data.data
            )
        elif n_buffers == 3:
            buffer = &view.buffer_views[1]
            buffers["offsets"] = (
                buffer.size_bytes,
                <uintptr_t> buffer.data.data
            )
            buffer = &view.buffer_views[2]
            buffers["data"] = (
                buffer.size_bytes,
                <uintptr_t> buffer.data.data
            )

        return buffers

    @property
    def null_count(self) -> int:
        return self.arrow_array.null_count

    @property
    def offset(self) -> int:
        return self.arrow_array.offset

    def __arrow_c_array__(self, requested_schema=None):
        """
        Returns
        -------
        Tuple[PyCapsule, PyCapsule]
            A pair of PyCapsules containing a C ArrowSchema and ArrowArray,
            respectively.
        """
        if requested_schema is not None:
            raise NotImplementedError("requested_schema")

        array_capsule = PyCapsule_New(
            self.arrow_array, 'arrow_array', &pycapsule_array_deleter
        )
        self.actual_array_release = self.arrow_array.release
        self.arrow_array.release = array_deleter
        schema_capsule = PyCapsule_New(
            self.arrow_schema, "arrow_schema", &pycapsule_schema_deleter
        )
        return schema_capsule, array_capsule


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\interchange\protocol.py
# ========================================

# -----------------------------------------------------------------------------
# MIT License

# Copyright (c) 2025 Consortium for Python Data API Standards contributors

# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:

# The above copyright notice and this permission notice shall be included in
# all copies or substantial portions of the Software.

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# protocol.py
#
# Implement DataFrame class as documented in the standard
# https://data-apis.org/dataframe-protocol/latest/API.html
#
# The DataFrame API standard has this file with the following changes:
# https://github.com/data-apis/dataframe-api/blob/main/protocol/dataframe_protocol.py
#   - addition of license and this block of comments
#   - addition of DtypeKind DECIMAL (24)
#   - correction of typing for Column for older versions of Python
#   - Black formatting
# -----------------------------------------------------------------------------

from abc import (
    ABC,
    abstractmethod,
)
import enum
from typing import (
    Any,
    Dict,
    Iterable,
    Optional,
    Sequence,
    Tuple,
    TypedDict,
)


class DlpackDeviceType(enum.IntEnum):
    """Integer enum for device type codes matching DLPack."""

    CPU = 1
    CUDA = 2
    CPU_PINNED = 3
    OPENCL = 4
    VULKAN = 7
    METAL = 8
    VPI = 9
    ROCM = 10


class DtypeKind(enum.IntEnum):
    """
    Integer enum for data types.

    Attributes
    ----------
    INT : int
        Matches to signed integer data type.
    UINT : int
        Matches to unsigned integer data type.
    FLOAT : int
        Matches to floating point data type.
    BOOL : int
        Matches to boolean data type.
    STRING : int
        Matches to string data type (UTF-8 encoded).
    DATETIME : int
        Matches to datetime data type.
    CATEGORICAL : int
        Matches to categorical data type.
    """

    INT = 0
    UINT = 1
    FLOAT = 2
    BOOL = 20
    STRING = 21  # UTF-8
    DATETIME = 22
    CATEGORICAL = 23
    DECIMAL = 24


Dtype = Tuple[DtypeKind, int, str, str]  # see Column.dtype


class ColumnNullType(enum.IntEnum):
    """
    Integer enum for null type representation.

    Attributes
    ----------
    NON_NULLABLE : int
        Non-nullable column.
    USE_NAN : int
        Use explicit float NaN value.
    USE_SENTINEL : int
        Sentinel value besides NaN.
    USE_BITMASK : int
        The bit is set/unset representing a null on a certain position.
    USE_BYTEMASK : int
        The byte is set/unset representing a null on a certain position.
    """

    NON_NULLABLE = 0
    USE_NAN = 1
    USE_SENTINEL = 2
    USE_BITMASK = 3
    USE_BYTEMASK = 4


class ColumnBuffers(TypedDict):
    # first element is a buffer containing the column data;
    # second element is the data buffer's associated dtype
    data: Tuple["Buffer", Dtype]

    # first element is a buffer containing mask values indicating missing data;
    # second element is the mask value buffer's associated dtype.
    # None if the null representation is not a bit or byte mask
    validity: Optional[Tuple["Buffer", Dtype]]

    # first element is a buffer containing the offset values for
    # variable-size binary data (e.g., variable-length strings);
    # second element is the offsets buffer's associated dtype.
    # None if the data buffer does not have an associated offsets buffer
    offsets: Optional[Tuple["Buffer", Dtype]]


class CategoricalDescription(TypedDict):
    # whether the ordering of dictionary indices is semantically meaningful
    is_ordered: bool
    # whether a dictionary-style mapping of categorical values to other objects
    # exists
    is_dictionary: bool
    # Python-level only (e.g. ``{int: str}``).
    # None if not a dictionary-style categorical.
    categories: Optional["Column"]


class Buffer(ABC):
    """
    Data in the buffer is guaranteed to be contiguous in memory.

    Note that there is no dtype attribute present, a buffer can be thought of
    as simply a block of memory. However, if the column that the buffer is
    attached to has a dtype that's supported by DLPack and ``__dlpack__`` is
    implemented, then that dtype information will be contained in the return
    value from ``__dlpack__``.

    This distinction is useful to support both data exchange via DLPack on a
    buffer and (b) dtypes like variable-length strings which do not have a
    fixed number of bytes per element.
    """

    @property
    @abstractmethod
    def bufsize(self) -> int:
        """
        Buffer size in bytes.
        """
        pass

    @property
    @abstractmethod
    def ptr(self) -> int:
        """
        Pointer to start of the buffer as an integer.
        """
        pass

    @abstractmethod
    def __dlpack__(self):
        """
        Produce DLPack capsule (see array API standard).

        Raises:

            - TypeError : if the buffer contains unsupported dtypes.
            - NotImplementedError : if DLPack support is not implemented

        Useful to have to connect to array libraries. Support optional because
        it's not completely trivial to implement for a Python-only library.
        """
        raise NotImplementedError("__dlpack__")

    @abstractmethod
    def __dlpack_device__(self) -> Tuple[DlpackDeviceType, Optional[int]]:
        """
        Device type and device ID for where the data in the buffer resides.
        Uses device type codes matching DLPack.
        Note: must be implemented even if ``__dlpack__`` is not.
        """
        pass


class Column(ABC):
    """
    A column object, with only the methods and properties required by the
    interchange protocol defined.

    A column can contain one or more chunks. Each chunk can contain up to three
    buffers - a data buffer, a mask buffer (depending on null representation),
    and an offsets buffer (if variable-size binary; e.g., variable-length
    strings).

    TBD: there's also the "chunk" concept here, which is implicit in Arrow as
         multiple buffers per array (= column here). Semantically it may make
         sense to have both: chunks were meant for example for lazy evaluation
         of data which doesn't fit in memory, while multiple buffers per column
         could also come from doing a selection operation on a single
         contiguous buffer.

         Given these concepts, one would expect chunks to be all of the same
         size (say a 10,000 row dataframe could have 10 chunks of 1,000 rows),
         while multiple buffers could have data-dependent lengths. Not an issue
         in pandas if one column is backed by a single NumPy array, but in
         Arrow it seems possible.
         Are multiple chunks *and* multiple buffers per column necessary for
         the purposes of this interchange protocol, or must producers either
         reuse the chunk concept for this or copy the data?

    Note: this Column object can only be produced by ``__dataframe__``, so
          doesn't need its own version or ``__column__`` protocol.
    """

    @abstractmethod
    def size(self) -> int:
        """
        Size of the column, in elements.

        Corresponds to DataFrame.num_rows() if column is a single chunk;
        equal to size of this current chunk otherwise.

        Is a method rather than a property because it may cause a (potentially
        expensive) computation for some dataframe implementations.
        """
        pass

    @property
    @abstractmethod
    def offset(self) -> int:
        """
        Offset of first element.

        May be > 0 if using chunks; for example for a column with N chunks of
        equal size M (only the last chunk may be shorter),
        ``offset = n * M``, ``n = 0 .. N-1``.
        """
        pass

    @property
    @abstractmethod
    def dtype(self) -> Dtype:
        """
        Dtype description as a tuple ``(kind, bit-width, format string,
        endianness)``.

        Bit-width : the number of bits as an integer
        Format string : data type description format string in Apache Arrow C
                        Data Interface format.
        Endianness : current only native endianness (``=``) is supported

        Notes:
            - Kind specifiers are aligned with DLPack where possible (hence the
              jump to 20, leave enough room for future extension)
            - Masks must be specified as boolean with either bit width 1 (for
              bit masks) or 8 (for byte masks).
            - Dtype width in bits was preferred over bytes
            - Endianness isn't too useful, but included now in case in the
              future we need to support non-native endianness
            - Went with Apache Arrow format strings over NumPy format strings
              because they're more complete from a dataframe perspective
            - Format strings are mostly useful for datetime specification, and
              for categoricals.
            - For categoricals, the format string describes the type of the
              categorical in the data buffer. In case of a separate encoding of
              the categorical (e.g. an integer to string mapping), this can
              be derived from ``self.describe_categorical``.
            - Data types not included: complex, Arrow-style null, binary,
              decimal, and nested (list, struct, map, union) dtypes.
        """
        pass

    @property
    @abstractmethod
    def describe_categorical(self) -> CategoricalDescription:
        """
        If the dtype is categorical, there are two options:
        - There are only values in the data buffer.
        - There is a separate non-categorical Column encoding categorical
          values.

        Raises TypeError if the dtype is not categorical

        Returns the dictionary with description on how to interpret the data
        buffer:
            - "is_ordered" : bool, whether the ordering of dictionary indices
                             is semantically meaningful.
            - "is_dictionary" : bool, whether a mapping of
                                categorical values to other objects exists
            - "categories" : Column representing the (implicit) mapping of
                             indices to category values (e.g. an array of cat1,
                             cat2, ...).
                             None if not a dictionary-style categorical.

        TBD: are there any other in-memory representations that are needed?
        """
        pass

    @property
    @abstractmethod
    def describe_null(self) -> Tuple[ColumnNullType, Any]:
        """
        Return the missing value (or "null") representation the column dtype
        uses, as a tuple ``(kind, value)``.

        Value : if kind is "sentinel value", the actual value. If kind is a bit
        mask or a byte mask, the value (0 or 1) indicating a missing value.
        None otherwise.
        """
        pass

    @property
    @abstractmethod
    def null_count(self) -> Optional[int]:
        """
        Number of null elements, if known.

        Note: Arrow uses -1 to indicate "unknown", but None seems cleaner.
        """
        pass

    @property
    @abstractmethod
    def metadata(self) -> Dict[str, Any]:
        """
        The metadata for the column. See `DataFrame.metadata` for more details.
        """
        pass

    @abstractmethod
    def num_chunks(self) -> int:
        """
        Return the number of chunks the column consists of.
        """
        pass

    @abstractmethod
    def get_chunks(self, n_chunks: Optional[int] = None) -> Iterable["Column"]:
        """
        Return an iterator yielding the chunks.

        See `DataFrame.get_chunks` for details on ``n_chunks``.
        """
        pass

    @abstractmethod
    def get_buffers(self) -> ColumnBuffers:
        """
        Return a dictionary containing the underlying buffers.

        The returned dictionary has the following contents:

            - "data": a two-element tuple whose first element is a buffer
                      containing the data and whose second element is the data
                      buffer's associated dtype.
            - "validity": a two-element tuple whose first element is a buffer
                          containing mask values indicating missing data and
                          whose second element is the mask value buffer's
                          associated dtype. None if the null representation is
                          not a bit or byte mask.
            - "offsets": a two-element tuple whose first element is a buffer
                         containing the offset values for variable-size binary
                         data (e.g., variable-length strings) and whose second
                         element is the offsets buffer's associated dtype. None
                         if the data buffer does not have an associated offsets
                         buffer.
        """
        pass


#    def get_children(self) -> Iterable[Column]:
#        """
#        Children columns underneath the column, each object in this iterator
#        must adhere to the column specification.
#        """
#        pass


class DataFrame(ABC):
    """
    A data frame class, with only the methods required by the interchange
    protocol defined.

    A "data frame" represents an ordered collection of named columns.
    A column's "name" must be a unique string.
    Columns may be accessed by name or by position.

    This could be a public data frame class, or an object with the methods and
    attributes defined on this DataFrame class could be returned from the
    ``__dataframe__`` method of a public data frame class in a library adhering
    to the dataframe interchange protocol specification.
    """

    version = 0  # version of the protocol

    @abstractmethod
    def __dataframe__(
        self, nan_as_null: bool = False, allow_copy: bool = True
    ) -> "DataFrame":
        """
        Construct a new exchange object, potentially changing the parameters.

        ``nan_as_null`` is a DEPRECATED keyword that should not be used. See
        warning below.
        ``allow_copy`` is a keyword that defines whether or not the library is
        allowed to make a copy of the data. For example, copying data would be
        necessary if a library supports strided buffers, given that this
        protocol specifies contiguous buffers.

        WARNING: the ``nan_as_null`` parameter will be removed from the API
        protocol.  Please avoid passing it as either a positional or keyword
        argument. Call this method using ``.__dataframe__(allow_copy=...)``.
        """
        pass

    @property
    @abstractmethod
    def metadata(self) -> Dict[str, Any]:
        """
        The metadata for the data frame, as a dictionary with string keys. The
        contents of `metadata` may be anything, they are meant for a library
        to store information that it needs to, e.g., roundtrip losslessly or
        for two implementations to share data that is not (yet) part of the
        interchange protocol specification. For avoiding collisions with other
        entries, please add name the keys with the name of the library
        followed by a period and the desired name, e.g, ``pandas.indexcol``.
        """
        pass

    @abstractmethod
    def num_columns(self) -> int:
        """
        Return the number of columns in the DataFrame.
        """
        pass

    @abstractmethod
    def num_rows(self) -> Optional[int]:
        # TODO: not happy with Optional, but need to flag it may be expensive
        #       why include it if it may be None - what do we expect consumers
        #       to do here?
        """
        Return the number of rows in the DataFrame, if available.
        """
        pass

    @abstractmethod
    def num_chunks(self) -> int:
        """
        Return the number of chunks the DataFrame consists of.
        """
        pass

    @abstractmethod
    def column_names(self) -> Iterable[str]:
        """
        Return an iterator yielding the column names.
        """
        pass

    @abstractmethod
    def get_column(self, i: int) -> Column:
        """
        Return the column at the indicated position.
        """
        pass

    @abstractmethod
    def get_column_by_name(self, name: str) -> Column:
        """
        Return the column whose name is the indicated name.
        """
        pass

    @abstractmethod
    def get_columns(self) -> Iterable[Column]:
        """
        Return an iterator yielding the columns.
        """
        pass

    @abstractmethod
    def select_columns(self, indices: Sequence[int]) -> "DataFrame":
        """
        Create a new DataFrame by selecting a subset of columns by index.
        """
        pass

    @abstractmethod
    def select_columns_by_name(self, names: Sequence[str]) -> "DataFrame":
        """
        Create a new DataFrame by selecting a subset of columns by name.
        """
        pass

    @abstractmethod
    def get_chunks(
        self, n_chunks: Optional[int] = None
    ) -> Iterable["DataFrame"]:
        """
        Return an iterator yielding the chunks.

        By default (None), yields the chunks that the data is stored as by the
        producer. If given, ``n_chunks`` must be a multiple of
        ``self.num_chunks()``, meaning the producer must subdivide each chunk
        before yielding it.

        Note that the producer must ensure that all columns are chunked the
        same way.
        """
        pass


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\interchange\__init__.py
# ========================================



# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\lob.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2021, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# lob.py
#
# Contains the LOB class for managing BLOB, CLOB, NCLOB and BFILE data.
# -----------------------------------------------------------------------------

from typing import Any, Union

from .base_impl import DB_TYPE_BFILE, DB_TYPE_BLOB
from . import __name__ as MODULE_NAME
from . import errors


class BaseLOB:
    __module__ = MODULE_NAME

    def __del__(self):
        self._impl.free_lob()

    def _check_is_bfile(self):
        if self._impl.dbtype is not DB_TYPE_BFILE:
            errors._raise_err(errors.ERR_OPERATION_ONLY_SUPPORTED_ON_BFILE)

    def _check_not_bfile(self):
        if self._impl.dbtype is DB_TYPE_BFILE:
            errors._raise_err(errors.ERR_OPERATION_NOT_SUPPORTED_ON_BFILE)

    def _check_value_to_write(self, value):
        """
        Check the value to write and return the actual value to write.
        Character LOBs must write strings but can accept UTF-8 encoded bytes
        (which will be decoded to strings). Binary LOBs must write bytes but
        can accept strings (which will be encoded in UTF-8).
        """
        if self.type is DB_TYPE_BLOB:
            if isinstance(value, str):
                return value.encode()
            elif isinstance(value, bytes):
                return value
        else:
            if isinstance(value, str):
                return value
            elif isinstance(value, bytes):
                return value.decode()
        raise TypeError("expecting string or bytes")

    @classmethod
    def _from_impl(cls, impl):
        lob = cls.__new__(cls)
        lob._impl = impl
        return lob

    def getfilename(self) -> tuple:
        """
        Return a two-tuple consisting of the directory alias and file name for
        a BFILE type LOB.
        """
        self._check_is_bfile()
        return self._impl.get_file_name()

    def setfilename(self, dir_alias: str, name: str) -> None:
        """
        Set the directory alias and name of a BFILE type LOB.
        """
        self._check_is_bfile()
        self._impl.set_file_name(dir_alias, name)

    @property
    def type(self) -> Any:
        """
        Returns the type of the LOB as one of the database type constants.
        """
        return self._impl.dbtype


class LOB(BaseLOB):
    __module__ = MODULE_NAME

    def __reduce__(self):
        value = self.read()
        return (type(value), (value,))

    def __str__(self):
        return self.read()

    def close(self) -> None:
        """
        Close the LOB. Call this when writing is completed so that the indexes
        associated with the LOB can be updated -– but only if open() was called
        first.
        """
        self._impl.close()

    def fileexists(self) -> bool:
        """
        Return a boolean indicating if the file referenced by a BFILE type LOB
        exists.
        """
        self._check_is_bfile()
        return self._impl.file_exists()

    def getchunksize(self) -> int:
        """
        Return the chunk size for the LOB. Reading and writing to the LOB in
        chunks of multiples of this size will improve performance.
        """
        self._check_not_bfile()
        return self._impl.get_chunk_size()

    def isopen(self) -> bool:
        """
        Return a boolean indicating if the LOB has been opened using the method
        open().
        """
        return self._impl.get_is_open()

    def open(self) -> None:
        """
        Open the LOB for writing. This will improve performance when writing to
        the LOB in chunks and there are functional or extensible indexes
        associated with the LOB. If this method is not called, each write will
        perform an open internally followed by a close after the write has been
        completed.
        """
        self._impl.open()

    def read(self, offset: int = 1, amount: int = None) -> Union[str, bytes]:
        """
        Return a portion (or all) of the data in the LOB. Note that the amount
        and offset are in bytes for BLOB and BFILE type LOBs and in UCS-2 code
        points for CLOB and NCLOB type LOBs. UCS-2 code points are equivalent
        to characters for all but supplemental characters. If supplemental
        characters are in the LOB, the offset and amount will have to be chosen
        carefully to avoid splitting a character.
        """
        if amount is None:
            amount = self._impl.get_max_amount()
            if amount >= offset:
                amount = amount - offset + 1
            else:
                amount = 1
        elif amount <= 0:
            errors._raise_err(errors.ERR_INVALID_LOB_AMOUNT)
        if offset <= 0:
            errors._raise_err(errors.ERR_INVALID_LOB_OFFSET)
        return self._impl.read(offset, amount)

    def size(self) -> int:
        """
        Returns the size of the data in the LOB. For BLOB and BFILE type LOBs
        this is the number of bytes. For CLOB and NCLOB type LOBs this is the
        number of UCS-2 code points. UCS-2 code points are equivalent to
        characters for all but supplemental characters.
        """
        return self._impl.get_size()

    def trim(self, new_size: int = 0, *, newSize: int = None) -> None:
        """
        Trim the LOB to the new size (the second parameter is deprecated and
        should not be used).
        """
        self._check_not_bfile()
        if newSize is not None:
            if new_size != 0:
                errors._raise_err(
                    errors.ERR_DUPLICATED_PARAMETER,
                    deprecated_name="newSize",
                    new_name="new_size",
                )
            new_size = newSize
        self._impl.trim(new_size)

    def write(self, data: Union[str, bytes], offset: int = 1) -> None:
        """
        Write the data to the LOB at the given offset. The offset is in bytes
        for BLOB type LOBs and in UCS-2 code points for CLOB and NCLOB type
        LOBs. UCS-2 code points are equivalent to characters for all but
        supplemental characters. If supplemental characters are in the LOB, the
        offset will have to be chosen carefully to avoid splitting a character.
        Note that if you want to make the LOB value smaller, you must use the
        trim() function.
        """
        self._check_not_bfile()
        self._impl.write(self._check_value_to_write(data), offset)


class AsyncLOB(BaseLOB):
    __module__ = MODULE_NAME

    async def close(self) -> None:
        """
        Close the LOB. Call this when writing is completed so that the indexes
        associated with the LOB can be updated -– but only if open() was called
        first.
        """
        await self._impl.close()

    async def fileexists(self) -> bool:
        """
        Return a boolean indicating if the file referenced by a BFILE type LOB
        exists.
        """
        self._check_is_bfile()
        return await self._impl.file_exists()

    async def getchunksize(self) -> int:
        """
        Return the chunk size for the LOB. Reading and writing to the LOB in
        chunks of multiples of this size will improve performance.
        """
        self._check_not_bfile()
        return await self._impl.get_chunk_size()

    async def isopen(self) -> bool:
        """
        Return a boolean indicating if the LOB has been opened using the method
        open().
        """
        return await self._impl.get_is_open()

    async def open(self) -> None:
        """
        Open the LOB for writing. This will improve performance when writing to
        the LOB in chunks and there are functional or extensible indexes
        associated with the LOB. If this method is not called, each write will
        perform an open internally followed by a close after the write has been
        completed.
        """
        await self._impl.open()

    async def read(
        self, offset: int = 1, amount: int = None
    ) -> Union[str, bytes]:
        """
        Return a portion (or all) of the data in the LOB. Note that the amount
        and offset are in bytes for BLOB and BFILE type LOBs and in UCS-2 code
        points for CLOB and NCLOB type LOBs. UCS-2 code points are equivalent
        to characters for all but supplemental characters. If supplemental
        characters are in the LOB, the offset and amount will have to be chosen
        carefully to avoid splitting a character.
        """
        if amount is None:
            amount = self._impl.get_max_amount()
            if amount >= offset:
                amount = amount - offset + 1
            else:
                amount = 1
        if offset <= 0:
            errors._raise_err(errors.ERR_INVALID_LOB_OFFSET)
        return await self._impl.read(offset, amount)

    async def size(self) -> int:
        """
        Returns the size of the data in the LOB. For BLOB and BFILE type LOBs
        this is the number of bytes. For CLOB and NCLOB type LOBs this is the
        number of UCS-2 code points. UCS-2 code points are equivalent to
        characters for all but supplemental characters.
        """
        return await self._impl.get_size()

    async def trim(self, new_size: int = 0, *, newSize: int = None) -> None:
        """
        Trim the LOB to the new size (the second parameter is deprecated and
        should not be used).
        """
        self._check_not_bfile()
        if newSize is not None:
            if new_size != 0:
                errors._raise_err(
                    errors.ERR_DUPLICATED_PARAMETER,
                    deprecated_name="newSize",
                    new_name="new_size",
                )
            new_size = newSize
        await self._impl.trim(new_size)

    async def write(self, data: Union[str, bytes], offset: int = 1) -> None:
        """
        Write the data to the LOB at the given offset. The offset is in bytes
        for BLOB type LOBs and in UCS-2 code points for CLOB and NCLOB type
        LOBs. UCS-2 code points are equivalent to characters for all but
        supplemental characters. If supplemental characters are in the LOB, the
        offset will have to be chosen carefully to avoid splitting a character.
        Note that if you want to make the LOB value smaller, you must use the
        trim() function.
        """
        self._check_not_bfile()
        await self._impl.write(self._check_value_to_write(data), offset)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\pipeline.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# pipeline.py
#
# Contains the Pipeline class used for executing multiple operations.
# -----------------------------------------------------------------------------

from typing import Any, Callable, Union

from . import __name__ as MODULE_NAME
from . import utils
from .defaults import defaults
from .fetch_info import FetchInfo
from .base_impl import PipelineImpl, PipelineOpImpl, PipelineOpResultImpl
from .enums import PipelineOpType
from .errors import _Error


class PipelineOp:
    __module__ = MODULE_NAME

    def __repr__(self):
        typ = self.__class__
        cls_name = f"{typ.__module__}.{typ.__qualname__}"
        return f"<{cls_name} of type {self.op_type.name}>"

    def _create_result(self):
        """
        Internal method used for creating a result object that is returned when
        running a pipeline.
        """
        impl = PipelineOpResultImpl(self._impl)
        result = PipelineOpResult.__new__(PipelineOpResult)
        result._operation = self
        result._impl = impl
        return result

    @property
    def arraysize(self) -> int:
        """
        Returns the array size to use when fetching all of the rows in a query.
        For all other operations the value returned is 0.
        """
        return self._impl.arraysize

    @property
    def keyword_parameters(self) -> Any:
        """
        Returns the keyword parameters to the stored procedure or function
        being called by the operation, if applicable.
        """
        return self._impl.keyword_parameters

    @property
    def name(self) -> Union[str, None]:
        """
        Returns the name of the stored procedure or function being called by
        the operation, if applicable.
        """
        return self._impl.name

    @property
    def num_rows(self) -> int:
        """
        Returns the number of rows to fetch when performing a query of a
        specific number of rows. For all operations, the value returned is 0.
        """
        return self._impl.num_rows

    @property
    def op_type(self) -> PipelineOpType:
        """
        Returns the type of operation that is taking place.
        """
        return PipelineOpType(self._impl.op_type)

    @property
    def parameters(self) -> Any:
        """
        Returns the parameters to the stored procedure or function or the
        parameters bound to the statement being executed by the operation, if
        applicable.
        """
        return self._impl.parameters

    @property
    def return_type(self) -> Any:
        """
        Returns the return type of the stored function being called by the
        operation, if applicable.
        """
        return self._impl.return_type

    @property
    def rowfactory(self) -> Union[Callable, None]:
        """
        Returns the row factory callable function to be used in a query
        executed by the operation, if applicable.
        """
        return self._impl.rowfactory

    @property
    def statement(self) -> Union[str, None]:
        """
        Returns the statement being executed by the operation, if applicable.
        """
        return self._impl.statement


class PipelineOpResult:
    __module__ = MODULE_NAME

    def __repr__(self):
        typ = self.__class__
        cls_name = f"{typ.__module__}.{typ.__qualname__}"
        return (
            f"<{cls_name} for operation of type {self.operation.op_type.name}>"
        )

    @property
    def columns(self) -> Union[list, None]:
        """
        Returns a list of FetchInfo instances containing metadata about an
        executed query, or the value None, if no fetch operation took place.
        """
        if self._impl.fetch_metadata is not None:
            return [FetchInfo._from_impl(i) for i in self._impl.fetch_metadata]

    @property
    def error(self) -> Union[_Error, None]:
        """
        Returns the error that occurred when running this operation, or the
        value None, if no error occurred.
        """
        return self._impl.error

    @property
    def operation(self) -> PipelineOp:
        """
        Returns the operation associated with the result.
        """
        return self._operation

    @property
    def return_value(self) -> Any:
        """
        Returns the return value of the called function, if a function was
        called for the operation.
        """
        return self._impl.return_value

    @property
    def rows(self) -> Union[list, None]:
        """
        Returns the rows that were fetched by the operation, if a query was
        executed.
        """
        return self._impl.rows

    @property
    def warning(self) -> Union[_Error, None]:
        """
        Returns the warning that was encountered when running this operation,
        or the value None, if no warning was encountered.
        """
        return self._impl.warning


class Pipeline:
    __module__ = MODULE_NAME

    def __repr__(self):
        typ = self.__class__
        cls_name = f"{typ.__module__}.{typ.__qualname__}"
        return f"<{cls_name} with {len(self._impl.operations)} operations>"

    def _add_op(self, op_impl):
        """
        Internal method for adding an PipelineOpImpl instance to the list of
        operations, creating an associated PipelineOp instance to correspond to
        it.
        """
        self._impl.operations.append(op_impl)
        op = PipelineOp.__new__(PipelineOp)
        op._impl = op_impl
        self._operations.append(op)
        return op

    def add_callfunc(
        self,
        name: str,
        return_type: Any,
        parameters: Union[list, tuple] = None,
        keyword_parameters: dict = None,
    ) -> PipelineOp:
        """
        Adds an operation that calls a stored function with the given
        parameters and return type. The PipelineOpResult object that is
        returned will have the "return_value" attribute populated with the
        return value of the function if the call completes successfully.
        """
        utils.verify_stored_proc_args(parameters, keyword_parameters)
        op_impl = PipelineOpImpl(
            op_type=PipelineOpType.CALL_FUNC,
            name=name,
            return_type=return_type,
            parameters=parameters,
            keyword_parameters=keyword_parameters,
        )
        return self._add_op(op_impl)

    def add_callproc(
        self,
        name: str,
        parameters: Union[list, tuple] = None,
        keyword_parameters: dict = None,
    ) -> PipelineOp:
        """
        Adds an operation that calls a stored procedure with the given
        parameters.
        """
        utils.verify_stored_proc_args(parameters, keyword_parameters)
        op_impl = PipelineOpImpl(
            op_type=PipelineOpType.CALL_PROC,
            name=name,
            parameters=parameters,
            keyword_parameters=keyword_parameters,
        )
        return self._add_op(op_impl)

    def add_commit(self) -> PipelineOp:
        """
        Adds an operation that performs a commit.
        """
        op_impl = PipelineOpImpl(op_type=PipelineOpType.COMMIT)
        return self._add_op(op_impl)

    def add_execute(
        self,
        statement: str,
        parameters: Union[list, tuple, dict] = None,
    ) -> PipelineOp:
        """
        Adds an operation that executes a statement with the given parameters.
        """
        op_impl = PipelineOpImpl(
            op_type=PipelineOpType.EXECUTE,
            statement=statement,
            parameters=parameters,
        )
        return self._add_op(op_impl)

    def add_executemany(
        self,
        statement: Union[str, None],
        parameters: Union[list, int],
    ) -> PipelineOp:
        """
        Adds an operation that executes a statement multiple times with the
        given list of parameters (or number of iterations).
        """
        op_impl = PipelineOpImpl(
            op_type=PipelineOpType.EXECUTE_MANY,
            statement=statement,
            parameters=parameters,
        )
        return self._add_op(op_impl)

    def add_fetchall(
        self,
        statement: str,
        parameters: Union[list, tuple, dict] = None,
        arraysize: int = None,
        rowfactory: Callable = None,
    ) -> PipelineOp:
        """
        Adds an operation that executes a query and returns up to the
        specified number of rows from the result set. The PipelineOpResult
        object that is returned will have the "return_value" attribute
        populated with the list of rows returned by the query.
        """
        if arraysize is None:
            arraysize = defaults.arraysize
        op_impl = PipelineOpImpl(
            op_type=PipelineOpType.FETCH_ALL,
            statement=statement,
            parameters=parameters,
            arraysize=arraysize,
            rowfactory=rowfactory,
        )
        return self._add_op(op_impl)

    def add_fetchmany(
        self,
        statement: str,
        parameters: Union[list, tuple, dict] = None,
        num_rows: int = None,
        rowfactory: Callable = None,
    ) -> PipelineOp:
        """
        Adds an operation that executes a query and returns up to the specified
        number of rows from the result set. The PipelineOpResult object that is
        returned will have the "return_value" attribute populated with the list
        of rows returned by the query.
        """
        if num_rows is None:
            num_rows = defaults.arraysize
        op_impl = PipelineOpImpl(
            op_type=PipelineOpType.FETCH_MANY,
            statement=statement,
            parameters=parameters,
            num_rows=num_rows,
            rowfactory=rowfactory,
        )
        return self._add_op(op_impl)

    def add_fetchone(
        self,
        statement: str,
        parameters: Union[list, tuple, dict] = None,
        rowfactory: Callable = None,
    ) -> PipelineOp:
        """
        Adds an operation that executes a query and returns the first row of
        the result set if one exists (or None, if no rows exist). The
        PipelineOpResult object that is returned will have the "return_value"
        attribute populated with this row if the query is performed
        successfully.
        """
        op_impl = PipelineOpImpl(
            op_type=PipelineOpType.FETCH_ONE,
            statement=statement,
            parameters=parameters,
            rowfactory=rowfactory,
        )
        return self._add_op(op_impl)

    @property
    def operations(self) -> list:
        """
        Returns the list of operations associated with the pipeline.
        """
        return self._operations


def create_pipeline() -> Pipeline:
    """
    Creates a pipeline object which can be used to process a set of operations
    against a database.
    """
    pipeline = Pipeline.__new__(Pipeline)
    pipeline._impl = PipelineImpl()
    pipeline._operations = []
    return pipeline


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\plugins\azure_config_provider.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2024, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# azure_config_provider.py
#
# Python file contains the hook method config_azure_hook() that fetches config
# store from Azure App Configuration.
# -----------------------------------------------------------------------------

import json
import re

import oracledb

from urllib.parse import urlparse, parse_qs
from azure.appconfiguration import AzureAppConfigurationClient
from azure.keyvault.secrets import SecretClient
from azure.core.exceptions import ResourceNotFoundError
from azure.identity import (
    ClientSecretCredential,
    CertificateCredential,
    ManagedIdentityCredential,
    ChainedTokenCredential,
    EnvironmentCredential,
)


def _get_authentication_method(parameters):
    auth_method = parameters.get("authentication", parameters.get("method"))
    if auth_method is not None:
        auth_method = auth_method.upper()
        if auth_method == "AZURE_DEFAULT":
            auth_method = None
    return auth_method


def _get_credential(parameters):
    """
    Returns the appropriate credential given the input supplied by the original
    connect string.
    """

    tokens = []
    auth_method = _get_authentication_method(parameters)

    if auth_method is None or auth_method == "AZURE_SERVICE_PRINCIPAL":
        if "azure_client_secret" in parameters:
            tokens.append(
                ClientSecretCredential(
                    _get_required_parameter(parameters, "azure_tenant_id"),
                    _get_required_parameter(parameters, "azure_client_id"),
                    _get_required_parameter(parameters, "azure_client_secret"),
                )
            )
        elif "azure_client_certificate_path" in parameters:
            tokens.append(
                CertificateCredential(
                    _get_required_parameter(parameters, "azure_tenant_id"),
                    _get_required_parameter(parameters, "azure_client_id"),
                    _get_required_parameter(
                        parameters, "azure_client_certificate_path"
                    ),
                )
            )
    if auth_method is None or auth_method == "AZURE_MANAGED_IDENTITY":
        client_id = parameters.get("azure_managed_identity_client_id")
        if client_id is not None:
            tokens.append(ManagedIdentityCredential(client_id=client_id))

    if len(tokens) == 0:
        message = (
            "Authentication options were not available in Connection String"
        )
        raise Exception(message)
    elif len(tokens) == 1:
        return tokens[0]
    tokens.append(EnvironmentCredential())
    return ChainedTokenCredential(*tokens)


def _get_password(pwd_string, parameters):
    try:
        pwd = json.loads(pwd_string)
    except json.JSONDecodeError:
        message = (
            "Password is expected to be JSON"
            " containing Azure Vault details."
        )
        raise Exception(message)

    pwd["value"] = pwd.pop("uri")
    pwd["type"] = "azurevault"

    # make authentication section
    pwd["authentication"] = authentication = {}

    authentication["method"] = auth_method = _get_authentication_method(
        parameters
    )

    if auth_method is None or auth_method == "AZURE_SERVICE_PRINCIPAL":
        if "azure_client_secret" in parameters:
            authentication["azure_tenant_id"] = _get_required_parameter(
                parameters, "azure_tenant_id"
            )
            authentication["azure_client_id"] = _get_required_parameter(
                parameters, "azure_client_id"
            )
            authentication["azure_client_secret"] = _get_required_parameter(
                parameters, "azure_client_secret"
            )

        elif "azure_client_certificate_path" in parameters:
            authentication["azure_tenant_id"] = (
                _get_required_parameter(parameters, "azure_tenant_id"),
            )
            authentication["azure_client_id"] = (
                _get_required_parameter(parameters, "azure_client_id"),
            )
            authentication["azure_client_certificate_path"] = (
                _get_required_parameter(
                    parameters, "azure_client_certificate_path"
                )
            )

    if auth_method is None or auth_method == "AZURE_MANAGED_IDENTITY":
        authentication["azure_managed_identity_client_id"] = parameters.get(
            "azure_managed_identity_client_id"
        )
    return pwd


def _get_required_parameter(parameters, name, location="connection string"):
    try:
        return parameters[name]
    except KeyError:
        message = f'Parameter named "{name}" is missing from {location}'
        raise Exception(message) from None


def _get_setting(client, key, sub_key, label, required=True):
    """
    Returns the configuration setting given the client, key and label.
    """
    try:
        if key.endswith("/"):
            actual_key = f"{key}{sub_key}"
        else:
            actual_key = f"{key}/{sub_key}"
        obj = client.get_configuration_setting(key=actual_key, label=label)
    except ResourceNotFoundError:
        if required:
            message = f"Missing required configuration key: {actual_key}"
            raise Exception(message)
        return None
    return obj.value


def _parse_parameters(protocol_arg: str) -> dict:
    """
    Parse the parameters from the protocol argument string.
    """
    pos = protocol_arg.find("?")
    parsed_url = urlparse(protocol_arg[pos + 1 :])
    parsed_values = parse_qs(parsed_url.path)
    parameters = {
        key.lower(): value[0] for key, value in parsed_values.items()
    }
    parameters["appconfigname"] = (
        protocol_arg[:pos].rstrip("/").rstrip(".azconfig.io") + ".azconfig.io"
    )
    return parameters


def password_type_azure_vault_hook(args):
    uri = _get_required_parameter(args, "value", '"password" key section')
    credential = args.get("credential")

    if credential is None:
        # if credential not present, this might be coming
        # from oci config provider, so create credential
        # for azure key vault.
        auth = args.get("authentication")
        if auth is None:
            raise Exception(
                "Azure Vault authentication details were not provided."
            )
        credential = _get_credential(auth)

    pattern = re.compile(
        r"(?P<vault_url>https://[A-Za-z0-9._-]+)/"
        r"secrets/(?P<secretKey>[A-Za-z][A-Za-z0-9-]*)$"
    )
    match = pattern.match(uri)
    if match is None:
        raise Exception("Invalid Azure Vault details")
    vault_url = match.group("vault_url")
    secret_key = match.group("secretKey")
    secret_client = SecretClient(vault_url, credential)
    return secret_client.get_secret(secret_key).value


def _process_config(parameters, connect_params):
    """
    Processes the configuration stored in the Azure App configuration store.
    """

    credential = _get_credential(parameters)
    client = AzureAppConfigurationClient(
        "https://" + _get_required_parameter(parameters, "appconfigname"),
        credential,
    )
    key = _get_required_parameter(parameters, "key")
    label = parameters.get("label")

    # get the common parameters
    config = {}
    config["connect_descriptor"] = _get_setting(
        client, key, "connect_descriptor", label
    )
    config["user"] = _get_setting(client, key, "user", label, required=False)
    pwd = _get_setting(client, key, "password", label, required=False)
    if pwd is not None:
        config["password"] = _get_password(pwd, parameters)

    config["config_time_to_live"] = _get_setting(
        client, key, "config_time_to_live", label, required=False
    )
    config["config_time_to_live_grace_period"] = _get_setting(
        client, key, "config_time_to_live_grace_period", label, required=False
    )

    # get the python-oracledb specific parameters
    settings = _get_setting(client, key, "pyo", label, required=False)
    if settings is not None:
        config["pyo"] = json.loads(settings)

    # set the configuration
    connect_params.set_from_config(config)


def config_azure_hook(protocol, protocol_arg, connect_params):
    """
    Hook for handling parameters stored in an Azure configuration store.
    """
    parameters = _parse_parameters(protocol_arg)
    _process_config(parameters, connect_params)


oracledb.register_password_type("azurevault", password_type_azure_vault_hook)
oracledb.register_protocol("config-azure", config_azure_hook)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\plugins\azure_tokens.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2024, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# azure_tokens.py
#
# Methods that generates an OAuth2 access token using the MSAL SDK
# -----------------------------------------------------------------------------

import msal
import oracledb


def generate_token(token_auth_config, refresh=False):
    """
    Generates an Azure access token based on provided credentials.
    """
    user_auth_type = token_auth_config.get("auth_type") or ""
    auth_type = user_auth_type.lower()
    if auth_type == "azureserviceprincipal":
        return _service_principal_credentials(token_auth_config)
    else:
        raise ValueError(
            f"Unrecognized auth_type authentication method: {user_auth_type}"
        )


def _service_principal_credentials(token_auth_config):
    """
    Returns the access token for authentication as a service principal.
    """
    msal_config = {
        "authority": token_auth_config["authority"],
        "client_id": token_auth_config["client_id"],
        "client_credential": token_auth_config["client_credential"],
    }
    # Initialize the Confidential Client Application
    cca = msal.ConfidentialClientApplication(**msal_config)
    auth_response = cca.acquire_token_for_client(
        scopes=[token_auth_config["scopes"]]
    )

    if "access_token" in auth_response:
        return auth_response["access_token"]


def azure_token_hook(params: oracledb.ConnectParams):
    """
    Azure-specific hook for generating a token.
    """
    if params.extra_auth_params is not None:

        def token_callback(refresh):
            return generate_token(params.extra_auth_params, refresh)

        params.set(access_token=token_callback)


# Register the token hook for Azure
oracledb.register_params_hook(azure_token_hook)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\plugins\oci_config_provider.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2024, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# oci_config_provider.py
#
# Python file contains the hook method config_oci_hook() that fetches config
# store from OCI Object Storage.
# -----------------------------------------------------------------------------

import base64
import json
import oci
import oracledb
import re

from urllib.parse import urlparse, parse_qs

oci_from_file = oci.config.from_file
oci_client_error = oci.exceptions.ClientError
oci_object_storage_client = oci.object_storage.ObjectStorageClient
oci_secrets_client = oci.secrets.SecretsClient


"""
Pattern to parse OCI Object Connect String
"""
cloud_net_naming_pattern_oci = re.compile(
    r"(?P<objservername>[^/]+)/n/(?P<namespace>[^/]+)/b/(?P<bucketname>[^/]+)/o/(?P<filename>[^/]+)(/c/(?P<alias>[^/]+))?"
)


def _get_config(parameters, connect_params):
    config = {}

    credential, signer = _get_credential(parameters)
    auth_method = parameters.get("authentication")
    if auth_method is not None:
        auth_method = auth_method.upper()

    if auth_method is None or auth_method == "OCI_DEFAULT":
        client_oci = oci_object_storage_client(credential)
    elif (
        auth_method == "OCI_INSTANCE_PRINCIPAL"
        or auth_method == "OCI_RESOURCE_PRINCIPAL"
    ):
        client_oci = oci_object_storage_client(
            config=credential, signer=signer
        )
    get_object_request = {
        "object_name": _get_required_parameter(parameters, "filename"),
        "bucket_name": _get_required_parameter(parameters, "bucketname"),
        "namespace_name": _get_required_parameter(parameters, "namespace"),
    }

    get_object_response = client_oci.get_object(**get_object_request)
    resp = _stream_to_string(get_object_response.data)
    settings = json.loads(resp)
    user_alias = parameters.get("alias")
    if user_alias:
        settings = settings[user_alias]

    # Connect Descriptor
    config["connect_descriptor"] = _get_required_parameter(
        settings, "connect_descriptor"
    )

    # user and password
    if connect_params.user is None:
        config["user"] = settings.get("user")
        if "password" in settings:
            config["password"] = pwd = settings["password"]
            if pwd["type"] == "ocivault":
                authentication = pwd.setdefault("authentication", {})
                authentication.setdefault("method", auth_method)
                authentication["credential"] = credential

    # config cache settings
    config["config_time_to_live"] = settings.get("config_time_to_live")
    config["config_time_to_live_grace_period"] = settings.get(
        "config_time_to_live_grace_period"
    )

    # pyo parameters settings
    config["pyo"] = settings.get("pyo", None)

    # set the configuration
    connect_params.set_from_config(config)


def _get_credential(parameters):
    """
    Returns the appropriate credential given the input supplied by the original
    connect string.
    """
    auth_method = parameters.get("authentication", parameters.get("method"))

    if auth_method is not None:
        auth_method = auth_method.upper()

    # if region is not in connection string, retrieve from object server name.
    region = parameters.get(
        "oci_region", _retrieve_region(parameters.get("objservername"))
    )

    try:
        if auth_method is None or auth_method == "OCI_DEFAULT":
            # Default Authentication
            # default path ~/.oci/config
            return oci_from_file(), None
    except oci.exceptions.ClientError:
        # try to create config with connection string parameters.
        if "oci_tenancy" in parameters and "oci_user" in parameters:
            with open(parameters["oci_key_file"], "r") as file_content:
                public_key = file_content.read()
            provider = dict(
                tenancy=parameters["oci_tenancy"],
                user=parameters["oci_user"],
                fingerprint=parameters["oci_fingerprint"],
                key_file=parameters["oci_key_file"],
                private_key_content=public_key,
                region=region,
            )
            return provider, None

    if auth_method == "OCI_INSTANCE_PRINCIPAL":
        signer = oci.auth.signers.InstancePrincipalsSecurityTokenSigner()
        return (
            dict(region=region),
            signer,
        )

    elif auth_method == "OCI_RESOURCE_PRINCIPAL":
        signer = oci.auth.signers.get_resource_principals_signer()
        return {}, signer
    else:
        msg = "Authentication options were not available in Connection String"
        raise Exception(msg)


def _get_required_parameter(parameters, name, location="connection string"):
    try:
        return parameters[name]
    except KeyError:
        message = f'Parameter named "{name}" is missing from {location}'
        raise Exception(message) from None


def _parse_parameters(protocol_arg: str) -> dict:
    """
    Parse the parameters from the protocol argument string.
    """
    pos = protocol_arg.find("?")
    parsed_url = urlparse(protocol_arg[pos + 1 :])
    parsed_values = parse_qs(parsed_url.path)
    parameters = {
        key.lower(): value[0] for key, value in parsed_values.items()
    }

    match = cloud_net_naming_pattern_oci.match(protocol_arg[:pos])
    if match:
        parameters["objservername"] = match.group("objservername")
        parameters["namespace"] = match.group("namespace")
        parameters["bucketname"] = match.group("bucketname")
        parameters["filename"] = match.group("filename")
        if match.group("alias"):
            parameters["alias"] = match.group("alias")
    return parameters


def password_type_oci_vault_hook(args):
    secret_id = _get_required_parameter(
        args, "value", '"password" key section'
    )
    authentication = args.get("authentication")
    if authentication is None:
        raise Exception(
            "OCI Key Vault authentication details were not provided."
        )

    # if credentials are not present, create credentials with given
    # authentication details.
    credential = authentication.get("credential")
    if credential is None:
        credential, signer = _get_credential(authentication)

    auth_method = authentication.get("method")
    if auth_method is not None:
        auth_method = auth_method.upper()
    if auth_method is None or auth_method == "OCI_DEFAULT":
        secret_client_oci = oci_secrets_client(credential)
    elif auth_method == "OCI_INSTANCE_PRINCIPAL":
        signer = oci.auth.signers.InstancePrincipalsSecurityTokenSigner()
        secret_client_oci = oci_secrets_client(
            config=credential, signer=signer
        )
    elif auth_method == "OCI_RESOURCE_PRINCIPAL":
        signer = oci.auth.signers.get_resource_principals_signer()
        secret_client_oci = oci_secrets_client(
            config=credential, signer=signer
        )

    get_secret_bundle_response = secret_client_oci.get_secret_bundle(
        secret_id=secret_id
    )
    # decoding the vault content
    b64content = get_secret_bundle_response.data.secret_bundle_content.content
    return base64.b64decode(b64content).decode()


def _retrieve_region(objservername):
    if objservername is not None:
        arr = objservername.split(".")
        return arr[1].lower().replace("_", "-")


def _stream_to_string(stream):
    return b"".join(stream).decode()


def config_oci_hook(
    protocol: str, protocol_arg: str, connect_params: oracledb.ConnectParams
):
    """
    Hook for handling parameters stored in an OCI Object store.
    """
    parameters = _parse_parameters(protocol_arg)
    _get_config(parameters, connect_params)


oracledb.register_password_type("ocivault", password_type_oci_vault_hook)
oracledb.register_protocol("config-ociobject", config_oci_hook)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\plugins\oci_tokens.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2024, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# oci_tokens.py
#
# Methods that generates an OCI access token using the OCI SDK
# -----------------------------------------------------------------------------

import oci
import oracledb
from cryptography.hazmat.primitives.asymmetric import rsa
from cryptography.hazmat.primitives import serialization


def generate_token(token_auth_config, refresh=False):
    """
    Generates an OCI access token based on provided credentials.
    """
    user_auth_type = token_auth_config.get("auth_type") or ""
    auth_type = user_auth_type.lower()
    if auth_type == "configfileauthentication":
        return _config_file_based_authentication(token_auth_config)
    elif auth_type == "simpleauthentication":
        return _simple_authentication(token_auth_config)
    else:
        raise ValueError(
            f"Unrecognized auth_type authentication method {user_auth_type}"
        )


def _get_key_pair():
    """
    Generates a public-private key pair for proof of possession.
    """
    private_key = rsa.generate_private_key(
        public_exponent=65537,
        key_size=4096,
    )
    private_key_pem = private_key.private_bytes(
        encoding=serialization.Encoding.PEM,
        format=serialization.PrivateFormat.PKCS8,
        encryption_algorithm=serialization.NoEncryption(),
    ).decode("utf-8")

    public_key_pem = (
        private_key.public_key()
        .public_bytes(
            encoding=serialization.Encoding.PEM,
            format=serialization.PublicFormat.SubjectPublicKeyInfo,
        )
        .decode("utf-8")
    )

    if not oracledb.is_thin_mode():
        p_key = "".join(
            line.strip()
            for line in private_key_pem.splitlines()
            if not (
                line.startswith("-----BEGIN") or line.startswith("-----END")
            )
        )
        private_key_pem = p_key

    return {"private_key": private_key_pem, "public_key": public_key_pem}


def _config_file_based_authentication(token_auth_config):
    """
    Config file base authentication implementation: config parameters
    are provided in a file.
    """
    file_location = token_auth_config.get(
        "file_location", oci.config.DEFAULT_LOCATION
    )
    profile = token_auth_config.get("profile", oci.config.DEFAULT_PROFILE)

    # Load OCI config
    config = oci.config.from_file(file_location, profile)
    oci.config.validate_config(config)

    # Initialize service client with default config file
    client = oci.identity_data_plane.DataplaneClient(config)

    key_pair = _get_key_pair()

    response = client.generate_scoped_access_token(
        generate_scoped_access_token_details=oci.identity_data_plane.models.GenerateScopedAccessTokenDetails(
            scope="urn:oracle:db::id::*", public_key=key_pair["public_key"]
        )
    )

    # access_token is a tuple holding token and private key
    access_token = (
        response.data.token,
        key_pair["private_key"],
    )

    return access_token


def _simple_authentication(token_auth_config):
    """
    Simple authentication: config parameters are passed as parameters
    """
    config = {
        "user": token_auth_config["user"],
        "key_file": token_auth_config["key_file"],
        "fingerprint": token_auth_config["fingerprint"],
        "tenancy": token_auth_config["tenancy"],
        "region": token_auth_config["region"],
        "profile": token_auth_config["profile"],
    }
    oci.config.validate_config(config)

    # Initialize service client with given configuration
    client = oci.identity_data_plane.DataplaneClient(config)

    key_pair = _get_key_pair()

    response = client.generate_scoped_access_token(
        generate_scoped_access_token_details=oci.identity_data_plane.models.GenerateScopedAccessTokenDetails(
            scope="urn:oracle:db::id::*", public_key=key_pair["public_key"]
        )
    )

    # access_token is a tuple holding token and private key
    access_token = (
        response.data.token,
        key_pair["private_key"],
    )

    return access_token


def oci_token_hook(params: oracledb.ConnectParams):
    """
    OCI-specific hook for generating a token.
    """
    if params.extra_auth_params is not None:

        def token_callback(refresh):
            return generate_token(params.extra_auth_params, refresh)

        params.set(access_token=token_callback)


# Register the token hook for OCI
oracledb.register_params_hook(oci_token_hook)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\pool.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# pool.py
#
# Contains the ConnectionPool class and the factory method create_pool() used
# for creating connection pools.
#
# *** NOTICE *** This file is generated from a template and should not be
# modified directly. See build_from_template.py in the utils subdirectory for
# more information.
# -----------------------------------------------------------------------------

import functools
import ssl
import threading
from typing import Callable, Type, Union, Any, Optional

import oracledb

from . import base_impl, thick_impl, thin_impl
from . import connection as connection_module
from . import driver_mode
from . import errors
from .pool_params import PoolParams


class BaseConnectionPool:
    __module__ = oracledb.__name__
    _impl = None

    def __init__(
        self,
        dsn: Optional[str] = None,
        *,
        params: Optional[PoolParams] = None,
        cache_name: Optional[str] = None,
        **kwargs,
    ) -> None:
        """
        Constructor for creating a connection pool. Connection pooling creates
        a pool of available connections to the database, allowing applications
        to acquire a connection very quickly. It is of primary use in a server
        where connections are requested in rapid succession and used for a
        short period of time, for example in a web server.

        The dsn parameter (data source name) can be a string in the format
        user/password@connect_string or can simply be the connect string (in
        which case authentication credentials such as the username and password
        need to be specified separately). See the documentation on connection
        strings for more information.

        The params parameter is expected to be of type PoolParams and contains
        parameters that are used to create the pool. See the documentation on
        PoolParams for more information. If this parameter is not specified,
        the additional keyword parameters will be used to create an instance of
        PoolParams. If both the params parameter and additional keyword
        parameters are specified, the values in the keyword parameters have
        precedence. Note that if a dsn is also supplied, then in the
        python-oracledb Thin mode, the values of the parameters specified
        (if any) within the dsn will override the values passed as additional
        keyword parameters, which themselves override the values set in the
        params parameter object.
        """
        if params is None:
            params_impl = base_impl.PoolParamsImpl()
        elif not isinstance(params, PoolParams):
            errors._raise_err(errors.ERR_INVALID_POOL_PARAMS)
        else:
            params_impl = params._impl.copy()
        with driver_mode.get_manager() as mode_mgr:
            thin = mode_mgr.thin
            dsn = params_impl.process_args(dsn, kwargs, thin)
            self._set_connection_type(params_impl.connectiontype)
            self._cache_name = cache_name
            if cache_name is not None:
                named_pools.add_pool(cache_name, self)
            try:
                if issubclass(
                    self._connection_type, connection_module.AsyncConnection
                ):
                    impl = thin_impl.AsyncThinPoolImpl(dsn, params_impl)
                elif thin:
                    impl = thin_impl.ThinPoolImpl(dsn, params_impl)
                else:
                    impl = thick_impl.ThickPoolImpl(dsn, params_impl)
                self._impl = impl
                self.session_callback = params_impl.session_callback
            except:
                if cache_name is not None:
                    del named_pools.pools[cache_name]
                raise

    def _verify_open(self) -> None:
        """
        Verifies that the pool is open and able to perform its work.
        """
        if self._impl is None:
            errors._raise_err(errors.ERR_POOL_NOT_OPEN)

    @property
    def busy(self) -> int:
        """
        Returns the number of connections that have been acquired from the pool
        and have not yet been returned to the pool.
        """
        self._verify_open()
        return self._impl.get_busy_count()

    @property
    def dsn(self) -> str:
        """
        Returns the connection string (TNS entry) of the database to which
        connections in the pool have been established.
        """
        self._verify_open()
        return self._impl.dsn

    @property
    def getmode(self) -> oracledb.PoolGetMode:
        self._verify_open()
        return oracledb.PoolGetMode(self._impl.get_getmode())

    @getmode.setter
    def getmode(self, value: oracledb.PoolGetMode) -> None:
        self._verify_open()
        self._impl.set_getmode(value)

    @property
    def homogeneous(self) -> bool:
        """
        Returns a boolean indicating if the pool is homogeneous or not. If the
        pool is not homogeneous, different authentication can be used for each
        connection acquired from the pool.
        """
        self._verify_open()
        return self._impl.homogeneous

    @property
    def increment(self) -> int:
        """
        Returns the number of connections that will be created when additional
        connections need to be created to satisfy requests.
        """
        self._verify_open()
        return self._impl.increment

    @property
    def max(self) -> int:
        """
        Returns the maximum number of connections that the pool can control.
        """
        self._verify_open()
        return self._impl.max

    @property
    def max_lifetime_session(self) -> int:
        """
        Returns the maximum length of time (in seconds) that a pooled
        connection may exist. Connections that are in use will not be closed.
        They become candidates for termination only when they are released back
        to the pool and have existed for longer than max_lifetime_session
        seconds. Note that termination only occurs when the pool is accessed. A
        value of 0 means that there is no maximum length of time that a pooled
        connection may exist. This attribute is only available in Oracle
        Database 12.1.
        """
        self._verify_open()
        return self._impl.get_max_lifetime_session()

    @max_lifetime_session.setter
    def max_lifetime_session(self, value: int) -> None:
        self._verify_open()
        self._impl.set_max_lifetime_session(value)

    @property
    def max_sessions_per_shard(self) -> int:
        """
        Returns the number of sessions that can be created per shard in the
        pool.  Setting this attribute greater than zero specifies the maximum
        number of sessions in the pool that can be used for any given shard in
        a sharded database. This lets connections in the pool be balanced
        across the shards.  A value of zero will not set any maximum number of
        sessions for each shard.  This attribute is only available in Oracle
        Client 18.3 and higher.
        """
        self._verify_open()
        return self._impl.get_max_sessions_per_shard()

    @max_sessions_per_shard.setter
    def max_sessions_per_shard(self, value: int) -> None:
        self._verify_open()
        self._impl.set_max_sessions_per_shard(value)

    @property
    def min(self) -> int:
        """
        Returns the minimum number of connections that the pool will control.
        These are created when the pool is first created.
        """
        self._verify_open()
        return self._impl.min

    @property
    def name(self) -> str:
        """
        Returns the name assigned to the pool by Oracle. This attribute is only
        relevant in python-oracledb thick mode.
        """
        self._verify_open()
        return self._impl.name

    @property
    def opened(self) -> int:
        """
        Returns the number of connections currently opened by the pool.
        """
        self._verify_open()
        return self._impl.get_open_count()

    @property
    def ping_interval(self) -> int:
        """
        Returns the pool ping interval in seconds. When a connection is
        acquired from the pool, a check is first made to see how long it
        has been since the connection was put into the pool. If
        this idle time exceeds ping_interval, then a round-trip ping to the
        database is performed. If the connection is unusable, it is discarded
        and a different connection is selected to be returned by
        SessionPool.acquire(). Setting ping_interval to a negative value
        disables pinging. Setting it to 0 forces a ping for every aquire()
        and is not recommended.
        """
        self._verify_open()
        return self._impl.get_ping_interval()

    @ping_interval.setter
    def ping_interval(self, value: int) -> None:
        self._impl.set_ping_interval(value)

    @property
    def soda_metadata_cache(self) -> bool:
        """
        Specifies whether the SODA metadata cache is enabled or not. Enabling
        the cache significantly improves the performance of methods
        SodaDatabase.createCollection() (when not specifying a value for the
        metadata parameter) and SodaDatabase.openCollection(). Note that the
        cache can become out of date if changes to the metadata of cached
        collections are made externally.
        """
        self._verify_open()
        return self._impl.get_soda_metadata_cache()

    @soda_metadata_cache.setter
    def soda_metadata_cache(self, value: bool) -> None:
        if not isinstance(value, bool):
            message = "soda_metadata_cache must be a boolean value."
            raise TypeError(message)
        self._verify_open()
        self._impl.set_soda_metadata_cache(value)

    @property
    def stmtcachesize(self) -> int:
        """
        Specifies the size of the statement cache that will be used as the
        starting point for any connections that are created by the pool. Once a
        connection is created, that connection’s statement cache size can only
        be changed by setting the stmtcachesize attribute on the connection
        itself.
        """
        self._verify_open()
        return self._impl.get_stmt_cache_size()

    @stmtcachesize.setter
    def stmtcachesize(self, value: int) -> None:
        self._verify_open()
        self._impl.set_stmt_cache_size(value)

    @property
    def thin(self) -> bool:
        """
        Returns a boolean indicating if the pool was created in
        python-oracledb's thin mode (True) or thick mode (False).
        """
        self._verify_open()
        return not isinstance(self._impl, thick_impl.ThickPoolImpl)

    @property
    def timeout(self) -> int:
        """
        Specifies the time (in seconds) after which idle connections will be
        terminated in order to maintain an optimum number of open connections.
        A value of 0 means that no idle connections are terminated. Note that
        in thick mode with older Oracle Client libraries termination only
        occurs when the pool is accessed.
        """
        self._verify_open()
        return self._impl.get_timeout()

    @timeout.setter
    def timeout(self, value: int) -> None:
        self._verify_open()
        self._impl.set_timeout(value)

    @property
    def tnsentry(self) -> str:
        """
        Deprecated. Use dsn instead.
        """
        return self.dsn

    @property
    def username(self) -> str:
        """
        Returns the name of the user which was used to create the pool.
        """
        self._verify_open()
        return self._impl.username

    @property
    def wait_timeout(self) -> int:
        """
        Specifies the time (in milliseconds) that the caller should wait for a
        connection to become available in the pool before returning with an
        error.  This value is only used if the getmode parameter used to create
        the pool was POOL_GETMODE_TIMEDWAIT.
        """
        self._verify_open()
        return self._impl.get_wait_timeout()

    @wait_timeout.setter
    def wait_timeout(self, value: int) -> None:
        self._verify_open()
        self._impl.set_wait_timeout(value)


class ConnectionPool(BaseConnectionPool):
    __module__ = oracledb.__name__

    def __del__(self):
        if self._impl is not None:
            self._impl.close(True)
            self._impl = None

    def _set_connection_type(self, conn_class):
        """
        Called internally when the pool is created to ensure that the correct
        connection class is used for all connections created by the pool.
        """
        if conn_class is None:
            conn_class = connection_module.Connection
        elif not issubclass(
            conn_class, connection_module.Connection
        ) or issubclass(conn_class, connection_module.AsyncConnection):
            errors._raise_err(errors.ERR_INVALID_CONN_CLASS)
        self._connection_type = conn_class

    def acquire(
        self,
        user: Optional[str] = None,
        password: Optional[str] = None,
        cclass: Optional[str] = None,
        purity: int = oracledb.PURITY_DEFAULT,
        tag: Optional[str] = None,
        matchanytag: bool = False,
        shardingkey: Optional[list] = None,
        supershardingkey: Optional[list] = None,
    ) -> "connection_module.Connection":
        """
        Acquire a connection from the pool and return it.

        If the pool is homogeneous, the user and password parameters cannot be
        specified. If they are, an exception will be raised.

        The cclass parameter, if specified, should be a string corresponding to
        the connection class for database resident connection pooling (DRCP).

        The purity parameter is expected to be one of PURITY_DEFAULT,
        PURITY_NEW, or PURITY_SELF.

        The tag parameter, if specified, is expected to be a string with
        name=value pairs like “k1=v1;k2=v2” and will limit the connections that
        can be returned from a pool unless the matchanytag parameter is
        set to True. In that case connections with the specified tag will be
        preferred over others, but if no such connections are available a
        connection with a different tag may be returned instead. In any case,
        untagged connections will always be returned if no connections with the
        specified tag are available. Connections are tagged when they are
        released back to the pool.

        The shardingkey and supershardingkey parameters, if specified, are
        expected to be a sequence of values which will be used to identify the
        database shard to connect to. The key values can be strings, numbers,
        bytes or dates.
        """
        self._verify_open()

        return oracledb.connect(
            conn_class=self._connection_type,
            user=user,
            password=password,
            cclass=cclass,
            purity=purity,
            tag=tag,
            matchanytag=matchanytag,
            shardingkey=shardingkey,
            supershardingkey=supershardingkey,
            pool=self,
        )

    def close(self, force: bool = False) -> None:
        """
        Close the pool now, rather than when the last reference to it is
        released, which makes it unusable for further work.

        If any connections have been acquired and not released back to the
        pool, this method will fail unless the force parameter is set to True.
        """
        self._verify_open()
        self._impl.close(force)
        if self._cache_name is not None:
            named_pools.remove_pool(self._cache_name)
        self._impl = None

    def drop(self, connection: "connection_module.Connection") -> None:
        """
        Drop the connection from the pool, which is useful if the connection is
        no longer usable (such as when the database session is killed).
        """
        self._verify_open()
        if not isinstance(connection, connection_module.Connection):
            message = "connection must be an instance of oracledb.Connection"
            raise TypeError(message)
        connection._verify_connected()
        self._impl.drop(connection._impl)
        connection._impl = None

    def release(
        self,
        connection: "connection_module.Connection",
        tag: Optional[str] = None,
    ) -> None:
        """
        Release the connection back to the pool now, rather than whenever
        __del__ is called. The connection will be unusable from this point
        forward; an Error exception will be raised if any operation is
        attempted with the connection. Any cursors or LOBs created by the
        connection will also be marked unusable and an Error exception will be
        raised if any operation is attempted with them.

        Internally, references to the connection are held by cursor objects,
        LOB objects, etc. Once all of these references are released, the
        connection itself will be released back to the pool automatically.
        Either control references to these related objects carefully or
        explicitly release connections back to the pool in order to ensure
        sufficient resources are available.

        If the tag is not None, it is expected to be a string with name=value
        pairs like “k1=v1;k2=v2” and will override the value in the property
        Connection.tag. If either Connection.tag or the tag parameter are not
        None, the connection will be retagged when it is released back to the
        pool.
        """
        self._verify_open()
        if not isinstance(connection, connection_module.Connection):
            message = "connection must be an instance of oracledb.Connection"
            raise TypeError(message)
        if tag is not None:
            connection.tag = tag
        connection.close()

    def reconfigure(
        self,
        min: Optional[int] = None,
        max: Optional[int] = None,
        increment: Optional[int] = None,
        getmode: Optional[int] = None,
        timeout: Optional[int] = None,
        wait_timeout: Optional[int] = None,
        max_lifetime_session: Optional[int] = None,
        max_sessions_per_shard: Optional[int] = None,
        soda_metadata_cache: Optional[bool] = None,
        stmtcachesize: Optional[int] = None,
        ping_interval: Optional[int] = None,
    ) -> None:
        """
        Reconfigures various parameters of a connection pool. The pool size
        can be altered with reconfigure() by passing values for min, max
        or increment. The getmode, timeout, wait_timeout,
        max_lifetime_session, max_sessions_per_shard, soda_metadata_cache,
        stmtcachesize and ping_interval can be set directly or by using
        reconfigure(). All parameters are optional. Unspecified parameters
        will leave those pool attributes unchanged. The parameters are
        processed in two stages. After any size change has been processed,
        reconfiguration on the other parameters is done sequentially. If
        an error such as an invalid value occurs when changing one attribute,
        then an exception will be generated but any already changed
        attributes will retain their new values.

        During reconfiguration of a pool's size, the behavior of acquire()
        depends on the getmode in effect when acquire() is called:

        * With mode POOL_GETMODE_FORCEGET, an acquire() call will wait until
          the pool has been reconfigured.

        * With mode POOL_GETMODE__TIMEDWAIT, an acquire() call will try to
          acquire a connection in the time specified by pool.wait_timeout and
          return an error if the time taken exceeds that value.

        * With mode POOL_GETMODE_WAIT, an acquire() call will wait until after
          the pool has been reconfigured and a connection is available.

        * With mode POOL_GETMODE_NOWAIT, if the number of busy connections is
          less than the pool size, acquire() will return a new connection
          after pool reconfiguration is complete.

        Closing connections with pool.release() or connection.close() will
        wait until any pool size reconfiguration is complete.

        Closing the connection pool with pool.close() will wait until
        reconfiguration is complete.
        """

        if min is None:
            min = self.min
        if max is None:
            max = self.max
        if increment is None:
            increment = self.increment
        if self.min != min or self.max != max or self.increment != increment:
            self._impl.reconfigure(min, max, increment)
        if getmode is not None:
            self.getmode = getmode
        if timeout is not None:
            self.timeout = timeout
        if wait_timeout is not None:
            self.wait_timeout = wait_timeout
        if max_lifetime_session is not None:
            self.max_lifetime_session = max_lifetime_session
        if max_sessions_per_shard is not None:
            self.max_sessions_per_shard = max_sessions_per_shard
        if soda_metadata_cache is not None:
            self.soda_metadata_cache = soda_metadata_cache
        if stmtcachesize is not None:
            self.stmtcachesize = stmtcachesize
        if ping_interval is not None:
            self.ping_interval = ping_interval


def _pool_factory(
    f: Callable[..., ConnectionPool]
) -> Callable[..., ConnectionPool]:
    """
    Decorator which checks the validity of the supplied keyword parameters by
    calling the original function (which does nothing), then creates and
    returns an instance of the requested ConnectionPool class. The base
    ConnectionPool class constructor does not check the validity of the
    supplied keyword parameters.
    """

    @functools.wraps(f)
    def create_pool(
        dsn: Optional[str] = None,
        *,
        pool_class: Type[ConnectionPool] = ConnectionPool,
        pool_alias: Optional[str] = None,
        params: Optional[PoolParams] = None,
        **kwargs,
    ) -> ConnectionPool:
        f(
            dsn=dsn,
            pool_class=pool_class,
            pool_alias=pool_alias,
            params=params,
            **kwargs,
        )
        if not issubclass(pool_class, ConnectionPool):
            errors._raise_err(errors.ERR_INVALID_POOL_CLASS)
        return pool_class(dsn, params=params, cache_name=pool_alias, **kwargs)

    return create_pool


@_pool_factory
def create_pool(
    dsn: Optional[str] = None,
    *,
    pool_class: Type[ConnectionPool] = ConnectionPool,
    pool_alias: Optional[str] = None,
    params: Optional[PoolParams] = None,
    min: Optional[int] = None,
    max: Optional[int] = None,
    increment: Optional[int] = None,
    connectiontype: Optional[Type["oracledb.Connection"]] = None,
    getmode: Optional[oracledb.PoolGetMode] = None,
    homogeneous: Optional[bool] = None,
    timeout: Optional[int] = None,
    wait_timeout: Optional[int] = None,
    max_lifetime_session: Optional[int] = None,
    session_callback: Optional[Callable] = None,
    max_sessions_per_shard: Optional[int] = None,
    soda_metadata_cache: Optional[bool] = None,
    ping_interval: Optional[int] = None,
    ping_timeout: Optional[int] = None,
    user: Optional[str] = None,
    proxy_user: Optional[str] = None,
    password: Optional[str] = None,
    newpassword: Optional[str] = None,
    wallet_password: Optional[str] = None,
    access_token: Optional[Union[str, tuple, Callable]] = None,
    host: Optional[str] = None,
    port: Optional[int] = None,
    protocol: Optional[str] = None,
    https_proxy: Optional[str] = None,
    https_proxy_port: Optional[int] = None,
    service_name: Optional[str] = None,
    instance_name: Optional[str] = None,
    sid: Optional[str] = None,
    server_type: Optional[str] = None,
    cclass: Optional[str] = None,
    purity: Optional[oracledb.Purity] = None,
    expire_time: Optional[int] = None,
    retry_count: Optional[int] = None,
    retry_delay: Optional[int] = None,
    tcp_connect_timeout: Optional[float] = None,
    ssl_server_dn_match: Optional[bool] = None,
    ssl_server_cert_dn: Optional[str] = None,
    wallet_location: Optional[str] = None,
    events: Optional[bool] = None,
    externalauth: Optional[bool] = None,
    mode: Optional[oracledb.AuthMode] = None,
    disable_oob: Optional[bool] = None,
    stmtcachesize: Optional[int] = None,
    edition: Optional[str] = None,
    tag: Optional[str] = None,
    matchanytag: Optional[bool] = None,
    config_dir: Optional[str] = None,
    appcontext: Optional[list] = None,
    shardingkey: Optional[list] = None,
    supershardingkey: Optional[list] = None,
    debug_jdwp: Optional[str] = None,
    connection_id_prefix: Optional[str] = None,
    ssl_context: Optional[Any] = None,
    sdu: Optional[int] = None,
    pool_boundary: Optional[str] = None,
    use_tcp_fast_open: Optional[bool] = None,
    ssl_version: Optional[ssl.TLSVersion] = None,
    program: Optional[str] = None,
    machine: Optional[str] = None,
    terminal: Optional[str] = None,
    osuser: Optional[str] = None,
    driver_name: Optional[str] = None,
    use_sni: Optional[bool] = None,
    thick_mode_dsn_passthrough: Optional[bool] = None,
    extra_auth_params: Optional[dict] = None,
    handle: Optional[int] = None,
) -> ConnectionPool:
    """
    Creates a connection pool with the supplied parameters and returns it.

    The dsn parameter (data source name) can be a string in the format
    user/password@connect_string or can simply be the connect string (in
    which case authentication credentials such as the username and password
    need to be specified separately). See the documentation on connection
    strings for more information.

    The pool_class parameter is expected to be ConnectionPool or a subclass of
    ConnectionPool.

    The pool_alias parameter is expected to be a string representing the name
    used to store and reference the pool in the python-oracledb connection
    pool cache. If this parameter is not specified, then the pool will not be
    added to the cache. The value of this parameter can be used with the
    oracledb.get_pool() and oracledb.connect() methods to access the pool.

    The params parameter is expected to be of type PoolParams and contains
    parameters that are used to create the pool. See the documentation on
    PoolParams for more information. If this parameter is not specified, the
    additional keyword parameters will be used to create an instance of
    PoolParams. If both the params parameter and additional keyword parameters
    are specified, the values in the keyword parameters have precedence.
    Note that if a dsn is also supplied, then in the python-oracledb Thin mode,
    the values of the parameters specified (if any) within the dsn will
    override the values passed as additional keyword parameters, which
    themselves override the values set in the params parameter object.

    The following parameters are all optional. A brief description of each
    parameter follows:

    - min: the minimum number of connections the pool should contain (default:
      1)

    - max: the maximum number of connections the pool should contain (default:
      2)

    - increment: the number of connections that should be added to the pool
      whenever a new connection needs to be created (default: 1)

    - connectiontype: the class of the connection that should be returned
      during calls to pool.acquire(). It must be oracledb.Connection or a
      subclass of oracledb.Connection (default: None)

    - getmode: how pool.acquire() will behave. One of the constants
      oracledb.POOL_GETMODE_WAIT, oracledb.POOL_GETMODE_NOWAIT,
      oracledb.POOL_GETMODE_FORCEGET, or oracledb.POOL_GETMODE_TIMEDWAIT
      (default: oracledb.POOL_GETMODE_WAIT)

    - homogeneous: a boolean indicating whether the connections are homogeneous
      (same user) or heterogeneous (multiple users) (default: True)

    - timeout: length of time (in seconds) that a connection may remain idle in
      the pool before it is terminated. If it is 0 then connections are never
      terminated (default: 0)

    - wait_timeout: length of time (in milliseconds) that a caller should wait
      when acquiring a connection from the pool with getmode set to
      oracledb.POOL_GETMODE_TIMEDWAIT (default: 0)

    - max_lifetime_session: length of time (in seconds) that connections can
      remain in the pool. If it is 0 then connections may remain in the pool
      indefinitely (default: 0)

    - session_callback: a callable that is invoked when a connection is
      returned from the pool for the first time, or when the connection tag
      differs from the one requested (default: None)

    - max_sessions_per_shard: the maximum number of connections that may be
      associated with a particular shard (default: 0)

    - soda_metadata_cache: boolean indicating whether or not the SODA metadata
      cache should be enabled (default: False)

    - ping_interval: length of time (in seconds) after which an unused
      connection in the pool will be a candidate for pinging when
      pool.acquire() is called. If the ping to the database indicates the
      connection is not alive a replacement connection will be returned by
      pool.acquire(). If ping_interval is a negative value the ping
      functionality will be disabled (default: 60)

    - ping_timeout: maximum length of time (in milliseconds) to wait for a
      connection in the pool to respond to an internal ping to the database
      before being discarded and replaced during a call to acquire() (default:
      5000)

    - user: the name of the user to connect to (default: None)

    - proxy_user: the name of the proxy user to connect to. If this value is
      not specified, it will be parsed out of user if user is in the form
      "user[proxy_user]" (default: None)

    - password: the password for the user (default: None)

    - newpassword: the new password for the user. The new password will take
      effect immediately upon a successful connection to the database (default:
      None)

    - wallet_password: the password to use to decrypt the wallet, if it is
      encrypted. This value is only used in thin mode (default: None)

    - access_token: expected to be a string or a 2-tuple or a callable. If it
      is a string, it specifies an Azure AD OAuth2 token used for Open
      Authorization (OAuth 2.0) token based authentication. If it is a 2-tuple,
      it specifies the token and private key strings used for Oracle Cloud
      Infrastructure (OCI) Identity and Access Management (IAM) token based
      authentication. If it is a callable, it returns either a string or a
      2-tuple used for OAuth 2.0 or OCI IAM token based authentication and is
      useful when the pool needs to expand and create new connections but the
      current authentication token has expired (default: None)

    - host: the name or IP address of the machine hosting the database or the
      database listener (default: None)

    - port: the port number on which the database listener is listening
      (default: 1521)

    - protocol: one of the strings "tcp" or "tcps" indicating whether to use
      unencrypted network traffic or encrypted network traffic (TLS) (default:
      "tcp")

    - https_proxy: the name or IP address of a proxy host to use for tunneling
      secure connections (default: None)

    - https_proxy_port: the port on which to communicate with the proxy host
      (default: 0)

    - service_name: the service name of the database (default: None)

    - instance_name: the instance name of the database (default: None)

    - sid: the system identifier (SID) of the database. Note using a
      service_name instead is recommended (default: None)

    - server_type: the type of server connection that should be established. If
      specified, it should be one of "dedicated", "shared" or "pooled"
      (default: None)

    - cclass: connection class to use for Database Resident Connection Pooling
      (DRCP) (default: None)

    - purity: purity to use for Database Resident Connection Pooling (DRCP)
      (default: oracledb.PURITY_DEFAULT)

    - expire_time: an integer indicating the number of minutes between the
      sending of keepalive probes. If this parameter is set to a value greater
      than zero it enables keepalive (default: 0)

    - retry_count: the number of times that a connection attempt should be
      retried before the attempt is terminated (default: 0)

    - retry_delay: the number of seconds to wait before making a new connection
      attempt (default: 1)

    - tcp_connect_timeout: a float indicating the maximum number of seconds to
      wait for establishing a connection to the database host (default: 20.0)

    - ssl_server_dn_match: boolean indicating whether the server certificate
      distinguished name (DN) should be matched in addition to the regular
      certificate verification that is performed. Note that if the
      ssl_server_cert_dn parameter is not privided, host name matching is
      performed instead (default: True)

    - ssl_server_cert_dn: the distinguished name (DN) which should be matched
      with the server. This value is ignored if the ssl_server_dn_match
      parameter is not set to the value True. If specified this value is used
      for any verfication. Otherwise the hostname will be used (default: None)

    - wallet_location: the directory where the wallet can be found. In thin
      mode this must be the directory containing the PEM-encoded wallet file
      ewallet.pem. In thick mode this must be the directory containing the file
      cwallet.sso (default: None)

    - events: boolean specifying whether events mode should be enabled. This
      value is only used in thick mode and is needed for continuous query
      notification and high availability event notifications (default: False)

    - externalauth: a boolean indicating whether to use external authentication
      (default: False)

    - mode: authorization mode to use. For example oracledb.AUTH_MODE_SYSDBA
      (default: oracledb.AUTH_MODE_DEFAULT)

    - disable_oob: boolean indicating whether out-of-band breaks should be
      disabled. This value is only used in thin mode. It has no effect on
      Windows which does not support this functionality (default: False)

    - stmtcachesize: identifies the initial size of the statement cache
      (default: oracledb.defaults.stmtcachesize)

    - edition: edition to use for the connection. This parameter cannot be used
      simultaneously with the cclass parameter (default: None)

    - tag: identifies the type of connection that should be returned from a
      pool. This value is only used in thick mode (default: None)

    - matchanytag: boolean specifying whether any tag can be used when
      acquiring a connection from the pool. This value is only used in thick
      mode (default: False)

    - config_dir: directory in which the optional tnsnames.ora configuration
      file is located. This value is only used in thin mode. For thick mode use
      the config_dir parameter of init_oracle_client() (default:
      oracledb.defaults.config_dir)

    - appcontext: application context used by the connection. It should be a
      list of 3-tuples (namespace, name, value) and each entry in the tuple
      should be a string. This value is only used in thick mode (default: None)

    - shardingkey: a list of strings, numbers, bytes or dates that identify the
      database shard to connect to. This value is only used in thick mode
      (default: None)

    - supershardingkey: a list of strings, numbers, bytes or dates that
      identify the database shard to connect to. This value is only used in
      thick mode (default: None)

    - debug_jdwp: a string with the format "host=<host>;port=<port>" that
      specifies the host and port of the PL/SQL debugger. This value is only
      used in thin mode. For thick mode set the ORA_DEBUG_JDWP environment
      variable (default: None)

    - connection_id_prefix: an application specific prefix that is added to the
      connection identifier used for tracing (default: None)

    - ssl_context: an SSLContext object used for connecting to the database
      using TLS.  This SSL context will be modified to include the private key
      or any certificates found in a separately supplied wallet. This parameter
      should only be specified if the default SSLContext object cannot be used
      (default: None)

    - sdu: the requested size of the Session Data Unit (SDU), in bytes. The
      value tunes internal buffers used for communication to the database.
      Bigger values can increase throughput for large queries or bulk data
      loads, but at the cost of higher memory use. The SDU size that will
      actually be used is negotiated down to the lower of this value and the
      database network SDU configuration value (default: 8192)

    - pool_boundary: one of the values "statement" or "transaction" indicating
      when pooled DRCP connections can be returned to the pool. This requires
      the use of DRCP with Oracle Database 23.4 or higher (default: None)

    - use_tcp_fast_open: boolean indicating whether to use TCP fast open. This
      is an Oracle Autonomous Database Serverless (ADB-S) specific property for
      clients connecting from within OCI Cloud network. Please refer to the
      ADB-S documentation for more information (default: False)

    - ssl_version: one of the values ssl.TLSVersion.TLSv1_2 or
      ssl.TLSVersion.TLSv1_3 indicating which TLS version to use (default:
      None)

    - program: the name of the executable program or application connected to
      the Oracle Database (default: oracledb.defaults.program)

    - machine: the machine name of the client connecting to the Oracle Database
      (default: oracledb.defaults.machine)

    - terminal: the terminal identifier from which the connection originates
      (default: oracledb.defaults.terminal)

    - osuser: the operating system user that initiates the database connection
      (default: oracledb.defaults.osuser)

    - driver_name: the driver name used by the client to connect to the Oracle
      Database (default: oracledb.defaults.driver_name)

    - use_sni: boolean indicating whether to use the TLS SNI extension to
      bypass the second TLS neogiation that would otherwise be required
      (default: False)

    - thick_mode_dsn_passthrough: boolean indicating whether to pass the
      connect string to the Oracle Client libraries unchanged without parsing
      by the driver. Setting this to False makes thick and thin mode
      applications behave similarly regarding connection string parameter
      handling and locating any optional tnsnames.ora configuration file
      (default: oracledb.defaults.thick_mode_dsn_passthrough)

    - extra_auth_params: a dictionary containing configuration parameters
      necessary for Oracle Database authentication using plugins, such as the
      Azure and OCI cloud-native authentication plugins (default: None)

    - handle: an integer representing a pointer to a valid service context
      handle. This value is only used in thick mode. It should be used with
      extreme caution (default: 0)
    """
    pass


class AsyncConnectionPool(BaseConnectionPool):
    __module__ = oracledb.__name__

    def _set_connection_type(self, conn_class):
        """
        Called internally when the pool is created to ensure that the correct
        connection class is used for all connections created by the pool.
        """
        if conn_class is None:
            conn_class = connection_module.AsyncConnection
        elif not issubclass(conn_class, connection_module.AsyncConnection):
            errors._raise_err(errors.ERR_INVALID_CONN_CLASS)
        self._connection_type = conn_class

    def acquire(
        self,
        user: Optional[str] = None,
        password: Optional[str] = None,
        cclass: Optional[str] = None,
        purity: int = oracledb.PURITY_DEFAULT,
        tag: Optional[str] = None,
        matchanytag: bool = False,
        shardingkey: Optional[list] = None,
        supershardingkey: Optional[list] = None,
    ) -> "connection_module.AsyncConnection":
        """
        Acquire a connection from the pool and return it.

        If the pool is homogeneous, the user and password parameters cannot be
        specified. If they are, an exception will be raised.

        The cclass parameter, if specified, should be a string corresponding to
        the connection class for database resident connection pooling (DRCP).

        The purity parameter is expected to be one of PURITY_DEFAULT,
        PURITY_NEW, or PURITY_SELF.

        The tag parameter, if specified, is expected to be a string with
        name=value pairs like “k1=v1;k2=v2” and will limit the connections that
        can be returned from a pool unless the matchanytag parameter is
        set to True. In that case connections with the specified tag will be
        preferred over others, but if no such connections are available a
        connection with a different tag may be returned instead. In any case,
        untagged connections will always be returned if no connections with the
        specified tag are available. Connections are tagged when they are
        released back to the pool.

        The shardingkey and supershardingkey parameters, if specified, are
        expected to be a sequence of values which will be used to identify the
        database shard to connect to. The key values can be strings, numbers,
        bytes or dates.
        """
        self._verify_open()

        return oracledb.connect_async(
            conn_class=self._connection_type,
            user=user,
            password=password,
            cclass=cclass,
            purity=purity,
            tag=tag,
            matchanytag=matchanytag,
            shardingkey=shardingkey,
            supershardingkey=supershardingkey,
            pool=self,
        )

    async def close(self, force: bool = False) -> None:
        """
        Close the pool now, rather than when the last reference to it is
        released, which makes it unusable for further work.

        If any connections have been acquired and not released back to the
        pool, this method will fail unless the force parameter is set to True.
        """
        self._verify_open()
        await self._impl.close(force)
        if self._cache_name is not None:
            named_pools.remove_pool(self._cache_name)
        self._impl = None

    async def drop(self, connection: "connection_module.Connection") -> None:
        """
        Drop the connection from the pool, which is useful if the connection is
        no longer usable (such as when the database session is killed).
        """
        self._verify_open()
        if not isinstance(connection, connection_module.AsyncConnection):
            message = (
                "connection must be an instance of oracledb.AsyncConnection"
            )
            raise TypeError(message)
        connection._verify_connected()
        await self._impl.drop(connection._impl)
        connection._impl = None

    async def release(
        self,
        connection: "connection_module.AsyncConnection",
        tag: Optional[str] = None,
    ) -> None:
        """
        Release the connection back to the pool now, rather than whenever
        __del__ is called. The connection will be unusable from this point
        forward; an Error exception will be raised if any operation is
        attempted with the connection. Any cursors or LOBs created by the
        connection will also be marked unusable and an Error exception will be
        raised if any operation is attempted with them.

        Internally, references to the connection are held by cursor objects,
        LOB objects, etc. Once all of these references are released, the
        connection itself will be released back to the pool automatically.
        Either control references to these related objects carefully or
        explicitly release connections back to the pool in order to ensure
        sufficient resources are available.

        If the tag is not None, it is expected to be a string with name=value
        pairs like “k1=v1;k2=v2” and will override the value in the property
        Connection.tag. If either Connection.tag or the tag parameter are not
        None, the connection will be retagged when it is released back to the
        pool.
        """
        self._verify_open()
        if not isinstance(connection, connection_module.AsyncConnection):
            message = (
                "connection must be an instance of oracledb.AsyncConnection"
            )
            raise TypeError(message)
        if tag is not None:
            connection.tag = tag
        await connection.close()


def _async_pool_factory(
    f: Callable[..., AsyncConnectionPool]
) -> Callable[..., AsyncConnectionPool]:
    """
    Decorator which checks the validity of the supplied keyword parameters by
    calling the original function (which does nothing), then creates and
    returns an instance of the requested ConnectionPool class. The base
    ConnectionPool class constructor does not check the validity of the
    supplied keyword parameters.
    """

    @functools.wraps(f)
    def create_pool_async(
        dsn: Optional[str] = None,
        *,
        pool_class: Type[ConnectionPool] = AsyncConnectionPool,
        pool_alias: Optional[str] = None,
        params: Optional[PoolParams] = None,
        **kwargs,
    ) -> AsyncConnectionPool:
        f(
            dsn=dsn,
            pool_class=pool_class,
            pool_alias=pool_alias,
            params=params,
            **kwargs,
        )
        oracledb.enable_thin_mode()
        if not issubclass(pool_class, AsyncConnectionPool):
            errors._raise_err(errors.ERR_INVALID_POOL_CLASS)
        return pool_class(dsn, params=params, cache_name=pool_alias, **kwargs)

    return create_pool_async


@_async_pool_factory
def create_pool_async(
    dsn: Optional[str] = None,
    *,
    pool_class: Type[ConnectionPool] = AsyncConnectionPool,
    pool_alias: Optional[str] = None,
    params: Optional[PoolParams] = None,
    min: Optional[int] = None,
    max: Optional[int] = None,
    increment: Optional[int] = None,
    connectiontype: Optional[Type["oracledb.AsyncConnection"]] = None,
    getmode: Optional[oracledb.PoolGetMode] = None,
    homogeneous: Optional[bool] = None,
    timeout: Optional[int] = None,
    wait_timeout: Optional[int] = None,
    max_lifetime_session: Optional[int] = None,
    session_callback: Optional[Callable] = None,
    max_sessions_per_shard: Optional[int] = None,
    soda_metadata_cache: Optional[bool] = None,
    ping_interval: Optional[int] = None,
    ping_timeout: Optional[int] = None,
    user: Optional[str] = None,
    proxy_user: Optional[str] = None,
    password: Optional[str] = None,
    newpassword: Optional[str] = None,
    wallet_password: Optional[str] = None,
    access_token: Optional[Union[str, tuple, Callable]] = None,
    host: Optional[str] = None,
    port: Optional[int] = None,
    protocol: Optional[str] = None,
    https_proxy: Optional[str] = None,
    https_proxy_port: Optional[int] = None,
    service_name: Optional[str] = None,
    instance_name: Optional[str] = None,
    sid: Optional[str] = None,
    server_type: Optional[str] = None,
    cclass: Optional[str] = None,
    purity: Optional[oracledb.Purity] = None,
    expire_time: Optional[int] = None,
    retry_count: Optional[int] = None,
    retry_delay: Optional[int] = None,
    tcp_connect_timeout: Optional[float] = None,
    ssl_server_dn_match: Optional[bool] = None,
    ssl_server_cert_dn: Optional[str] = None,
    wallet_location: Optional[str] = None,
    events: Optional[bool] = None,
    externalauth: Optional[bool] = None,
    mode: Optional[oracledb.AuthMode] = None,
    disable_oob: Optional[bool] = None,
    stmtcachesize: Optional[int] = None,
    edition: Optional[str] = None,
    tag: Optional[str] = None,
    matchanytag: Optional[bool] = None,
    config_dir: Optional[str] = None,
    appcontext: Optional[list] = None,
    shardingkey: Optional[list] = None,
    supershardingkey: Optional[list] = None,
    debug_jdwp: Optional[str] = None,
    connection_id_prefix: Optional[str] = None,
    ssl_context: Optional[Any] = None,
    sdu: Optional[int] = None,
    pool_boundary: Optional[str] = None,
    use_tcp_fast_open: Optional[bool] = None,
    ssl_version: Optional[ssl.TLSVersion] = None,
    program: Optional[str] = None,
    machine: Optional[str] = None,
    terminal: Optional[str] = None,
    osuser: Optional[str] = None,
    driver_name: Optional[str] = None,
    use_sni: Optional[bool] = None,
    thick_mode_dsn_passthrough: Optional[bool] = None,
    extra_auth_params: Optional[dict] = None,
    handle: Optional[int] = None,
) -> AsyncConnectionPool:
    """
    Creates a connection pool with the supplied parameters and returns it.

    The dsn parameter (data source name) can be a string in the format
    user/password@connect_string or can simply be the connect string (in
    which case authentication credentials such as the username and password
    need to be specified separately). See the documentation on connection
    strings for more information.

    The pool_class parameter is expected to be AsyncConnectionPool or a
    subclass of AsyncConnectionPool.

    The pool_alias parameter is expected to be a string representing the name
    used to store and reference the pool in the python-oracledb connection
    pool cache. If this parameter is not specified, then the pool will not be
    added to the cache. The value of this parameter can be used with the
    oracledb.get_pool() and oracledb.connect_async() methods to access the
    pool.

    The params parameter is expected to be of type PoolParams and contains
    parameters that are used to create the pool. See the documentation on
    PoolParams for more information. If this parameter is not specified, the
    additional keyword parameters will be used to create an instance of
    PoolParams. If both the params parameter and additional keyword parameters
    are specified, the values in the keyword parameters have precedence.
    Note that if a dsn is also supplied, then in the python-oracledb Thin mode,
    the values of the parameters specified (if any) within the dsn will
    override the values passed as additional keyword parameters, which
    themselves override the values set in the params parameter object.

    The following parameters are all optional. A brief description of each
    parameter follows:

    - min: the minimum number of connections the pool should contain (default:
      1)

    - max: the maximum number of connections the pool should contain (default:
      2)

    - increment: the number of connections that should be added to the pool
      whenever a new connection needs to be created (default: 1)

    - connectiontype: the class of the connection that should be returned
      during calls to pool.acquire(). It must be oracledb.AsyncConnection or a
      subclass of oracledb.AsyncConnection (default: None)

    - getmode: how pool.acquire() will behave. One of the constants
      oracledb.POOL_GETMODE_WAIT, oracledb.POOL_GETMODE_NOWAIT,
      oracledb.POOL_GETMODE_FORCEGET, or oracledb.POOL_GETMODE_TIMEDWAIT
      (default: oracledb.POOL_GETMODE_WAIT)

    - homogeneous: a boolean indicating whether the connections are homogeneous
      (same user) or heterogeneous (multiple users) (default: True)

    - timeout: length of time (in seconds) that a connection may remain idle in
      the pool before it is terminated. If it is 0 then connections are never
      terminated (default: 0)

    - wait_timeout: length of time (in milliseconds) that a caller should wait
      when acquiring a connection from the pool with getmode set to
      oracledb.POOL_GETMODE_TIMEDWAIT (default: 0)

    - max_lifetime_session: length of time (in seconds) that connections can
      remain in the pool. If it is 0 then connections may remain in the pool
      indefinitely (default: 0)

    - session_callback: a callable that is invoked when a connection is
      returned from the pool for the first time, or when the connection tag
      differs from the one requested (default: None)

    - max_sessions_per_shard: the maximum number of connections that may be
      associated with a particular shard (default: 0)

    - soda_metadata_cache: boolean indicating whether or not the SODA metadata
      cache should be enabled (default: False)

    - ping_interval: length of time (in seconds) after which an unused
      connection in the pool will be a candidate for pinging when
      pool.acquire() is called. If the ping to the database indicates the
      connection is not alive a replacement connection will be returned by
      pool.acquire(). If ping_interval is a negative value the ping
      functionality will be disabled (default: 60)

    - ping_timeout: maximum length of time (in milliseconds) to wait for a
      connection in the pool to respond to an internal ping to the database
      before being discarded and replaced during a call to acquire() (default:
      5000)

    - user: the name of the user to connect to (default: None)

    - proxy_user: the name of the proxy user to connect to. If this value is
      not specified, it will be parsed out of user if user is in the form
      "user[proxy_user]" (default: None)

    - password: the password for the user (default: None)

    - newpassword: the new password for the user. The new password will take
      effect immediately upon a successful connection to the database (default:
      None)

    - wallet_password: the password to use to decrypt the wallet, if it is
      encrypted. This value is only used in thin mode (default: None)

    - access_token: expected to be a string or a 2-tuple or a callable. If it
      is a string, it specifies an Azure AD OAuth2 token used for Open
      Authorization (OAuth 2.0) token based authentication. If it is a 2-tuple,
      it specifies the token and private key strings used for Oracle Cloud
      Infrastructure (OCI) Identity and Access Management (IAM) token based
      authentication. If it is a callable, it returns either a string or a
      2-tuple used for OAuth 2.0 or OCI IAM token based authentication and is
      useful when the pool needs to expand and create new connections but the
      current authentication token has expired (default: None)

    - host: the name or IP address of the machine hosting the database or the
      database listener (default: None)

    - port: the port number on which the database listener is listening
      (default: 1521)

    - protocol: one of the strings "tcp" or "tcps" indicating whether to use
      unencrypted network traffic or encrypted network traffic (TLS) (default:
      "tcp")

    - https_proxy: the name or IP address of a proxy host to use for tunneling
      secure connections (default: None)

    - https_proxy_port: the port on which to communicate with the proxy host
      (default: 0)

    - service_name: the service name of the database (default: None)

    - instance_name: the instance name of the database (default: None)

    - sid: the system identifier (SID) of the database. Note using a
      service_name instead is recommended (default: None)

    - server_type: the type of server connection that should be established. If
      specified, it should be one of "dedicated", "shared" or "pooled"
      (default: None)

    - cclass: connection class to use for Database Resident Connection Pooling
      (DRCP) (default: None)

    - purity: purity to use for Database Resident Connection Pooling (DRCP)
      (default: oracledb.PURITY_DEFAULT)

    - expire_time: an integer indicating the number of minutes between the
      sending of keepalive probes. If this parameter is set to a value greater
      than zero it enables keepalive (default: 0)

    - retry_count: the number of times that a connection attempt should be
      retried before the attempt is terminated (default: 0)

    - retry_delay: the number of seconds to wait before making a new connection
      attempt (default: 1)

    - tcp_connect_timeout: a float indicating the maximum number of seconds to
      wait for establishing a connection to the database host (default: 20.0)

    - ssl_server_dn_match: boolean indicating whether the server certificate
      distinguished name (DN) should be matched in addition to the regular
      certificate verification that is performed. Note that if the
      ssl_server_cert_dn parameter is not privided, host name matching is
      performed instead (default: True)

    - ssl_server_cert_dn: the distinguished name (DN) which should be matched
      with the server. This value is ignored if the ssl_server_dn_match
      parameter is not set to the value True. If specified this value is used
      for any verfication. Otherwise the hostname will be used (default: None)

    - wallet_location: the directory where the wallet can be found. In thin
      mode this must be the directory containing the PEM-encoded wallet file
      ewallet.pem. In thick mode this must be the directory containing the file
      cwallet.sso (default: None)

    - events: boolean specifying whether events mode should be enabled. This
      value is only used in thick mode and is needed for continuous query
      notification and high availability event notifications (default: False)

    - externalauth: a boolean indicating whether to use external authentication
      (default: False)

    - mode: authorization mode to use. For example oracledb.AUTH_MODE_SYSDBA
      (default: oracledb.AUTH_MODE_DEFAULT)

    - disable_oob: boolean indicating whether out-of-band breaks should be
      disabled. This value is only used in thin mode. It has no effect on
      Windows which does not support this functionality (default: False)

    - stmtcachesize: identifies the initial size of the statement cache
      (default: oracledb.defaults.stmtcachesize)

    - edition: edition to use for the connection. This parameter cannot be used
      simultaneously with the cclass parameter (default: None)

    - tag: identifies the type of connection that should be returned from a
      pool. This value is only used in thick mode (default: None)

    - matchanytag: boolean specifying whether any tag can be used when
      acquiring a connection from the pool. This value is only used in thick
      mode (default: False)

    - config_dir: directory in which the optional tnsnames.ora configuration
      file is located. This value is only used in thin mode. For thick mode use
      the config_dir parameter of init_oracle_client() (default:
      oracledb.defaults.config_dir)

    - appcontext: application context used by the connection. It should be a
      list of 3-tuples (namespace, name, value) and each entry in the tuple
      should be a string. This value is only used in thick mode (default: None)

    - shardingkey: a list of strings, numbers, bytes or dates that identify the
      database shard to connect to. This value is only used in thick mode
      (default: None)

    - supershardingkey: a list of strings, numbers, bytes or dates that
      identify the database shard to connect to. This value is only used in
      thick mode (default: None)

    - debug_jdwp: a string with the format "host=<host>;port=<port>" that
      specifies the host and port of the PL/SQL debugger. This value is only
      used in thin mode. For thick mode set the ORA_DEBUG_JDWP environment
      variable (default: None)

    - connection_id_prefix: an application specific prefix that is added to the
      connection identifier used for tracing (default: None)

    - ssl_context: an SSLContext object used for connecting to the database
      using TLS.  This SSL context will be modified to include the private key
      or any certificates found in a separately supplied wallet. This parameter
      should only be specified if the default SSLContext object cannot be used
      (default: None)

    - sdu: the requested size of the Session Data Unit (SDU), in bytes. The
      value tunes internal buffers used for communication to the database.
      Bigger values can increase throughput for large queries or bulk data
      loads, but at the cost of higher memory use. The SDU size that will
      actually be used is negotiated down to the lower of this value and the
      database network SDU configuration value (default: 8192)

    - pool_boundary: one of the values "statement" or "transaction" indicating
      when pooled DRCP connections can be returned to the pool. This requires
      the use of DRCP with Oracle Database 23.4 or higher (default: None)

    - use_tcp_fast_open: boolean indicating whether to use TCP fast open. This
      is an Oracle Autonomous Database Serverless (ADB-S) specific property for
      clients connecting from within OCI Cloud network. Please refer to the
      ADB-S documentation for more information (default: False)

    - ssl_version: one of the values ssl.TLSVersion.TLSv1_2 or
      ssl.TLSVersion.TLSv1_3 indicating which TLS version to use (default:
      None)

    - program: the name of the executable program or application connected to
      the Oracle Database (default: oracledb.defaults.program)

    - machine: the machine name of the client connecting to the Oracle Database
      (default: oracledb.defaults.machine)

    - terminal: the terminal identifier from which the connection originates
      (default: oracledb.defaults.terminal)

    - osuser: the operating system user that initiates the database connection
      (default: oracledb.defaults.osuser)

    - driver_name: the driver name used by the client to connect to the Oracle
      Database (default: oracledb.defaults.driver_name)

    - use_sni: boolean indicating whether to use the TLS SNI extension to
      bypass the second TLS neogiation that would otherwise be required
      (default: False)

    - thick_mode_dsn_passthrough: boolean indicating whether to pass the
      connect string to the Oracle Client libraries unchanged without parsing
      by the driver. Setting this to False makes thick and thin mode
      applications behave similarly regarding connection string parameter
      handling and locating any optional tnsnames.ora configuration file
      (default: oracledb.defaults.thick_mode_dsn_passthrough)

    - extra_auth_params: a dictionary containing configuration parameters
      necessary for Oracle Database authentication using plugins, such as the
      Azure and OCI cloud-native authentication plugins (default: None)

    - handle: an integer representing a pointer to a valid service context
      handle. This value is only used in thick mode. It should be used with
      extreme caution (default: 0)
    """
    pass


class NamedPools:

    def __init__(self):
        self.lock = threading.Lock()
        self.pools = {}

    def add_pool(self, alias, pool):
        """
        Adds a pool to the cache. An exception is raised if a pool is already
        cached with the given alias.
        """
        if not isinstance(alias, str):
            raise TypeError("pool_alias must be a string")
        with self.lock:
            if alias in self.pools:
                errors._raise_err(errors.ERR_NAMED_POOL_EXISTS, alias=alias)
            self.pools[alias] = pool

    def remove_pool(self, alias):
        """
        Removes the pool with the given alias from the cache. An exception is
        raised if there is no pool cached with the given alias.
        """
        with self.lock:
            if alias not in self.pools:
                errors._raise_err(errors.ERR_NAMED_POOL_MISSING, alias=alias)
            del self.pools[alias]


named_pools = NamedPools()


def get_pool(
    pool_alias: str,
) -> Union[ConnectionPool, AsyncConnectionPool, None]:
    """
    Returns the connection pool with the given alias from the python-oracledb
    connection pool cache. If a pool with that alias does not exist, the value
    "None" will be returned.
    """
    return named_pools.pools.get(pool_alias)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\pool_params.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2022, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# pool_params.py
#
# Contains the PoolParams class used for managing the parameters required to
# create a connection pool.
#
# *** NOTICE *** This file is generated from a template and should not be
# modified directly. See build_from_template.py in the utils subdirectory for
# more information.
# -----------------------------------------------------------------------------

import ssl
from typing import Callable, Type, Union, Any, Optional

import oracledb

from . import base_impl, utils
from .connect_params import ConnectParams


class PoolParams(ConnectParams):
    """
    Contains all parameters used for creating a connection pool.
    """

    __module__ = oracledb.__name__
    __slots__ = ["_impl"]
    _impl_class = base_impl.PoolParamsImpl

    @utils.params_initer
    def __init__(
        self,
        *,
        min: Optional[int] = None,
        max: Optional[int] = None,
        increment: Optional[int] = None,
        connectiontype: Optional[Type["oracledb.Connection"]] = None,
        getmode: Optional[oracledb.PoolGetMode] = None,
        homogeneous: Optional[bool] = None,
        timeout: Optional[int] = None,
        wait_timeout: Optional[int] = None,
        max_lifetime_session: Optional[int] = None,
        session_callback: Optional[Callable] = None,
        max_sessions_per_shard: Optional[int] = None,
        soda_metadata_cache: Optional[bool] = None,
        ping_interval: Optional[int] = None,
        ping_timeout: Optional[int] = None,
        user: Optional[str] = None,
        proxy_user: Optional[str] = None,
        password: Optional[str] = None,
        newpassword: Optional[str] = None,
        wallet_password: Optional[str] = None,
        access_token: Optional[Union[str, tuple, Callable]] = None,
        host: Optional[str] = None,
        port: Optional[int] = None,
        protocol: Optional[str] = None,
        https_proxy: Optional[str] = None,
        https_proxy_port: Optional[int] = None,
        service_name: Optional[str] = None,
        instance_name: Optional[str] = None,
        sid: Optional[str] = None,
        server_type: Optional[str] = None,
        cclass: Optional[str] = None,
        purity: Optional[oracledb.Purity] = None,
        expire_time: Optional[int] = None,
        retry_count: Optional[int] = None,
        retry_delay: Optional[int] = None,
        tcp_connect_timeout: Optional[float] = None,
        ssl_server_dn_match: Optional[bool] = None,
        ssl_server_cert_dn: Optional[str] = None,
        wallet_location: Optional[str] = None,
        events: Optional[bool] = None,
        externalauth: Optional[bool] = None,
        mode: Optional[oracledb.AuthMode] = None,
        disable_oob: Optional[bool] = None,
        stmtcachesize: Optional[int] = None,
        edition: Optional[str] = None,
        tag: Optional[str] = None,
        matchanytag: Optional[bool] = None,
        config_dir: Optional[str] = None,
        appcontext: Optional[list] = None,
        shardingkey: Optional[list] = None,
        supershardingkey: Optional[list] = None,
        debug_jdwp: Optional[str] = None,
        connection_id_prefix: Optional[str] = None,
        ssl_context: Optional[Any] = None,
        sdu: Optional[int] = None,
        pool_boundary: Optional[str] = None,
        use_tcp_fast_open: Optional[bool] = None,
        ssl_version: Optional[ssl.TLSVersion] = None,
        program: Optional[str] = None,
        machine: Optional[str] = None,
        terminal: Optional[str] = None,
        osuser: Optional[str] = None,
        driver_name: Optional[str] = None,
        use_sni: Optional[bool] = None,
        thick_mode_dsn_passthrough: Optional[bool] = None,
        extra_auth_params: Optional[dict] = None,
        handle: Optional[int] = None,
    ):
        """
        All parameters are optional. A brief description of each parameter
        follows:

        - min: the minimum number of connections the pool should contain
          (default: 1)

        - max: the maximum number of connections the pool should contain
          (default: 2)

        - increment: the number of connections that should be added to the pool
          whenever a new connection needs to be created (default: 1)

        - connectiontype: the class of the connection that should be returned
          during calls to pool.acquire(). It must be oracledb.Connection or a
          subclass of oracledb.Connection (default: None)

        - getmode: how pool.acquire() will behave. One of the constants
          oracledb.POOL_GETMODE_WAIT, oracledb.POOL_GETMODE_NOWAIT,
          oracledb.POOL_GETMODE_FORCEGET, or oracledb.POOL_GETMODE_TIMEDWAIT
          (default: oracledb.POOL_GETMODE_WAIT)

        - homogeneous: a boolean indicating whether the connections are
          homogeneous (same user) or heterogeneous (multiple users) (default:
          True)

        - timeout: length of time (in seconds) that a connection may remain
          idle in the pool before it is terminated. If it is 0 then connections
          are never terminated (default: 0)

        - wait_timeout: length of time (in milliseconds) that a caller should
          wait when acquiring a connection from the pool with getmode set to
          oracledb.POOL_GETMODE_TIMEDWAIT (default: 0)

        - max_lifetime_session: length of time (in seconds) that connections
          can remain in the pool. If it is 0 then connections may remain in the
          pool indefinitely (default: 0)

        - session_callback: a callable that is invoked when a connection is
          returned from the pool for the first time, or when the connection tag
          differs from the one requested (default: None)

        - max_sessions_per_shard: the maximum number of connections that may be
          associated with a particular shard (default: 0)

        - soda_metadata_cache: boolean indicating whether or not the SODA
          metadata cache should be enabled (default: False)

        - ping_interval: length of time (in seconds) after which an unused
          connection in the pool will be a candidate for pinging when
          pool.acquire() is called. If the ping to the database indicates the
          connection is not alive a replacement connection will be returned by
          pool.acquire(). If ping_interval is a negative value the ping
          functionality will be disabled (default: 60)

        - ping_timeout: maximum length of time (in milliseconds) to wait for a
          connection in the pool to respond to an internal ping to the database
          before being discarded and replaced during a call to acquire()
          (default: 5000)

        - user: the name of the user to connect to (default: None)

        - proxy_user: the name of the proxy user to connect to. If this value
          is not specified, it will be parsed out of user if user is in the
          form "user[proxy_user]" (default: None)

        - password: the password for the user (default: None)

        - newpassword: the new password for the user. The new password will
          take effect immediately upon a successful connection to the database
          (default: None)

        - wallet_password: the password to use to decrypt the wallet, if it is
          encrypted. This value is only used in thin mode (default: None)

        - access_token: expected to be a string or a 2-tuple or a callable. If
          it is a string, it specifies an Azure AD OAuth2 token used for Open
          Authorization (OAuth 2.0) token based authentication. If it is a
          2-tuple, it specifies the token and private key strings used for
          Oracle Cloud Infrastructure (OCI) Identity and Access Management
          (IAM) token based authentication. If it is a callable, it returns
          either a string or a 2-tuple used for OAuth 2.0 or OCI IAM token
          based authentication and is useful when the pool needs to expand and
          create new connections but the current authentication token has
          expired (default: None)

        - host: the name or IP address of the machine hosting the database or
          the database listener (default: None)

        - port: the port number on which the database listener is listening
          (default: 1521)

        - protocol: one of the strings "tcp" or "tcps" indicating whether to
          use unencrypted network traffic or encrypted network traffic (TLS)
          (default: "tcp")

        - https_proxy: the name or IP address of a proxy host to use for
          tunneling secure connections (default: None)

        - https_proxy_port: the port on which to communicate with the proxy
          host (default: 0)

        - service_name: the service name of the database (default: None)

        - instance_name: the instance name of the database (default: None)

        - sid: the system identifier (SID) of the database. Note using a
          service_name instead is recommended (default: None)

        - server_type: the type of server connection that should be
          established. If specified, it should be one of "dedicated", "shared"
          or "pooled" (default: None)

        - cclass: connection class to use for Database Resident Connection
          Pooling (DRCP) (default: None)

        - purity: purity to use for Database Resident Connection Pooling (DRCP)
          (default: oracledb.PURITY_DEFAULT)

        - expire_time: an integer indicating the number of minutes between the
          sending of keepalive probes. If this parameter is set to a value
          greater than zero it enables keepalive (default: 0)

        - retry_count: the number of times that a connection attempt should be
          retried before the attempt is terminated (default: 0)

        - retry_delay: the number of seconds to wait before making a new
          connection attempt (default: 1)

        - tcp_connect_timeout: a float indicating the maximum number of seconds
          to wait for establishing a connection to the database host (default:
          20.0)

        - ssl_server_dn_match: boolean indicating whether the server
          certificate distinguished name (DN) should be matched in addition to
          the regular certificate verification that is performed. Note that if
          the ssl_server_cert_dn parameter is not privided, host name matching
          is performed instead (default: True)

        - ssl_server_cert_dn: the distinguished name (DN) which should be
          matched with the server. This value is ignored if the
          ssl_server_dn_match parameter is not set to the value True. If
          specified this value is used for any verfication. Otherwise the
          hostname will be used (default: None)

        - wallet_location: the directory where the wallet can be found. In thin
          mode this must be the directory containing the PEM-encoded wallet
          file ewallet.pem. In thick mode this must be the directory containing
          the file cwallet.sso (default: None)

        - events: boolean specifying whether events mode should be enabled.
          This value is only used in thick mode and is needed for continuous
          query notification and high availability event notifications
          (default: False)

        - externalauth: a boolean indicating whether to use external
          authentication (default: False)

        - mode: authorization mode to use. For example
          oracledb.AUTH_MODE_SYSDBA (default: oracledb.AUTH_MODE_DEFAULT)

        - disable_oob: boolean indicating whether out-of-band breaks should be
          disabled. This value is only used in thin mode. It has no effect on
          Windows which does not support this functionality (default: False)

        - stmtcachesize: identifies the initial size of the statement cache
          (default: oracledb.defaults.stmtcachesize)

        - edition: edition to use for the connection. This parameter cannot be
          used simultaneously with the cclass parameter (default: None)

        - tag: identifies the type of connection that should be returned from a
          pool. This value is only used in thick mode (default: None)

        - matchanytag: boolean specifying whether any tag can be used when
          acquiring a connection from the pool. This value is only used in
          thick mode (default: False)

        - config_dir: directory in which the optional tnsnames.ora
          configuration file is located. This value is only used in thin mode.
          For thick mode use the config_dir parameter of init_oracle_client()
          (default: oracledb.defaults.config_dir)

        - appcontext: application context used by the connection. It should be
          a list of 3-tuples (namespace, name, value) and each entry in the
          tuple should be a string. This value is only used in thick mode
          (default: None)

        - shardingkey: a list of strings, numbers, bytes or dates that identify
          the database shard to connect to. This value is only used in thick
          mode (default: None)

        - supershardingkey: a list of strings, numbers, bytes or dates that
          identify the database shard to connect to. This value is only used in
          thick mode (default: None)

        - debug_jdwp: a string with the format "host=<host>;port=<port>" that
          specifies the host and port of the PL/SQL debugger. This value is
          only used in thin mode. For thick mode set the ORA_DEBUG_JDWP
          environment variable (default: None)

        - connection_id_prefix: an application specific prefix that is added to
          the connection identifier used for tracing (default: None)

        - ssl_context: an SSLContext object used for connecting to the database
          using TLS.  This SSL context will be modified to include the private
          key or any certificates found in a separately supplied wallet. This
          parameter should only be specified if the default SSLContext object
          cannot be used (default: None)

        - sdu: the requested size of the Session Data Unit (SDU), in bytes. The
          value tunes internal buffers used for communication to the database.
          Bigger values can increase throughput for large queries or bulk data
          loads, but at the cost of higher memory use. The SDU size that will
          actually be used is negotiated down to the lower of this value and
          the database network SDU configuration value (default: 8192)

        - pool_boundary: one of the values "statement" or "transaction"
          indicating when pooled DRCP connections can be returned to the pool.
          This requires the use of DRCP with Oracle Database 23.4 or higher
          (default: None)

        - use_tcp_fast_open: boolean indicating whether to use TCP fast open.
          This is an Oracle Autonomous Database Serverless (ADB-S) specific
          property for clients connecting from within OCI Cloud network. Please
          refer to the ADB-S documentation for more information (default:
          False)

        - ssl_version: one of the values ssl.TLSVersion.TLSv1_2 or
          ssl.TLSVersion.TLSv1_3 indicating which TLS version to use (default:
          None)

        - program: the name of the executable program or application connected
          to the Oracle Database (default: oracledb.defaults.program)

        - machine: the machine name of the client connecting to the Oracle
          Database (default: oracledb.defaults.machine)

        - terminal: the terminal identifier from which the connection
          originates (default: oracledb.defaults.terminal)

        - osuser: the operating system user that initiates the database
          connection (default: oracledb.defaults.osuser)

        - driver_name: the driver name used by the client to connect to the
          Oracle Database (default: oracledb.defaults.driver_name)

        - use_sni: boolean indicating whether to use the TLS SNI extension to
          bypass the second TLS neogiation that would otherwise be required
          (default: False)

        - thick_mode_dsn_passthrough: boolean indicating whether to pass the
          connect string to the Oracle Client libraries unchanged without
          parsing by the driver. Setting this to False makes thick and thin
          mode applications behave similarly regarding connection string
          parameter handling and locating any optional tnsnames.ora
          configuration file (default:
          oracledb.defaults.thick_mode_dsn_passthrough)

        - extra_auth_params: a dictionary containing configuration parameters
          necessary for Oracle Database authentication using plugins, such as
          the Azure and OCI cloud-native authentication plugins (default: None)

        - handle: an integer representing a pointer to a valid service context
          handle. This value is only used in thick mode. It should be used with
          extreme caution (default: 0)
        """
        pass

    def __repr__(self):
        return (
            self.__class__.__qualname__ + "("
            f"min={self.min!r}, "
            f"max={self.max!r}, "
            f"increment={self.increment!r}, "
            f"connectiontype={self.connectiontype!r}, "
            f"getmode={self.getmode!r}, "
            f"homogeneous={self.homogeneous!r}, "
            f"timeout={self.timeout!r}, "
            f"wait_timeout={self.wait_timeout!r}, "
            f"max_lifetime_session={self.max_lifetime_session!r}, "
            f"session_callback={self.session_callback!r}, "
            f"max_sessions_per_shard={self.max_sessions_per_shard!r}, "
            f"soda_metadata_cache={self.soda_metadata_cache!r}, "
            f"ping_interval={self.ping_interval!r}, "
            f"ping_timeout={self.ping_timeout!r}, "
            f"user={self.user!r}, "
            f"proxy_user={self.proxy_user!r}, "
            f"host={self.host!r}, "
            f"port={self.port!r}, "
            f"protocol={self.protocol!r}, "
            f"https_proxy={self.https_proxy!r}, "
            f"https_proxy_port={self.https_proxy_port!r}, "
            f"service_name={self.service_name!r}, "
            f"instance_name={self.instance_name!r}, "
            f"sid={self.sid!r}, "
            f"server_type={self.server_type!r}, "
            f"cclass={self.cclass!r}, "
            f"purity={self.purity!r}, "
            f"expire_time={self.expire_time!r}, "
            f"retry_count={self.retry_count!r}, "
            f"retry_delay={self.retry_delay!r}, "
            f"tcp_connect_timeout={self.tcp_connect_timeout!r}, "
            f"ssl_server_dn_match={self.ssl_server_dn_match!r}, "
            f"ssl_server_cert_dn={self.ssl_server_cert_dn!r}, "
            f"wallet_location={self.wallet_location!r}, "
            f"events={self.events!r}, "
            f"externalauth={self.externalauth!r}, "
            f"mode={self.mode!r}, "
            f"disable_oob={self.disable_oob!r}, "
            f"stmtcachesize={self.stmtcachesize!r}, "
            f"edition={self.edition!r}, "
            f"tag={self.tag!r}, "
            f"matchanytag={self.matchanytag!r}, "
            f"config_dir={self.config_dir!r}, "
            f"appcontext={self.appcontext!r}, "
            f"shardingkey={self.shardingkey!r}, "
            f"supershardingkey={self.supershardingkey!r}, "
            f"debug_jdwp={self.debug_jdwp!r}, "
            f"connection_id_prefix={self.connection_id_prefix!r}, "
            f"ssl_context={self.ssl_context!r}, "
            f"sdu={self.sdu!r}, "
            f"pool_boundary={self.pool_boundary!r}, "
            f"use_tcp_fast_open={self.use_tcp_fast_open!r}, "
            f"ssl_version={self.ssl_version!r}, "
            f"program={self.program!r}, "
            f"machine={self.machine!r}, "
            f"terminal={self.terminal!r}, "
            f"osuser={self.osuser!r}, "
            f"driver_name={self.driver_name!r}, "
            f"use_sni={self.use_sni!r}, "
            f"thick_mode_dsn_passthrough={self.thick_mode_dsn_passthrough!r}, "
            f"extra_auth_params={self.extra_auth_params!r}"
            ")"
        )

    @property
    def connectiontype(self) -> Type["oracledb.Connection"]:
        """
        The class of the connection that should be returned during calls to
        pool.acquire(). It must be oracledb.Connection or a subclass of
        oracledb.Connection.
        """
        return self._impl.connectiontype

    @property
    def getmode(self) -> oracledb.PoolGetMode:
        """
        How pool.acquire() will behave. One of the constants
        oracledb.POOL_GETMODE_WAIT, oracledb.POOL_GETMODE_NOWAIT,
        oracledb.POOL_GETMODE_FORCEGET, or oracledb.POOL_GETMODE_TIMEDWAIT.
        """
        return oracledb.PoolGetMode(self._impl.getmode)

    @property
    def homogeneous(self) -> bool:
        """
        A boolean indicating whether the connections are homogeneous (same
        user) or heterogeneous (multiple users).
        """
        return self._impl.homogeneous

    @property
    def increment(self) -> int:
        """
        The number of connections that should be added to the pool whenever a
        new connection needs to be created.
        """
        return self._impl.increment

    @property
    def max(self) -> int:
        """
        The maximum number of connections the pool should contain.
        """
        return self._impl.max

    @property
    def max_lifetime_session(self) -> int:
        """
        Length of time (in seconds) that connections can remain in the pool. If
        it is 0 then connections may remain in the pool indefinitely.
        """
        return self._impl.max_lifetime_session

    @property
    def max_sessions_per_shard(self) -> int:
        """
        The maximum number of connections that may be associated with a
        particular shard.
        """
        return self._impl.max_sessions_per_shard

    @property
    def min(self) -> int:
        """
        The minimum number of connections the pool should contain.
        """
        return self._impl.min

    @property
    def ping_interval(self) -> int:
        """
        Length of time (in seconds) after which an unused connection in the
        pool will be a candidate for pinging when pool.acquire() is called. If
        the ping to the database indicates the connection is not alive a
        replacement connection will be returned by pool.acquire(). If
        ping_interval is a negative value the ping functionality will be
        disabled.
        """
        return self._impl.ping_interval

    @property
    def ping_timeout(self) -> int:
        """
        Maximum length of time (in milliseconds) to wait for a connection in
        the pool to respond to an internal ping to the database before being
        discarded and replaced during a call to acquire().
        """
        return self._impl.ping_timeout

    @property
    def session_callback(self) -> Callable:
        """
        A callable that is invoked when a connection is returned from the pool
        for the first time, or when the connection tag differs from the one
        requested.
        """
        return self._impl.session_callback

    @property
    def soda_metadata_cache(self) -> bool:
        """
        Boolean indicating whether or not the SODA metadata cache should be
        enabled.
        """
        return self._impl.soda_metadata_cache

    @property
    def timeout(self) -> int:
        """
        Length of time (in seconds) that a connection may remain idle in the
        pool before it is terminated. If it is 0 then connections are never
        terminated.
        """
        return self._impl.timeout

    @property
    def wait_timeout(self) -> int:
        """
        Length of time (in milliseconds) that a caller should wait when
        acquiring a connection from the pool with getmode set to
        oracledb.POOL_GETMODE_TIMEDWAIT.
        """
        return self._impl.wait_timeout

    def copy(self) -> "PoolParams":
        """
        Creates a copy of the parameters and returns it.
        """
        params = PoolParams.__new__(PoolParams)
        params._impl = self._impl.copy()
        return params

    @utils.params_setter
    def set(
        self,
        *,
        min: Optional[int] = None,
        max: Optional[int] = None,
        increment: Optional[int] = None,
        connectiontype: Optional[Type["oracledb.Connection"]] = None,
        getmode: Optional[oracledb.PoolGetMode] = None,
        homogeneous: Optional[bool] = None,
        timeout: Optional[int] = None,
        wait_timeout: Optional[int] = None,
        max_lifetime_session: Optional[int] = None,
        session_callback: Optional[Callable] = None,
        max_sessions_per_shard: Optional[int] = None,
        soda_metadata_cache: Optional[bool] = None,
        ping_interval: Optional[int] = None,
        ping_timeout: Optional[int] = None,
        user: Optional[str] = None,
        proxy_user: Optional[str] = None,
        password: Optional[str] = None,
        newpassword: Optional[str] = None,
        wallet_password: Optional[str] = None,
        access_token: Optional[Union[str, tuple, Callable]] = None,
        host: Optional[str] = None,
        port: Optional[int] = None,
        protocol: Optional[str] = None,
        https_proxy: Optional[str] = None,
        https_proxy_port: Optional[int] = None,
        service_name: Optional[str] = None,
        instance_name: Optional[str] = None,
        sid: Optional[str] = None,
        server_type: Optional[str] = None,
        cclass: Optional[str] = None,
        purity: Optional[oracledb.Purity] = None,
        expire_time: Optional[int] = None,
        retry_count: Optional[int] = None,
        retry_delay: Optional[int] = None,
        tcp_connect_timeout: Optional[float] = None,
        ssl_server_dn_match: Optional[bool] = None,
        ssl_server_cert_dn: Optional[str] = None,
        wallet_location: Optional[str] = None,
        events: Optional[bool] = None,
        externalauth: Optional[bool] = None,
        mode: Optional[oracledb.AuthMode] = None,
        disable_oob: Optional[bool] = None,
        stmtcachesize: Optional[int] = None,
        edition: Optional[str] = None,
        tag: Optional[str] = None,
        matchanytag: Optional[bool] = None,
        config_dir: Optional[str] = None,
        appcontext: Optional[list] = None,
        shardingkey: Optional[list] = None,
        supershardingkey: Optional[list] = None,
        debug_jdwp: Optional[str] = None,
        connection_id_prefix: Optional[str] = None,
        ssl_context: Optional[Any] = None,
        sdu: Optional[int] = None,
        pool_boundary: Optional[str] = None,
        use_tcp_fast_open: Optional[bool] = None,
        ssl_version: Optional[ssl.TLSVersion] = None,
        program: Optional[str] = None,
        machine: Optional[str] = None,
        terminal: Optional[str] = None,
        osuser: Optional[str] = None,
        driver_name: Optional[str] = None,
        use_sni: Optional[bool] = None,
        thick_mode_dsn_passthrough: Optional[bool] = None,
        extra_auth_params: Optional[dict] = None,
        handle: Optional[int] = None,
    ):
        """
        All parameters are optional. A brief description of each parameter
        follows:

        - min: the minimum number of connections the pool should contain

        - max: the maximum number of connections the pool should contain

        - increment: the number of connections that should be added to the pool
          whenever a new connection needs to be created

        - connectiontype: the class of the connection that should be returned
          during calls to pool.acquire(). It must be oracledb.Connection or a
          subclass of oracledb.Connection

        - getmode: how pool.acquire() will behave. One of the constants
          oracledb.POOL_GETMODE_WAIT, oracledb.POOL_GETMODE_NOWAIT,
          oracledb.POOL_GETMODE_FORCEGET, or oracledb.POOL_GETMODE_TIMEDWAIT

        - homogeneous: a boolean indicating whether the connections are
          homogeneous (same user) or heterogeneous (multiple users)

        - timeout: length of time (in seconds) that a connection may remain
          idle in the pool before it is terminated. If it is 0 then connections
          are never terminated

        - wait_timeout: length of time (in milliseconds) that a caller should
          wait when acquiring a connection from the pool with getmode set to
          oracledb.POOL_GETMODE_TIMEDWAIT

        - max_lifetime_session: length of time (in seconds) that connections
          can remain in the pool. If it is 0 then connections may remain in the
          pool indefinitely

        - session_callback: a callable that is invoked when a connection is
          returned from the pool for the first time, or when the connection tag
          differs from the one requested

        - max_sessions_per_shard: the maximum number of connections that may be
          associated with a particular shard

        - soda_metadata_cache: boolean indicating whether or not the SODA
          metadata cache should be enabled

        - ping_interval: length of time (in seconds) after which an unused
          connection in the pool will be a candidate for pinging when
          pool.acquire() is called. If the ping to the database indicates the
          connection is not alive a replacement connection will be returned by
          pool.acquire(). If ping_interval is a negative value the ping
          functionality will be disabled

        - ping_timeout: maximum length of time (in milliseconds) to wait for a
          connection in the pool to respond to an internal ping to the database
          before being discarded and replaced during a call to acquire()

        - user: the name of the user to connect to

        - proxy_user: the name of the proxy user to connect to. If this value
          is not specified, it will be parsed out of user if user is in the
          form "user[proxy_user]"

        - password: the password for the user

        - newpassword: the new password for the user. The new password will
          take effect immediately upon a successful connection to the database

        - wallet_password: the password to use to decrypt the wallet, if it is
          encrypted. This value is only used in thin mode

        - access_token: expected to be a string or a 2-tuple or a callable. If
          it is a string, it specifies an Azure AD OAuth2 token used for Open
          Authorization (OAuth 2.0) token based authentication. If it is a
          2-tuple, it specifies the token and private key strings used for
          Oracle Cloud Infrastructure (OCI) Identity and Access Management
          (IAM) token based authentication. If it is a callable, it returns
          either a string or a 2-tuple used for OAuth 2.0 or OCI IAM token
          based authentication and is useful when the pool needs to expand and
          create new connections but the current authentication token has
          expired

        - host: the name or IP address of the machine hosting the database or
          the database listener

        - port: the port number on which the database listener is listening

        - protocol: one of the strings "tcp" or "tcps" indicating whether to
          use unencrypted network traffic or encrypted network traffic (TLS)

        - https_proxy: the name or IP address of a proxy host to use for
          tunneling secure connections

        - https_proxy_port: the port on which to communicate with the proxy
          host

        - service_name: the service name of the database

        - instance_name: the instance name of the database

        - sid: the system identifier (SID) of the database. Note using a
          service_name instead is recommended

        - server_type: the type of server connection that should be
          established. If specified, it should be one of "dedicated", "shared"
          or "pooled"

        - cclass: connection class to use for Database Resident Connection
          Pooling (DRCP)

        - purity: purity to use for Database Resident Connection Pooling (DRCP)

        - expire_time: an integer indicating the number of minutes between the
          sending of keepalive probes. If this parameter is set to a value
          greater than zero it enables keepalive

        - retry_count: the number of times that a connection attempt should be
          retried before the attempt is terminated

        - retry_delay: the number of seconds to wait before making a new
          connection attempt

        - tcp_connect_timeout: a float indicating the maximum number of seconds
          to wait for establishing a connection to the database host

        - ssl_server_dn_match: boolean indicating whether the server
          certificate distinguished name (DN) should be matched in addition to
          the regular certificate verification that is performed. Note that if
          the ssl_server_cert_dn parameter is not privided, host name matching
          is performed instead

        - ssl_server_cert_dn: the distinguished name (DN) which should be
          matched with the server. This value is ignored if the
          ssl_server_dn_match parameter is not set to the value True. If
          specified this value is used for any verfication. Otherwise the
          hostname will be used

        - wallet_location: the directory where the wallet can be found. In thin
          mode this must be the directory containing the PEM-encoded wallet
          file ewallet.pem. In thick mode this must be the directory containing
          the file cwallet.sso

        - events: boolean specifying whether events mode should be enabled.
          This value is only used in thick mode and is needed for continuous
          query notification and high availability event notifications

        - externalauth: a boolean indicating whether to use external
          authentication

        - mode: authorization mode to use. For example
          oracledb.AUTH_MODE_SYSDBA

        - disable_oob: boolean indicating whether out-of-band breaks should be
          disabled. This value is only used in thin mode. It has no effect on
          Windows which does not support this functionality

        - stmtcachesize: identifies the initial size of the statement cache

        - edition: edition to use for the connection. This parameter cannot be
          used simultaneously with the cclass parameter

        - tag: identifies the type of connection that should be returned from a
          pool. This value is only used in thick mode

        - matchanytag: boolean specifying whether any tag can be used when
          acquiring a connection from the pool. This value is only used in
          thick mode

        - config_dir: directory in which the optional tnsnames.ora
          configuration file is located. This value is only used in thin mode.
          For thick mode use the config_dir parameter of init_oracle_client()

        - appcontext: application context used by the connection. It should be
          a list of 3-tuples (namespace, name, value) and each entry in the
          tuple should be a string. This value is only used in thick mode

        - shardingkey: a list of strings, numbers, bytes or dates that identify
          the database shard to connect to. This value is only used in thick
          mode

        - supershardingkey: a list of strings, numbers, bytes or dates that
          identify the database shard to connect to. This value is only used in
          thick mode

        - debug_jdwp: a string with the format "host=<host>;port=<port>" that
          specifies the host and port of the PL/SQL debugger. This value is
          only used in thin mode. For thick mode set the ORA_DEBUG_JDWP
          environment variable

        - connection_id_prefix: an application specific prefix that is added to
          the connection identifier used for tracing

        - ssl_context: an SSLContext object used for connecting to the database
          using TLS.  This SSL context will be modified to include the private
          key or any certificates found in a separately supplied wallet. This
          parameter should only be specified if the default SSLContext object
          cannot be used

        - sdu: the requested size of the Session Data Unit (SDU), in bytes. The
          value tunes internal buffers used for communication to the database.
          Bigger values can increase throughput for large queries or bulk data
          loads, but at the cost of higher memory use. The SDU size that will
          actually be used is negotiated down to the lower of this value and
          the database network SDU configuration value

        - pool_boundary: one of the values "statement" or "transaction"
          indicating when pooled DRCP connections can be returned to the pool.
          This requires the use of DRCP with Oracle Database 23.4 or higher

        - use_tcp_fast_open: boolean indicating whether to use TCP fast open.
          This is an Oracle Autonomous Database Serverless (ADB-S) specific
          property for clients connecting from within OCI Cloud network. Please
          refer to the ADB-S documentation for more information

        - ssl_version: one of the values ssl.TLSVersion.TLSv1_2 or
          ssl.TLSVersion.TLSv1_3 indicating which TLS version to use

        - program: the name of the executable program or application connected
          to the Oracle Database

        - machine: the machine name of the client connecting to the Oracle
          Database

        - terminal: the terminal identifier from which the connection
          originates

        - osuser: the operating system user that initiates the database
          connection

        - driver_name: the driver name used by the client to connect to the
          Oracle Database

        - use_sni: boolean indicating whether to use the TLS SNI extension to
          bypass the second TLS neogiation that would otherwise be required

        - thick_mode_dsn_passthrough: boolean indicating whether to pass the
          connect string to the Oracle Client libraries unchanged without
          parsing by the driver. Setting this to False makes thick and thin
          mode applications behave similarly regarding connection string
          parameter handling and locating any optional tnsnames.ora
          configuration file

        - extra_auth_params: a dictionary containing configuration parameters
          necessary for Oracle Database authentication using plugins, such as
          the Azure and OCI cloud-native authentication plugins

        - handle: an integer representing a pointer to a valid service context
          handle. This value is only used in thick mode. It should be used with
          extreme caution
        """
        pass


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\soda.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2021, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# soda.py
#
# Contains the classes for managing Simple Oracle Document Access (SODA):
# SodaDatabase, SodaCollection, SodaDocument, SodaDocCursor and SodaOperation.
# -----------------------------------------------------------------------------

from typing import Any, Union, List
import json

from . import errors


class SodaDatabase:
    def __repr__(self):
        return f"<oracledb.SodaDatabase on {self._conn!r}>"

    @classmethod
    def _from_impl(cls, conn, impl):
        db = cls.__new__(cls)
        db._conn = conn
        db._impl = impl
        return db

    def _create_doc_impl(
        self, content: Any, key: str = None, media_type: str = None
    ) -> "SodaDocument":
        """
        Internal method used for creating a document implementation object with
        the given content, key and media type.
        """
        if isinstance(content, str):
            content_bytes = content.encode()
        elif isinstance(content, bytes):
            content_bytes = content
        elif self._impl.supports_json:
            return self._impl.create_json_document(content, key)
        else:
            content_bytes = json.dumps(content).encode()
        return self._impl.create_document(content_bytes, key, media_type)

    def createCollection(
        self,
        name: str,
        metadata: Union[str, dict] = None,
        mapMode: bool = False,
    ) -> "SodaCollection":
        """
        Creates a SODA collection with the given name and returns a new SODA
        collection object. If you try to create a collection, and a collection
        with the same name and metadata already exists, then that existing
        collection is opened without error.

        If metadata is specified, it is expected to be a string containing
        valid JSON or a dictionary that will be transformed into a JSON string.
        This JSON permits you to specify the configuration of the collection
        including storage options; specifying the presence or absence of
        columns for creation timestamp, last modified timestamp and version;
        whether the collection can store only JSON documents; and methods of
        key and version generation. The default metadata creates a collection
        that only supports JSON documents and uses system generated keys.

        If the mapMode parameter is set to True, the new collection is mapped
        to an existing table instead of creating a table. If a collection is
        created in this way, dropping the collection will not drop the existing
        table either.
        """
        if metadata is not None and not isinstance(metadata, str):
            metadata = json.dumps(metadata)
        collection_impl = self._impl.create_collection(name, metadata, mapMode)
        return SodaCollection._from_impl(self, collection_impl)

    def createDocument(
        self,
        content: Any,
        key: str = None,
        mediaType: str = "application/json",
    ) -> "SodaDocument":
        """
        Creates a SODA document usable for SODA write operations. You only need
        to use this method if your collection requires client-assigned keys or
        has non-JSON content; otherwise, you can pass your content directly to
        SODA write operations. SodaDocument attributes "createdOn",
        "lastModified" and "version" will be None.

        The content parameter can be a dictionary or list which will be
        transformed into a JSON string and then UTF-8 encoded. It can also be a
        string which will be UTF-8 encoded or it can be a bytes object which
        will be stored unchanged. If a bytes object is provided and the content
        is expected to be JSON, note that SODA only supports UTF-8, UTF-16LE
        and UTF-16BE encodings.

        The key parameter should only be supplied if the collection in which
        the document is to be placed requires client-assigned keys.

        The mediaType parameter should only be supplied if the collection in
        which the document is to be placed supports non-JSON documents and the
        content for this document is non-JSON. Using a standard MIME type for
        this value is recommended but any string will be accepted.
        """
        doc_impl = self._create_doc_impl(content, key, mediaType)
        return SodaDocument._from_impl(doc_impl)

    def getCollectionNames(
        self, startName: str = None, limit: int = 0
    ) -> List[str]:
        """
        Returns a list of the names of collections in the database that match
        the criteria, in alphabetical order.

        If the startName parameter is specified, the list of names returned
        will start with this value and also contain any names that fall after
        this value in alphabetical order.

        If the limit parameter is specified and is non-zero, the number of
        collection names returned will be limited to this value.
        """
        return self._impl.get_collection_names(startName, limit)

    def openCollection(self, name: str) -> "SodaCollection":
        """
        Opens an existing collection with the given name and returns a new SODA
        collection object. If a collection with that name does not exist, None
        is returned.
        """
        collection_impl = self._impl.open_collection(name)
        if collection_impl is not None:
            return SodaCollection._from_impl(self, collection_impl)


class SodaCollection:
    @classmethod
    def _from_impl(cls, db, impl):
        coll = cls.__new__(cls)
        coll._db = db
        coll._impl = impl
        return coll

    def _process_doc_arg(self, arg):
        if isinstance(arg, SodaDocument):
            return arg._impl
        return self._db._create_doc_impl(arg)

    def createIndex(self, spec: Union[dict, str]) -> None:
        """
        Creates an index on a SODA collection. The spec is expected to be a
        dictionary or a JSON-encoded string.

        Note that a commit should be performed before attempting to create an
        index.
        """
        if isinstance(spec, dict):
            spec = json.dumps(spec)
        elif not isinstance(spec, str):
            raise TypeError("expecting a dictionary or string")
        self._impl.create_index(spec)

    def drop(self) -> bool:
        """
        Drops the collection from the database, if it exists. Note that if the
        collection was created with mapMode set to True the underlying table
        will not be dropped.

        A boolean value is returned indicating if the collection was actually
        dropped.
        """
        return self._impl.drop()

    def dropIndex(self, name: str, force: bool = False) -> bool:
        """
        Drops the index with the specified name, if it exists.

        The force parameter, if set to True, can be used to force the dropping
        of an index that the underlying Oracle Database domain index doesn’t
        normally permit. This is only applicable to spatial and JSON search
        indexes. See here for more information.

        A boolean value is returned indicating if the index was actually
        dropped.
        """
        return self._impl.drop_index(name, force)

    def find(self) -> "SodaOperation":
        """
        This method is used to begin an operation that will act upon documents
        in the collection. It creates and returns a SodaOperation object which
        is used to specify the criteria and the operation that will be
        performed on the documents that match that criteria.
        """
        return SodaOperation(self)

    def getDataGuide(self) -> "SodaDocument":
        """
        Returns a SODA document object containing property names, data types
        and lengths inferred from the JSON documents in the collection. It can
        be useful for exploring the schema of a collection. Note that this
        method is only supported for JSON-only collections where a JSON search
        index has been created with the ‘dataguide’ option enabled. If there
        are no documents in the collection, None is returned.
        """
        doc_impl = self._impl.get_data_guide()
        if doc_impl is not None:
            return SodaDocument._from_impl(doc_impl)

    def insertMany(self, docs: list) -> None:
        """
        Inserts a list of documents into the collection at one time. Each of
        the input documents can be a dictionary or list or an existing SODA
        document object.
        """
        doc_impls = [self._process_doc_arg(d) for d in docs]
        self._impl.insert_many(doc_impls, hint=None, return_docs=False)

    def insertManyAndGet(self, docs: list, hint: str = None) -> list:
        """
        Similarly to insertMany() this method inserts a list of documents into
        the collection at one time. The only difference is that it returns a
        list of SODA Document objects. Note that for performance reasons the
        returned documents do not contain the content.

        The hint parameter, if specified, supplies a hint to the database when
        processing the SODA operation. This is expected to be a string in the
        same format as SQL hints but without any comment characters, for
        example hint="MONITOR". While you could use this to pass any SQL hint,
        the hints MONITOR (turn on monitoring) and NO_MONITOR (turn off
        monitoring) are the most useful. Use of the hint parameter requires
        Oracle Client 21.3 or higher (or Oracle Client 19 from 19.11).
        """
        doc_impls = [self._process_doc_arg(d) for d in docs]
        if hint is not None and not isinstance(hint, str):
            raise TypeError("expecting a string")
        return_doc_impls = self._impl.insert_many(
            doc_impls, hint, return_docs=True
        )
        return [SodaDocument._from_impl(i) for i in return_doc_impls]

    def insertOne(self, doc: Any) -> None:
        """
        Inserts a given document into the collection. The input document can be
        a dictionary or list or an existing SODA document object.
        """
        doc_impl = self._process_doc_arg(doc)
        self._impl.insert_one(doc_impl, hint=None, return_doc=False)

    def insertOneAndGet(self, doc: Any, hint: str = None) -> "SodaDocument":
        """
        Similarly to insertOne() this method inserts a given document into the
        collection. The only difference is that it returns a SODA Document
        object. Note that for performance reasons the returned document does
        not contain the content.

        The hint parameter, if specified, supplies a hint to the database when
        processing the SODA operation. This is expected to be a string in the
        same format as SQL hints but without any comment characters, for
        example hint="MONITOR". While you could use this to pass any SQL hint,
        the hints MONITOR (turn on monitoring) and NO_MONITOR (turn off
        monitoring) are the most useful. Use of the hint parameter requires
        Oracle Client 21.3 or higher (or Oracle Client 19 from 19.11).
        """
        doc_impl = self._process_doc_arg(doc)
        if hint is not None and not isinstance(hint, str):
            raise TypeError("expecting a string")
        return_doc_impl = self._impl.insert_one(
            doc_impl, hint, return_doc=True
        )
        return SodaDocument._from_impl(return_doc_impl)

    def listIndexes(self) -> list:
        """
        Return a list of indexes associated with the collection.
        """
        return [json.loads(s) for s in self._impl.list_indexes()]

    @property
    def metadata(self) -> dict:
        """
        This read-only attribute returns a dictionary containing the metadata
        that was used to create the collection.
        """
        return json.loads(self._impl.get_metadata())

    @property
    def name(self) -> str:
        """
        This read-only attribute returns the name of the collection.
        """
        return self._impl.name

    def save(self, doc: Any) -> None:
        """
        Saves a document into the collection. This method is equivalent to
        insertOne() except that if client-assigned keys are used, and the
        document with the specified key already exists in the collection, it
        will be replaced with the input document.
        """
        doc_impl = self._process_doc_arg(doc)
        self._impl.save(doc_impl, hint=None, return_doc=False)

    def saveAndGet(self, doc: Any, hint: str = None) -> "SodaDocument":
        """
        Saves a document into the collection. This method is equivalent to
        insertOneAndGet() except that if client-assigned keys are used, and the
        document with the specified key already exists in the collection, it
        will be replaced with the input document.

        The hint parameter, if specified, supplies a hint to the database when
        processing the SODA operation. This is expected to be a string in the
        same format as SQL hints but without any comment characters, for
        example hint="MONITOR". While you could use this to pass any SQL hint,
        the hints MONITOR (turn on monitoring) and NO_MONITOR (turn off
        monitoring) are the most useful. Use of the hint parameter requires
        Oracle Client 21.3 or higher (or Oracle Client 19 from 19.11).
        """
        doc_impl = self._process_doc_arg(doc)
        if hint is not None and not isinstance(hint, str):
            raise TypeError("expecting a string")
        return_doc_impl = self._impl.save(doc_impl, hint, return_doc=True)
        return SodaDocument._from_impl(return_doc_impl)

    def truncate(self) -> None:
        """
        Removes all of the documents in the collection, similarly to what is
        done for rows in a table by the TRUNCATE TABLE statement.
        """
        self._impl.truncate()


class SodaDocument:
    @classmethod
    def _from_impl(cls, impl):
        doc = cls.__new__(cls)
        doc._impl = impl
        return doc

    @property
    def createdOn(self) -> str:
        """
        This read-only attribute returns the creation time of the document in
        ISO 8601 format. Documents created by SodaDatabase.createDocument() or
        fetched from collections where this attribute is not stored will return
        None.
        """
        return self._impl.get_created_on()

    def getContent(self) -> Union[dict, list]:
        """
        Returns the content of the document as a dictionary or list. This
        method assumes that the content is application/json and will raise an
        exception if this is not the case. If there is no content, however,
        None will be returned.
        """
        content, encoding = self._impl.get_content()
        if isinstance(content, bytes) and self.mediaType == "application/json":
            return json.loads(content.decode(encoding))
        return content

    def getContentAsBytes(self) -> bytes:
        """
        Returns the content of the document as a bytes object. If there is no
        content, however, None will be returned.
        """
        content, encoding = self._impl.get_content()
        if isinstance(content, bytes):
            return content
        elif content is not None:
            return str(content).encode()

    def getContentAsString(self) -> str:
        """
        Returns the content of the document as a string. If the document
        encoding is not known, UTF-8 will be used. If there is no content,
        however, None will be returned.
        """
        content, encoding = self._impl.get_content()
        if isinstance(content, bytes):
            return content.decode(encoding)
        elif content is not None:
            return str(content)

    @property
    def key(self) -> str:
        """
        This read-only attribute returns the unique key assigned to this
        document. Documents created by SodaDatabase.createDocument() may not
        have a value assigned to them and return None.
        """
        return self._impl.get_key()

    @property
    def lastModified(self) -> str:
        """
        This read-only attribute returns the last modified time of the document
        in ISO 8601 format. Documents created by SodaDatabase.createDocument()
        or fetched from collections where this attribute is not stored will
        return None.
        """
        return self._impl.get_last_modified()

    @property
    def mediaType(self) -> str:
        """
        This read-only attribute returns the media type assigned to the
        document. By convention this is expected to be a MIME type but no
        checks are performed on this value. If a value is not specified when
        calling SodaDatabase.createDocument() or the document is fetched from a
        collection where this component is not stored, the string
        “application/json” is returned.
        """
        return self._impl.get_media_type()

    @property
    def version(self) -> str:
        """
        This read-only attribute returns the version assigned to this document.
        Documents created by SodaDatabase.createDocument() or fetched from
        collections where this attribute is not stored will return None.
        """
        return self._impl.get_version()


class SodaDocCursor:
    def __iter__(self):
        return self

    def __next__(self):
        if self._impl is None:
            errors._raise_err(errors.ERR_CURSOR_NOT_OPEN)
        doc_impl = self._impl.get_next_doc()
        if doc_impl is not None:
            return SodaDocument._from_impl(doc_impl)
        raise StopIteration

    @classmethod
    def _from_impl(cls, impl):
        cursor = cls.__new__(cls)
        cursor._impl = impl
        return cursor

    def close(self) -> None:
        """
        Close the cursor now, rather than whenever __del__ is called. The
        cursor will be unusable from this point forward; an Error exception
        will be raised if any operation is attempted with the cursor.
        """
        if self._impl is None:
            errors._raise_err(errors.ERR_CURSOR_NOT_OPEN)
        self._impl.close()
        self._impl = None


class SodaOperation:
    def __init__(self, collection: SodaCollection) -> None:
        self._collection = collection
        self._key = None
        self._keys = None
        self._version = None
        self._filter = None
        self._hint = None
        self._skip = None
        self._limit = None
        self._fetch_array_size = None
        self._lock = False

    def count(self) -> int:
        """
        Returns a count of the number of documents in the collection that match
        the criteria. If skip() or limit() were called on this object, an
        exception is raised.
        """
        return self._collection._impl.get_count(self)

    def fetchArraySize(self, value: int) -> "SodaOperation":
        """
        This is a tuning method to specify the number of documents that are
        internally fetched in batches by calls to getCursor() and
        getDocuments(). It does not affect how many documents are returned to
        the application. A value of 0 will use the default value (100). This
        method is only available in Oracle Client 19.5 and higher.

        As a convenience, the SodaOperation object is returned so that further
        criteria can be specified by chaining methods together.
        """
        if not isinstance(value, int) or value < 0:
            raise TypeError("expecting integer >= 0")
        if value == 0:
            self._fetch_array_size = None
        else:
            self._fetch_array_size = value
        return self

    def filter(self, value: Union[dict, str]) -> "SodaOperation":
        """
        Sets a filter specification for complex document queries and ordering
        of JSON documents. Filter specifications must be provided as a
        dictionary or JSON-encoded string and can include comparisons, regular
        expressions, logical and spatial operators, among others. See the
        overview of SODA filter specifications for more information.

        As a convenience, the SodaOperation object is returned so that further
        criteria can be specified by chaining methods together.
        """
        if isinstance(value, dict):
            self._filter = json.dumps(value)
        elif isinstance(value, str):
            self._filter = value
        else:
            raise TypeError("expecting string or dictionary")
        return self

    def getCursor(self) -> "SodaDocCursor":
        """
        Returns a SodaDocCursor object that can be used to iterate over the
        documents that match the criteria.
        """
        impl = self._collection._impl.get_cursor(self)
        return SodaDocCursor._from_impl(impl)

    def getDocuments(self) -> list:
        """
        Returns a list of SodaDocument objects that match the criteria.
        """
        return [d for d in self.getCursor()]

    def getOne(self) -> Union["SodaDocument", None]:
        """
        Returns a single SodaDocument object that matches the criteria. Note
        that if multiple documents match the criteria only the first one is
        returned.
        """
        doc_impl = self._collection._impl.get_one(self)
        if doc_impl is not None:
            return SodaDocument._from_impl(doc_impl)

    def hint(self, value: str) -> "SodaOperation":
        """
        Specifies a hint that will be provided to the SODA operation when it is
        performed. This is expected to be a string in the same format as SQL
        hints but without any comment characters. While you could use this to
        pass any SQL hint, the hints MONITOR (turn on monitoring) and
        NO_MONITOR (turn off monitoring) are the most useful. Use of this
        method requires Oracle Client 21.3 or higher (or Oracle Client 19 from
        19.11).

        As a convenience, the SodaOperation object is returned so that further
        criteria can be specified by chaining methods together.
        """
        if not isinstance(value, str):
            raise TypeError("expecting a string")
        self._hint = value
        return self

    def lock(self) -> "SodaOperation":
        """
        Specifies whether the documents fetched from the collection should be
        locked (equivalent to SQL "select for update"). Use of this method
        requires Oracle Client 21.3 or higher (or Oracle Client 19 from 19.11).

        As a convenience, the SodaOperation object is returned so that further
        criteria can be specified by chaining methods together.
        """
        self._lock = True
        return self

    def key(self, value: str) -> "SodaOperation":
        """
        Specifies that the document with the specified key should be returned.
        This causes any previous calls made to this method and keys() to be
        ignored.

        As a convenience, the SodaOperation object is returned so that further
        criteria can be specified by chaining methods together.
        """
        if not isinstance(value, str):
            raise TypeError("expecting string")
        self._key = value
        self._keys = None
        return self

    def keys(self, value: list) -> "SodaOperation":
        """
        Specifies that documents that match the keys found in the supplied
        sequence should be returned. This causes any previous calls made to
        this method and key() to be ignored.

        As a convenience, the SodaOperation object is returned so that further
        criteria can be specified by chaining methods together.
        """
        value_as_list = list(value)
        for element in value_as_list:
            if not isinstance(element, str):
                raise TypeError("expecting sequence of strings")
        self._keys = value_as_list
        self._key = None
        return self

    def limit(self, value: int) -> "SodaOperation":
        """
        Specifies that only the specified number of documents should be
        returned. This method is only usable for read operations such as
        getCursor() and getDocuments(). For write operations, any value set
        using this method is ignored.

        As a convenience, the SodaOperation object is returned so that further
        criteria can be specified by chaining methods together.
        """
        if not isinstance(value, int) or value <= 0:
            raise TypeError("expecting positive integer")
        self._limit = value
        return self

    def remove(self) -> int:
        """
        Removes all of the documents in the collection that match the criteria.
        The number of documents that have been removed is returned.
        """
        return self._collection._impl.remove(self)

    def replaceOne(self, doc: Any) -> bool:
        """
        Replaces a single document in the collection with the specified
        document. The input document can be a dictionary or list or an existing
        SODA document object. A boolean indicating if a document was replaced
        or not is returned.

        Currently the method key() must be called before this method can be
        called.
        """
        doc_impl = self._collection._process_doc_arg(doc)
        return self._collection._impl.replace_one(
            self, doc_impl, return_doc=False
        )

    def replaceOneAndGet(self, doc: Any) -> "SodaDocument":
        """
        Similarly to replaceOne(), this method replaces a single document in
        the collection with the specified document. The only difference is that
        it returns a SodaDocument object. Note that for performance reasons the
        returned document does not contain the content.
        """
        doc_impl = self._collection._process_doc_arg(doc)
        return_doc_impl = self._collection._impl.replace_one(
            self, doc_impl, return_doc=True
        )
        return SodaDocument._from_impl(return_doc_impl)

    def skip(self, value: int) -> "SodaOperation":
        """
        Specifies the number of documents that match the other criteria that
        will be skipped. This method is only usable for read operations such as
        getCursor() and getDocuments(). For write operations, any value set
        using this method is ignored.

        As a convenience, the SodaOperation object is returned so that further
        criteria can be specified by chaining methods together.
        """
        if not isinstance(value, int) or value < 0:
            raise TypeError("expecting integer >= 0")
        self._skip = value
        return self

    def version(self, value: str) -> "SodaOperation":
        """
        Specifies that documents with the specified version should be returned.
        Typically this is used with key() to implement optimistic locking, so
        that the write operation called later does not affect a document that
        someone else has modified.

        As a convenience, the SodaOperation object is returned so that further
        criteria can be specified by chaining methods together.
        """
        if not isinstance(value, str):
            raise TypeError("expecting string")
        self._version = value
        return self


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\sparse_vector.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# sparse_vector.py
#
# Contains the SparseVector class which stores information about a sparse
# vector. Sparse vectors are available in Oracle Database 23.6 and higher.
# -----------------------------------------------------------------------------

import array
from typing import Union

from .base_impl import get_array_type_code_uint32, SparseVectorImpl
from . import __name__ as MODULE_NAME

ARRAY_TYPE_CODE_UINT32 = get_array_type_code_uint32()


class SparseVector:
    """
    Provides information about sparse vectors.
    """

    __module__ = MODULE_NAME

    def __init__(
        self,
        num_dimensions: int,
        indices: Union[list, array.array],
        values: Union[list, array.array],
    ):
        if (
            not isinstance(indices, array.array)
            or indices.typecode != ARRAY_TYPE_CODE_UINT32
        ):
            indices = array.array(ARRAY_TYPE_CODE_UINT32, indices)
        if not isinstance(values, array.array):
            values = array.array("d", values)
        if len(indices) != len(values):
            raise TypeError("indices and values must be of the same length!")
        self._impl = SparseVectorImpl.from_values(
            num_dimensions, indices, values
        )

    def __repr__(self):
        return (
            f"{MODULE_NAME}.{self.__class__.__name__}({self.num_dimensions}, "
            f"{self.indices}, {self.values})"
        )

    def __str__(self):
        return (
            f"[{self.num_dimensions}, {list(self.indices)}, "
            f"{list(self.values)}]"
        )

    @classmethod
    def _from_impl(cls, impl):
        vector = cls.__new__(cls)
        vector._impl = impl
        return vector

    @property
    def indices(self) -> array.array:
        """
        Returns the indices (zero-based) of non-zero values in the vector.
        """
        return self._impl.indices

    @property
    def num_dimensions(self) -> int:
        """
        Returns the number of dimensions contained in the vector.
        """
        return self._impl.num_dimensions

    @property
    def values(self) -> array.array:
        """
        Returns the non-zero values stored in the vector.
        """
        return self._impl.values


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\subscr.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2021, 2023, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# subscr.py
#
# Contains the Subscription class and Message classes used for managing
# subscriptions to database events and the messages that are sent when those
# events are detected.
# -----------------------------------------------------------------------------

from typing import Callable, Union, List
from . import connection


class Subscription:
    def __repr__(self):
        return f"<oracledb.Subscription on {self.connection!r}>"

    @classmethod
    def _from_impl(cls, impl):
        subscr = cls.__new__(cls)
        subscr._impl = impl
        return subscr

    @property
    def callback(self) -> Callable:
        """
        Returns the callback that was registered when the subscription was
        created.
        """
        return self._impl.callback

    @property
    def connection(self) -> "connection.Connection":
        """
        Returns the connection that was used to register the subscription when
        it was created.
        """
        return self._impl.connection

    @property
    def id(self) -> int:
        """
        Returns the value of REGID found in the database view
        USER_CHANGE_NOTIFICATION_REGS or the value of REG_ID found in the
        database view USER_SUBSCR_REGISTRATIONS. For AQ subscriptions, this
        value is 0.
        """
        return self._impl.id

    @property
    def ip_address(self) -> str:
        """
        Returns the IP address used for callback notifications from the
        database server. If not set during construction, this value is None.
        """
        return self._impl.ip_address

    @property
    def ipAddress(self) -> str:
        """
        Deprecated. Use property ip_address instead.
        """
        return self.ip_address

    @property
    def name(self) -> str:
        """
        Returns the name used to register the subscription when it was created.
        """
        return self._impl.name

    @property
    def namespace(self) -> int:
        """
        Returns the namespace used to register the subscription when it was
        created.
        """
        return self._impl.namespace

    @property
    def operations(self) -> int:
        """
        Returns the operations that will send notifications for each table or
        query that is registered using this subscription.
        """
        return self._impl.operations

    @property
    def port(self) -> int:
        """
        Returns the port used for callback notifications from the database
        server. If not set during construction, this value is zero.
        """
        return self._impl.port

    @property
    def protocol(self) -> int:
        """
        Returns the protocol used to register the subscription when it was
        created.
        """
        return self._impl.protocol

    @property
    def qos(self) -> int:
        """
        Returns the quality of service flags used to register the subscription
        when it was created.
        """
        return self._impl.qos

    def registerquery(
        self, statement: str, args: Union[list, dict] = None
    ) -> int:
        """
        Register the query for subsequent notification when tables referenced
        by the query are changed. This behaves similarly to cursor.execute()
        but only queries are permitted and the args parameter, if specified,
        must be a sequence or dictionary. If the qos parameter included the
        flag SUBSCR_QOS_QUERY when the subscription was created, then the ID
        for the registered query is returned; otherwise, None is returned.
        """
        if args is not None and not isinstance(args, (list, dict)):
            raise TypeError("expecting args to be a dictionary or list")
        return self._impl.register_query(statement, args)

    @property
    def timeout(self) -> int:
        """
        Returns the timeout (in seconds) that was specified when the
        subscription was created. A value of 0 indicates that there is no
        timeout.
        """
        return self._impl.timeout


class Message:
    def __init__(self, subscription: Subscription) -> None:
        self._subscription = subscription
        self._consumer_name = None
        self._dbname = None
        self._queries = []
        self._queue_name = None
        self._registered = False
        self._tables = []
        self._txid = None
        self._type = 0
        self._msgid = None

    @property
    def consumer_name(self) -> Union[str, None]:
        """
        Returns the name of the consumer which generated the notification. It
        will be populated if the subscription was created with the namespace
        SUBSCR_NAMESPACE_AQ and the queue is a multiple consumer queue.
        """
        return self._consumer_name

    @property
    def consumerName(self) -> Union[str, None]:
        """
        Deprecated. Use property consumer_name instead.
        """
        return self.consumer_name

    @property
    def dbname(self) -> Union[str, None]:
        """
        Returns the name of the database that generated the notification.
        """
        return self._dbname

    @property
    def msgid(self) -> Union[bytes, None]:
        """
        Returns the message id of the AQ message that generated the
        notification.
        """
        return self._msgid

    @property
    def queries(self) -> List["MessageQuery"]:
        """
        Returns a list of message query objects that give information about
        query result sets changed for this notification. This attribute will be
        an empty list if the qos parameter did not include the flag
        SUBSCR_QOS_QUERY when the subscription was created.
        """
        return self._queries

    @property
    def queue_name(self) -> Union[str, None]:
        """
        Returns the name of the queue which generated the notification. It will
        only be populated if the subscription was created with the namespace
        SUBSCR_NAMESPACE_AQ.
        """
        return self._queue_name

    @property
    def queueName(self) -> Union[str, None]:
        """
        Deprecated. Use property queue_name instead.
        """
        return self.queue_name

    @property
    def registered(self) -> bool:
        """
        Returns whether the subscription which generated this notification is
        still registered with the database. The subscription is automatically
        deregistered with the database when the subscription timeout value is
        reached or when the first notification is sent (when the quality of
        service flag SUBSCR_QOS_DEREG_NFY is used).
        """
        return self._registered

    @property
    def subscription(self) -> Subscription:
        """
        Returns the subscription object for which this notification was
        generated.
        """
        return self._subscription

    @property
    def tables(self) -> List["MessageTable"]:
        """
        Returns a list of message table objects that give information about the
        tables changed for this notification. This attribute will be an empty
        list if the qos parameter included the flag SUBSCR_QOS_QUERY when the
        subscription was created.
        """
        return self._tables

    @property
    def txid(self) -> Union[bytes, None]:
        """
        Returns the id of the transaction that generated the notification.
        """
        return self._txid

    @property
    def type(self) -> int:
        """
        Returns the type of message that has been sent.
        """
        return self._type


class MessageQuery:
    def __init__(self) -> None:
        self._id = 0
        self._operation = 0
        self._tables = []

    @property
    def id(self) -> int:
        """
        Returns the query id of the query for which the result set changed. The
        value will match the value returned by Subscription.registerquery()
        when the related query was registered.
        """
        return self._id

    @property
    def operation(self) -> int:
        """
        Returns the operation that took place on the query result set that was
        changed. Valid values for this attribute are EVENT_DEREG and
        EVENT_QUERYCHANGE.
        """
        return self._operation

    @property
    def tables(self) -> List["MessageTable"]:
        """
        Returns a list of message table objects that give information about the
        table changes that caused the query result set to change for this
        notification.
        """
        return self._tables


class MessageRow:
    def __init__(self) -> None:
        self._operation = 0
        self._rowid = None

    @property
    def operation(self) -> int:
        """
        Returns the operation that took place on the row that was changed.
        """
        return self._operation

    @property
    def rowid(self) -> Union[str, None]:
        """
        Returns the rowid of the row that was changed.
        """
        return self._rowid


class MessageTable:
    def __init__(self) -> None:
        self._name = None
        self._operation = 0
        self._rows = []

    @property
    def name(self) -> Union[str, None]:
        """
        Returns the name of the table that was changed.
        """
        return self._name

    @property
    def operation(self) -> int:
        """
        Returns the operation that took place on the table that was changed.
        """
        return self._operation

    @property
    def rows(self) -> List["MessageRow"]:
        """
        Returns a list of message row objects that give information about the
        rows changed on the table. This value is only filled in if the qos
        parameter to the Connection.subscribe() method included the flag
        SUBSCR_QOS_ROWIDS.
        """
        return self._rows


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\thick_impl.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# thick_impl.pyx
#
# Cython file for interfacing with ODPI-C.
#------------------------------------------------------------------------------

# cython: language_level=3

cimport cython
cimport cpython
cimport cpython.datetime as cydatetime
from cpython cimport array

import array
import datetime
import decimal
import locale
import sys

cydatetime.import_datetime()

from .base_impl cimport (
    ARRAY_TYPE_CODE_UINT32,
    BaseConnImpl,
    BaseCursorImpl,
    BaseDbObjectImpl,
    BaseDbObjectAttrImpl,
    BaseDbObjectTypeImpl,
    BaseDeqOptionsImpl,
    BaseEnqOptionsImpl,
    BaseLobImpl,
    BaseMsgPropsImpl,
    BasePoolImpl,
    BaseQueueImpl,
    BaseSodaCollImpl,
    BaseSodaDbImpl,
    BaseSodaDocImpl,
    BaseSodaDocCursorImpl,
    BaseSubscrImpl,
    BaseVarImpl,
    BindVar,
    C_DEFAULTS,
    char_type,
    ConnectParamsImpl,
    convert_oracle_data_to_arrow,
    DbType,
    DB_TYPE_NUM_CURSOR,
    DRIVER_NAME,
    DRIVER_VERSION,
    DRIVER_INSTALLATION_URL,
    ENCODING_UTF8,
    OracleData,
    OracleMetadata,
    PURITY_DEFAULT,
    PY_TYPE_DATE,
    PY_TYPE_DATETIME,
    PY_TYPE_DB_OBJECT,
    PY_TYPE_DECIMAL,
    PY_TYPE_JSON_ID,
    PY_TYPE_INTERVAL_YM,
    PY_TYPE_LOB,
    PY_TYPE_MESSAGE,
    PY_TYPE_MESSAGE_QUERY,
    PY_TYPE_MESSAGE_ROW,
    PY_TYPE_MESSAGE_TABLE,
    PY_TYPE_SPARSE_VECTOR,
    PY_TYPE_TIMEDELTA,
    PoolParamsImpl,
    PY_TYPE_NUM_FLOAT,
    PY_TYPE_NUM_INT,
    PY_TYPE_NUM_DECIMAL,
    SparseVectorImpl,
    VectorDecoder,
    VectorEncoder,
)
from libc.string cimport memchr, memcpy, memset

include "impl/thick/odpi.pxd"

cdef struct DriverInfo:
    dpiContext *context
    dpiVersionInfo client_version_info
    bint soda_use_json_desc

cdef DriverInfo driver_info = \
        DriverInfo(NULL, dpiVersionInfo(0, 0, 0, 0, 0, 0), True)

driver_context_params = None

include "impl/thick/buffer.pyx"
include "impl/thick/connection.pyx"
include "impl/thick/pool.pyx"
include "impl/thick/cursor.pyx"
include "impl/thick/lob.pyx"
include "impl/thick/json.pyx"
include "impl/thick/var.pyx"
include "impl/thick/dbobject.pyx"
include "impl/thick/soda.pyx"
include "impl/thick/queue.pyx"
include "impl/thick/subscr.pyx"
include "impl/thick/utils.pyx"


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\thin_impl.pyx
# ========================================

#------------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#------------------------------------------------------------------------------

#------------------------------------------------------------------------------
# thin_impl.pyx
#
# Cython file for communicating with the server directly without the use of
# any Oracle Client library.
#------------------------------------------------------------------------------

# cython: language_level=3

cimport cython
cimport cpython
cimport cpython.datetime as cydatetime
cimport cpython.ref

from libc.stdint cimport int8_t, int16_t, int32_t, int64_t
from libc.stdint cimport uint8_t, uint16_t, uint32_t, uint64_t
from libc.string cimport memcpy, memset
from cpython cimport array

import array
import asyncio
import base64
import collections
import datetime
import decimal
import getpass
import hashlib
import inspect
import json
import os
import socket
import re
import secrets
import select
import ssl
import subprocess
import sys
import threading
import time
import uuid

try:
    import certifi
except ImportError:
    certifi = None
macos_certs = None

cydatetime.import_datetime()

from .base_impl cimport (
    Address,
    AddressList,
    AUTH_MODE_DEFAULT,
    AUTH_MODE_PRELIM,
    AUTH_MODE_SYSASM,
    AUTH_MODE_SYSBKP,
    AUTH_MODE_SYSDBA,
    AUTH_MODE_SYSDGD,
    AUTH_MODE_SYSKMT,
    AUTH_MODE_SYSOPER,
    AUTH_MODE_SYSRAC,
    BaseConnImpl,
    BaseCursorImpl,
    BaseDbObjectAttrImpl,
    BaseDbObjectImpl,
    BaseDbObjectTypeImpl,
    BaseDeqOptionsImpl,
    BaseEnqOptionsImpl,
    BaseMsgPropsImpl,
    BaseQueueImpl,
    BaseLobImpl,
    BaseParser,
    BasePoolImpl,
    BaseVarImpl,
    PipelineOpImpl,
    PipelineOpResultImpl,
    PIPELINE_OP_TYPE_CALL_FUNC,
    PIPELINE_OP_TYPE_CALL_PROC,
    PIPELINE_OP_TYPE_COMMIT,
    PIPELINE_OP_TYPE_EXECUTE,
    PIPELINE_OP_TYPE_EXECUTE_MANY,
    PIPELINE_OP_TYPE_FETCH_ALL,
    PIPELINE_OP_TYPE_FETCH_MANY,
    PIPELINE_OP_TYPE_FETCH_ONE,
    BindVar,
    Buffer,
    ConnectParamsImpl,
    convert_oracle_data_to_python,
    convert_oracle_data_to_arrow,
    convert_date_to_python,
    CS_FORM_IMPLICIT,
    CS_FORM_NCHAR,
    DbType,
    Description,
    DescriptionList,
    DRIVER_NAME,
    DRIVER_VERSION,
    ENCODING_UTF8,
    ENCODING_UTF16,
    GrowableBuffer,
    PY_TYPE_NUM_FLOAT,
    PY_TYPE_NUM_INT,
    PY_TYPE_NUM_DECIMAL,
    PY_TYPE_NUM_STR,
    ORA_TYPE_NUM_BFILE,
    ORA_TYPE_NUM_BINARY_DOUBLE,
    ORA_TYPE_NUM_BINARY_FLOAT,
    ORA_TYPE_NUM_BINARY_INTEGER,
    ORA_TYPE_NUM_BLOB,
    ORA_TYPE_NUM_BOOLEAN,
    ORA_TYPE_NUM_CHAR,
    ORA_TYPE_NUM_CLOB,
    ORA_TYPE_NUM_CURSOR,
    ORA_TYPE_NUM_DATE,
    ORA_TYPE_NUM_INTERVAL_DS,
    ORA_TYPE_NUM_INTERVAL_YM,
    ORA_TYPE_NUM_JSON,
    ORA_TYPE_NUM_LONG,
    ORA_TYPE_NUM_LONG_RAW,
    ORA_TYPE_NUM_NUMBER,
    ORA_TYPE_NUM_OBJECT,
    ORA_TYPE_NUM_RAW,
    ORA_TYPE_NUM_ROWID,
    ORA_TYPE_NUM_TIMESTAMP,
    ORA_TYPE_NUM_TIMESTAMP_LTZ,
    ORA_TYPE_NUM_TIMESTAMP_TZ,
    ORA_TYPE_NUM_UROWID,
    ORA_TYPE_NUM_VARCHAR,
    ORA_TYPE_NUM_VECTOR,
    OracleMetadata,
    OracleData,
    OsonDecoder,
    OsonEncoder,
    POOL_GETMODE_FORCEGET,
    POOL_GETMODE_NOWAIT,
    POOL_GETMODE_TIMEDWAIT,
    POOL_GETMODE_WAIT,
    PoolParamsImpl,
    PURITY_DEFAULT,
    PURITY_NEW,
    PURITY_SELF,
    PY_TYPE_ASYNC_LOB,
    PY_TYPE_DATE,
    PY_TYPE_DATETIME,
    PY_TYPE_DB_OBJECT,
    PY_TYPE_DECIMAL,
    PY_TYPE_INTERVAL_YM,
    PY_TYPE_LOB,
    PY_TYPE_TIMEDELTA,
    TNS_LONG_LENGTH_INDICATOR,
    TNS_NULL_LENGTH_INDICATOR,
    decode_uint16be,
    decode_uint32be,
    decode_date,
    VectorDecoder,
    VectorEncoder,
    encode_uint16be,
)

from .base_impl import (
    DB_TYPE_BLOB,
    DB_TYPE_CLOB,
    DB_TYPE_NCLOB,
    DB_TYPE_BINARY_INTEGER,
    DB_TYPE_CURSOR,
    DB_TYPE_NUMBER,
    DB_TYPE_OBJECT,
    DB_TYPE_XMLTYPE,
)

from .interchange.nanoarrow_bridge cimport (
    OracleArrowArray,
)

ctypedef unsigned char char_type

# flag whether the cryptography package exists
cdef object CRYPTOGRAPHY_IMPORT_ERROR = None

include "impl/thin/constants.pxi"
include "impl/thin/utils.pyx"
include "impl/thin/crypto.pyx"
include "impl/thin/capabilities.pyx"
include "impl/thin/transport.pyx"
include "impl/thin/packet.pyx"
include "impl/thin/messages/base.pyx"
include "impl/thin/messages/aq_base.pyx"
include "impl/thin/messages/aq_array.pyx"
include "impl/thin/messages/aq_deq.pyx"
include "impl/thin/messages/aq_enq.pyx"
include "impl/thin/messages/auth.pyx"
include "impl/thin/messages/commit.pyx"
include "impl/thin/messages/connect.pyx"
include "impl/thin/messages/data_types.pyx"
include "impl/thin/messages/end_pipeline.pyx"
include "impl/thin/messages/execute.pyx"
include "impl/thin/messages/fetch.pyx"
include "impl/thin/messages/lob_op.pyx"
include "impl/thin/messages/logoff.pyx"
include "impl/thin/messages/ping.pyx"
include "impl/thin/messages/protocol.pyx"
include "impl/thin/messages/fast_auth.pyx"
include "impl/thin/messages/rollback.pyx"
include "impl/thin/messages/session_release.pyx"
include "impl/thin/messages/tpc_change_state.pyx"
include "impl/thin/messages/tpc_switch.pyx"
include "impl/thin/protocol.pyx"
include "impl/thin/queue.pyx"
include "impl/thin/connection.pyx"
include "impl/thin/statement.pyx"
include "impl/thin/statement_cache.pyx"
include "impl/thin/cursor.pyx"
include "impl/thin/var.pyx"
include "impl/thin/dbobject.pyx"
include "impl/thin/dbobject_cache.pyx"
include "impl/thin/lob.pyx"
include "impl/thin/pool.pyx"


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\utils.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# utils.py
#
# Contains utility classes and methods.
# -----------------------------------------------------------------------------

from typing import Callable, Union

from . import base_impl
from . import driver_mode
from . import errors


def enable_thin_mode():
    """
    Makes python-oracledb be in Thin mode. After this method is called, Thick
    mode cannot be enabled. If python-oracledb is already in Thick mode, then
    calling ``enable_thin_mode()`` will fail. If connections have already been
    opened, or a connection pool created, in Thin mode, then calling
    ``enable_thin_mode()`` is a no-op.

    Since python-oracledb defaults to Thin mode, almost all applications do not
    need to call this method. However, because it bypasses python-oracledb's
    internal mode-determination heuristic, it may be useful for applications
    that are using standalone connections in multiple threads to concurrently
    create connections when the application starts.
    """
    with driver_mode.get_manager(requested_thin_mode=True):
        pass


def params_initer(f):
    """
    Decorator function which is used on the ConnectParams and PoolParams
    classes. It creates the implementation object using the implementation
    class stored on the parameter class. It first, however, calls the original
    method to ensure that the keyword parameters supplied are valid (the
    original method itself does nothing).
    """

    def wrapped_f(self, *args, **kwargs):
        f(self, *args, **kwargs)
        self._impl = self._impl_class()
        if kwargs:
            self._impl.set(kwargs)

    return wrapped_f


def params_setter(f):
    """
    Decorator function which is used on the ConnectParams and PoolParams
    classes. It calls the set() method on the parameter implementation object
    with the supplied keyword arguments. It first, however, calls the original
    method to ensure that the keyword parameters supplied are valid (the
    original method itself does nothing).
    """

    def wrapped_f(self, *args, **kwargs):
        f(self, *args, **kwargs)
        self._impl.set(kwargs)

    return wrapped_f


def register_params_hook(hook_function: Callable) -> None:
    """
    Registers a user function to be called internally prior to connection or
    pool creation. The hook function accepts a copy of the parameters that will
    be used to create the pool or standalone connection and may modify them.
    For example, the cloud native authentication plugins modify the
    "access_token" parameter with a function that will acquire the token using
    information found in the "extra_auth_parms" parameter.
    """
    if hook_function is None or not callable(hook_function):
        raise TypeError("hook_function must be a callable and cannot be None")
    base_impl.REGISTERED_PARAMS_HOOKS.append(hook_function)


def register_password_type(
    password_type: str, hook_function: Callable
) -> None:
    """
    Registers a user function to be called when a password is provided as a
    dictionary containing a key "type" with the specified value. The hook
    function is expected to use the dictionary and return the password value.
    If the supplied function is None, the registration is removed.
    """
    if not isinstance(password_type, str):
        raise TypeError("password_type must be a string")
    if hook_function is not None and not callable(hook_function):
        raise TypeError("hook_function must be a callable")
    password_type = password_type.lower()
    if hook_function is None:
        base_impl.REGISTERED_PASSWORD_TYPES.pop(password_type)
    else:
        base_impl.REGISTERED_PASSWORD_TYPES[password_type] = hook_function


def register_protocol(protocol: str, hook_function: Callable) -> None:
    """
    Registers a user function to be called prior to connection or pool creation
    when an Easy Connect connection string prefixed with the specified protocol
    is being parsed internally by python-oracledb in Thin mode. The registered
    function will also be invoked by ConnectParams.parse_connect_string() in
    Thin and Thick modes. Your hook function is expected to find or construct a
    valid connection string. If the supplied function is None, the registration
    is removed.
    """
    if not isinstance(protocol, str):
        raise TypeError("protocol must be a string")
    if hook_function is not None and not callable(hook_function):
        raise TypeError("hook_function must be a callable")
    protocol = protocol.lower()
    if hook_function is None:
        base_impl.REGISTERED_PROTOCOLS.pop(protocol)
    else:
        base_impl.REGISTERED_PROTOCOLS[protocol] = hook_function


def unregister_params_hook(hook_function: Callable) -> None:
    """
    Unregisters a user function that was earlier registered with a call to
    register_params_hook().
    """
    base_impl.REGISTERED_PARAMS_HOOKS.remove(hook_function)


def verify_stored_proc_args(
    parameters: Union[list, tuple], keyword_parameters: dict
) -> None:
    """
    Verifies that the arguments to a call to a stored procedure or function
    are acceptable.
    """
    if parameters is not None and not isinstance(parameters, (list, tuple)):
        errors._raise_err(errors.ERR_ARGS_MUST_BE_LIST_OR_TUPLE)
    if keyword_parameters is not None and not isinstance(
        keyword_parameters, dict
    ):
        errors._raise_err(errors.ERR_KEYWORD_ARGS_MUST_BE_DICT)


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\var.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2021, 2024, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# var.py
#
# Contains the Var class used for managing variables used during bind and
# fetch. These hold the metadata as well as any necessary buffers.
# -----------------------------------------------------------------------------

from typing import Any, Callable, Union
from .dbobject import DbObjectType
from .base_impl import DbType


class Var:
    def __repr__(self):
        value = self._impl.get_all_values()
        if not self._impl.is_array and len(value) == 1:
            value = value[0]
        typ = self._type
        return f"<oracledb.Var of type {typ.name} with value {repr(value)}>"

    @classmethod
    def _from_impl(cls, impl, typ=None):
        var = cls.__new__(cls)
        var._impl = impl
        if typ is not None:
            var._type = typ
        elif impl.metadata.objtype is not None:
            var._type = DbObjectType._from_impl(impl.metadata.objtype)
        else:
            var._type = impl.metadata.dbtype
        return var

    @property
    def actual_elements(self) -> int:
        """
        This read-only attribute returns the actual number of elements in the
        variable. This corresponds to the number of elements in a PL/SQL
        index-by table for variables that are created using the method
        Cursor.arrayvar(). For all other variables this value will be identical
        to the attribute num_elements.
        """
        if self._impl.is_array:
            return self._impl.num_elements_in_array
        return self._impl.num_elements

    @property
    def actualElements(self) -> int:
        """
        Deprecated. Use property actual_elements instead.
        """
        return self.actual_elements

    @property
    def buffer_size(self) -> int:
        """
        This read-only attribute returns the size of the buffer allocated for
        each element in bytes.
        """
        return self._impl.metadata.buffer_size

    @property
    def bufferSize(self) -> int:
        """
        Deprecated. Use property buffer_size intead().
        """
        return self.buffer_size

    @property
    def convert_nulls(self) -> bool:
        """
        This read-only attribute returns whether null values are converted
        using the supplied ``outconverter``.
        """
        return self._impl.convert_nulls

    def getvalue(self, pos: int = 0) -> Any:
        """
        Return the value at the given position in the variable. For variables
        created using the method Cursor.arrayvar() the value returned will be a
        list of each of the values in the PL/SQL index-by table. For variables
        bound to DML returning statements, the value returned will also be a
        list corresponding to the returned data for the given execution of the
        statement (as identified by the pos parameter).
        """
        return self._impl.get_value(pos)

    @property
    def inconverter(self) -> Callable:
        """
        This read-only attribute specifies the method used to convert data from
        Python to the Oracle database. The method signature is converter(value)
        and the expected return value is the value to bind to the database. If
        this attribute is None, the value is bound directly without any
        conversion.
        """
        return self._impl.inconverter

    @property
    def num_elements(self) -> int:
        """
        This read-only attribute returns the number of elements allocated in an
        array, or the number of scalar items that can be fetched into the
        variable or bound to the variable.
        """
        return self._impl.num_elements

    @property
    def numElements(self) -> int:
        """
        Deprecated. Use property num_elements instead.
        """
        return self.num_elements

    @property
    def outconverter(self) -> Callable:
        """
        This read-only attribute specifies the method used to convert data from
        the Oracle database to Python. The method signature is converter(value)
        and the expected return value is the value to return to Python. If this
        attribute is None, the value is returned directly without any
        conversion.
        """
        return self._impl.outconverter

    def setvalue(self, pos: int, value: Any) -> None:
        """
        Set the value at the given position in the variable.
        """
        self._impl.set_value(pos, value)

    @property
    def size(self) -> int:
        """
        This read-only attribute returns the size of the variable. For strings
        this value is the size in characters. For all others, this is same
        value as the attribute buffer_size.
        """
        return self._impl.metadata.max_size

    @property
    def type(self) -> Union[DbType, DbObjectType]:
        """
        This read-only attribute returns the type of the variable. This will be
        an Oracle Object Type if the variable binds Oracle objects; otherwise,
        it will be one of the database type constants.
        """
        return self._type

    @property
    def values(self) -> list:
        """
        This read-only attribute returns a copy of the value of all actual
        positions in the variable as a list. This is the equivalent of calling
        getvalue() for each valid position and the length will correspond to
        the value of the actual_elements attribute.
        """
        return self._impl.get_all_values()


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\version.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2021, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# version.py
#
# Defines the version of the package. This is the only place where this is
# found. The setup.cfg configuration file and the documentation configuration
# file doc/src/conf.py both reference this file directly.
# -----------------------------------------------------------------------------

__version__ = "3.1.0b1"


# ========================================
# Source file: C:\MyProjectsDart\oracledb_dart\python-oracledb\src\oracledb\__init__.py
# ========================================

# -----------------------------------------------------------------------------
# Copyright (c) 2020, 2025, Oracle and/or its affiliates.
#
# This software is dual-licensed to you under the Universal Permissive License
# (UPL) 1.0 as shown at https://oss.oracle.com/licenses/upl and Apache License
# 2.0 as shown at http://www.apache.org/licenses/LICENSE-2.0. You may choose
# either license.
#
# If you elect to accept the software under the Apache License, Version 2.0,
# the following applies:
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#    https://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# -----------------------------------------------------------------------------

# -----------------------------------------------------------------------------
# __init__.py
#
# Package initialization module.
# -----------------------------------------------------------------------------

import collections
import sys
import warnings

if sys.version_info[:2] < (3, 9):
    message = (
        f"Python {sys.version_info[0]}.{sys.version_info[1]} is no longer "
        "supported by the Python core team. Therefore, support for it is "
        "deprecated in python-oracledb and will be removed in a future release"
    )
    warnings.warn(message)

from . import base_impl, thick_impl, thin_impl

from .base_impl import (
    # database types
    DB_TYPE_BFILE as DB_TYPE_BFILE,
    DB_TYPE_BINARY_DOUBLE as DB_TYPE_BINARY_DOUBLE,
    DB_TYPE_BINARY_FLOAT as DB_TYPE_BINARY_FLOAT,
    DB_TYPE_BINARY_INTEGER as DB_TYPE_BINARY_INTEGER,
    DB_TYPE_BLOB as DB_TYPE_BLOB,
    DB_TYPE_BOOLEAN as DB_TYPE_BOOLEAN,
    DB_TYPE_CHAR as DB_TYPE_CHAR,
    DB_TYPE_CLOB as DB_TYPE_CLOB,
    DB_TYPE_CURSOR as DB_TYPE_CURSOR,
    DB_TYPE_DATE as DB_TYPE_DATE,
    DB_TYPE_INTERVAL_DS as DB_TYPE_INTERVAL_DS,
    DB_TYPE_INTERVAL_YM as DB_TYPE_INTERVAL_YM,
    DB_TYPE_JSON as DB_TYPE_JSON,
    DB_TYPE_LONG as DB_TYPE_LONG,
    DB_TYPE_LONG_NVARCHAR as DB_TYPE_LONG_NVARCHAR,
    DB_TYPE_LONG_RAW as DB_TYPE_LONG_RAW,
    DB_TYPE_NCHAR as DB_TYPE_NCHAR,
    DB_TYPE_NCLOB as DB_TYPE_NCLOB,
    DB_TYPE_NUMBER as DB_TYPE_NUMBER,
    DB_TYPE_NVARCHAR as DB_TYPE_NVARCHAR,
    DB_TYPE_OBJECT as DB_TYPE_OBJECT,
    DB_TYPE_RAW as DB_TYPE_RAW,
    DB_TYPE_ROWID as DB_TYPE_ROWID,
    DB_TYPE_TIMESTAMP as DB_TYPE_TIMESTAMP,
    DB_TYPE_TIMESTAMP_LTZ as DB_TYPE_TIMESTAMP_LTZ,
    DB_TYPE_TIMESTAMP_TZ as DB_TYPE_TIMESTAMP_TZ,
    DB_TYPE_UNKNOWN as DB_TYPE_UNKNOWN,
    DB_TYPE_UROWID as DB_TYPE_UROWID,
    DB_TYPE_VARCHAR as DB_TYPE_VARCHAR,
    DB_TYPE_VECTOR as DB_TYPE_VECTOR,
    DB_TYPE_XMLTYPE as DB_TYPE_XMLTYPE,
    # API types
    BINARY as BINARY,
    DATETIME as DATETIME,
    NUMBER as NUMBER,
    ROWID as ROWID,
    STRING as STRING,
)

from .enums import (
    # authentication modes
    AuthMode as AuthMode,
    AUTH_MODE_DEFAULT as AUTH_MODE_DEFAULT,
    AUTH_MODE_PRELIM as AUTH_MODE_PRELIM,
    AUTH_MODE_SYSASM as AUTH_MODE_SYSASM,
    AUTH_MODE_SYSBKP as AUTH_MODE_SYSBKP,
    AUTH_MODE_SYSDBA as AUTH_MODE_SYSDBA,
    AUTH_MODE_SYSDGD as AUTH_MODE_SYSDGD,
    AUTH_MODE_SYSKMT as AUTH_MODE_SYSKMT,
    AUTH_MODE_SYSOPER as AUTH_MODE_SYSOPER,
    AUTH_MODE_SYSRAC as AUTH_MODE_SYSRAC,
    # pipeline operation types
    PipelineOpType as PipelineOpType,
    PIPELINE_OP_TYPE_CALL_FUNC as PIPELINE_OP_TYPE_CALL_FUNC,
    PIPELINE_OP_TYPE_CALL_PROC as PIPELINE_OP_TYPE_CALL_PROC,
    PIPELINE_OP_TYPE_COMMIT as PIPELINE_OP_TYPE_COMMIT,
    PIPELINE_OP_TYPE_EXECUTE as PIPELINE_OP_TYPE_EXECUTE,
    PIPELINE_OP_TYPE_EXECUTE_MANY as PIPELINE_OP_TYPE_EXECUTE_MANY,
    PIPELINE_OP_TYPE_FETCH_ALL as PIPELINE_OP_TYPE_FETCH_ALL,
    PIPELINE_OP_TYPE_FETCH_MANY as PIPELINE_OP_TYPE_FETCH_MANY,
    PIPELINE_OP_TYPE_FETCH_ONE as PIPELINE_OP_TYPE_FETCH_ONE,
    # pool "get" modes
    PoolGetMode as PoolGetMode,
    POOL_GETMODE_WAIT as POOL_GETMODE_WAIT,
    POOL_GETMODE_NOWAIT as POOL_GETMODE_NOWAIT,
    POOL_GETMODE_FORCEGET as POOL_GETMODE_FORCEGET,
    POOL_GETMODE_TIMEDWAIT as POOL_GETMODE_TIMEDWAIT,
    # purity values
    Purity as Purity,
    PURITY_DEFAULT as PURITY_DEFAULT,
    PURITY_NEW as PURITY_NEW,
    PURITY_SELF as PURITY_SELF,
    # vector formats
    VectorFormat as VectorFormat,
    VECTOR_FORMAT_BINARY as VECTOR_FORMAT_BINARY,
    VECTOR_FORMAT_FLOAT32 as VECTOR_FORMAT_FLOAT32,
    VECTOR_FORMAT_FLOAT64 as VECTOR_FORMAT_FLOAT64,
    VECTOR_FORMAT_INT8 as VECTOR_FORMAT_INT8,
)

from .version import __version__ as __version__

from .constants import (
    # mandated DB API constants
    apilevel as apilevel,
    threadsafety as threadsafety,
    paramstyle as paramstyle,
    # AQ delivery modes
    MSG_BUFFERED as MSG_BUFFERED,
    MSG_PERSISTENT as MSG_PERSISTENT,
    MSG_PERSISTENT_OR_BUFFERED as MSG_PERSISTENT_OR_BUFFERED,
    # AQ dequeue modes
    DEQ_BROWSE as DEQ_BROWSE,
    DEQ_LOCKED as DEQ_LOCKED,
    DEQ_REMOVE as DEQ_REMOVE,
    DEQ_REMOVE_NODATA as DEQ_REMOVE_NODATA,
    # AQ dequeue navigation modes
    DEQ_FIRST_MSG as DEQ_FIRST_MSG,
    DEQ_NEXT_MSG as DEQ_NEXT_MSG,
    DEQ_NEXT_TRANSACTION as DEQ_NEXT_TRANSACTION,
    # AQ dequeue visibility modes
    DEQ_IMMEDIATE as DEQ_IMMEDIATE,
    DEQ_ON_COMMIT as DEQ_ON_COMMIT,
    # AQ dequeue wait modes
    DEQ_NO_WAIT as DEQ_NO_WAIT,
    DEQ_WAIT_FOREVER as DEQ_WAIT_FOREVER,
    # AQ enqueue visibility modes
    ENQ_IMMEDIATE as ENQ_IMMEDIATE,
    ENQ_ON_COMMIT as ENQ_ON_COMMIT,
    # AQ message states
    MSG_EXPIRED as MSG_EXPIRED,
    MSG_PROCESSED as MSG_PROCESSED,
    MSG_READY as MSG_READY,
    MSG_WAITING as MSG_WAITING,
    # AQ other constants
    MSG_NO_DELAY as MSG_NO_DELAY,
    MSG_NO_EXPIRATION as MSG_NO_EXPIRATION,
    # shutdown modes
    DBSHUTDOWN_ABORT as DBSHUTDOWN_ABORT,
    DBSHUTDOWN_FINAL as DBSHUTDOWN_FINAL,
    DBSHUTDOWN_IMMEDIATE as DBSHUTDOWN_IMMEDIATE,
    DBSHUTDOWN_TRANSACTIONAL as DBSHUTDOWN_TRANSACTIONAL,
    DBSHUTDOWN_TRANSACTIONAL_LOCAL as DBSHUTDOWN_TRANSACTIONAL_LOCAL,
    # subscription grouping classes
    SUBSCR_GROUPING_CLASS_NONE as SUBSCR_GROUPING_CLASS_NONE,
    SUBSCR_GROUPING_CLASS_TIME as SUBSCR_GROUPING_CLASS_TIME,
    # subscription grouping types
    SUBSCR_GROUPING_TYPE_SUMMARY as SUBSCR_GROUPING_TYPE_SUMMARY,
    SUBSCR_GROUPING_TYPE_LAST as SUBSCR_GROUPING_TYPE_LAST,
    # subscription namespaces
    SUBSCR_NAMESPACE_AQ as SUBSCR_NAMESPACE_AQ,
    SUBSCR_NAMESPACE_DBCHANGE as SUBSCR_NAMESPACE_DBCHANGE,
    # subscription protocols
    SUBSCR_PROTO_HTTP as SUBSCR_PROTO_HTTP,
    SUBSCR_PROTO_MAIL as SUBSCR_PROTO_MAIL,
    SUBSCR_PROTO_CALLBACK as SUBSCR_PROTO_CALLBACK,
    SUBSCR_PROTO_SERVER as SUBSCR_PROTO_SERVER,
    # subscription quality of service
    SUBSCR_QOS_BEST_EFFORT as SUBSCR_QOS_BEST_EFFORT,
    SUBSCR_QOS_DEFAULT as SUBSCR_QOS_DEFAULT,
    SUBSCR_QOS_DEREG_NFY as SUBSCR_QOS_DEREG_NFY,
    SUBSCR_QOS_QUERY as SUBSCR_QOS_QUERY,
    SUBSCR_QOS_RELIABLE as SUBSCR_QOS_RELIABLE,
    SUBSCR_QOS_ROWIDS as SUBSCR_QOS_ROWIDS,
    # event types
    EVENT_AQ as EVENT_AQ,
    EVENT_DEREG as EVENT_DEREG,
    EVENT_NONE as EVENT_NONE,
    EVENT_OBJCHANGE as EVENT_OBJCHANGE,
    EVENT_QUERYCHANGE as EVENT_QUERYCHANGE,
    EVENT_SHUTDOWN as EVENT_SHUTDOWN,
    EVENT_SHUTDOWN_ANY as EVENT_SHUTDOWN_ANY,
    EVENT_STARTUP as EVENT_STARTUP,
    # operation codes
    OPCODE_ALLOPS as OPCODE_ALLOPS,
    OPCODE_ALLROWS as OPCODE_ALLROWS,
    OPCODE_ALTER as OPCODE_ALTER,
    OPCODE_DELETE as OPCODE_DELETE,
    OPCODE_DROP as OPCODE_DROP,
    OPCODE_INSERT as OPCODE_INSERT,
    OPCODE_UPDATE as OPCODE_UPDATE,
    # flags for tpc_begin()
    TPC_BEGIN_JOIN as TPC_BEGIN_JOIN,
    TPC_BEGIN_NEW as TPC_BEGIN_NEW,
    TPC_BEGIN_PROMOTE as TPC_BEGIN_PROMOTE,
    TPC_BEGIN_RESUME as TPC_BEGIN_RESUME,
    # flags for tpc_end()
    TPC_END_NORMAL as TPC_END_NORMAL,
    TPC_END_SUSPEND as TPC_END_SUSPEND,
)

from .exceptions import (
    Warning as Warning,
    Error as Error,
    DatabaseError as DatabaseError,
    DataError as DataError,
    IntegrityError as IntegrityError,
    InterfaceError as InterfaceError,
    InternalError as InternalError,
    NotSupportedError as NotSupportedError,
    OperationalError as OperationalError,
    ProgrammingError as ProgrammingError,
)

from .errors import _Error as _Error

from .defaults import defaults as defaults

from .pipeline import (
    Pipeline as Pipeline,
    PipelineOp as PipelineOp,
    PipelineOpResult as PipelineOpResult,
    create_pipeline as create_pipeline,
)

from .connection import (
    AsyncConnection as AsyncConnection,
    connect as connect,
    connect_async as connect_async,
    Connection as Connection,
)

from .cursor import (
    AsyncCursor as AsyncCursor,
    Cursor as Cursor,
)

from .pool import (
    AsyncConnectionPool as AsyncConnectionPool,
    ConnectionPool as ConnectionPool,
    create_pool as create_pool,
    create_pool_async as create_pool_async,
    get_pool as get_pool,
)

from .subscr import (
    Message as Message,
    MessageQuery as MessageQuery,
    MessageRow as MessageRow,
    MessageTable as MessageTable,
)

from .connect_params import ConnectParams as ConnectParams

from .pool_params import PoolParams as PoolParams

from .lob import (
    LOB as LOB,
    AsyncLOB as AsyncLOB,
)

from .dbobject import DbObject as DbObject, DbObjectType as DbObjectType

from .fetch_info import FetchInfo as FetchInfo

from .var import Var as Var

from .dsn import makedsn as makedsn

from .driver_mode import is_thin_mode as is_thin_mode

from .utils import (
    enable_thin_mode as enable_thin_mode,
    register_params_hook as register_params_hook,
    register_password_type as register_password_type,
    register_protocol as register_protocol,
    unregister_params_hook as unregister_params_hook,
)

from .thick_impl import (
    clientversion as clientversion,
    init_oracle_client as init_oracle_client,
)

from .constructors import (
    Binary as Binary,
    Date as Date,
    DateFromTicks as DateFromTicks,
    Time as Time,
    TimeFromTicks as TimeFromTicks,
    Timestamp as Timestamp,
    TimestampFromTicks as TimestampFromTicks,
)

from .future import (
    future as __future__,  # noqa: F401
)

from .sparse_vector import (
    SparseVector as SparseVector,
)

from .interchange.dataframe import (
    OracleDataFrame as OracleDataFrame,
)

from . import builtin_hooks

IntervalYM = collections.namedtuple("IntervalYM", ["years", "months"])


class JsonId(bytes):
    pass


package = sys.modules[__name__]
base_impl.init_base_impl(package)
thick_impl.init_thick_impl(package)
thin_impl.init_thin_impl(package)
del package

# remove unnecessary symbols
del (
    aq,  # noqa
    base_impl,  # noqa
    builtin_hooks,  # noqa
    connect_params,  # noqa
    connection,  # noqa
    constants,  # noqa
    constructors,  # noqa
    cursor,  # noqa
    dbobject,  # noqa
    driver_mode,  # noqa
    dsn,  # noqa
    errors,  # noqa
    exceptions,  # noqa
    fetch_info,  # noqa
    future,  # noqa
    lob,  # noqa
    pool,  # noqa
    pool_params,  # noqa
    sparse_vector,  # noqa
    soda,  # noqa
    subscr,  # noqa
    sys,  # noqa
    thick_impl,  # noqa
    thin_impl,  # noqa
    utils,  # noqa
    var,  # noqa
    warnings,  # noqa
)

# general aliases (for backwards compatibility)
ObjectType = DbObjectType
Object = DbObject
SessionPool = ConnectionPool
version = __version__

# aliases for database types (for backwards compatibility)
BFILE = DB_TYPE_BFILE
BLOB = DB_TYPE_BLOB
BOOLEAN = DB_TYPE_BOOLEAN
CLOB = DB_TYPE_CLOB
CURSOR = DB_TYPE_CURSOR
FIXED_CHAR = DB_TYPE_CHAR
FIXED_NCHAR = DB_TYPE_NCHAR
INTERVAL = DB_TYPE_INTERVAL_DS
LONG_BINARY = DB_TYPE_LONG_RAW
LONG_STRING = DB_TYPE_LONG
NATIVE_INT = DB_TYPE_BINARY_INTEGER
NATIVE_FLOAT = DB_TYPE_BINARY_DOUBLE
NCHAR = DB_TYPE_NVARCHAR
OBJECT = DB_TYPE_OBJECT
NCLOB = DB_TYPE_NCLOB
TIMESTAMP = DB_TYPE_TIMESTAMP

# aliases for authentication modes (for backwards compatibility)
DEFAULT_AUTH = AUTH_MODE_DEFAULT
SYSASM = AUTH_MODE_SYSASM
SYSBKP = AUTH_MODE_SYSBKP
SYSDBA = AUTH_MODE_SYSDBA
SYSDGD = AUTH_MODE_SYSDGD
SYSKMT = AUTH_MODE_SYSKMT
SYSOPER = AUTH_MODE_SYSOPER
SYSRAC = AUTH_MODE_SYSRAC
PRELIM_AUTH = AUTH_MODE_PRELIM

# aliases for pool "get" modes (for backwards compatibility)
SPOOL_ATTRVAL_WAIT = POOL_GETMODE_WAIT
SPOOL_ATTRVAL_NOWAIT = POOL_GETMODE_NOWAIT
SPOOL_ATTRVAL_FORCEGET = POOL_GETMODE_FORCEGET
SPOOL_ATTRVAL_TIMEDWAIT = POOL_GETMODE_TIMEDWAIT

# aliases for purity (for backwards compatibility)
ATTR_PURITY_DEFAULT = PURITY_DEFAULT
ATTR_PURITY_NEW = PURITY_NEW
ATTR_PURITY_SELF = PURITY_SELF

# aliases for subscription protocols (for backwards compatibility)
SUBSCR_PROTO_OCI = SUBSCR_PROTO_CALLBACK
